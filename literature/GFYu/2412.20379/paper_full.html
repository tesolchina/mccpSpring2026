<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism</title>
<!--Generated on Fri Dec 27 06:32:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2412.20379v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S1" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and Motivation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2.SS1" title="In 2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Graph Neural Networks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2.SS2" title="In 2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Distributed GNN Training with Data Parallelism</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2.SS3" title="In 2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Opportunity: Tensor Parallelism</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S3" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>GNN Tensor Parallelism</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S3.SS1" title="In 3. GNN Tensor Parallelism â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>GNN Tensor Parallelism Workflow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S3.SS2" title="In 3. GNN Tensor Parallelism â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Workload Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S3.SS3" title="In 3. GNN Tensor Parallelism â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Challenges</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>The NeutronTP</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS1" title="In 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Generalized Decoupled Training Method</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS1.SSS1" title="In 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Decoupled GNN Training Approaches</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS1.SSS2" title="In 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Decoupled GNN Tensor Parallelism</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS1.SSS3" title="In 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Convergence Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS2" title="In 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Memory-efficient Task Scheduling Strategy</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS2.SSS1" title="In 4.2. Memory-efficient Task Scheduling Strategy â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Chunk-based task Scheduling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS2.SSS2" title="In 4.2. Memory-efficient Task Scheduling Strategy â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Inter-chunk Pipelining</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.SS3" title="In 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Overall Execution Flow in NeutronTP</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS1" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS2" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Overall Comparison</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS3" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Computation and Communication Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS4" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Performance Gain Analysis of NeutronTP</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS5" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Scalability Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS6" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.6 </span>GPU Utilization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS7" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.7 </span>Accuracy Comparisons</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS8" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.8 </span><span class="ltx_text" style="color:#000000;">Extension to heterogeneous graphs</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.SS9" title="In 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.9 </span><span class="ltx_text" style="color:#000000;">Training cost breakdown</span></span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S6" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S7" title="In NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xin Ai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id4.1.id1.1">China</span>
<br class="ltx_break"/>aixin0@
<br class="ltx_break"/>stumail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hao Yuan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id5.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id5.1.id1.1">China</span>
<br class="ltx_break"/>yuanhao@
<br class="ltx_break"/>stumail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zeyu Ling
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id6.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id6.1.id1.1">China</span>
<br class="ltx_break"/>lingzeyu@
<br class="ltx_break"/>stumail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qiange Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">National University of Singapore<span class="ltx_text ltx_affiliation_country" id="id7.1.id1.1">Singapore</span>
<br class="ltx_break"/>wang.qg@nus.edu.sg</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yanfeng Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id8.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id8.1.id1.1">China</span>
<br class="ltx_break"/>zhangyf@
<br class="ltx_break"/>mail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhenbo Fu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id9.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id9.1.id1.1">China</span>
<br class="ltx_break"/>fuzhenbo@
<br class="ltx_break"/>stumail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chaoyi Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id10.1.id1.1">China</span>
<br class="ltx_break"/>chenchaoy@
<br class="ltx_break"/>stumail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yu Gu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id11.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id11.1.id1.1">China</span>
<br class="ltx_break"/>guyu@
<br class="ltx_break"/>mail.neu.edu.cn</span>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ge Yu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id12.1.id1">Northeastern University<span class="ltx_text ltx_affiliation_country" id="id12.1.id1.1">China</span>
<br class="ltx_break"/>yuge@
<br class="ltx_break"/>mail.neu.edu.cn</span>
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id13.id1">Graph neural networks (GNNs) have emerged as a promising direction. Training large-scale graphs that relies on distributed computing power poses new challenges.
Existing distributed GNN systems leverage data parallelism by partitioning the input graph and distributing it to multiple workers.
However, due to the irregular nature of the graph structure, existing distributed approaches suffer from unbalanced workloads and high overhead in managing cross-worker vertex dependencies.
</p>
<p class="ltx_p" id="id2.2">In this paper, we leverage tensor parallelism for distributed GNN training. GNN tensor parallelism eliminates cross-worker vertex dependencies by partitioning features instead of graph structures. Different workers are assigned training tasks on different feature slices with the same dimensional size, leading to a complete load balance. We achieve efficient GNN tensor parallelism through two critical functions. Firstly, we employ a generalized decoupled training framework to decouple NN operations from graph aggregation operations, significantly reducing the communication overhead caused by NN operations which must be computed using complete features. Secondly, we employ a memory-efficient task scheduling strategy to support the training of large graphs exceeding single GPU memory, while further improving performance by overlapping communication and computation. By integrating the above techniques, we propose a distributed GNN training system NeutronTP. Our experimental results on a 16-node Aliyun cluster demonstrate that NeutronTP achieves 1.29<math alttext="\times" class="ltx_Math" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mo id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><times id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">Ã—</annotation></semantics></math>-8.72<math alttext="\times" class="ltx_Math" display="inline" id="id2.2.m2.1"><semantics id="id2.2.m2.1a"><mo id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="id2.2.m2.1b"><times id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.1d">Ã—</annotation></semantics></math> speedup over state-of-the-art GNN systems including DistDGL, NeutronStar, and Sancus.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1" style="font-size:90%;">PVLDB Reference Format:
<br class="ltx_break"/></span><span class="ltx_text" id="p1.1.2" style="font-size:90%;">Xin Ai, Hao Yuan, Zeyu Ling, Qiange Wang, Yanfeng Zhang, Zhenbo Fu, Chaoyi Chen, Yu Gu, Ge Yu.  PVLDB, 18(2): 173 - 186, 2024.</span>
<br class="ltx_break"/><a class="ltx_ref ltx_href" href="https://doi.org/10.14778/3705829.3705837" style="font-size:90%;" title="">doi:10.14778/3705829.3705837</a><span class="ltx_text" id="p1.1.3" style="font-size:90%;">
</span><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup>This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" title="">https://creativecommons.org/licenses/by-nc-nd/4.0/</a> to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing <a class="ltx_ref ltx_href" href="mailto:info@vldb.org" title="">info@vldb.org</a>. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. 
<br class="ltx_break"/>Proceedings of the VLDB Endowment, Vol. 18, No. 2Â ISSN 2150-8097. 
<br class="ltx_break"/><a class="ltx_ref ltx_href" href="https://doi.org/10.14778/3705829.3705837" title="">doi:10.14778/3705829.3705837</a>
<br class="ltx_break"/></span></span></span></p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<p class="ltx_p" id="p2.1"><span class="ltx_text ltx_font_bold" id="p2.1.1" style="font-size:90%;">PVLDB Artifact Availability:
<br class="ltx_break"/></span><span class="ltx_text" id="p2.1.2" style="font-size:90%;">The source code, data, and/or other artifacts have been made available at </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="%leave%20empty%20if%20no%20availability%20url%20should%20be%20sethttps://github.com/AiX-im/NeutronTP" style="font-size:90%;" title="">%leaveâ£emptyâ£ifâ£noâ£availabilityâ£urlâ£shouldâ£beâ£sethttps://github.com/AiX-im/NeutronTP</a><span class="ltx_text" id="p2.1.3" style="font-size:90%;">.
</span><span class="ltx_text" id="p2.1.4"></span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="127" id="S1.F1.g1" src="x1.png" width="318"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Illustration of a single-layer computation process in a GNN model, including graph aggregation operations and neural network (NN) operations.</figcaption>
</figure>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness in machine learning tasks <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib46" title="">2019</a>; Yao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib49" title="">2019</a>; Ying etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib50" title="">2018</a>; Fan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib10" title="">2019</a>)</cite>.
Graph-structured data serves as the input for GNNs, where each vertex is associated with a high-dimensional feature vector.
The expressive power of GNNs stems from their ability to learn from relationships between data samples, whereas traditional DNNs are trained on individual samples <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib58" title="">2020</a>)</cite>. Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S1.F1" title="Figure 1 â€£ 1. Introduction â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates the computational process of GNNs, involving graph aggregation and neural network (NN) operations. In each GNN layer, obtaining a vertexâ€™s new embedding entails aggregating its neighborsâ€™ embeddings from the previous layer (or neighborsâ€™ features at layer 0) and then applying NN operations. By iteratively performing these two steps, the GNN model can capture structural information from multi-hop neighbors.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recently, full-graph GNN training, which involves training on the entire graph, has emerged as a promising GNN training method for its effectiveness brought by full-neighbor aggregation semantics and full-batch gradient descent <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>; Md etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib26" title="">2021</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>)</cite>. Given the massive scale of graphs generated from applications, large-scale parallel and distributed computing becomes imperative for handling GNNs effectively <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib22" title="">2023</a>; Shao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib33" title="">2022</a>; Yuan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib51" title="">2023</a>)</cite>. A common approach to scaling GNN training on large-scale graph data is data parallelism, where the graph data is partitioned across different workers for parallel training <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib59" title="">2019</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>; Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>; Md etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib26" title="">2021</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib52" title="">2020</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib39" title="">2022a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>; Tripathy etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib37" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Despite that partitioning graph data enables distributed GNN systems to handle large-scale data, it also constitutes a primary constraint on the performance of GNN data parallelism. Firstly, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S1.F2" title="Figure 2 â€£ 1. Introduction â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">2</span></a> (a), the irregular nature of graph data makes it challenging to ensure load balance when partitioning the workload. Many survey papers <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib22" title="">2023</a>; Shao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib33" title="">2022</a>; Yuan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib51" title="">2023</a>)</cite> highlight workload imbalance as a primary challenge, both in mini-batch and full-graph training. Secondly, the edges among data samples (i.e., vertices) lead to complex cross-worker vertex dependencies since graph aggregation may require neighbor data located on remote workers <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite>.
Existing systems adopt methods such as cross-worker neighbor replication <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib59" title="">2019</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib52" title="">2020</a>; Gandhi and Iyer, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib12" title="">2021</a>)</cite> and neighbor communication <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib39" title="">2022a</a>; Md etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib26" title="">2021</a>)</cite> to manage vertex dependencies. As a result, the efficiency of GNN data parallelism is constrained by redundant computations and substantial communication overhead <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>; Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we leverage tensor parallelism for distributed GNN training, eliminating cross-worker vertex dependencies by partitioning features instead of the graph structure. GNN tensor parallelism efficiently balances workload by evenly partitioning vertex features along dimensions. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S1.F2" title="Figure 2 â€£ 1. Introduction â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">2</span></a> (b), GNN tensor parallelism divides vertex features according to the number of workers. Different workers are responsible for GNN training with feature slices of the same dimension, achieving complete computational load balance. GNN tensor parallelism involves two communication operations: <span class="ltx_text ltx_font_typewriter" id="S1.p4.1.1">gather</span> and <span class="ltx_text ltx_font_typewriter" id="S1.p4.1.2">split</span>. They collect complete embeddings for NN operations at each model layer, as NN operations include some non-linear operations that cannot be partially computed, and then redistribute the embedding slices back to the corresponding workers. These two communication operations involve all vertices. We only need to ensure that each worker handles the communication task of the same number of vertices to achieve load-balanced communication.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We further enhance the efficiency of GNN tensor parallelism by optimizing communication and memory overhead. Firstly, we employ a generalized decoupled training approach to reduce communication overhead, avoiding frequent execution of two communication operations in each model layer.
Inspired by existing decoupled GNN training methods <cite class="ltx_cite ltx_citemacro_citep">(Bojchevski etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib5" title="">2020</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib57" title="">2023</a>)</cite>, we decouple NN operations from graph aggregation operations, confining <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.1">split</span> and <span class="ltx_text ltx_font_typewriter" id="S1.p5.1.2">gather</span> operations to occur before and after consecutive graph operations, significantly reducing communication overhead.
Additionally, we support decoupled training of complex models <cite class="ltx_cite ltx_citemacro_citep">(Velickovic etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib38" title="">2018</a>)</cite> through the precomputation of edge attention, providing generalized support for decoupled training.
Secondly, we employ a memory-efficient task scheduling strategy to reduce memory overhead, mitigating out-of-memory errors caused by loading the entire graph topology during training. This strategy offers a lightweight subgraph logical partitioning method and further enhances performance by overlapping the computation and communication of different subgraphs.</p>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="478" id="S1.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>GNN data parallelism vs. GNN tensor parallelism. The thickness of the arrows and the size of the circles are positively proportional to the feature/embedding dimension and indicate the computation volume of GNN training.</figcaption>
</figure>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">By integrating the above techniques, we propose NeutronTP, a distributed GNN training system that achieves a well-balanced workload. We make the following contributions in this paper.</p>
</div>
<div class="ltx_para" id="S1.p7">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a distributed GNN training method based on tensor parallelism, which eliminates cross-worker vertex dependencies and achieves complete load balancing.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a generalized decoupling training method to separate NN operations from graph aggregation, significantly reducing communication frequency in GNN tensor parallelism.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We propose a memory-efficient task scheduling strategy to support large-scale graph processing and overlap the communication and computation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">We develop NeutronTP, a distributed system for full-graph GNN training that utilizes tensor parallelism to achieve fully balanced workloads and integrates a series of optimizations to achieve high performance.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.7">We evaluate NeutronTP on a 16-node Aliyun GPU cluster. The experimental results show that NeutronTP outperforms the state-of-the-art GNN systems on homogeneous graphs, achieving 1.29<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.1.m1.1"><semantics id="S1.p8.1.m1.1a"><mo id="S1.p8.1.m1.1.1" xref="S1.p8.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.1.m1.1b"><times id="S1.p8.1.m1.1.1.cmml" xref="S1.p8.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.1.m1.1d">Ã—</annotation></semantics></math>-6.36<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.2.m2.1"><semantics id="S1.p8.2.m2.1a"><mo id="S1.p8.2.m2.1.1" xref="S1.p8.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.2.m2.1b"><times id="S1.p8.2.m2.1.1.cmml" xref="S1.p8.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.2.m2.1d">Ã—</annotation></semantics></math> speedups over DistDGL <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>, 4.68<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.3.m3.1"><semantics id="S1.p8.3.m3.1a"><mo id="S1.p8.3.m3.1.1" xref="S1.p8.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.3.m3.1b"><times id="S1.p8.3.m3.1.1.cmml" xref="S1.p8.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.3.m3.1d">Ã—</annotation></semantics></math>-8.72<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.4.m4.1"><semantics id="S1.p8.4.m4.1a"><mo id="S1.p8.4.m4.1.1" xref="S1.p8.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.4.m4.1b"><times id="S1.p8.4.m4.1.1.cmml" xref="S1.p8.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.4.m4.1d">Ã—</annotation></semantics></math> speedups over NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite>, and 3.41<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.5.m5.1"><semantics id="S1.p8.5.m5.1a"><mo id="S1.p8.5.m5.1.1" xref="S1.p8.5.m5.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.5.m5.1b"><times id="S1.p8.5.m5.1.1.cmml" xref="S1.p8.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.5.m5.1d">Ã—</annotation></semantics></math>-4.81<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.6.m6.1"><semantics id="S1.p8.6.m6.1a"><mo id="S1.p8.6.m6.1.1" xref="S1.p8.6.m6.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.6.m6.1b"><times id="S1.p8.6.m6.1.1.cmml" xref="S1.p8.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.6.m6.1d">Ã—</annotation></semantics></math> speedups over SANCUS <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>)</cite>. Additionally, NeutronTP achieves 6.15<math alttext="\times" class="ltx_Math" display="inline" id="S1.p8.7.m7.1"><semantics id="S1.p8.7.m7.1a"><mo id="S1.p8.7.m7.1.1" xref="S1.p8.7.m7.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S1.p8.7.m7.1b"><times id="S1.p8.7.m7.1.1.cmml" xref="S1.p8.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p8.7.m7.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p8.7.m7.1d">Ã—</annotation></semantics></math> speedups over DistDGLv2 <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib56" title="">2022b</a>)</cite> on heterogeneous graphs.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">The rest of this work is organized as follows. Section <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2" title="2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">2</span></a> describes the background and motivations. Section <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S3" title="3. GNN Tensor Parallelism â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">3</span></a> provides a detailed description of the proposed GNN tensor parallelism. Section 4 gives an overview of NeutronTP and describes the generalized decoupling training method and the memory-efficient task scheduling strategy.
Section <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5" title="5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">5</span></a> presents results. Section <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S6" title="6. Related work â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">6</span></a> presents a discussion on related work. Section <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S7" title="7. Conclusion â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">7</span></a> concludes the paper.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Background and Motivation</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Graph Neural Networks</h3>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.6">Graph-structured data is input to GNNs, with each vertex having a high-dimensional feature vector.
A typical GNN computes low-dimensional embeddings for vertices through multiple layers, aiding tasks like node classification and link prediction.
Each layer includes an aggregation and an update phase <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib58" title="">2020</a>)</cite>.
In a GNN with <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_L</annotation></semantics></math> layers, during layer <math alttext="l" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">l</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_l</annotation></semantics></math>â€™s aggregation phase, each vertex <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_v</annotation></semantics></math> aggregates its neighborsâ€™ embeddings from layer <math alttext="l-1" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml">l</mi><mo id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">âˆ’</mo><mn id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><minus id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"></minus><ci id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2">ğ‘™</ci><cn id="S2.SS1.p1.4.m4.1.1.3.cmml" type="integer" xref="S2.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">l-1</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_l - 1</annotation></semantics></math> and its own to produce <math alttext="a_{v}^{l}" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><msubsup id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi id="S2.SS1.p1.5.m5.1.1.2.2" xref="S2.SS1.p1.5.m5.1.1.2.2.cmml">a</mi><mi id="S2.SS1.p1.5.m5.1.1.2.3" xref="S2.SS1.p1.5.m5.1.1.2.3.cmml">v</mi><mi id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">superscript</csymbol><apply id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.2.1.cmml" xref="S2.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.2.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2.2">ğ‘</ci><ci id="S2.SS1.p1.5.m5.1.1.2.3.cmml" xref="S2.SS1.p1.5.m5.1.1.2.3">ğ‘£</ci></apply><ci id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">a_{v}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> using an <math alttext="AGG" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.1"><semantics id="S2.SS1.p1.6.m6.1a"><mrow id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml"><mi id="S2.SS1.p1.6.m6.1.1.2" xref="S2.SS1.p1.6.m6.1.1.2.cmml">A</mi><mo id="S2.SS1.p1.6.m6.1.1.1" xref="S2.SS1.p1.6.m6.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.6.m6.1.1.3" xref="S2.SS1.p1.6.m6.1.1.3.cmml">G</mi><mo id="S2.SS1.p1.6.m6.1.1.1a" xref="S2.SS1.p1.6.m6.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.6.m6.1.1.4" xref="S2.SS1.p1.6.m6.1.1.4.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><apply id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1"><times id="S2.SS1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1.1"></times><ci id="S2.SS1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.p1.6.m6.1.1.2">ğ´</ci><ci id="S2.SS1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.p1.6.m6.1.1.3">ğº</ci><ci id="S2.SS1.p1.6.m6.1.1.4.cmml" xref="S2.SS1.p1.6.m6.1.1.4">ğº</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">AGG</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.1d">italic_A italic_G italic_G</annotation></semantics></math> function:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx1">
<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle a_{v}^{l}" class="ltx_Math" display="inline" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><msubsup id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><mi id="S2.E1.m1.1.1.2.2" xref="S2.E1.m1.1.1.2.2.cmml">a</mi><mi id="S2.E1.m1.1.1.2.3" xref="S2.E1.m1.1.1.2.3.cmml">v</mi><mi id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1">superscript</csymbol><apply id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.2.1.cmml" xref="S2.E1.m1.1.1">subscript</csymbol><ci id="S2.E1.m1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.2.2">ğ‘</ci><ci id="S2.E1.m1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.2.3">ğ‘£</ci></apply><ci id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\displaystyle a_{v}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=AGG(h_{u}^{l-1}|\forall{u}\in{N_{in}(v)}\cup\{v\})" class="ltx_Math" display="inline" id="S2.E1.m2.3"><semantics id="S2.E1.m2.3a"><mrow id="S2.E1.m2.3.3" xref="S2.E1.m2.3.3.cmml"><mi id="S2.E1.m2.3.3.3" xref="S2.E1.m2.3.3.3.cmml"></mi><mo id="S2.E1.m2.3.3.2" xref="S2.E1.m2.3.3.2.cmml">=</mo><mrow id="S2.E1.m2.3.3.1" xref="S2.E1.m2.3.3.1.cmml"><mi id="S2.E1.m2.3.3.1.3" xref="S2.E1.m2.3.3.1.3.cmml">A</mi><mo id="S2.E1.m2.3.3.1.2" xref="S2.E1.m2.3.3.1.2.cmml">â¢</mo><mi id="S2.E1.m2.3.3.1.4" xref="S2.E1.m2.3.3.1.4.cmml">G</mi><mo id="S2.E1.m2.3.3.1.2a" xref="S2.E1.m2.3.3.1.2.cmml">â¢</mo><mi id="S2.E1.m2.3.3.1.5" xref="S2.E1.m2.3.3.1.5.cmml">G</mi><mo id="S2.E1.m2.3.3.1.2b" xref="S2.E1.m2.3.3.1.2.cmml">â¢</mo><mrow id="S2.E1.m2.3.3.1.1.1" xref="S2.E1.m2.3.3.1.1.1.1.cmml"><mo id="S2.E1.m2.3.3.1.1.1.2" stretchy="false" xref="S2.E1.m2.3.3.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m2.3.3.1.1.1.1" xref="S2.E1.m2.3.3.1.1.1.1.cmml"><mrow id="S2.E1.m2.3.3.1.1.1.1.2" xref="S2.E1.m2.3.3.1.1.1.1.2.cmml"><msubsup id="S2.E1.m2.3.3.1.1.1.1.2.2" xref="S2.E1.m2.3.3.1.1.1.1.2.2.cmml"><mi id="S2.E1.m2.3.3.1.1.1.1.2.2.2.2" xref="S2.E1.m2.3.3.1.1.1.1.2.2.2.2.cmml">h</mi><mi id="S2.E1.m2.3.3.1.1.1.1.2.2.2.3" xref="S2.E1.m2.3.3.1.1.1.1.2.2.2.3.cmml">u</mi><mrow id="S2.E1.m2.3.3.1.1.1.1.2.2.3" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.cmml"><mi id="S2.E1.m2.3.3.1.1.1.1.2.2.3.2" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.2.cmml">l</mi><mo id="S2.E1.m2.3.3.1.1.1.1.2.2.3.1" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.1.cmml">âˆ’</mo><mn id="S2.E1.m2.3.3.1.1.1.1.2.2.3.3" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo fence="false" id="S2.E1.m2.3.3.1.1.1.1.2.1" xref="S2.E1.m2.3.3.1.1.1.1.2.1.cmml">|</mo><mrow id="S2.E1.m2.3.3.1.1.1.1.2.3" xref="S2.E1.m2.3.3.1.1.1.1.2.3.cmml"><mo id="S2.E1.m2.3.3.1.1.1.1.2.3.1" rspace="0.167em" xref="S2.E1.m2.3.3.1.1.1.1.2.3.1.cmml">âˆ€</mo><mi id="S2.E1.m2.3.3.1.1.1.1.2.3.2" xref="S2.E1.m2.3.3.1.1.1.1.2.3.2.cmml">u</mi></mrow></mrow><mo id="S2.E1.m2.3.3.1.1.1.1.1" xref="S2.E1.m2.3.3.1.1.1.1.1.cmml">âˆˆ</mo><mrow id="S2.E1.m2.3.3.1.1.1.1.3" xref="S2.E1.m2.3.3.1.1.1.1.3.cmml"><mrow id="S2.E1.m2.3.3.1.1.1.1.3.2" xref="S2.E1.m2.3.3.1.1.1.1.3.2.cmml"><msub id="S2.E1.m2.3.3.1.1.1.1.3.2.2" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.cmml"><mi id="S2.E1.m2.3.3.1.1.1.1.3.2.2.2" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.2.cmml">N</mi><mrow id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.cmml"><mi id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.2" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.2.cmml">i</mi><mo id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.1" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.1.cmml">â¢</mo><mi id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.3" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.3.cmml">n</mi></mrow></msub><mo id="S2.E1.m2.3.3.1.1.1.1.3.2.1" xref="S2.E1.m2.3.3.1.1.1.1.3.2.1.cmml">â¢</mo><mrow id="S2.E1.m2.3.3.1.1.1.1.3.2.3.2" xref="S2.E1.m2.3.3.1.1.1.1.3.2.cmml"><mo id="S2.E1.m2.3.3.1.1.1.1.3.2.3.2.1" stretchy="false" xref="S2.E1.m2.3.3.1.1.1.1.3.2.cmml">(</mo><mi id="S2.E1.m2.1.1" xref="S2.E1.m2.1.1.cmml">v</mi><mo id="S2.E1.m2.3.3.1.1.1.1.3.2.3.2.2" stretchy="false" xref="S2.E1.m2.3.3.1.1.1.1.3.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m2.3.3.1.1.1.1.3.1" xref="S2.E1.m2.3.3.1.1.1.1.3.1.cmml">âˆª</mo><mrow id="S2.E1.m2.3.3.1.1.1.1.3.3.2" xref="S2.E1.m2.3.3.1.1.1.1.3.3.1.cmml"><mo id="S2.E1.m2.3.3.1.1.1.1.3.3.2.1" stretchy="false" xref="S2.E1.m2.3.3.1.1.1.1.3.3.1.cmml">{</mo><mi id="S2.E1.m2.2.2" xref="S2.E1.m2.2.2.cmml">v</mi><mo id="S2.E1.m2.3.3.1.1.1.1.3.3.2.2" stretchy="false" xref="S2.E1.m2.3.3.1.1.1.1.3.3.1.cmml">}</mo></mrow></mrow></mrow><mo id="S2.E1.m2.3.3.1.1.1.3" stretchy="false" xref="S2.E1.m2.3.3.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m2.3b"><apply id="S2.E1.m2.3.3.cmml" xref="S2.E1.m2.3.3"><eq id="S2.E1.m2.3.3.2.cmml" xref="S2.E1.m2.3.3.2"></eq><csymbol cd="latexml" id="S2.E1.m2.3.3.3.cmml" xref="S2.E1.m2.3.3.3">absent</csymbol><apply id="S2.E1.m2.3.3.1.cmml" xref="S2.E1.m2.3.3.1"><times id="S2.E1.m2.3.3.1.2.cmml" xref="S2.E1.m2.3.3.1.2"></times><ci id="S2.E1.m2.3.3.1.3.cmml" xref="S2.E1.m2.3.3.1.3">ğ´</ci><ci id="S2.E1.m2.3.3.1.4.cmml" xref="S2.E1.m2.3.3.1.4">ğº</ci><ci id="S2.E1.m2.3.3.1.5.cmml" xref="S2.E1.m2.3.3.1.5">ğº</ci><apply id="S2.E1.m2.3.3.1.1.1.1.cmml" xref="S2.E1.m2.3.3.1.1.1"><in id="S2.E1.m2.3.3.1.1.1.1.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.1"></in><apply id="S2.E1.m2.3.3.1.1.1.1.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2"><csymbol cd="latexml" id="S2.E1.m2.3.3.1.1.1.1.2.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.1">conditional</csymbol><apply id="S2.E1.m2.3.3.1.1.1.1.2.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E1.m2.3.3.1.1.1.1.2.2.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2">superscript</csymbol><apply id="S2.E1.m2.3.3.1.1.1.1.2.2.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.E1.m2.3.3.1.1.1.1.2.2.2.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2">subscript</csymbol><ci id="S2.E1.m2.3.3.1.1.1.1.2.2.2.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2.2.2">â„</ci><ci id="S2.E1.m2.3.3.1.1.1.1.2.2.2.3.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2.2.3">ğ‘¢</ci></apply><apply id="S2.E1.m2.3.3.1.1.1.1.2.2.3.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3"><minus id="S2.E1.m2.3.3.1.1.1.1.2.2.3.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.1"></minus><ci id="S2.E1.m2.3.3.1.1.1.1.2.2.3.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.2">ğ‘™</ci><cn id="S2.E1.m2.3.3.1.1.1.1.2.2.3.3.cmml" type="integer" xref="S2.E1.m2.3.3.1.1.1.1.2.2.3.3">1</cn></apply></apply><apply id="S2.E1.m2.3.3.1.1.1.1.2.3.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.3"><csymbol cd="latexml" id="S2.E1.m2.3.3.1.1.1.1.2.3.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.3.1">for-all</csymbol><ci id="S2.E1.m2.3.3.1.1.1.1.2.3.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.2.3.2">ğ‘¢</ci></apply></apply><apply id="S2.E1.m2.3.3.1.1.1.1.3.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3"><union id="S2.E1.m2.3.3.1.1.1.1.3.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.1"></union><apply id="S2.E1.m2.3.3.1.1.1.1.3.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2"><times id="S2.E1.m2.3.3.1.1.1.1.3.2.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.1"></times><apply id="S2.E1.m2.3.3.1.1.1.1.3.2.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m2.3.3.1.1.1.1.3.2.2.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2">subscript</csymbol><ci id="S2.E1.m2.3.3.1.1.1.1.3.2.2.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.2">ğ‘</ci><apply id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3"><times id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.1"></times><ci id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.2.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.2">ğ‘–</ci><ci id="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.3.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.2.2.3.3">ğ‘›</ci></apply></apply><ci id="S2.E1.m2.1.1.cmml" xref="S2.E1.m2.1.1">ğ‘£</ci></apply><set id="S2.E1.m2.3.3.1.1.1.1.3.3.1.cmml" xref="S2.E1.m2.3.3.1.1.1.1.3.3.2"><ci id="S2.E1.m2.2.2.cmml" xref="S2.E1.m2.2.2">ğ‘£</ci></set></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m2.3c">\displaystyle=AGG(h_{u}^{l-1}|\forall{u}\in{N_{in}(v)}\cup\{v\})</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m2.3d">= italic_A italic_G italic_G ( italic_h start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l - 1 end_POSTSUPERSCRIPT | âˆ€ italic_u âˆˆ italic_N start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ( italic_v ) âˆª { italic_v } )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.16">where <math alttext="{N_{in}(v)}" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m1.1"><semantics id="S2.SS1.p1.7.m1.1a"><mrow id="S2.SS1.p1.7.m1.1.2" xref="S2.SS1.p1.7.m1.1.2.cmml"><msub id="S2.SS1.p1.7.m1.1.2.2" xref="S2.SS1.p1.7.m1.1.2.2.cmml"><mi id="S2.SS1.p1.7.m1.1.2.2.2" xref="S2.SS1.p1.7.m1.1.2.2.2.cmml">N</mi><mrow id="S2.SS1.p1.7.m1.1.2.2.3" xref="S2.SS1.p1.7.m1.1.2.2.3.cmml"><mi id="S2.SS1.p1.7.m1.1.2.2.3.2" xref="S2.SS1.p1.7.m1.1.2.2.3.2.cmml">i</mi><mo id="S2.SS1.p1.7.m1.1.2.2.3.1" xref="S2.SS1.p1.7.m1.1.2.2.3.1.cmml">â¢</mo><mi id="S2.SS1.p1.7.m1.1.2.2.3.3" xref="S2.SS1.p1.7.m1.1.2.2.3.3.cmml">n</mi></mrow></msub><mo id="S2.SS1.p1.7.m1.1.2.1" xref="S2.SS1.p1.7.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SS1.p1.7.m1.1.2.3.2" xref="S2.SS1.p1.7.m1.1.2.cmml"><mo id="S2.SS1.p1.7.m1.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.7.m1.1.2.cmml">(</mo><mi id="S2.SS1.p1.7.m1.1.1" xref="S2.SS1.p1.7.m1.1.1.cmml">v</mi><mo id="S2.SS1.p1.7.m1.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.7.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m1.1b"><apply id="S2.SS1.p1.7.m1.1.2.cmml" xref="S2.SS1.p1.7.m1.1.2"><times id="S2.SS1.p1.7.m1.1.2.1.cmml" xref="S2.SS1.p1.7.m1.1.2.1"></times><apply id="S2.SS1.p1.7.m1.1.2.2.cmml" xref="S2.SS1.p1.7.m1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m1.1.2.2.1.cmml" xref="S2.SS1.p1.7.m1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.7.m1.1.2.2.2.cmml" xref="S2.SS1.p1.7.m1.1.2.2.2">ğ‘</ci><apply id="S2.SS1.p1.7.m1.1.2.2.3.cmml" xref="S2.SS1.p1.7.m1.1.2.2.3"><times id="S2.SS1.p1.7.m1.1.2.2.3.1.cmml" xref="S2.SS1.p1.7.m1.1.2.2.3.1"></times><ci id="S2.SS1.p1.7.m1.1.2.2.3.2.cmml" xref="S2.SS1.p1.7.m1.1.2.2.3.2">ğ‘–</ci><ci id="S2.SS1.p1.7.m1.1.2.2.3.3.cmml" xref="S2.SS1.p1.7.m1.1.2.2.3.3">ğ‘›</ci></apply></apply><ci id="S2.SS1.p1.7.m1.1.1.cmml" xref="S2.SS1.p1.7.m1.1.1">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m1.1c">{N_{in}(v)}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m1.1d">italic_N start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ( italic_v )</annotation></semantics></math> represents the incoming neighbors of vertex <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m2.1"><semantics id="S2.SS1.p1.8.m2.1a"><mi id="S2.SS1.p1.8.m2.1.1" xref="S2.SS1.p1.8.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m2.1b"><ci id="S2.SS1.p1.8.m2.1.1.cmml" xref="S2.SS1.p1.8.m2.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m2.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m2.1d">italic_v</annotation></semantics></math>, <math alttext="h_{v}^{l}" class="ltx_Math" display="inline" id="S2.SS1.p1.9.m3.1"><semantics id="S2.SS1.p1.9.m3.1a"><msubsup id="S2.SS1.p1.9.m3.1.1" xref="S2.SS1.p1.9.m3.1.1.cmml"><mi id="S2.SS1.p1.9.m3.1.1.2.2" xref="S2.SS1.p1.9.m3.1.1.2.2.cmml">h</mi><mi id="S2.SS1.p1.9.m3.1.1.2.3" xref="S2.SS1.p1.9.m3.1.1.2.3.cmml">v</mi><mi id="S2.SS1.p1.9.m3.1.1.3" xref="S2.SS1.p1.9.m3.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m3.1b"><apply id="S2.SS1.p1.9.m3.1.1.cmml" xref="S2.SS1.p1.9.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m3.1.1.1.cmml" xref="S2.SS1.p1.9.m3.1.1">superscript</csymbol><apply id="S2.SS1.p1.9.m3.1.1.2.cmml" xref="S2.SS1.p1.9.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.9.m3.1.1.2.1.cmml" xref="S2.SS1.p1.9.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.9.m3.1.1.2.2.cmml" xref="S2.SS1.p1.9.m3.1.1.2.2">â„</ci><ci id="S2.SS1.p1.9.m3.1.1.2.3.cmml" xref="S2.SS1.p1.9.m3.1.1.2.3">ğ‘£</ci></apply><ci id="S2.SS1.p1.9.m3.1.1.3.cmml" xref="S2.SS1.p1.9.m3.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m3.1c">h_{v}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.9.m3.1d">italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> represents the embedding vector of vertex <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p1.10.m4.1"><semantics id="S2.SS1.p1.10.m4.1a"><mi id="S2.SS1.p1.10.m4.1.1" xref="S2.SS1.p1.10.m4.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m4.1b"><ci id="S2.SS1.p1.10.m4.1.1.cmml" xref="S2.SS1.p1.10.m4.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m4.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.10.m4.1d">italic_v</annotation></semantics></math> at <math alttext="l" class="ltx_Math" display="inline" id="S2.SS1.p1.11.m5.1"><semantics id="S2.SS1.p1.11.m5.1a"><mi id="S2.SS1.p1.11.m5.1.1" xref="S2.SS1.p1.11.m5.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m5.1b"><ci id="S2.SS1.p1.11.m5.1.1.cmml" xref="S2.SS1.p1.11.m5.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m5.1c">l</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.11.m5.1d">italic_l</annotation></semantics></math>-th layer, and <math alttext="h_{v}^{0}" class="ltx_Math" display="inline" id="S2.SS1.p1.12.m6.1"><semantics id="S2.SS1.p1.12.m6.1a"><msubsup id="S2.SS1.p1.12.m6.1.1" xref="S2.SS1.p1.12.m6.1.1.cmml"><mi id="S2.SS1.p1.12.m6.1.1.2.2" xref="S2.SS1.p1.12.m6.1.1.2.2.cmml">h</mi><mi id="S2.SS1.p1.12.m6.1.1.2.3" xref="S2.SS1.p1.12.m6.1.1.2.3.cmml">v</mi><mn id="S2.SS1.p1.12.m6.1.1.3" xref="S2.SS1.p1.12.m6.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.12.m6.1b"><apply id="S2.SS1.p1.12.m6.1.1.cmml" xref="S2.SS1.p1.12.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m6.1.1.1.cmml" xref="S2.SS1.p1.12.m6.1.1">superscript</csymbol><apply id="S2.SS1.p1.12.m6.1.1.2.cmml" xref="S2.SS1.p1.12.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.12.m6.1.1.2.1.cmml" xref="S2.SS1.p1.12.m6.1.1">subscript</csymbol><ci id="S2.SS1.p1.12.m6.1.1.2.2.cmml" xref="S2.SS1.p1.12.m6.1.1.2.2">â„</ci><ci id="S2.SS1.p1.12.m6.1.1.2.3.cmml" xref="S2.SS1.p1.12.m6.1.1.2.3">ğ‘£</ci></apply><cn id="S2.SS1.p1.12.m6.1.1.3.cmml" type="integer" xref="S2.SS1.p1.12.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.12.m6.1c">h_{v}^{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.12.m6.1d">italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math> is the input feature of vertex <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p1.13.m7.1"><semantics id="S2.SS1.p1.13.m7.1a"><mi id="S2.SS1.p1.13.m7.1.1" xref="S2.SS1.p1.13.m7.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.13.m7.1b"><ci id="S2.SS1.p1.13.m7.1.1.cmml" xref="S2.SS1.p1.13.m7.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.13.m7.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.13.m7.1d">italic_v</annotation></semantics></math>. Next, during the update phase, each vertex computes its output embedding vector <math alttext="h_{v}^{l}" class="ltx_Math" display="inline" id="S2.SS1.p1.14.m8.1"><semantics id="S2.SS1.p1.14.m8.1a"><msubsup id="S2.SS1.p1.14.m8.1.1" xref="S2.SS1.p1.14.m8.1.1.cmml"><mi id="S2.SS1.p1.14.m8.1.1.2.2" xref="S2.SS1.p1.14.m8.1.1.2.2.cmml">h</mi><mi id="S2.SS1.p1.14.m8.1.1.2.3" xref="S2.SS1.p1.14.m8.1.1.2.3.cmml">v</mi><mi id="S2.SS1.p1.14.m8.1.1.3" xref="S2.SS1.p1.14.m8.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.14.m8.1b"><apply id="S2.SS1.p1.14.m8.1.1.cmml" xref="S2.SS1.p1.14.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.14.m8.1.1.1.cmml" xref="S2.SS1.p1.14.m8.1.1">superscript</csymbol><apply id="S2.SS1.p1.14.m8.1.1.2.cmml" xref="S2.SS1.p1.14.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.14.m8.1.1.2.1.cmml" xref="S2.SS1.p1.14.m8.1.1">subscript</csymbol><ci id="S2.SS1.p1.14.m8.1.1.2.2.cmml" xref="S2.SS1.p1.14.m8.1.1.2.2">â„</ci><ci id="S2.SS1.p1.14.m8.1.1.2.3.cmml" xref="S2.SS1.p1.14.m8.1.1.2.3">ğ‘£</ci></apply><ci id="S2.SS1.p1.14.m8.1.1.3.cmml" xref="S2.SS1.p1.14.m8.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.14.m8.1c">h_{v}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.14.m8.1d">italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> by applying an <math alttext="UPDATE" class="ltx_Math" display="inline" id="S2.SS1.p1.15.m9.1"><semantics id="S2.SS1.p1.15.m9.1a"><mrow id="S2.SS1.p1.15.m9.1.1" xref="S2.SS1.p1.15.m9.1.1.cmml"><mi id="S2.SS1.p1.15.m9.1.1.2" xref="S2.SS1.p1.15.m9.1.1.2.cmml">U</mi><mo id="S2.SS1.p1.15.m9.1.1.1" xref="S2.SS1.p1.15.m9.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.15.m9.1.1.3" xref="S2.SS1.p1.15.m9.1.1.3.cmml">P</mi><mo id="S2.SS1.p1.15.m9.1.1.1a" xref="S2.SS1.p1.15.m9.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.15.m9.1.1.4" xref="S2.SS1.p1.15.m9.1.1.4.cmml">D</mi><mo id="S2.SS1.p1.15.m9.1.1.1b" xref="S2.SS1.p1.15.m9.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.15.m9.1.1.5" xref="S2.SS1.p1.15.m9.1.1.5.cmml">A</mi><mo id="S2.SS1.p1.15.m9.1.1.1c" xref="S2.SS1.p1.15.m9.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.15.m9.1.1.6" xref="S2.SS1.p1.15.m9.1.1.6.cmml">T</mi><mo id="S2.SS1.p1.15.m9.1.1.1d" xref="S2.SS1.p1.15.m9.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p1.15.m9.1.1.7" xref="S2.SS1.p1.15.m9.1.1.7.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.15.m9.1b"><apply id="S2.SS1.p1.15.m9.1.1.cmml" xref="S2.SS1.p1.15.m9.1.1"><times id="S2.SS1.p1.15.m9.1.1.1.cmml" xref="S2.SS1.p1.15.m9.1.1.1"></times><ci id="S2.SS1.p1.15.m9.1.1.2.cmml" xref="S2.SS1.p1.15.m9.1.1.2">ğ‘ˆ</ci><ci id="S2.SS1.p1.15.m9.1.1.3.cmml" xref="S2.SS1.p1.15.m9.1.1.3">ğ‘ƒ</ci><ci id="S2.SS1.p1.15.m9.1.1.4.cmml" xref="S2.SS1.p1.15.m9.1.1.4">ğ·</ci><ci id="S2.SS1.p1.15.m9.1.1.5.cmml" xref="S2.SS1.p1.15.m9.1.1.5">ğ´</ci><ci id="S2.SS1.p1.15.m9.1.1.6.cmml" xref="S2.SS1.p1.15.m9.1.1.6">ğ‘‡</ci><ci id="S2.SS1.p1.15.m9.1.1.7.cmml" xref="S2.SS1.p1.15.m9.1.1.7">ğ¸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.15.m9.1c">UPDATE</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.15.m9.1d">italic_U italic_P italic_D italic_A italic_T italic_E</annotation></semantics></math> function to the aggregation result <math alttext="a_{v}^{l}" class="ltx_Math" display="inline" id="S2.SS1.p1.16.m10.1"><semantics id="S2.SS1.p1.16.m10.1a"><msubsup id="S2.SS1.p1.16.m10.1.1" xref="S2.SS1.p1.16.m10.1.1.cmml"><mi id="S2.SS1.p1.16.m10.1.1.2.2" xref="S2.SS1.p1.16.m10.1.1.2.2.cmml">a</mi><mi id="S2.SS1.p1.16.m10.1.1.2.3" xref="S2.SS1.p1.16.m10.1.1.2.3.cmml">v</mi><mi id="S2.SS1.p1.16.m10.1.1.3" xref="S2.SS1.p1.16.m10.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.16.m10.1b"><apply id="S2.SS1.p1.16.m10.1.1.cmml" xref="S2.SS1.p1.16.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.16.m10.1.1.1.cmml" xref="S2.SS1.p1.16.m10.1.1">superscript</csymbol><apply id="S2.SS1.p1.16.m10.1.1.2.cmml" xref="S2.SS1.p1.16.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.16.m10.1.1.2.1.cmml" xref="S2.SS1.p1.16.m10.1.1">subscript</csymbol><ci id="S2.SS1.p1.16.m10.1.1.2.2.cmml" xref="S2.SS1.p1.16.m10.1.1.2.2">ğ‘</ci><ci id="S2.SS1.p1.16.m10.1.1.2.3.cmml" xref="S2.SS1.p1.16.m10.1.1.2.3">ğ‘£</ci></apply><ci id="S2.SS1.p1.16.m10.1.1.3.cmml" xref="S2.SS1.p1.16.m10.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.16.m10.1c">a_{v}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.16.m10.1d">italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx2">
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(2)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle h_{v}^{l}" class="ltx_Math" display="inline" id="S2.E2.m1.1"><semantics id="S2.E2.m1.1a"><msubsup id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><mi id="S2.E2.m1.1.1.2.2" xref="S2.E2.m1.1.1.2.2.cmml">h</mi><mi id="S2.E2.m1.1.1.2.3" xref="S2.E2.m1.1.1.2.3.cmml">v</mi><mi id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1">superscript</csymbol><apply id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.2.1.cmml" xref="S2.E2.m1.1.1">subscript</csymbol><ci id="S2.E2.m1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.2.2">â„</ci><ci id="S2.E2.m1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.2.3">ğ‘£</ci></apply><ci id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\displaystyle h_{v}^{l}</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.1d">italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=UPDATE(W_{v}^{l},a_{v}^{l})" class="ltx_Math" display="inline" id="S2.E2.m2.2"><semantics id="S2.E2.m2.2a"><mrow id="S2.E2.m2.2.2" xref="S2.E2.m2.2.2.cmml"><mi id="S2.E2.m2.2.2.4" xref="S2.E2.m2.2.2.4.cmml"></mi><mo id="S2.E2.m2.2.2.3" xref="S2.E2.m2.2.2.3.cmml">=</mo><mrow id="S2.E2.m2.2.2.2" xref="S2.E2.m2.2.2.2.cmml"><mi id="S2.E2.m2.2.2.2.4" xref="S2.E2.m2.2.2.2.4.cmml">U</mi><mo id="S2.E2.m2.2.2.2.3" xref="S2.E2.m2.2.2.2.3.cmml">â¢</mo><mi id="S2.E2.m2.2.2.2.5" xref="S2.E2.m2.2.2.2.5.cmml">P</mi><mo id="S2.E2.m2.2.2.2.3a" xref="S2.E2.m2.2.2.2.3.cmml">â¢</mo><mi id="S2.E2.m2.2.2.2.6" xref="S2.E2.m2.2.2.2.6.cmml">D</mi><mo id="S2.E2.m2.2.2.2.3b" xref="S2.E2.m2.2.2.2.3.cmml">â¢</mo><mi id="S2.E2.m2.2.2.2.7" xref="S2.E2.m2.2.2.2.7.cmml">A</mi><mo id="S2.E2.m2.2.2.2.3c" xref="S2.E2.m2.2.2.2.3.cmml">â¢</mo><mi id="S2.E2.m2.2.2.2.8" xref="S2.E2.m2.2.2.2.8.cmml">T</mi><mo id="S2.E2.m2.2.2.2.3d" xref="S2.E2.m2.2.2.2.3.cmml">â¢</mo><mi id="S2.E2.m2.2.2.2.9" xref="S2.E2.m2.2.2.2.9.cmml">E</mi><mo id="S2.E2.m2.2.2.2.3e" xref="S2.E2.m2.2.2.2.3.cmml">â¢</mo><mrow id="S2.E2.m2.2.2.2.2.2" xref="S2.E2.m2.2.2.2.2.3.cmml"><mo id="S2.E2.m2.2.2.2.2.2.3" stretchy="false" xref="S2.E2.m2.2.2.2.2.3.cmml">(</mo><msubsup id="S2.E2.m2.1.1.1.1.1.1" xref="S2.E2.m2.1.1.1.1.1.1.cmml"><mi id="S2.E2.m2.1.1.1.1.1.1.2.2" xref="S2.E2.m2.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.E2.m2.1.1.1.1.1.1.2.3" xref="S2.E2.m2.1.1.1.1.1.1.2.3.cmml">v</mi><mi id="S2.E2.m2.1.1.1.1.1.1.3" xref="S2.E2.m2.1.1.1.1.1.1.3.cmml">l</mi></msubsup><mo id="S2.E2.m2.2.2.2.2.2.4" xref="S2.E2.m2.2.2.2.2.3.cmml">,</mo><msubsup id="S2.E2.m2.2.2.2.2.2.2" xref="S2.E2.m2.2.2.2.2.2.2.cmml"><mi id="S2.E2.m2.2.2.2.2.2.2.2.2" xref="S2.E2.m2.2.2.2.2.2.2.2.2.cmml">a</mi><mi id="S2.E2.m2.2.2.2.2.2.2.2.3" xref="S2.E2.m2.2.2.2.2.2.2.2.3.cmml">v</mi><mi id="S2.E2.m2.2.2.2.2.2.2.3" xref="S2.E2.m2.2.2.2.2.2.2.3.cmml">l</mi></msubsup><mo id="S2.E2.m2.2.2.2.2.2.5" stretchy="false" xref="S2.E2.m2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m2.2b"><apply id="S2.E2.m2.2.2.cmml" xref="S2.E2.m2.2.2"><eq id="S2.E2.m2.2.2.3.cmml" xref="S2.E2.m2.2.2.3"></eq><csymbol cd="latexml" id="S2.E2.m2.2.2.4.cmml" xref="S2.E2.m2.2.2.4">absent</csymbol><apply id="S2.E2.m2.2.2.2.cmml" xref="S2.E2.m2.2.2.2"><times id="S2.E2.m2.2.2.2.3.cmml" xref="S2.E2.m2.2.2.2.3"></times><ci id="S2.E2.m2.2.2.2.4.cmml" xref="S2.E2.m2.2.2.2.4">ğ‘ˆ</ci><ci id="S2.E2.m2.2.2.2.5.cmml" xref="S2.E2.m2.2.2.2.5">ğ‘ƒ</ci><ci id="S2.E2.m2.2.2.2.6.cmml" xref="S2.E2.m2.2.2.2.6">ğ·</ci><ci id="S2.E2.m2.2.2.2.7.cmml" xref="S2.E2.m2.2.2.2.7">ğ´</ci><ci id="S2.E2.m2.2.2.2.8.cmml" xref="S2.E2.m2.2.2.2.8">ğ‘‡</ci><ci id="S2.E2.m2.2.2.2.9.cmml" xref="S2.E2.m2.2.2.2.9">ğ¸</ci><interval closure="open" id="S2.E2.m2.2.2.2.2.3.cmml" xref="S2.E2.m2.2.2.2.2.2"><apply id="S2.E2.m2.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m2.1.1.1.1.1.1.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E2.m2.1.1.1.1.1.1.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m2.1.1.1.1.1.1.2.1.cmml" xref="S2.E2.m2.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m2.1.1.1.1.1.1.2.2.cmml" xref="S2.E2.m2.1.1.1.1.1.1.2.2">ğ‘Š</ci><ci id="S2.E2.m2.1.1.1.1.1.1.2.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.2.3">ğ‘£</ci></apply><ci id="S2.E2.m2.1.1.1.1.1.1.3.cmml" xref="S2.E2.m2.1.1.1.1.1.1.3">ğ‘™</ci></apply><apply id="S2.E2.m2.2.2.2.2.2.2.cmml" xref="S2.E2.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m2.2.2.2.2.2.2.1.cmml" xref="S2.E2.m2.2.2.2.2.2.2">superscript</csymbol><apply id="S2.E2.m2.2.2.2.2.2.2.2.cmml" xref="S2.E2.m2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m2.2.2.2.2.2.2.2.1.cmml" xref="S2.E2.m2.2.2.2.2.2.2">subscript</csymbol><ci id="S2.E2.m2.2.2.2.2.2.2.2.2.cmml" xref="S2.E2.m2.2.2.2.2.2.2.2.2">ğ‘</ci><ci id="S2.E2.m2.2.2.2.2.2.2.2.3.cmml" xref="S2.E2.m2.2.2.2.2.2.2.2.3">ğ‘£</ci></apply><ci id="S2.E2.m2.2.2.2.2.2.2.3.cmml" xref="S2.E2.m2.2.2.2.2.2.2.3">ğ‘™</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m2.2c">\displaystyle=UPDATE(W_{v}^{l},a_{v}^{l})</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m2.2d">= italic_U italic_P italic_D italic_A italic_T italic_E ( italic_W start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT , italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.18">After <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p1.17.m1.1"><semantics id="S2.SS1.p1.17.m1.1a"><mi id="S2.SS1.p1.17.m1.1.1" xref="S2.SS1.p1.17.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.17.m1.1b"><ci id="S2.SS1.p1.17.m1.1.1.cmml" xref="S2.SS1.p1.17.m1.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.17.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.17.m1.1d">italic_L</annotation></semantics></math> layers, each vertexâ€™s feature vector becomes a low-dimensional embedding of its neighbors up to <math alttext="L" class="ltx_Math" display="inline" id="S2.SS1.p1.18.m2.1"><semantics id="S2.SS1.p1.18.m2.1a"><mi id="S2.SS1.p1.18.m2.1.1" xref="S2.SS1.p1.18.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.18.m2.1b"><ci id="S2.SS1.p1.18.m2.1.1.cmml" xref="S2.SS1.p1.18.m2.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.18.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.18.m2.1d">italic_L</annotation></semantics></math> hops away.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.2">Both the <math alttext="AGG" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">A</mi><mo id="S2.SS1.p2.1.m1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">G</mi><mo id="S2.SS1.p2.1.m1.1.1.1a" xref="S2.SS1.p2.1.m1.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.1.m1.1.1.4" xref="S2.SS1.p2.1.m1.1.1.4.cmml">G</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><times id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1"></times><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">ğ´</ci><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">ğº</ci><ci id="S2.SS1.p2.1.m1.1.1.4.cmml" xref="S2.SS1.p2.1.m1.1.1.4">ğº</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">AGG</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_A italic_G italic_G</annotation></semantics></math> and <math alttext="UPDATE" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><mrow id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.p2.2.m2.1.1.2" xref="S2.SS1.p2.2.m2.1.1.2.cmml">U</mi><mo id="S2.SS1.p2.2.m2.1.1.1" xref="S2.SS1.p2.2.m2.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.2.m2.1.1.3" xref="S2.SS1.p2.2.m2.1.1.3.cmml">P</mi><mo id="S2.SS1.p2.2.m2.1.1.1a" xref="S2.SS1.p2.2.m2.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.2.m2.1.1.4" xref="S2.SS1.p2.2.m2.1.1.4.cmml">D</mi><mo id="S2.SS1.p2.2.m2.1.1.1b" xref="S2.SS1.p2.2.m2.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.2.m2.1.1.5" xref="S2.SS1.p2.2.m2.1.1.5.cmml">A</mi><mo id="S2.SS1.p2.2.m2.1.1.1c" xref="S2.SS1.p2.2.m2.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.2.m2.1.1.6" xref="S2.SS1.p2.2.m2.1.1.6.cmml">T</mi><mo id="S2.SS1.p2.2.m2.1.1.1d" xref="S2.SS1.p2.2.m2.1.1.1.cmml">â¢</mo><mi id="S2.SS1.p2.2.m2.1.1.7" xref="S2.SS1.p2.2.m2.1.1.7.cmml">E</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><apply id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1"><times id="S2.SS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1.1"></times><ci id="S2.SS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2">ğ‘ˆ</ci><ci id="S2.SS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3">ğ‘ƒ</ci><ci id="S2.SS1.p2.2.m2.1.1.4.cmml" xref="S2.SS1.p2.2.m2.1.1.4">ğ·</ci><ci id="S2.SS1.p2.2.m2.1.1.5.cmml" xref="S2.SS1.p2.2.m2.1.1.5">ğ´</ci><ci id="S2.SS1.p2.2.m2.1.1.6.cmml" xref="S2.SS1.p2.2.m2.1.1.6">ğ‘‡</ci><ci id="S2.SS1.p2.2.m2.1.1.7.cmml" xref="S2.SS1.p2.2.m2.1.1.7">ğ¸</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">UPDATE</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">italic_U italic_P italic_D italic_A italic_T italic_E</annotation></semantics></math> functions can be neural networks, which are updated during training.
For simple GNN models, such as GCN <cite class="ltx_cite ltx_citemacro_citep">(Kipf and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib19" title="">2017</a>)</cite>, which only incorporate vertex-associated NN operations. The computational formulas for GCN are as follows:</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx3">
<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(3)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle AGG:a_{v}^{l}=\sum_{u\in N_{in}(v)}(\frac{1}{\sqrt{deg_{in}(v)%
\cdot deg_{out}(u)}}\cdot h_{u}^{l-1})" class="ltx_Math" display="inline" id="S2.E3.m1.4"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mrow id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml"><mi id="S2.E3.m1.4.4.3.2" xref="S2.E3.m1.4.4.3.2.cmml">A</mi><mo id="S2.E3.m1.4.4.3.1" xref="S2.E3.m1.4.4.3.1.cmml">â¢</mo><mi id="S2.E3.m1.4.4.3.3" xref="S2.E3.m1.4.4.3.3.cmml">G</mi><mo id="S2.E3.m1.4.4.3.1a" xref="S2.E3.m1.4.4.3.1.cmml">â¢</mo><mi id="S2.E3.m1.4.4.3.4" xref="S2.E3.m1.4.4.3.4.cmml">G</mi></mrow><mo id="S2.E3.m1.4.4.2" lspace="0.278em" rspace="0.278em" xref="S2.E3.m1.4.4.2.cmml">:</mo><mrow id="S2.E3.m1.4.4.1" xref="S2.E3.m1.4.4.1.cmml"><msubsup id="S2.E3.m1.4.4.1.3" xref="S2.E3.m1.4.4.1.3.cmml"><mi id="S2.E3.m1.4.4.1.3.2.2" xref="S2.E3.m1.4.4.1.3.2.2.cmml">a</mi><mi id="S2.E3.m1.4.4.1.3.2.3" xref="S2.E3.m1.4.4.1.3.2.3.cmml">v</mi><mi id="S2.E3.m1.4.4.1.3.3" xref="S2.E3.m1.4.4.1.3.3.cmml">l</mi></msubsup><mo id="S2.E3.m1.4.4.1.2" xref="S2.E3.m1.4.4.1.2.cmml">=</mo><mrow id="S2.E3.m1.4.4.1.1" xref="S2.E3.m1.4.4.1.1.cmml"><mstyle displaystyle="true" id="S2.E3.m1.4.4.1.1.2" xref="S2.E3.m1.4.4.1.1.2.cmml"><munder id="S2.E3.m1.4.4.1.1.2a" xref="S2.E3.m1.4.4.1.1.2.cmml"><mo id="S2.E3.m1.4.4.1.1.2.2" movablelimits="false" xref="S2.E3.m1.4.4.1.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E3.m1.1.1.1" xref="S2.E3.m1.1.1.1.cmml"><mi id="S2.E3.m1.1.1.1.3" xref="S2.E3.m1.1.1.1.3.cmml">u</mi><mo id="S2.E3.m1.1.1.1.2" xref="S2.E3.m1.1.1.1.2.cmml">âˆˆ</mo><mrow id="S2.E3.m1.1.1.1.4" xref="S2.E3.m1.1.1.1.4.cmml"><msub id="S2.E3.m1.1.1.1.4.2" xref="S2.E3.m1.1.1.1.4.2.cmml"><mi id="S2.E3.m1.1.1.1.4.2.2" xref="S2.E3.m1.1.1.1.4.2.2.cmml">N</mi><mrow id="S2.E3.m1.1.1.1.4.2.3" xref="S2.E3.m1.1.1.1.4.2.3.cmml"><mi id="S2.E3.m1.1.1.1.4.2.3.2" xref="S2.E3.m1.1.1.1.4.2.3.2.cmml">i</mi><mo id="S2.E3.m1.1.1.1.4.2.3.1" xref="S2.E3.m1.1.1.1.4.2.3.1.cmml">â¢</mo><mi id="S2.E3.m1.1.1.1.4.2.3.3" xref="S2.E3.m1.1.1.1.4.2.3.3.cmml">n</mi></mrow></msub><mo id="S2.E3.m1.1.1.1.4.1" xref="S2.E3.m1.1.1.1.4.1.cmml">â¢</mo><mrow id="S2.E3.m1.1.1.1.4.3.2" xref="S2.E3.m1.1.1.1.4.cmml"><mo id="S2.E3.m1.1.1.1.4.3.2.1" stretchy="false" xref="S2.E3.m1.1.1.1.4.cmml">(</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">v</mi><mo id="S2.E3.m1.1.1.1.4.3.2.2" stretchy="false" xref="S2.E3.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder></mstyle><mrow id="S2.E3.m1.4.4.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.cmml"><mo id="S2.E3.m1.4.4.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.4.4.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml"><mfrac id="S2.E3.m1.3.3a" xref="S2.E3.m1.3.3.cmml"><mn id="S2.E3.m1.3.3.4" xref="S2.E3.m1.3.3.4.cmml">1</mn><msqrt id="S2.E3.m1.3.3.2" xref="S2.E3.m1.3.3.2.cmml"><mrow id="S2.E3.m1.3.3.2.2.2" xref="S2.E3.m1.3.3.2.2.2.cmml"><mrow id="S2.E3.m1.3.3.2.2.2.4" xref="S2.E3.m1.3.3.2.2.2.4.cmml"><mrow id="S2.E3.m1.3.3.2.2.2.4.2" xref="S2.E3.m1.3.3.2.2.2.4.2.cmml"><mi id="S2.E3.m1.3.3.2.2.2.4.2.2" xref="S2.E3.m1.3.3.2.2.2.4.2.2.cmml">d</mi><mo id="S2.E3.m1.3.3.2.2.2.4.2.1" xref="S2.E3.m1.3.3.2.2.2.4.2.1.cmml">â¢</mo><mi id="S2.E3.m1.3.3.2.2.2.4.2.3" xref="S2.E3.m1.3.3.2.2.2.4.2.3.cmml">e</mi><mo id="S2.E3.m1.3.3.2.2.2.4.2.1a" xref="S2.E3.m1.3.3.2.2.2.4.2.1.cmml">â¢</mo><msub id="S2.E3.m1.3.3.2.2.2.4.2.4" xref="S2.E3.m1.3.3.2.2.2.4.2.4.cmml"><mi id="S2.E3.m1.3.3.2.2.2.4.2.4.2" xref="S2.E3.m1.3.3.2.2.2.4.2.4.2.cmml">g</mi><mrow id="S2.E3.m1.3.3.2.2.2.4.2.4.3" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.cmml"><mi id="S2.E3.m1.3.3.2.2.2.4.2.4.3.2" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.2.cmml">i</mi><mo id="S2.E3.m1.3.3.2.2.2.4.2.4.3.1" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.1.cmml">â¢</mo><mi id="S2.E3.m1.3.3.2.2.2.4.2.4.3.3" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.3.cmml">n</mi></mrow></msub><mo id="S2.E3.m1.3.3.2.2.2.4.2.1b" xref="S2.E3.m1.3.3.2.2.2.4.2.1.cmml">â¢</mo><mrow id="S2.E3.m1.3.3.2.2.2.4.2.5.2" xref="S2.E3.m1.3.3.2.2.2.4.2.cmml"><mo id="S2.E3.m1.3.3.2.2.2.4.2.5.2.1" stretchy="false" xref="S2.E3.m1.3.3.2.2.2.4.2.cmml">(</mo><mi id="S2.E3.m1.2.2.1.1.1.1" xref="S2.E3.m1.2.2.1.1.1.1.cmml">v</mi><mo id="S2.E3.m1.3.3.2.2.2.4.2.5.2.2" rspace="0.055em" stretchy="false" xref="S2.E3.m1.3.3.2.2.2.4.2.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.3.3.2.2.2.4.1" rspace="0.222em" xref="S2.E3.m1.3.3.2.2.2.4.1.cmml">â‹…</mo><mi id="S2.E3.m1.3.3.2.2.2.4.3" xref="S2.E3.m1.3.3.2.2.2.4.3.cmml">d</mi></mrow><mo id="S2.E3.m1.3.3.2.2.2.3" xref="S2.E3.m1.3.3.2.2.2.3.cmml">â¢</mo><mi id="S2.E3.m1.3.3.2.2.2.5" xref="S2.E3.m1.3.3.2.2.2.5.cmml">e</mi><mo id="S2.E3.m1.3.3.2.2.2.3a" xref="S2.E3.m1.3.3.2.2.2.3.cmml">â¢</mo><msub id="S2.E3.m1.3.3.2.2.2.6" xref="S2.E3.m1.3.3.2.2.2.6.cmml"><mi id="S2.E3.m1.3.3.2.2.2.6.2" xref="S2.E3.m1.3.3.2.2.2.6.2.cmml">g</mi><mrow id="S2.E3.m1.3.3.2.2.2.6.3" xref="S2.E3.m1.3.3.2.2.2.6.3.cmml"><mi id="S2.E3.m1.3.3.2.2.2.6.3.2" xref="S2.E3.m1.3.3.2.2.2.6.3.2.cmml">o</mi><mo id="S2.E3.m1.3.3.2.2.2.6.3.1" xref="S2.E3.m1.3.3.2.2.2.6.3.1.cmml">â¢</mo><mi id="S2.E3.m1.3.3.2.2.2.6.3.3" xref="S2.E3.m1.3.3.2.2.2.6.3.3.cmml">u</mi><mo id="S2.E3.m1.3.3.2.2.2.6.3.1a" xref="S2.E3.m1.3.3.2.2.2.6.3.1.cmml">â¢</mo><mi id="S2.E3.m1.3.3.2.2.2.6.3.4" xref="S2.E3.m1.3.3.2.2.2.6.3.4.cmml">t</mi></mrow></msub><mo id="S2.E3.m1.3.3.2.2.2.3b" xref="S2.E3.m1.3.3.2.2.2.3.cmml">â¢</mo><mrow id="S2.E3.m1.3.3.2.2.2.7.2" xref="S2.E3.m1.3.3.2.2.2.cmml"><mo id="S2.E3.m1.3.3.2.2.2.7.2.1" stretchy="false" xref="S2.E3.m1.3.3.2.2.2.cmml">(</mo><mi id="S2.E3.m1.3.3.2.2.2.2" xref="S2.E3.m1.3.3.2.2.2.2.cmml">u</mi><mo id="S2.E3.m1.3.3.2.2.2.7.2.2" stretchy="false" xref="S2.E3.m1.3.3.2.2.2.cmml">)</mo></mrow></mrow></msqrt></mfrac></mstyle><mo id="S2.E3.m1.4.4.1.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml">â‹…</mo><msubsup id="S2.E3.m1.4.4.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2.2.cmml">h</mi><mi id="S2.E3.m1.4.4.1.1.1.1.1.2.2.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2.3.cmml">u</mi><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.2.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.2.cmml">l</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.2.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.1.cmml">âˆ’</mo><mn id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msubsup></mrow><mo id="S2.E3.m1.4.4.1.1.1.1.3" stretchy="false" xref="S2.E3.m1.4.4.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><ci id="S2.E3.m1.4.4.2.cmml" xref="S2.E3.m1.4.4.2">:</ci><apply id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"><times id="S2.E3.m1.4.4.3.1.cmml" xref="S2.E3.m1.4.4.3.1"></times><ci id="S2.E3.m1.4.4.3.2.cmml" xref="S2.E3.m1.4.4.3.2">ğ´</ci><ci id="S2.E3.m1.4.4.3.3.cmml" xref="S2.E3.m1.4.4.3.3">ğº</ci><ci id="S2.E3.m1.4.4.3.4.cmml" xref="S2.E3.m1.4.4.3.4">ğº</ci></apply><apply id="S2.E3.m1.4.4.1.cmml" xref="S2.E3.m1.4.4.1"><eq id="S2.E3.m1.4.4.1.2.cmml" xref="S2.E3.m1.4.4.1.2"></eq><apply id="S2.E3.m1.4.4.1.3.cmml" xref="S2.E3.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.3.1.cmml" xref="S2.E3.m1.4.4.1.3">superscript</csymbol><apply id="S2.E3.m1.4.4.1.3.2.cmml" xref="S2.E3.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.3.2.1.cmml" xref="S2.E3.m1.4.4.1.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.3.2.2.cmml" xref="S2.E3.m1.4.4.1.3.2.2">ğ‘</ci><ci id="S2.E3.m1.4.4.1.3.2.3.cmml" xref="S2.E3.m1.4.4.1.3.2.3">ğ‘£</ci></apply><ci id="S2.E3.m1.4.4.1.3.3.cmml" xref="S2.E3.m1.4.4.1.3.3">ğ‘™</ci></apply><apply id="S2.E3.m1.4.4.1.1.cmml" xref="S2.E3.m1.4.4.1.1"><apply id="S2.E3.m1.4.4.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.2.1.cmml" xref="S2.E3.m1.4.4.1.1.2">subscript</csymbol><sum id="S2.E3.m1.4.4.1.1.2.2.cmml" xref="S2.E3.m1.4.4.1.1.2.2"></sum><apply id="S2.E3.m1.1.1.1.cmml" xref="S2.E3.m1.1.1.1"><in id="S2.E3.m1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.2"></in><ci id="S2.E3.m1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.3">ğ‘¢</ci><apply id="S2.E3.m1.1.1.1.4.cmml" xref="S2.E3.m1.1.1.1.4"><times id="S2.E3.m1.1.1.1.4.1.cmml" xref="S2.E3.m1.1.1.1.4.1"></times><apply id="S2.E3.m1.1.1.1.4.2.cmml" xref="S2.E3.m1.1.1.1.4.2"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.4.2.1.cmml" xref="S2.E3.m1.1.1.1.4.2">subscript</csymbol><ci id="S2.E3.m1.1.1.1.4.2.2.cmml" xref="S2.E3.m1.1.1.1.4.2.2">ğ‘</ci><apply id="S2.E3.m1.1.1.1.4.2.3.cmml" xref="S2.E3.m1.1.1.1.4.2.3"><times id="S2.E3.m1.1.1.1.4.2.3.1.cmml" xref="S2.E3.m1.1.1.1.4.2.3.1"></times><ci id="S2.E3.m1.1.1.1.4.2.3.2.cmml" xref="S2.E3.m1.1.1.1.4.2.3.2">ğ‘–</ci><ci id="S2.E3.m1.1.1.1.4.2.3.3.cmml" xref="S2.E3.m1.1.1.1.4.2.3.3">ğ‘›</ci></apply></apply><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">ğ‘£</ci></apply></apply></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1"><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1">â‹…</ci><apply id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3"><divide id="S2.E3.m1.3.3.3.cmml" xref="S2.E3.m1.3.3"></divide><cn id="S2.E3.m1.3.3.4.cmml" type="integer" xref="S2.E3.m1.3.3.4">1</cn><apply id="S2.E3.m1.3.3.2.cmml" xref="S2.E3.m1.3.3.2"><root id="S2.E3.m1.3.3.2a.cmml" xref="S2.E3.m1.3.3.2"></root><apply id="S2.E3.m1.3.3.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2"><times id="S2.E3.m1.3.3.2.2.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2.3"></times><apply id="S2.E3.m1.3.3.2.2.2.4.cmml" xref="S2.E3.m1.3.3.2.2.2.4"><ci id="S2.E3.m1.3.3.2.2.2.4.1.cmml" xref="S2.E3.m1.3.3.2.2.2.4.1">â‹…</ci><apply id="S2.E3.m1.3.3.2.2.2.4.2.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2"><times id="S2.E3.m1.3.3.2.2.2.4.2.1.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.1"></times><ci id="S2.E3.m1.3.3.2.2.2.4.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.2">ğ‘‘</ci><ci id="S2.E3.m1.3.3.2.2.2.4.2.3.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.3">ğ‘’</ci><apply id="S2.E3.m1.3.3.2.2.2.4.2.4.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.2.2.4.2.4.1.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4">subscript</csymbol><ci id="S2.E3.m1.3.3.2.2.2.4.2.4.2.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4.2">ğ‘”</ci><apply id="S2.E3.m1.3.3.2.2.2.4.2.4.3.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3"><times id="S2.E3.m1.3.3.2.2.2.4.2.4.3.1.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.1"></times><ci id="S2.E3.m1.3.3.2.2.2.4.2.4.3.2.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.2">ğ‘–</ci><ci id="S2.E3.m1.3.3.2.2.2.4.2.4.3.3.cmml" xref="S2.E3.m1.3.3.2.2.2.4.2.4.3.3">ğ‘›</ci></apply></apply><ci id="S2.E3.m1.2.2.1.1.1.1.cmml" xref="S2.E3.m1.2.2.1.1.1.1">ğ‘£</ci></apply><ci id="S2.E3.m1.3.3.2.2.2.4.3.cmml" xref="S2.E3.m1.3.3.2.2.2.4.3">ğ‘‘</ci></apply><ci id="S2.E3.m1.3.3.2.2.2.5.cmml" xref="S2.E3.m1.3.3.2.2.2.5">ğ‘’</ci><apply id="S2.E3.m1.3.3.2.2.2.6.cmml" xref="S2.E3.m1.3.3.2.2.2.6"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.2.2.2.6.1.cmml" xref="S2.E3.m1.3.3.2.2.2.6">subscript</csymbol><ci id="S2.E3.m1.3.3.2.2.2.6.2.cmml" xref="S2.E3.m1.3.3.2.2.2.6.2">ğ‘”</ci><apply id="S2.E3.m1.3.3.2.2.2.6.3.cmml" xref="S2.E3.m1.3.3.2.2.2.6.3"><times id="S2.E3.m1.3.3.2.2.2.6.3.1.cmml" xref="S2.E3.m1.3.3.2.2.2.6.3.1"></times><ci id="S2.E3.m1.3.3.2.2.2.6.3.2.cmml" xref="S2.E3.m1.3.3.2.2.2.6.3.2">ğ‘œ</ci><ci id="S2.E3.m1.3.3.2.2.2.6.3.3.cmml" xref="S2.E3.m1.3.3.2.2.2.6.3.3">ğ‘¢</ci><ci id="S2.E3.m1.3.3.2.2.2.6.3.4.cmml" xref="S2.E3.m1.3.3.2.2.2.6.3.4">ğ‘¡</ci></apply></apply><ci id="S2.E3.m1.3.3.2.2.2.2.cmml" xref="S2.E3.m1.3.3.2.2.2.2">ğ‘¢</ci></apply></apply></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2">superscript</csymbol><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2.2">â„</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.2.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2.3">ğ‘¢</ci></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3"><minus id="S2.E3.m1.4.4.1.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.1"></minus><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.2">ğ‘™</ci><cn id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\displaystyle AGG:a_{v}^{l}=\sum_{u\in N_{in}(v)}(\frac{1}{\sqrt{deg_{in}(v)%
\cdot deg_{out}(u)}}\cdot h_{u}^{l-1})</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.4d">italic_A italic_G italic_G : italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = âˆ‘ start_POSTSUBSCRIPT italic_u âˆˆ italic_N start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ( italic_v ) end_POSTSUBSCRIPT ( divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_d italic_e italic_g start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ( italic_v ) â‹… italic_d italic_e italic_g start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT ( italic_u ) end_ARG end_ARG â‹… italic_h start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l - 1 end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx4">
<tbody id="S2.E4"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(4)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle UPDATE:h_{v}^{l}=\sigma(W^{l}a_{v}^{l})" class="ltx_Math" display="inline" id="S2.E4.m1.1"><semantics id="S2.E4.m1.1a"><mrow id="S2.E4.m1.1.1" xref="S2.E4.m1.1.1.cmml"><mrow id="S2.E4.m1.1.1.3" xref="S2.E4.m1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.3.2" xref="S2.E4.m1.1.1.3.2.cmml">U</mi><mo id="S2.E4.m1.1.1.3.1" xref="S2.E4.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E4.m1.1.1.3.3" xref="S2.E4.m1.1.1.3.3.cmml">P</mi><mo id="S2.E4.m1.1.1.3.1a" xref="S2.E4.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E4.m1.1.1.3.4" xref="S2.E4.m1.1.1.3.4.cmml">D</mi><mo id="S2.E4.m1.1.1.3.1b" xref="S2.E4.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E4.m1.1.1.3.5" xref="S2.E4.m1.1.1.3.5.cmml">A</mi><mo id="S2.E4.m1.1.1.3.1c" xref="S2.E4.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E4.m1.1.1.3.6" xref="S2.E4.m1.1.1.3.6.cmml">T</mi><mo id="S2.E4.m1.1.1.3.1d" xref="S2.E4.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E4.m1.1.1.3.7" xref="S2.E4.m1.1.1.3.7.cmml">E</mi></mrow><mo id="S2.E4.m1.1.1.2" lspace="0.278em" rspace="0.278em" xref="S2.E4.m1.1.1.2.cmml">:</mo><mrow id="S2.E4.m1.1.1.1" xref="S2.E4.m1.1.1.1.cmml"><msubsup id="S2.E4.m1.1.1.1.3" xref="S2.E4.m1.1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.1.3.2.2" xref="S2.E4.m1.1.1.1.3.2.2.cmml">h</mi><mi id="S2.E4.m1.1.1.1.3.2.3" xref="S2.E4.m1.1.1.1.3.2.3.cmml">v</mi><mi id="S2.E4.m1.1.1.1.3.3" xref="S2.E4.m1.1.1.1.3.3.cmml">l</mi></msubsup><mo id="S2.E4.m1.1.1.1.2" xref="S2.E4.m1.1.1.1.2.cmml">=</mo><mrow id="S2.E4.m1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.cmml"><mi id="S2.E4.m1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.3.cmml">Ïƒ</mi><mo id="S2.E4.m1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.2.cmml">â¢</mo><mrow id="S2.E4.m1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml"><mo id="S2.E4.m1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E4.m1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml"><msup id="S2.E4.m1.1.1.1.1.1.1.1.2" xref="S2.E4.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.1.2.2" xref="S2.E4.m1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.E4.m1.1.1.1.1.1.1.1.2.3" xref="S2.E4.m1.1.1.1.1.1.1.1.2.3.cmml">l</mi></msup><mo id="S2.E4.m1.1.1.1.1.1.1.1.1" xref="S2.E4.m1.1.1.1.1.1.1.1.1.cmml">â¢</mo><msubsup id="S2.E4.m1.1.1.1.1.1.1.1.3" xref="S2.E4.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E4.m1.1.1.1.1.1.1.1.3.2.2" xref="S2.E4.m1.1.1.1.1.1.1.1.3.2.2.cmml">a</mi><mi id="S2.E4.m1.1.1.1.1.1.1.1.3.2.3" xref="S2.E4.m1.1.1.1.1.1.1.1.3.2.3.cmml">v</mi><mi id="S2.E4.m1.1.1.1.1.1.1.1.3.3" xref="S2.E4.m1.1.1.1.1.1.1.1.3.3.cmml">l</mi></msubsup></mrow><mo id="S2.E4.m1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E4.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E4.m1.1b"><apply id="S2.E4.m1.1.1.cmml" xref="S2.E4.m1.1.1"><ci id="S2.E4.m1.1.1.2.cmml" xref="S2.E4.m1.1.1.2">:</ci><apply id="S2.E4.m1.1.1.3.cmml" xref="S2.E4.m1.1.1.3"><times id="S2.E4.m1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.3.1"></times><ci id="S2.E4.m1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.3.2">ğ‘ˆ</ci><ci id="S2.E4.m1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.3.3">ğ‘ƒ</ci><ci id="S2.E4.m1.1.1.3.4.cmml" xref="S2.E4.m1.1.1.3.4">ğ·</ci><ci id="S2.E4.m1.1.1.3.5.cmml" xref="S2.E4.m1.1.1.3.5">ğ´</ci><ci id="S2.E4.m1.1.1.3.6.cmml" xref="S2.E4.m1.1.1.3.6">ğ‘‡</ci><ci id="S2.E4.m1.1.1.3.7.cmml" xref="S2.E4.m1.1.1.3.7">ğ¸</ci></apply><apply id="S2.E4.m1.1.1.1.cmml" xref="S2.E4.m1.1.1.1"><eq id="S2.E4.m1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.2"></eq><apply id="S2.E4.m1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.3">superscript</csymbol><apply id="S2.E4.m1.1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.3.2.1.cmml" xref="S2.E4.m1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.3.2.2.cmml" xref="S2.E4.m1.1.1.1.3.2.2">â„</ci><ci id="S2.E4.m1.1.1.1.3.2.3.cmml" xref="S2.E4.m1.1.1.1.3.2.3">ğ‘£</ci></apply><ci id="S2.E4.m1.1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.1.3.3">ğ‘™</ci></apply><apply id="S2.E4.m1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1"><times id="S2.E4.m1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.2"></times><ci id="S2.E4.m1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.3">ğœ</ci><apply id="S2.E4.m1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1"><times id="S2.E4.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.1"></times><apply id="S2.E4.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.2.2">ğ‘Š</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><apply id="S2.E4.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S2.E4.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E4.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E4.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3.2.2">ğ‘</ci><ci id="S2.E4.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3.2.3">ğ‘£</ci></apply><ci id="S2.E4.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E4.m1.1.1.1.1.1.1.1.3.3">ğ‘™</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E4.m1.1c">\displaystyle UPDATE:h_{v}^{l}=\sigma(W^{l}a_{v}^{l})</annotation><annotation encoding="application/x-llamapun" id="S2.E4.m1.1d">italic_U italic_P italic_D italic_A italic_T italic_E : italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = italic_Ïƒ ( italic_W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.5">, where <math alttext="deg_{out}(u)" class="ltx_Math" display="inline" id="S2.SS1.p5.1.m1.1"><semantics id="S2.SS1.p5.1.m1.1a"><mrow id="S2.SS1.p5.1.m1.1.2" xref="S2.SS1.p5.1.m1.1.2.cmml"><mi id="S2.SS1.p5.1.m1.1.2.2" xref="S2.SS1.p5.1.m1.1.2.2.cmml">d</mi><mo id="S2.SS1.p5.1.m1.1.2.1" xref="S2.SS1.p5.1.m1.1.2.1.cmml">â¢</mo><mi id="S2.SS1.p5.1.m1.1.2.3" xref="S2.SS1.p5.1.m1.1.2.3.cmml">e</mi><mo id="S2.SS1.p5.1.m1.1.2.1a" xref="S2.SS1.p5.1.m1.1.2.1.cmml">â¢</mo><msub id="S2.SS1.p5.1.m1.1.2.4" xref="S2.SS1.p5.1.m1.1.2.4.cmml"><mi id="S2.SS1.p5.1.m1.1.2.4.2" xref="S2.SS1.p5.1.m1.1.2.4.2.cmml">g</mi><mrow id="S2.SS1.p5.1.m1.1.2.4.3" xref="S2.SS1.p5.1.m1.1.2.4.3.cmml"><mi id="S2.SS1.p5.1.m1.1.2.4.3.2" xref="S2.SS1.p5.1.m1.1.2.4.3.2.cmml">o</mi><mo id="S2.SS1.p5.1.m1.1.2.4.3.1" xref="S2.SS1.p5.1.m1.1.2.4.3.1.cmml">â¢</mo><mi id="S2.SS1.p5.1.m1.1.2.4.3.3" xref="S2.SS1.p5.1.m1.1.2.4.3.3.cmml">u</mi><mo id="S2.SS1.p5.1.m1.1.2.4.3.1a" xref="S2.SS1.p5.1.m1.1.2.4.3.1.cmml">â¢</mo><mi id="S2.SS1.p5.1.m1.1.2.4.3.4" xref="S2.SS1.p5.1.m1.1.2.4.3.4.cmml">t</mi></mrow></msub><mo id="S2.SS1.p5.1.m1.1.2.1b" xref="S2.SS1.p5.1.m1.1.2.1.cmml">â¢</mo><mrow id="S2.SS1.p5.1.m1.1.2.5.2" xref="S2.SS1.p5.1.m1.1.2.cmml"><mo id="S2.SS1.p5.1.m1.1.2.5.2.1" stretchy="false" xref="S2.SS1.p5.1.m1.1.2.cmml">(</mo><mi id="S2.SS1.p5.1.m1.1.1" xref="S2.SS1.p5.1.m1.1.1.cmml">u</mi><mo id="S2.SS1.p5.1.m1.1.2.5.2.2" stretchy="false" xref="S2.SS1.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.1b"><apply id="S2.SS1.p5.1.m1.1.2.cmml" xref="S2.SS1.p5.1.m1.1.2"><times id="S2.SS1.p5.1.m1.1.2.1.cmml" xref="S2.SS1.p5.1.m1.1.2.1"></times><ci id="S2.SS1.p5.1.m1.1.2.2.cmml" xref="S2.SS1.p5.1.m1.1.2.2">ğ‘‘</ci><ci id="S2.SS1.p5.1.m1.1.2.3.cmml" xref="S2.SS1.p5.1.m1.1.2.3">ğ‘’</ci><apply id="S2.SS1.p5.1.m1.1.2.4.cmml" xref="S2.SS1.p5.1.m1.1.2.4"><csymbol cd="ambiguous" id="S2.SS1.p5.1.m1.1.2.4.1.cmml" xref="S2.SS1.p5.1.m1.1.2.4">subscript</csymbol><ci id="S2.SS1.p5.1.m1.1.2.4.2.cmml" xref="S2.SS1.p5.1.m1.1.2.4.2">ğ‘”</ci><apply id="S2.SS1.p5.1.m1.1.2.4.3.cmml" xref="S2.SS1.p5.1.m1.1.2.4.3"><times id="S2.SS1.p5.1.m1.1.2.4.3.1.cmml" xref="S2.SS1.p5.1.m1.1.2.4.3.1"></times><ci id="S2.SS1.p5.1.m1.1.2.4.3.2.cmml" xref="S2.SS1.p5.1.m1.1.2.4.3.2">ğ‘œ</ci><ci id="S2.SS1.p5.1.m1.1.2.4.3.3.cmml" xref="S2.SS1.p5.1.m1.1.2.4.3.3">ğ‘¢</ci><ci id="S2.SS1.p5.1.m1.1.2.4.3.4.cmml" xref="S2.SS1.p5.1.m1.1.2.4.3.4">ğ‘¡</ci></apply></apply><ci id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1">ğ‘¢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.1c">deg_{out}(u)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.1.m1.1d">italic_d italic_e italic_g start_POSTSUBSCRIPT italic_o italic_u italic_t end_POSTSUBSCRIPT ( italic_u )</annotation></semantics></math> is the out-degree of vertex <math alttext="u" class="ltx_Math" display="inline" id="S2.SS1.p5.2.m2.1"><semantics id="S2.SS1.p5.2.m2.1a"><mi id="S2.SS1.p5.2.m2.1.1" xref="S2.SS1.p5.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.2.m2.1b"><ci id="S2.SS1.p5.2.m2.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.2.m2.1c">u</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.2.m2.1d">italic_u</annotation></semantics></math>, and <math alttext="deg_{in}(v)" class="ltx_Math" display="inline" id="S2.SS1.p5.3.m3.1"><semantics id="S2.SS1.p5.3.m3.1a"><mrow id="S2.SS1.p5.3.m3.1.2" xref="S2.SS1.p5.3.m3.1.2.cmml"><mi id="S2.SS1.p5.3.m3.1.2.2" xref="S2.SS1.p5.3.m3.1.2.2.cmml">d</mi><mo id="S2.SS1.p5.3.m3.1.2.1" xref="S2.SS1.p5.3.m3.1.2.1.cmml">â¢</mo><mi id="S2.SS1.p5.3.m3.1.2.3" xref="S2.SS1.p5.3.m3.1.2.3.cmml">e</mi><mo id="S2.SS1.p5.3.m3.1.2.1a" xref="S2.SS1.p5.3.m3.1.2.1.cmml">â¢</mo><msub id="S2.SS1.p5.3.m3.1.2.4" xref="S2.SS1.p5.3.m3.1.2.4.cmml"><mi id="S2.SS1.p5.3.m3.1.2.4.2" xref="S2.SS1.p5.3.m3.1.2.4.2.cmml">g</mi><mrow id="S2.SS1.p5.3.m3.1.2.4.3" xref="S2.SS1.p5.3.m3.1.2.4.3.cmml"><mi id="S2.SS1.p5.3.m3.1.2.4.3.2" xref="S2.SS1.p5.3.m3.1.2.4.3.2.cmml">i</mi><mo id="S2.SS1.p5.3.m3.1.2.4.3.1" xref="S2.SS1.p5.3.m3.1.2.4.3.1.cmml">â¢</mo><mi id="S2.SS1.p5.3.m3.1.2.4.3.3" xref="S2.SS1.p5.3.m3.1.2.4.3.3.cmml">n</mi></mrow></msub><mo id="S2.SS1.p5.3.m3.1.2.1b" xref="S2.SS1.p5.3.m3.1.2.1.cmml">â¢</mo><mrow id="S2.SS1.p5.3.m3.1.2.5.2" xref="S2.SS1.p5.3.m3.1.2.cmml"><mo id="S2.SS1.p5.3.m3.1.2.5.2.1" stretchy="false" xref="S2.SS1.p5.3.m3.1.2.cmml">(</mo><mi id="S2.SS1.p5.3.m3.1.1" xref="S2.SS1.p5.3.m3.1.1.cmml">v</mi><mo id="S2.SS1.p5.3.m3.1.2.5.2.2" stretchy="false" xref="S2.SS1.p5.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.3.m3.1b"><apply id="S2.SS1.p5.3.m3.1.2.cmml" xref="S2.SS1.p5.3.m3.1.2"><times id="S2.SS1.p5.3.m3.1.2.1.cmml" xref="S2.SS1.p5.3.m3.1.2.1"></times><ci id="S2.SS1.p5.3.m3.1.2.2.cmml" xref="S2.SS1.p5.3.m3.1.2.2">ğ‘‘</ci><ci id="S2.SS1.p5.3.m3.1.2.3.cmml" xref="S2.SS1.p5.3.m3.1.2.3">ğ‘’</ci><apply id="S2.SS1.p5.3.m3.1.2.4.cmml" xref="S2.SS1.p5.3.m3.1.2.4"><csymbol cd="ambiguous" id="S2.SS1.p5.3.m3.1.2.4.1.cmml" xref="S2.SS1.p5.3.m3.1.2.4">subscript</csymbol><ci id="S2.SS1.p5.3.m3.1.2.4.2.cmml" xref="S2.SS1.p5.3.m3.1.2.4.2">ğ‘”</ci><apply id="S2.SS1.p5.3.m3.1.2.4.3.cmml" xref="S2.SS1.p5.3.m3.1.2.4.3"><times id="S2.SS1.p5.3.m3.1.2.4.3.1.cmml" xref="S2.SS1.p5.3.m3.1.2.4.3.1"></times><ci id="S2.SS1.p5.3.m3.1.2.4.3.2.cmml" xref="S2.SS1.p5.3.m3.1.2.4.3.2">ğ‘–</ci><ci id="S2.SS1.p5.3.m3.1.2.4.3.3.cmml" xref="S2.SS1.p5.3.m3.1.2.4.3.3">ğ‘›</ci></apply></apply><ci id="S2.SS1.p5.3.m3.1.1.cmml" xref="S2.SS1.p5.3.m3.1.1">ğ‘£</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.3.m3.1c">deg_{in}(v)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.3.m3.1d">italic_d italic_e italic_g start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ( italic_v )</annotation></semantics></math> denotes the in-degree of vertex of vertex <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p5.4.m4.1"><semantics id="S2.SS1.p5.4.m4.1a"><mi id="S2.SS1.p5.4.m4.1.1" xref="S2.SS1.p5.4.m4.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.4.m4.1b"><ci id="S2.SS1.p5.4.m4.1.1.cmml" xref="S2.SS1.p5.4.m4.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.4.m4.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.4.m4.1d">italic_v</annotation></semantics></math>.
The update phase applies standard DNN operations, including a matrix multiplication and a ReLU activation function (i.e., <math alttext="\sigma" class="ltx_Math" display="inline" id="S2.SS1.p5.5.m5.1"><semantics id="S2.SS1.p5.5.m5.1a"><mi id="S2.SS1.p5.5.m5.1.1" xref="S2.SS1.p5.5.m5.1.1.cmml">Ïƒ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.5.m5.1b"><ci id="S2.SS1.p5.5.m5.1.1.cmml" xref="S2.SS1.p5.5.m5.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.5.m5.1c">\sigma</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p5.5.m5.1d">italic_Ïƒ</annotation></semantics></math>) to the aggregation result.</p>
</div>
<div class="ltx_para" id="S2.SS1.p6">
<p class="ltx_p" id="S2.SS1.p6.1">For complex GNN models, such as GAT <cite class="ltx_cite ltx_citemacro_citep">(Velickovic etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib38" title="">2018</a>)</cite>, which include edge-associated NN operations and vertex-associated NN operations. The computational formulas for GAT are as follows:</p>
</div>
<div class="ltx_para" id="S2.SS1.p7">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx5">
<tbody id="S2.E5"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(5)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle AGG:\begin{cases}a_{uv}^{l}=softmax(\widehat{\sigma}(a^{T}[W^{l}%
h_{u}^{l-1}||W^{l}h_{v}^{l-1}]))\\
a_{v}^{l}=\sum_{u\in N_{in}(v)}(a_{uv}^{l}h_{u}^{l-1})\end{cases}" class="ltx_math_unparsed" display="inline" id="S2.E5.m1.2"><semantics id="S2.E5.m1.2a"><mrow id="S2.E5.m1.2.3"><mrow id="S2.E5.m1.2.3.2"><mi id="S2.E5.m1.2.3.2.2">A</mi><mo id="S2.E5.m1.2.3.2.1">â¢</mo><mi id="S2.E5.m1.2.3.2.3">G</mi><mo id="S2.E5.m1.2.3.2.1a">â¢</mo><mi id="S2.E5.m1.2.3.2.4">G</mi></mrow><mo id="S2.E5.m1.2.3.1" lspace="0.278em" rspace="0.278em">:</mo><mrow id="S2.E5.m1.2.2a"><mo id="S2.E5.m1.2.2a.3">{</mo><mtable columnspacing="5pt" id="S2.E5.m1.2.2.2a" rowspacing="0pt"><mtr id="S2.E5.m1.2.2.2aa"><mtd class="ltx_align_left" columnalign="left" id="S2.E5.m1.2.2.2ab"><mrow id="S2.E5.m1.1.1.1.1.1.1"><msubsup id="S2.E5.m1.1.1.1.1.1.1.1"><mi id="S2.E5.m1.1.1.1.1.1.1.1.2.2">a</mi><mrow id="S2.E5.m1.1.1.1.1.1.1.1.2.3"><mi id="S2.E5.m1.1.1.1.1.1.1.1.2.3.2">u</mi><mo id="S2.E5.m1.1.1.1.1.1.1.1.2.3.1">â¢</mo><mi id="S2.E5.m1.1.1.1.1.1.1.1.2.3.3">v</mi></mrow><mi id="S2.E5.m1.1.1.1.1.1.1.1.3">l</mi></msubsup><mo id="S2.E5.m1.1.1.1.1.1.1.2">=</mo><mi id="S2.E5.m1.1.1.1.1.1.1.3">s</mi><mi id="S2.E5.m1.1.1.1.1.1.1.4">o</mi><mi id="S2.E5.m1.1.1.1.1.1.1.5">f</mi><mi id="S2.E5.m1.1.1.1.1.1.1.6">t</mi><mi id="S2.E5.m1.1.1.1.1.1.1.7">m</mi><mi id="S2.E5.m1.1.1.1.1.1.1.8">a</mi><mi id="S2.E5.m1.1.1.1.1.1.1.9">x</mi><mrow id="S2.E5.m1.1.1.1.1.1.1.10"><mo id="S2.E5.m1.1.1.1.1.1.1.10.1" stretchy="false">(</mo><mover accent="true" id="S2.E5.m1.1.1.1.1.1.1.10.2"><mi id="S2.E5.m1.1.1.1.1.1.1.10.2.2">Ïƒ</mi><mo id="S2.E5.m1.1.1.1.1.1.1.10.2.1">^</mo></mover><mrow id="S2.E5.m1.1.1.1.1.1.1.10.3"><mo id="S2.E5.m1.1.1.1.1.1.1.10.3.1" stretchy="false">(</mo><msup id="S2.E5.m1.1.1.1.1.1.1.10.3.2"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.2.2">a</mi><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.2.3">T</mi></msup><mrow id="S2.E5.m1.1.1.1.1.1.1.10.3.3"><mo id="S2.E5.m1.1.1.1.1.1.1.10.3.3.1" stretchy="false">[</mo><msup id="S2.E5.m1.1.1.1.1.1.1.10.3.3.2"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.2.2">W</mi><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.2.3">l</mi></msup><msubsup id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3.2.2">h</mi><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3.2.3">u</mi><mrow id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3.3"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3.3.2">l</mi><mo id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3.3.1">âˆ’</mo><mn id="S2.E5.m1.1.1.1.1.1.1.10.3.3.3.3.3">1</mn></mrow></msubsup><mo fence="false" id="S2.E5.m1.1.1.1.1.1.1.10.3.3.4" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S2.E5.m1.1.1.1.1.1.1.10.3.3.5" rspace="0.167em" stretchy="false">|</mo><msup id="S2.E5.m1.1.1.1.1.1.1.10.3.3.6"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.6.2">W</mi><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.6.3">l</mi></msup><msubsup id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7.2.2">h</mi><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7.2.3">v</mi><mrow id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7.3"><mi id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7.3.2">l</mi><mo id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7.3.1">âˆ’</mo><mn id="S2.E5.m1.1.1.1.1.1.1.10.3.3.7.3.3">1</mn></mrow></msubsup><mo id="S2.E5.m1.1.1.1.1.1.1.10.3.3.8" stretchy="false">]</mo></mrow><mo id="S2.E5.m1.1.1.1.1.1.1.10.3.4" stretchy="false">)</mo></mrow><mo id="S2.E5.m1.1.1.1.1.1.1.10.4" stretchy="false">)</mo></mrow></mrow></mtd><mtd id="S2.E5.m1.2.2.2ac"></mtd></mtr><mtr id="S2.E5.m1.2.2.2ad"><mtd class="ltx_align_left" columnalign="left" id="S2.E5.m1.2.2.2ae"><mrow id="S2.E5.m1.2.2.2.2.1.1"><msubsup id="S2.E5.m1.2.2.2.2.1.1.4"><mi id="S2.E5.m1.2.2.2.2.1.1.4.2.2">a</mi><mi id="S2.E5.m1.2.2.2.2.1.1.4.2.3">v</mi><mi id="S2.E5.m1.2.2.2.2.1.1.4.3">l</mi></msubsup><mo id="S2.E5.m1.2.2.2.2.1.1.3" rspace="0.111em">=</mo><mrow id="S2.E5.m1.2.2.2.2.1.1.2"><msub id="S2.E5.m1.2.2.2.2.1.1.2.2"><mo id="S2.E5.m1.2.2.2.2.1.1.2.2.2" rspace="0em">âˆ‘</mo><mrow id="S2.E5.m1.2.2.2.2.1.1.1.1"><mi id="S2.E5.m1.2.2.2.2.1.1.1.1.3">u</mi><mo id="S2.E5.m1.2.2.2.2.1.1.1.1.2">âˆˆ</mo><mrow id="S2.E5.m1.2.2.2.2.1.1.1.1.4"><msub id="S2.E5.m1.2.2.2.2.1.1.1.1.4.2"><mi id="S2.E5.m1.2.2.2.2.1.1.1.1.4.2.2">N</mi><mrow id="S2.E5.m1.2.2.2.2.1.1.1.1.4.2.3"><mi id="S2.E5.m1.2.2.2.2.1.1.1.1.4.2.3.2">i</mi><mo id="S2.E5.m1.2.2.2.2.1.1.1.1.4.2.3.1">â¢</mo><mi id="S2.E5.m1.2.2.2.2.1.1.1.1.4.2.3.3">n</mi></mrow></msub><mo id="S2.E5.m1.2.2.2.2.1.1.1.1.4.1">â¢</mo><mrow id="S2.E5.m1.2.2.2.2.1.1.1.1.4.3.2"><mo id="S2.E5.m1.2.2.2.2.1.1.1.1.4.3.2.1" stretchy="false">(</mo><mi id="S2.E5.m1.2.2.2.2.1.1.1.1.1">v</mi><mo id="S2.E5.m1.2.2.2.2.1.1.1.1.4.3.2.2" stretchy="false">)</mo></mrow></mrow></mrow></msub><mrow id="S2.E5.m1.2.2.2.2.1.1.2.1.1"><mo id="S2.E5.m1.2.2.2.2.1.1.2.1.1.2" stretchy="false">(</mo><mrow id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1"><msubsup id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2"><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.2">a</mi><mrow id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.3"><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.3.2">u</mi><mo id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.3.1">â¢</mo><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2.2.3.3">v</mi></mrow><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.2.3">l</mi></msubsup><mo id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.1">â¢</mo><msubsup id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3"><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3.2.2">h</mi><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3.2.3">u</mi><mrow id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3.3"><mi id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3.3.2">l</mi><mo id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3.3.1">âˆ’</mo><mn id="S2.E5.m1.2.2.2.2.1.1.2.1.1.1.3.3.3">1</mn></mrow></msubsup></mrow><mo id="S2.E5.m1.2.2.2.2.1.1.2.1.1.3" stretchy="false">)</mo></mrow></mrow></mrow></mtd><mtd id="S2.E5.m1.2.2.2af"></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex" id="S2.E5.m1.2b">\displaystyle AGG:\begin{cases}a_{uv}^{l}=softmax(\widehat{\sigma}(a^{T}[W^{l}%
h_{u}^{l-1}||W^{l}h_{v}^{l-1}]))\\
a_{v}^{l}=\sum_{u\in N_{in}(v)}(a_{uv}^{l}h_{u}^{l-1})\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S2.E5.m1.2c">italic_A italic_G italic_G : { start_ROW start_CELL italic_a start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = italic_s italic_o italic_f italic_t italic_m italic_a italic_x ( over^ start_ARG italic_Ïƒ end_ARG ( italic_a start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT [ italic_W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT italic_h start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l - 1 end_POSTSUPERSCRIPT | | italic_W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l - 1 end_POSTSUPERSCRIPT ] ) ) end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = âˆ‘ start_POSTSUBSCRIPT italic_u âˆˆ italic_N start_POSTSUBSCRIPT italic_i italic_n end_POSTSUBSCRIPT ( italic_v ) end_POSTSUBSCRIPT ( italic_a start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT italic_h start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l - 1 end_POSTSUPERSCRIPT ) end_CELL start_CELL end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.SS1.p8">
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx6">
<tbody id="S2.E6"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(6)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle UPDATE:h_{v}^{l}=\sigma(W^{l}a_{v}^{l})" class="ltx_Math" display="inline" id="S2.E6.m1.1"><semantics id="S2.E6.m1.1a"><mrow id="S2.E6.m1.1.1" xref="S2.E6.m1.1.1.cmml"><mrow id="S2.E6.m1.1.1.3" xref="S2.E6.m1.1.1.3.cmml"><mi id="S2.E6.m1.1.1.3.2" xref="S2.E6.m1.1.1.3.2.cmml">U</mi><mo id="S2.E6.m1.1.1.3.1" xref="S2.E6.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E6.m1.1.1.3.3" xref="S2.E6.m1.1.1.3.3.cmml">P</mi><mo id="S2.E6.m1.1.1.3.1a" xref="S2.E6.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E6.m1.1.1.3.4" xref="S2.E6.m1.1.1.3.4.cmml">D</mi><mo id="S2.E6.m1.1.1.3.1b" xref="S2.E6.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E6.m1.1.1.3.5" xref="S2.E6.m1.1.1.3.5.cmml">A</mi><mo id="S2.E6.m1.1.1.3.1c" xref="S2.E6.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E6.m1.1.1.3.6" xref="S2.E6.m1.1.1.3.6.cmml">T</mi><mo id="S2.E6.m1.1.1.3.1d" xref="S2.E6.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.E6.m1.1.1.3.7" xref="S2.E6.m1.1.1.3.7.cmml">E</mi></mrow><mo id="S2.E6.m1.1.1.2" lspace="0.278em" rspace="0.278em" xref="S2.E6.m1.1.1.2.cmml">:</mo><mrow id="S2.E6.m1.1.1.1" xref="S2.E6.m1.1.1.1.cmml"><msubsup id="S2.E6.m1.1.1.1.3" xref="S2.E6.m1.1.1.1.3.cmml"><mi id="S2.E6.m1.1.1.1.3.2.2" xref="S2.E6.m1.1.1.1.3.2.2.cmml">h</mi><mi id="S2.E6.m1.1.1.1.3.2.3" xref="S2.E6.m1.1.1.1.3.2.3.cmml">v</mi><mi id="S2.E6.m1.1.1.1.3.3" xref="S2.E6.m1.1.1.1.3.3.cmml">l</mi></msubsup><mo id="S2.E6.m1.1.1.1.2" xref="S2.E6.m1.1.1.1.2.cmml">=</mo><mrow id="S2.E6.m1.1.1.1.1" xref="S2.E6.m1.1.1.1.1.cmml"><mi id="S2.E6.m1.1.1.1.1.3" xref="S2.E6.m1.1.1.1.1.3.cmml">Ïƒ</mi><mo id="S2.E6.m1.1.1.1.1.2" xref="S2.E6.m1.1.1.1.1.2.cmml">â¢</mo><mrow id="S2.E6.m1.1.1.1.1.1.1" xref="S2.E6.m1.1.1.1.1.1.1.1.cmml"><mo id="S2.E6.m1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E6.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E6.m1.1.1.1.1.1.1.1" xref="S2.E6.m1.1.1.1.1.1.1.1.cmml"><msup id="S2.E6.m1.1.1.1.1.1.1.1.2" xref="S2.E6.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E6.m1.1.1.1.1.1.1.1.2.2" xref="S2.E6.m1.1.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="S2.E6.m1.1.1.1.1.1.1.1.2.3" xref="S2.E6.m1.1.1.1.1.1.1.1.2.3.cmml">l</mi></msup><mo id="S2.E6.m1.1.1.1.1.1.1.1.1" xref="S2.E6.m1.1.1.1.1.1.1.1.1.cmml">â¢</mo><msubsup id="S2.E6.m1.1.1.1.1.1.1.1.3" xref="S2.E6.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E6.m1.1.1.1.1.1.1.1.3.2.2" xref="S2.E6.m1.1.1.1.1.1.1.1.3.2.2.cmml">a</mi><mi id="S2.E6.m1.1.1.1.1.1.1.1.3.2.3" xref="S2.E6.m1.1.1.1.1.1.1.1.3.2.3.cmml">v</mi><mi id="S2.E6.m1.1.1.1.1.1.1.1.3.3" xref="S2.E6.m1.1.1.1.1.1.1.1.3.3.cmml">l</mi></msubsup></mrow><mo id="S2.E6.m1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E6.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E6.m1.1b"><apply id="S2.E6.m1.1.1.cmml" xref="S2.E6.m1.1.1"><ci id="S2.E6.m1.1.1.2.cmml" xref="S2.E6.m1.1.1.2">:</ci><apply id="S2.E6.m1.1.1.3.cmml" xref="S2.E6.m1.1.1.3"><times id="S2.E6.m1.1.1.3.1.cmml" xref="S2.E6.m1.1.1.3.1"></times><ci id="S2.E6.m1.1.1.3.2.cmml" xref="S2.E6.m1.1.1.3.2">ğ‘ˆ</ci><ci id="S2.E6.m1.1.1.3.3.cmml" xref="S2.E6.m1.1.1.3.3">ğ‘ƒ</ci><ci id="S2.E6.m1.1.1.3.4.cmml" xref="S2.E6.m1.1.1.3.4">ğ·</ci><ci id="S2.E6.m1.1.1.3.5.cmml" xref="S2.E6.m1.1.1.3.5">ğ´</ci><ci id="S2.E6.m1.1.1.3.6.cmml" xref="S2.E6.m1.1.1.3.6">ğ‘‡</ci><ci id="S2.E6.m1.1.1.3.7.cmml" xref="S2.E6.m1.1.1.3.7">ğ¸</ci></apply><apply id="S2.E6.m1.1.1.1.cmml" xref="S2.E6.m1.1.1.1"><eq id="S2.E6.m1.1.1.1.2.cmml" xref="S2.E6.m1.1.1.1.2"></eq><apply id="S2.E6.m1.1.1.1.3.cmml" xref="S2.E6.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.3.1.cmml" xref="S2.E6.m1.1.1.1.3">superscript</csymbol><apply id="S2.E6.m1.1.1.1.3.2.cmml" xref="S2.E6.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.3.2.1.cmml" xref="S2.E6.m1.1.1.1.3">subscript</csymbol><ci id="S2.E6.m1.1.1.1.3.2.2.cmml" xref="S2.E6.m1.1.1.1.3.2.2">â„</ci><ci id="S2.E6.m1.1.1.1.3.2.3.cmml" xref="S2.E6.m1.1.1.1.3.2.3">ğ‘£</ci></apply><ci id="S2.E6.m1.1.1.1.3.3.cmml" xref="S2.E6.m1.1.1.1.3.3">ğ‘™</ci></apply><apply id="S2.E6.m1.1.1.1.1.cmml" xref="S2.E6.m1.1.1.1.1"><times id="S2.E6.m1.1.1.1.1.2.cmml" xref="S2.E6.m1.1.1.1.1.2"></times><ci id="S2.E6.m1.1.1.1.1.3.cmml" xref="S2.E6.m1.1.1.1.1.3">ğœ</ci><apply id="S2.E6.m1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1"><times id="S2.E6.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.1"></times><apply id="S2.E6.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S2.E6.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.2.2">ğ‘Š</ci><ci id="S2.E6.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.2.3">ğ‘™</ci></apply><apply id="S2.E6.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3">superscript</csymbol><apply id="S2.E6.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E6.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E6.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3.2.2">ğ‘</ci><ci id="S2.E6.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3.2.3">ğ‘£</ci></apply><ci id="S2.E6.m1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E6.m1.1.1.1.1.1.1.1.3.3">ğ‘™</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E6.m1.1c">\displaystyle UPDATE:h_{v}^{l}=\sigma(W^{l}a_{v}^{l})</annotation><annotation encoding="application/x-llamapun" id="S2.E6.m1.1d">italic_U italic_P italic_D italic_A italic_T italic_E : italic_h start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT = italic_Ïƒ ( italic_W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p9">
<p class="ltx_p" id="S2.SS1.p9.7">The aggregate phase first needs to assign an edge weight <math alttext="a_{uv}" class="ltx_Math" display="inline" id="S2.SS1.p9.1.m1.1"><semantics id="S2.SS1.p9.1.m1.1a"><msub id="S2.SS1.p9.1.m1.1.1" xref="S2.SS1.p9.1.m1.1.1.cmml"><mi id="S2.SS1.p9.1.m1.1.1.2" xref="S2.SS1.p9.1.m1.1.1.2.cmml">a</mi><mrow id="S2.SS1.p9.1.m1.1.1.3" xref="S2.SS1.p9.1.m1.1.1.3.cmml"><mi id="S2.SS1.p9.1.m1.1.1.3.2" xref="S2.SS1.p9.1.m1.1.1.3.2.cmml">u</mi><mo id="S2.SS1.p9.1.m1.1.1.3.1" xref="S2.SS1.p9.1.m1.1.1.3.1.cmml">â¢</mo><mi id="S2.SS1.p9.1.m1.1.1.3.3" xref="S2.SS1.p9.1.m1.1.1.3.3.cmml">v</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.1.m1.1b"><apply id="S2.SS1.p9.1.m1.1.1.cmml" xref="S2.SS1.p9.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p9.1.m1.1.1.1.cmml" xref="S2.SS1.p9.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p9.1.m1.1.1.2.cmml" xref="S2.SS1.p9.1.m1.1.1.2">ğ‘</ci><apply id="S2.SS1.p9.1.m1.1.1.3.cmml" xref="S2.SS1.p9.1.m1.1.1.3"><times id="S2.SS1.p9.1.m1.1.1.3.1.cmml" xref="S2.SS1.p9.1.m1.1.1.3.1"></times><ci id="S2.SS1.p9.1.m1.1.1.3.2.cmml" xref="S2.SS1.p9.1.m1.1.1.3.2">ğ‘¢</ci><ci id="S2.SS1.p9.1.m1.1.1.3.3.cmml" xref="S2.SS1.p9.1.m1.1.1.3.3">ğ‘£</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.1.m1.1c">a_{uv}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.1.m1.1d">italic_a start_POSTSUBSCRIPT italic_u italic_v end_POSTSUBSCRIPT</annotation></semantics></math> for each incoming edge to vertex <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p9.2.m2.1"><semantics id="S2.SS1.p9.2.m2.1a"><mi id="S2.SS1.p9.2.m2.1.1" xref="S2.SS1.p9.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.2.m2.1b"><ci id="S2.SS1.p9.2.m2.1.1.cmml" xref="S2.SS1.p9.2.m2.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.2.m2.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.2.m2.1d">italic_v</annotation></semantics></math>. This process involves concatenating (i.e., <math alttext="[\cdot||\cdot]" class="ltx_math_unparsed" display="inline" id="S2.SS1.p9.3.m3.1"><semantics id="S2.SS1.p9.3.m3.1a"><mrow id="S2.SS1.p9.3.m3.1b"><mo id="S2.SS1.p9.3.m3.1.1" stretchy="false">[</mo><mo id="S2.SS1.p9.3.m3.1.2" lspace="0em" rspace="0em">â‹…</mo><mo fence="false" id="S2.SS1.p9.3.m3.1.3" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S2.SS1.p9.3.m3.1.4" stretchy="false">|</mo><mo id="S2.SS1.p9.3.m3.1.5" lspace="0em" rspace="0em">â‹…</mo><mo id="S2.SS1.p9.3.m3.1.6" stretchy="false">]</mo></mrow><annotation encoding="application/x-tex" id="S2.SS1.p9.3.m3.1c">[\cdot||\cdot]</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.3.m3.1d">[ â‹… | | â‹… ]</annotation></semantics></math>) and mapping (i.e., <math alttext="a^{T}" class="ltx_Math" display="inline" id="S2.SS1.p9.4.m4.1"><semantics id="S2.SS1.p9.4.m4.1a"><msup id="S2.SS1.p9.4.m4.1.1" xref="S2.SS1.p9.4.m4.1.1.cmml"><mi id="S2.SS1.p9.4.m4.1.1.2" xref="S2.SS1.p9.4.m4.1.1.2.cmml">a</mi><mi id="S2.SS1.p9.4.m4.1.1.3" xref="S2.SS1.p9.4.m4.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.4.m4.1b"><apply id="S2.SS1.p9.4.m4.1.1.cmml" xref="S2.SS1.p9.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p9.4.m4.1.1.1.cmml" xref="S2.SS1.p9.4.m4.1.1">superscript</csymbol><ci id="S2.SS1.p9.4.m4.1.1.2.cmml" xref="S2.SS1.p9.4.m4.1.1.2">ğ‘</ci><ci id="S2.SS1.p9.4.m4.1.1.3.cmml" xref="S2.SS1.p9.4.m4.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.4.m4.1c">a^{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.4.m4.1d">italic_a start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>) the parameterized representations of the source <math alttext="u" class="ltx_Math" display="inline" id="S2.SS1.p9.5.m5.1"><semantics id="S2.SS1.p9.5.m5.1a"><mi id="S2.SS1.p9.5.m5.1.1" xref="S2.SS1.p9.5.m5.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.5.m5.1b"><ci id="S2.SS1.p9.5.m5.1.1.cmml" xref="S2.SS1.p9.5.m5.1.1">ğ‘¢</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.5.m5.1c">u</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.5.m5.1d">italic_u</annotation></semantics></math> and destination <math alttext="v" class="ltx_Math" display="inline" id="S2.SS1.p9.6.m6.1"><semantics id="S2.SS1.p9.6.m6.1a"><mi id="S2.SS1.p9.6.m6.1.1" xref="S2.SS1.p9.6.m6.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.6.m6.1b"><ci id="S2.SS1.p9.6.m6.1.1.cmml" xref="S2.SS1.p9.6.m6.1.1">ğ‘£</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.6.m6.1c">v</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.6.m6.1d">italic_v</annotation></semantics></math> to derive edge-wise attention coefficients. Then, these coefficients are fed to a LeakyReLU activation function (i.e., <math alttext="\widehat{\sigma}" class="ltx_Math" display="inline" id="S2.SS1.p9.7.m7.1"><semantics id="S2.SS1.p9.7.m7.1a"><mover accent="true" id="S2.SS1.p9.7.m7.1.1" xref="S2.SS1.p9.7.m7.1.1.cmml"><mi id="S2.SS1.p9.7.m7.1.1.2" xref="S2.SS1.p9.7.m7.1.1.2.cmml">Ïƒ</mi><mo id="S2.SS1.p9.7.m7.1.1.1" xref="S2.SS1.p9.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S2.SS1.p9.7.m7.1b"><apply id="S2.SS1.p9.7.m7.1.1.cmml" xref="S2.SS1.p9.7.m7.1.1"><ci id="S2.SS1.p9.7.m7.1.1.1.cmml" xref="S2.SS1.p9.7.m7.1.1.1">^</ci><ci id="S2.SS1.p9.7.m7.1.1.2.cmml" xref="S2.SS1.p9.7.m7.1.1.2">ğœ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p9.7.m7.1c">\widehat{\sigma}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p9.7.m7.1d">over^ start_ARG italic_Ïƒ end_ARG</annotation></semantics></math>) and use a softmax function to compute normalized edge weight for subsequent neighborhood aggregation. The update phase is the same as GCN.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="290" id="S2.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>GNN training workload of 4 partitions under different partitioning methods. (2-layer GCN on Reddit)</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Distributed GNN Training with Data Parallelism</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">When dealing with large-scale graphs, single machinesâ€™ limited memory and computational resources become bottlenecks for large-scale GNN training. Distributed computing offers sufficient computational resources, thereby enhancing training efficiency.
Existing GNN systems <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>; Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Ma etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib25" title="">2019</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>; Zhu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib59" title="">2019</a>)</cite> leverage data parallelism by partitioning the input graph and distributing it to multiple workers to train the same GNN model collaboratively. However, due to the graph aggregation operations in GNNs, which create vertex dependencies across these partitions, these graph partitions cannot be processed independently.
In NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite>, the authors summarize the current GNN systems into two categories according to the way they manage vertex dependencies: Dependency Cache (DepCache) methods and Dependency Communication (DepComm) methods. The GNN systems <cite class="ltx_cite ltx_citemacro_citep">(Zhu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib59" title="">2019</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib52" title="">2020</a>; Gandhi and Iyer, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib12" title="">2021</a>)</cite> employ the DepCache methods to replicate data of neighboring nodes from partitions outside to the local worker, enabling independent GNN training locally but incurring redundant computations.
In contrast, systems <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>; Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>; Md etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib26" title="">2021</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib39" title="">2022a</a>)</cite> employing the DepComm methods collect data of neighboring vertices through communication from remote workers. While avoiding redundant computations, these systems incur necessary communication costs.
The irregular nature of the graph causes extensive cross-worker vertex dependencies in data parallelism and thereby increases the difficulty of high-performance distributed GNN training. We summarize two major limitations below.</p>
</div>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="309" id="S2.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>The VD management overhead of DistDGL and NeutronStar.</figcaption>
</figure>
<figure class="ltx_figure" id="S2.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="298" id="S2.F5.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>The number of vertex dependencie of DistDGL and NeutronStar.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Limitation #1:Workload imbalance. </span>
Distributed GNN training with data parallelism is prone to workload imbalance due to the skewed interconnection structure of graphs.
To confirm our analysis, we employ Chunk-based graph partitioning and METIS-based graph partitioning in NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite>, evaluating the balance between computational and communication loads across each partition. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2.F3" title="Figure 3 â€£ 2.1. Graph Neural Networks â€£ 2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">3</span></a>.
The chunk-based graph partitioning strategy, employed by systems such as NeuGraph <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib25" title="">2019</a>)</cite>, ROC <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>)</cite>, and NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite>, divides the graph into chunks where nodes are arranged with consecutive IDs. Although this method achieves vertex balance, it may lead to significant workload imbalance because it does not account for the edge distribution among workers. On the other hand, the METIS algorithm, utilized by DistDGL <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>, SANCUS <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>)</cite>, and BNS-GCN <cite class="ltx_cite ltx_citemacro_citep">(Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib39" title="">2022a</a>)</cite>, aims to minimize cross-worker edges (i.e., edge-cuts) in its partitioning decisions. However, focusing on minimizing edge cuts does not guarantee balanced remote and local vertices within each partition, resulting in varied communication and computation loads across workers.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.8"><span class="ltx_text ltx_font_bold" id="S2.SS2.p3.8.1">Limitation #2:High overhead in managing cross-worker vertex dependencies. </span>
Managing vertex dependency (VD) constitutes the primary overhead in GNN data parallelism. Furthermore, as the cluster scale expands or model layers deepen, the proportion of VD management overhead further increases. To confirm our analysis, we analyze VD management overhead in DistDGL <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite> and NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite> when altering the cluster scale or model layer. We measure the proportion of VD management overhead by accounting for communication time and redundant computation time and quantify VDâ€™s scale by calculating communication and redundant computation edges.
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2.F4" title="Figure 4 â€£ 2.2. Distributed GNN Training with Data Parallelism â€£ 2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">4</span></a>, across different cluster sizes and model layers, the VD management overhead in DistDGL and NeutronStar averages 80.6% and 46.5% of the total execution time, respectively.
Furthermore, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S2.F5" title="Figure 5 â€£ 2.2. Distributed GNN Training with Data Parallelism â€£ 2. Background and Motivation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">5</span></a>, no matter increasing the number of partitions and workers or deepening models, the VD scale can be substantially increased.
When the number of workers scales from 2 to 16, the time proportion of VD management overhead in DistDGL and NeutronStar increases by 1.21<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mo id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><times id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">Ã—</annotation></semantics></math> and 1.45<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><mo id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><times id="S2.SS2.p3.2.m2.1.1.cmml" xref="S2.SS2.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">Ã—</annotation></semantics></math>, respectively, with the VD scale increasing by 8.1<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m3.1"><semantics id="S2.SS2.p3.3.m3.1a"><mo id="S2.SS2.p3.3.m3.1.1" xref="S2.SS2.p3.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m3.1b"><times id="S2.SS2.p3.3.m3.1.1.cmml" xref="S2.SS2.p3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m3.1d">Ã—</annotation></semantics></math> and 6.2<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m4.1"><semantics id="S2.SS2.p3.4.m4.1a"><mo id="S2.SS2.p3.4.m4.1.1" xref="S2.SS2.p3.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m4.1b"><times id="S2.SS2.p3.4.m4.1.1.cmml" xref="S2.SS2.p3.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m4.1d">Ã—</annotation></semantics></math>, respectively. Similarly, as increases the model layer from 2 to 5, the time proportion of VD management overhead in DistDGL and NeutronStar increases by 1.22<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.5.m5.1"><semantics id="S2.SS2.p3.5.m5.1a"><mo id="S2.SS2.p3.5.m5.1.1" xref="S2.SS2.p3.5.m5.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m5.1b"><times id="S2.SS2.p3.5.m5.1.1.cmml" xref="S2.SS2.p3.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.5.m5.1d">Ã—</annotation></semantics></math> and 1.06<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.6.m6.1"><semantics id="S2.SS2.p3.6.m6.1a"><mo id="S2.SS2.p3.6.m6.1.1" xref="S2.SS2.p3.6.m6.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m6.1b"><times id="S2.SS2.p3.6.m6.1.1.cmml" xref="S2.SS2.p3.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.6.m6.1d">Ã—</annotation></semantics></math>, respectively, with the VD scale increasing by 7.7<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.7.m7.1"><semantics id="S2.SS2.p3.7.m7.1a"><mo id="S2.SS2.p3.7.m7.1.1" xref="S2.SS2.p3.7.m7.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m7.1b"><times id="S2.SS2.p3.7.m7.1.1.cmml" xref="S2.SS2.p3.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m7.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.7.m7.1d">Ã—</annotation></semantics></math> and 3.0<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS2.p3.8.m8.1"><semantics id="S2.SS2.p3.8.m8.1a"><mo id="S2.SS2.p3.8.m8.1.1" xref="S2.SS2.p3.8.m8.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.8.m8.1b"><times id="S2.SS2.p3.8.m8.1.1.cmml" xref="S2.SS2.p3.8.m8.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.8.m8.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.8.m8.1d">Ã—</annotation></semantics></math>, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Opportunity: Tensor Parallelism</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Avoiding partitioning the graph structure across different workers is crucial to mitigating the limitations outlined above.
Therefore, we exploit tensor parallelism for distributed GNN training, partitioning vertex features instead of the graph structure, thereby eliminating cross-worker vertex dependencies while ensuring load balancing.
Inspired by DNN tensor parallelism <cite class="ltx_cite ltx_citemacro_citep">(Shoeybi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib34" title="">2019</a>)</cite> that supports DNN training with large-scale model data by partitioning model parameters instead of data samples. We extend tensor parallelism to distributed GNN training and change the partitioning target from model parameters to vertex data, as the memory overhead of GNN training mainly stems from vertex data (i.e., features and embeddings), while model data is typically small. Past DNN works employ multidimensional partitioning, such as 2D <cite class="ltx_cite ltx_citemacro_citep">(Xu and You, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib48" title="">2023</a>)</cite>, 2.5D <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib42" title="">2021</a>)</cite>, and 3D <cite class="ltx_cite ltx_citemacro_citep">(Bian etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib4" title="">2021</a>)</cite> partitioning, to reduce the communication and memory overhead in tensor parallelism. These multidimensional partitioning methods further partition DNN data samples into multiple disjoint subsets for matrix operations with model parameter subsets.
However, due to the unique graph aggregation training semantics of GNNs, further partitioning GNN data samples (i.e., graph data) reintroduces vertex dependencies. This renders us unable to directly apply past DNN tensor parallelism methods to optimize the efficiency of GNN tensor parallelism.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">Recent works in vertical feature partitioning. </span>
We note that some recent studies <cite class="ltx_cite ltx_citemacro_citep">(Gandhi and Iyer, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib12" title="">2021</a>; Du etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib7" title="">2023</a>)</cite> explore vertical feature partitioning in distributed GNN training. However, they employ feature partitioning approach only in partial training processes and focus on reducing the feature communication overhead (See Section <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S6" title="6. Related work â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">6</span></a> for details).
This feature partitioning approach cannot guarantee load balancing in the end-to-end training because most training still employs data parallelism. In contrast, we explore tensor parallelism throughout the entire training process, vertically partitioning both features and embeddings across all layers, achieving complete load balancing.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>GNN Tensor Parallelism</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we provide a detailed exposition of the workflow involved in GNN tensor parallelism and elucidate its advantages and challenges through workload analysis.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>GNN Tensor Parallelism Workflow</h3>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="227" id="S3.F6.g1" src="x6.png" width="436"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>GNN tensor parallelism workflow for a single layer.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.3">Unlike GNN data parallelism, which partitions the graph topology, GNN tensor parallelism vertically partitions vertex features along dimensions, where each worker is responsible for the complete graph GNN training of different feature slices with the same dimensional size.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S3.F6" title="Figure 6 â€£ 3.1. GNN Tensor Parallelism Workflow â€£ 3. GNN Tensor Parallelism â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the single-layer training workflow for GNN tensor parallelism. Initially, the feature vectors of the vertices are evenly partitioned among all workers according to their feature dimensions, i.e., each worker holds <math alttext="\frac{D}{N}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mfrac id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">D</mi><mi id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">N</mi></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><divide id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"></divide><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">ğ·</ci><ci id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\frac{D}{N}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">divide start_ARG italic_D end_ARG start_ARG italic_N end_ARG</annotation></semantics></math> dimensions of the feature vectors where <math alttext="D" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_D</annotation></semantics></math> is the total number of vertex feature dimensions, and <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_N</annotation></semantics></math> is the number of workers. <span class="ltx_text" id="S3.SS1.p1.3.1" style="color:#000000;">The GNN tensor parallelism directly leverages the structure of the raw graph for its computations. Specifically, at each layer of the GNN model, every vertex aggregates information from all its neighboring vertices along the incoming edges and then applies NN operations.</span></p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.3">Each worker stores the complete graph structure and conducts full-neighbor aggregation operations locally (âŠ).
Before the start of NN computations, a <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.3.1">gather</span> operation is performed to obtain complete vertex embeddings because nonlinear operations in NN computations cannot be partially computed (â‹). To ensure the uniform distribution of NN computation tasks and communication tasks across different workers, each worker is responsible for computing and communicating with <math alttext="\frac{V}{N}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mfrac id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">V</mi><mi id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">N</mi></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><divide id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"></divide><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">ğ‘‰</ci><ci id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\frac{V}{N}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">divide start_ARG italic_V end_ARG start_ARG italic_N end_ARG</annotation></semantics></math> vertices, where <math alttext="V" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mi id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><ci id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_V</annotation></semantics></math> represents the total number of vertices and <math alttext="N" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mi id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><ci id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_N</annotation></semantics></math> denotes the number of workers. All workers initiate <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.3.2">gather</span> operations simultaneously, sending local embedding slices to the corresponding workers. Subsequently, each worker commences the NN computation tasks for local vertices (âŒ). Finally, upon completion of NN computations, all workers initiate <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.3.3">split</span> operations simultaneously to re-segment local embeddings and send them to the corresponding workers to continue the next layer of GNN training (â).
The <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.3.4">gather</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS1.p2.3.5">split</span> operations are implemented by collective communication libraries such as NCCL <cite class="ltx_cite ltx_citemacro_citep">(NVIDIA., <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib29" title="">2021</a>)</cite> and Gloo <cite class="ltx_cite ltx_citemacro_citep">(Facebook., <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib9" title="">2021</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Workload Analysis</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.12"><span class="ltx_text" id="S3.SS2.p1.12.12" style="color:#000000;">GNN tensor parallelism achieves a well-balanced computation and communication load by evenly partitioning vertex features along dimensions.
In the computation process, each worker handles the full-graph aggregation operations of the same dimension feature slices and performs NN computations for the same number of vertices. The time and space complexities of graph aggregation operation are <math alttext="O(E\frac{D}{N})" class="ltx_Math" display="inline" id="S3.SS2.p1.1.1.m1.1"><semantics id="S3.SS2.p1.1.1.m1.1a"><mrow id="S3.SS2.p1.1.1.m1.1.1" xref="S3.SS2.p1.1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.1.m1.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.1.1.m1.1.1.3.cmml">O</mi><mo id="S3.SS2.p1.1.1.m1.1.1.2" xref="S3.SS2.p1.1.1.m1.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p1.1.1.m1.1.1.1.1" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.cmml"><mo id="S3.SS2.p1.1.1.m1.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.1.1.m1.1.1.1.1.1" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.1.1.m1.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.2.cmml">E</mi><mo id="S3.SS2.p1.1.1.m1.1.1.1.1.1.1" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.1.cmml">â¢</mo><mfrac id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.2.cmml">D</mi><mi id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.3.cmml">N</mi></mfrac></mrow><mo id="S3.SS2.p1.1.1.m1.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.1.m1.1b"><apply id="S3.SS2.p1.1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.1.m1.1.1"><times id="S3.SS2.p1.1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.1.m1.1.1.2"></times><ci id="S3.SS2.p1.1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.1.m1.1.1.3">ğ‘‚</ci><apply id="S3.SS2.p1.1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1"><times id="S3.SS2.p1.1.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.1"></times><ci id="S3.SS2.p1.1.1.m1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.2">ğ¸</ci><apply id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3"><divide id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3"></divide><ci id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.2">ğ·</ci><ci id="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.1.1.m1.1.1.1.1.1.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.1.m1.1c">O(E\frac{D}{N})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.1.m1.1d">italic_O ( italic_E divide start_ARG italic_D end_ARG start_ARG italic_N end_ARG )</annotation></semantics></math> and <math alttext="O(V\frac{D}{N})" class="ltx_Math" display="inline" id="S3.SS2.p1.2.2.m2.1"><semantics id="S3.SS2.p1.2.2.m2.1a"><mrow id="S3.SS2.p1.2.2.m2.1.1" xref="S3.SS2.p1.2.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.2.m2.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.2.2.m2.1.1.3.cmml">O</mi><mo id="S3.SS2.p1.2.2.m2.1.1.2" xref="S3.SS2.p1.2.2.m2.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p1.2.2.m2.1.1.1.1" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.p1.2.2.m2.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.2.2.m2.1.1.1.1.1" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.2.2.m2.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.2.cmml">V</mi><mo id="S3.SS2.p1.2.2.m2.1.1.1.1.1.1" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.1.cmml">â¢</mo><mfrac id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.2.cmml">D</mi><mi id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.3.cmml">N</mi></mfrac></mrow><mo id="S3.SS2.p1.2.2.m2.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.2.m2.1b"><apply id="S3.SS2.p1.2.2.m2.1.1.cmml" xref="S3.SS2.p1.2.2.m2.1.1"><times id="S3.SS2.p1.2.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.2.m2.1.1.2"></times><ci id="S3.SS2.p1.2.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.2.m2.1.1.3">ğ‘‚</ci><apply id="S3.SS2.p1.2.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1"><times id="S3.SS2.p1.2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.1"></times><ci id="S3.SS2.p1.2.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.2">ğ‘‰</ci><apply id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3"><divide id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3"></divide><ci id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.2">ğ·</ci><ci id="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.3.cmml" xref="S3.SS2.p1.2.2.m2.1.1.1.1.1.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.2.m2.1c">O(V\frac{D}{N})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.2.m2.1d">italic_O ( italic_V divide start_ARG italic_D end_ARG start_ARG italic_N end_ARG )</annotation></semantics></math>, respectively. The time and space complexities of NN operation are <math alttext="O(\frac{V}{N}D^{2})" class="ltx_Math" display="inline" id="S3.SS2.p1.3.3.m3.1"><semantics id="S3.SS2.p1.3.3.m3.1a"><mrow id="S3.SS2.p1.3.3.m3.1.1" xref="S3.SS2.p1.3.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.3.m3.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.3.3.m3.1.1.3.cmml">O</mi><mo id="S3.SS2.p1.3.3.m3.1.1.2" xref="S3.SS2.p1.3.3.m3.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p1.3.3.m3.1.1.1.1" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.cmml"><mo id="S3.SS2.p1.3.3.m3.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.3.3.m3.1.1.1.1.1" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.cmml"><mfrac id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.2" mathcolor="#000000" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.2.cmml">V</mi><mi id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.3" mathcolor="#000000" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.3.cmml">N</mi></mfrac><mo id="S3.SS2.p1.3.3.m3.1.1.1.1.1.1" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.1.cmml">â¢</mo><msup id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.cmml"><mi id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.2.cmml">D</mi><mn id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.3.cmml">2</mn></msup></mrow><mo id="S3.SS2.p1.3.3.m3.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.3.m3.1b"><apply id="S3.SS2.p1.3.3.m3.1.1.cmml" xref="S3.SS2.p1.3.3.m3.1.1"><times id="S3.SS2.p1.3.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.3.m3.1.1.2"></times><ci id="S3.SS2.p1.3.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.3.m3.1.1.3">ğ‘‚</ci><apply id="S3.SS2.p1.3.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1"><times id="S3.SS2.p1.3.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.1"></times><apply id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2"><divide id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2"></divide><ci id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.2">ğ‘‰</ci><ci id="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.1.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.2.cmml" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.2">ğ·</ci><cn id="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.3.cmml" type="integer" xref="S3.SS2.p1.3.3.m3.1.1.1.1.1.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.3.m3.1c">O(\frac{V}{N}D^{2})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.3.m3.1d">italic_O ( divide start_ARG italic_V end_ARG start_ARG italic_N end_ARG italic_D start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT )</annotation></semantics></math> and <math alttext="O(\frac{V}{N}D)" class="ltx_Math" display="inline" id="S3.SS2.p1.4.4.m4.1"><semantics id="S3.SS2.p1.4.4.m4.1a"><mrow id="S3.SS2.p1.4.4.m4.1.1" xref="S3.SS2.p1.4.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.4.m4.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.4.4.m4.1.1.3.cmml">O</mi><mo id="S3.SS2.p1.4.4.m4.1.1.2" xref="S3.SS2.p1.4.4.m4.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p1.4.4.m4.1.1.1.1" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.cmml"><mo id="S3.SS2.p1.4.4.m4.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.4.4.m4.1.1.1.1.1" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.cmml"><mfrac id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.cmml"><mi id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.2" mathcolor="#000000" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.2.cmml">V</mi><mi id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.3" mathcolor="#000000" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.3.cmml">N</mi></mfrac><mo id="S3.SS2.p1.4.4.m4.1.1.1.1.1.1" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.1.cmml">â¢</mo><mi id="S3.SS2.p1.4.4.m4.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.3.cmml">D</mi></mrow><mo id="S3.SS2.p1.4.4.m4.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.4.m4.1b"><apply id="S3.SS2.p1.4.4.m4.1.1.cmml" xref="S3.SS2.p1.4.4.m4.1.1"><times id="S3.SS2.p1.4.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.4.m4.1.1.2"></times><ci id="S3.SS2.p1.4.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.4.m4.1.1.3">ğ‘‚</ci><apply id="S3.SS2.p1.4.4.m4.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1"><times id="S3.SS2.p1.4.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.1"></times><apply id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2"><divide id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2"></divide><ci id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.2">ğ‘‰</ci><ci id="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.2.3">ğ‘</ci></apply><ci id="S3.SS2.p1.4.4.m4.1.1.1.1.1.3.cmml" xref="S3.SS2.p1.4.4.m4.1.1.1.1.1.3">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.4.m4.1c">O(\frac{V}{N}D)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.4.m4.1d">italic_O ( divide start_ARG italic_V end_ARG start_ARG italic_N end_ARG italic_D )</annotation></semantics></math>, respectively, where <math alttext="V" class="ltx_Math" display="inline" id="S3.SS2.p1.5.5.m5.1"><semantics id="S3.SS2.p1.5.5.m5.1a"><mi id="S3.SS2.p1.5.5.m5.1.1" mathcolor="#000000" xref="S3.SS2.p1.5.5.m5.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.5.m5.1b"><ci id="S3.SS2.p1.5.5.m5.1.1.cmml" xref="S3.SS2.p1.5.5.m5.1.1">ğ‘‰</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.5.m5.1c">V</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.5.m5.1d">italic_V</annotation></semantics></math> and <math alttext="E" class="ltx_Math" display="inline" id="S3.SS2.p1.6.6.m6.1"><semantics id="S3.SS2.p1.6.6.m6.1a"><mi id="S3.SS2.p1.6.6.m6.1.1" mathcolor="#000000" xref="S3.SS2.p1.6.6.m6.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.6.m6.1b"><ci id="S3.SS2.p1.6.6.m6.1.1.cmml" xref="S3.SS2.p1.6.6.m6.1.1">ğ¸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.6.m6.1c">E</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.6.m6.1d">italic_E</annotation></semantics></math> represent the total number of vertices and edges, <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p1.7.7.m7.1"><semantics id="S3.SS2.p1.7.7.m7.1a"><mi id="S3.SS2.p1.7.7.m7.1.1" mathcolor="#000000" xref="S3.SS2.p1.7.7.m7.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.7.m7.1b"><ci id="S3.SS2.p1.7.7.m7.1.1.cmml" xref="S3.SS2.p1.7.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.7.m7.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.7.m7.1d">italic_N</annotation></semantics></math> denotes the number of workers, and <math alttext="D" class="ltx_Math" display="inline" id="S3.SS2.p1.8.8.m8.1"><semantics id="S3.SS2.p1.8.8.m8.1a"><mi id="S3.SS2.p1.8.8.m8.1.1" mathcolor="#000000" xref="S3.SS2.p1.8.8.m8.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.8.m8.1b"><ci id="S3.SS2.p1.8.8.m8.1.1.cmml" xref="S3.SS2.p1.8.8.m8.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.8.m8.1c">D</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.8.8.m8.1d">italic_D</annotation></semantics></math> denotes the feature dimension, for simplicity, we assume that the feature dimensions are uniform across all layers. In the communication process, during the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.12.12.1">gather</span> phase, each worker receives the embedding slices of local NN computation vertices from the other <math alttext="N-1" class="ltx_Math" display="inline" id="S3.SS2.p1.9.9.m9.1"><semantics id="S3.SS2.p1.9.9.m9.1a"><mrow id="S3.SS2.p1.9.9.m9.1.1" xref="S3.SS2.p1.9.9.m9.1.1.cmml"><mi id="S3.SS2.p1.9.9.m9.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.9.9.m9.1.1.2.cmml">N</mi><mo id="S3.SS2.p1.9.9.m9.1.1.1" mathcolor="#000000" xref="S3.SS2.p1.9.9.m9.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.p1.9.9.m9.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.9.9.m9.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.9.m9.1b"><apply id="S3.SS2.p1.9.9.m9.1.1.cmml" xref="S3.SS2.p1.9.9.m9.1.1"><minus id="S3.SS2.p1.9.9.m9.1.1.1.cmml" xref="S3.SS2.p1.9.9.m9.1.1.1"></minus><ci id="S3.SS2.p1.9.9.m9.1.1.2.cmml" xref="S3.SS2.p1.9.9.m9.1.1.2">ğ‘</ci><cn id="S3.SS2.p1.9.9.m9.1.1.3.cmml" type="integer" xref="S3.SS2.p1.9.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.9.m9.1c">N-1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.9.9.m9.1d">italic_N - 1</annotation></semantics></math> workers. The time and space complexities are <math alttext="(N-1)\cdot\frac{V}{N}\cdot\frac{D}{N}\approx" class="ltx_Math" display="inline" id="S3.SS2.p1.10.10.m10.1"><semantics id="S3.SS2.p1.10.10.m10.1a"><mrow id="S3.SS2.p1.10.10.m10.1.1" xref="S3.SS2.p1.10.10.m10.1.1.cmml"><mrow id="S3.SS2.p1.10.10.m10.1.1.1" xref="S3.SS2.p1.10.10.m10.1.1.1.cmml"><mrow id="S3.SS2.p1.10.10.m10.1.1.1.1.1" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p1.10.10.m10.1.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.2.cmml">N</mi><mo id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.1" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p1.10.10.m10.1.1.1.1.1.3" mathcolor="#000000" rspace="0.055em" stretchy="false" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p1.10.10.m10.1.1.1.2" mathcolor="#000000" rspace="0.222em" xref="S3.SS2.p1.10.10.m10.1.1.1.2.cmml">â‹…</mo><mfrac id="S3.SS2.p1.10.10.m10.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.3.cmml"><mi id="S3.SS2.p1.10.10.m10.1.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.3.2.cmml">V</mi><mi id="S3.SS2.p1.10.10.m10.1.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.3.3.cmml">N</mi></mfrac><mo id="S3.SS2.p1.10.10.m10.1.1.1.2a" lspace="0.222em" mathcolor="#000000" rspace="0.222em" xref="S3.SS2.p1.10.10.m10.1.1.1.2.cmml">â‹…</mo><mfrac id="S3.SS2.p1.10.10.m10.1.1.1.4" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.4.cmml"><mi id="S3.SS2.p1.10.10.m10.1.1.1.4.2" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.4.2.cmml">D</mi><mi id="S3.SS2.p1.10.10.m10.1.1.1.4.3" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.1.4.3.cmml">N</mi></mfrac></mrow><mo id="S3.SS2.p1.10.10.m10.1.1.2" mathcolor="#000000" xref="S3.SS2.p1.10.10.m10.1.1.2.cmml">â‰ˆ</mo><mi id="S3.SS2.p1.10.10.m10.1.1.3" xref="S3.SS2.p1.10.10.m10.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.10.10.m10.1b"><apply id="S3.SS2.p1.10.10.m10.1.1.cmml" xref="S3.SS2.p1.10.10.m10.1.1"><approx id="S3.SS2.p1.10.10.m10.1.1.2.cmml" xref="S3.SS2.p1.10.10.m10.1.1.2"></approx><apply id="S3.SS2.p1.10.10.m10.1.1.1.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1"><ci id="S3.SS2.p1.10.10.m10.1.1.1.2.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.2">â‹…</ci><apply id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1"><minus id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.1"></minus><ci id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.2">ğ‘</ci><cn id="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.10.10.m10.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.10.10.m10.1.1.1.3.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.3"><divide id="S3.SS2.p1.10.10.m10.1.1.1.3.1.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.3"></divide><ci id="S3.SS2.p1.10.10.m10.1.1.1.3.2.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.3.2">ğ‘‰</ci><ci id="S3.SS2.p1.10.10.m10.1.1.1.3.3.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS2.p1.10.10.m10.1.1.1.4.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.4"><divide id="S3.SS2.p1.10.10.m10.1.1.1.4.1.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.4"></divide><ci id="S3.SS2.p1.10.10.m10.1.1.1.4.2.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.4.2">ğ·</ci><ci id="S3.SS2.p1.10.10.m10.1.1.1.4.3.cmml" xref="S3.SS2.p1.10.10.m10.1.1.1.4.3">ğ‘</ci></apply></apply><csymbol cd="latexml" id="S3.SS2.p1.10.10.m10.1.1.3.cmml" xref="S3.SS2.p1.10.10.m10.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.10.10.m10.1c">(N-1)\cdot\frac{V}{N}\cdot\frac{D}{N}\approx</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.10.10.m10.1d">( italic_N - 1 ) â‹… divide start_ARG italic_V end_ARG start_ARG italic_N end_ARG â‹… divide start_ARG italic_D end_ARG start_ARG italic_N end_ARG â‰ˆ</annotation></semantics></math> <math alttext="O(\frac{VD}{N})" class="ltx_Math" display="inline" id="S3.SS2.p1.11.11.m11.1"><semantics id="S3.SS2.p1.11.11.m11.1a"><mrow id="S3.SS2.p1.11.11.m11.1.2" xref="S3.SS2.p1.11.11.m11.1.2.cmml"><mi id="S3.SS2.p1.11.11.m11.1.2.2" mathcolor="#000000" xref="S3.SS2.p1.11.11.m11.1.2.2.cmml">O</mi><mo id="S3.SS2.p1.11.11.m11.1.2.1" xref="S3.SS2.p1.11.11.m11.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.p1.11.11.m11.1.2.3.2" xref="S3.SS2.p1.11.11.m11.1.1.cmml"><mo id="S3.SS2.p1.11.11.m11.1.2.3.2.1" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.11.11.m11.1.1.cmml">(</mo><mfrac id="S3.SS2.p1.11.11.m11.1.1" mathcolor="#000000" xref="S3.SS2.p1.11.11.m11.1.1.cmml"><mrow id="S3.SS2.p1.11.11.m11.1.1.2" xref="S3.SS2.p1.11.11.m11.1.1.2.cmml"><mi id="S3.SS2.p1.11.11.m11.1.1.2.2" mathcolor="#000000" xref="S3.SS2.p1.11.11.m11.1.1.2.2.cmml">V</mi><mo id="S3.SS2.p1.11.11.m11.1.1.2.1" xref="S3.SS2.p1.11.11.m11.1.1.2.1.cmml">â¢</mo><mi id="S3.SS2.p1.11.11.m11.1.1.2.3" mathcolor="#000000" xref="S3.SS2.p1.11.11.m11.1.1.2.3.cmml">D</mi></mrow><mi id="S3.SS2.p1.11.11.m11.1.1.3" mathcolor="#000000" xref="S3.SS2.p1.11.11.m11.1.1.3.cmml">N</mi></mfrac><mo id="S3.SS2.p1.11.11.m11.1.2.3.2.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.11.11.m11.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.11.11.m11.1b"><apply id="S3.SS2.p1.11.11.m11.1.2.cmml" xref="S3.SS2.p1.11.11.m11.1.2"><times id="S3.SS2.p1.11.11.m11.1.2.1.cmml" xref="S3.SS2.p1.11.11.m11.1.2.1"></times><ci id="S3.SS2.p1.11.11.m11.1.2.2.cmml" xref="S3.SS2.p1.11.11.m11.1.2.2">ğ‘‚</ci><apply id="S3.SS2.p1.11.11.m11.1.1.cmml" xref="S3.SS2.p1.11.11.m11.1.2.3.2"><divide id="S3.SS2.p1.11.11.m11.1.1.1.cmml" xref="S3.SS2.p1.11.11.m11.1.2.3.2"></divide><apply id="S3.SS2.p1.11.11.m11.1.1.2.cmml" xref="S3.SS2.p1.11.11.m11.1.1.2"><times id="S3.SS2.p1.11.11.m11.1.1.2.1.cmml" xref="S3.SS2.p1.11.11.m11.1.1.2.1"></times><ci id="S3.SS2.p1.11.11.m11.1.1.2.2.cmml" xref="S3.SS2.p1.11.11.m11.1.1.2.2">ğ‘‰</ci><ci id="S3.SS2.p1.11.11.m11.1.1.2.3.cmml" xref="S3.SS2.p1.11.11.m11.1.1.2.3">ğ·</ci></apply><ci id="S3.SS2.p1.11.11.m11.1.1.3.cmml" xref="S3.SS2.p1.11.11.m11.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.11.11.m11.1c">O(\frac{VD}{N})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.11.11.m11.1d">italic_O ( divide start_ARG italic_V italic_D end_ARG start_ARG italic_N end_ARG )</annotation></semantics></math> and <math alttext="O(\frac{VD}{N^{2}})" class="ltx_Math" display="inline" id="S3.SS2.p1.12.12.m12.1"><semantics id="S3.SS2.p1.12.12.m12.1a"><mrow id="S3.SS2.p1.12.12.m12.1.2" xref="S3.SS2.p1.12.12.m12.1.2.cmml"><mi id="S3.SS2.p1.12.12.m12.1.2.2" mathcolor="#000000" xref="S3.SS2.p1.12.12.m12.1.2.2.cmml">O</mi><mo id="S3.SS2.p1.12.12.m12.1.2.1" xref="S3.SS2.p1.12.12.m12.1.2.1.cmml">â¢</mo><mrow id="S3.SS2.p1.12.12.m12.1.2.3.2" xref="S3.SS2.p1.12.12.m12.1.1.cmml"><mo id="S3.SS2.p1.12.12.m12.1.2.3.2.1" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.12.12.m12.1.1.cmml">(</mo><mfrac id="S3.SS2.p1.12.12.m12.1.1" mathcolor="#000000" xref="S3.SS2.p1.12.12.m12.1.1.cmml"><mrow id="S3.SS2.p1.12.12.m12.1.1.2" xref="S3.SS2.p1.12.12.m12.1.1.2.cmml"><mi id="S3.SS2.p1.12.12.m12.1.1.2.2" mathcolor="#000000" xref="S3.SS2.p1.12.12.m12.1.1.2.2.cmml">V</mi><mo id="S3.SS2.p1.12.12.m12.1.1.2.1" xref="S3.SS2.p1.12.12.m12.1.1.2.1.cmml">â¢</mo><mi id="S3.SS2.p1.12.12.m12.1.1.2.3" mathcolor="#000000" xref="S3.SS2.p1.12.12.m12.1.1.2.3.cmml">D</mi></mrow><msup id="S3.SS2.p1.12.12.m12.1.1.3" xref="S3.SS2.p1.12.12.m12.1.1.3.cmml"><mi id="S3.SS2.p1.12.12.m12.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p1.12.12.m12.1.1.3.2.cmml">N</mi><mn id="S3.SS2.p1.12.12.m12.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p1.12.12.m12.1.1.3.3.cmml">2</mn></msup></mfrac><mo id="S3.SS2.p1.12.12.m12.1.2.3.2.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p1.12.12.m12.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.12.12.m12.1b"><apply id="S3.SS2.p1.12.12.m12.1.2.cmml" xref="S3.SS2.p1.12.12.m12.1.2"><times id="S3.SS2.p1.12.12.m12.1.2.1.cmml" xref="S3.SS2.p1.12.12.m12.1.2.1"></times><ci id="S3.SS2.p1.12.12.m12.1.2.2.cmml" xref="S3.SS2.p1.12.12.m12.1.2.2">ğ‘‚</ci><apply id="S3.SS2.p1.12.12.m12.1.1.cmml" xref="S3.SS2.p1.12.12.m12.1.2.3.2"><divide id="S3.SS2.p1.12.12.m12.1.1.1.cmml" xref="S3.SS2.p1.12.12.m12.1.2.3.2"></divide><apply id="S3.SS2.p1.12.12.m12.1.1.2.cmml" xref="S3.SS2.p1.12.12.m12.1.1.2"><times id="S3.SS2.p1.12.12.m12.1.1.2.1.cmml" xref="S3.SS2.p1.12.12.m12.1.1.2.1"></times><ci id="S3.SS2.p1.12.12.m12.1.1.2.2.cmml" xref="S3.SS2.p1.12.12.m12.1.1.2.2">ğ‘‰</ci><ci id="S3.SS2.p1.12.12.m12.1.1.2.3.cmml" xref="S3.SS2.p1.12.12.m12.1.1.2.3">ğ·</ci></apply><apply id="S3.SS2.p1.12.12.m12.1.1.3.cmml" xref="S3.SS2.p1.12.12.m12.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p1.12.12.m12.1.1.3.1.cmml" xref="S3.SS2.p1.12.12.m12.1.1.3">superscript</csymbol><ci id="S3.SS2.p1.12.12.m12.1.1.3.2.cmml" xref="S3.SS2.p1.12.12.m12.1.1.3.2">ğ‘</ci><cn id="S3.SS2.p1.12.12.m12.1.1.3.3.cmml" type="integer" xref="S3.SS2.p1.12.12.m12.1.1.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.12.12.m12.1c">O(\frac{VD}{N^{2}})</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.12.12.m12.1d">italic_O ( divide start_ARG italic_V italic_D end_ARG start_ARG italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG )</annotation></semantics></math>, respectively.
The <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.12.12.2">split</span> phase can be understood as the inverse process of the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.12.12.3">gather</span> phase, and it has the same time and space complexity as the <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.12.12.4">gather</span> phase.
</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.8"><span class="ltx_text" id="S3.SS2.p2.8.8" style="color:#000000;">We further analyze the total computation and communication load of GNN tensor parallelism. GNN tensor parallelism maintains the same total computational load as single-machine full-graph training without any redundant computations. Regarding communication load, GNN tensor parallelism performs <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.8.8.1">split</span> and <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.8.8.2">gather</span> operations at each layer to communicate embedding slices with the other <math alttext="(N-1)" class="ltx_Math" display="inline" id="S3.SS2.p2.1.1.m1.1"><semantics id="S3.SS2.p2.1.1.m1.1a"><mrow id="S3.SS2.p2.1.1.m1.1.1.1" xref="S3.SS2.p2.1.1.m1.1.1.1.1.cmml"><mo id="S3.SS2.p2.1.1.m1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.1.1.m1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p2.1.1.m1.1.1.1.1" xref="S3.SS2.p2.1.1.m1.1.1.1.1.cmml"><mi id="S3.SS2.p2.1.1.m1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.1.1.m1.1.1.1.1.2.cmml">N</mi><mo id="S3.SS2.p2.1.1.m1.1.1.1.1.1" mathcolor="#000000" xref="S3.SS2.p2.1.1.m1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.p2.1.1.m1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.1.1.m1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p2.1.1.m1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.1.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.1.m1.1b"><apply id="S3.SS2.p2.1.1.m1.1.1.1.1.cmml" xref="S3.SS2.p2.1.1.m1.1.1.1"><minus id="S3.SS2.p2.1.1.m1.1.1.1.1.1.cmml" xref="S3.SS2.p2.1.1.m1.1.1.1.1.1"></minus><ci id="S3.SS2.p2.1.1.m1.1.1.1.1.2.cmml" xref="S3.SS2.p2.1.1.m1.1.1.1.1.2">ğ‘</ci><cn id="S3.SS2.p2.1.1.m1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.1.1.m1.1.1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.1.m1.1c">(N-1)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.1.m1.1d">( italic_N - 1 )</annotation></semantics></math> workers. The total communication load for GNN tensor parallelism is <math alttext="N\times 2(N-1)\frac{VD}{N^{2}}L\approx 2VDL" class="ltx_Math" display="inline" id="S3.SS2.p2.2.2.m2.1"><semantics id="S3.SS2.p2.2.2.m2.1a"><mrow id="S3.SS2.p2.2.2.m2.1.1" xref="S3.SS2.p2.2.2.m2.1.1.cmml"><mrow id="S3.SS2.p2.2.2.m2.1.1.1" xref="S3.SS2.p2.2.2.m2.1.1.1.cmml"><mrow id="S3.SS2.p2.2.2.m2.1.1.1.3" xref="S3.SS2.p2.2.2.m2.1.1.1.3.cmml"><mi id="S3.SS2.p2.2.2.m2.1.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.3.2.cmml">N</mi><mo id="S3.SS2.p2.2.2.m2.1.1.1.3.1" lspace="0.222em" mathcolor="#000000" rspace="0.222em" xref="S3.SS2.p2.2.2.m2.1.1.1.3.1.cmml">Ã—</mo><mn id="S3.SS2.p2.2.2.m2.1.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.3.3.cmml">2</mn></mrow><mo id="S3.SS2.p2.2.2.m2.1.1.1.2" xref="S3.SS2.p2.2.2.m2.1.1.1.2.cmml">â¢</mo><mrow id="S3.SS2.p2.2.2.m2.1.1.1.1.1" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.2.2.m2.1.1.1.1.1.2" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.2.cmml">N</mi><mo id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.1" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.1.cmml">âˆ’</mo><mn id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p2.2.2.m2.1.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.p2.2.2.m2.1.1.1.2a" xref="S3.SS2.p2.2.2.m2.1.1.1.2.cmml">â¢</mo><mfrac id="S3.SS2.p2.2.2.m2.1.1.1.4" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.4.cmml"><mrow id="S3.SS2.p2.2.2.m2.1.1.1.4.2" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.cmml"><mi id="S3.SS2.p2.2.2.m2.1.1.1.4.2.2" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.2.cmml">V</mi><mo id="S3.SS2.p2.2.2.m2.1.1.1.4.2.1" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.1.cmml">â¢</mo><mi id="S3.SS2.p2.2.2.m2.1.1.1.4.2.3" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.3.cmml">D</mi></mrow><msup id="S3.SS2.p2.2.2.m2.1.1.1.4.3" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3.cmml"><mi id="S3.SS2.p2.2.2.m2.1.1.1.4.3.2" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3.2.cmml">N</mi><mn id="S3.SS2.p2.2.2.m2.1.1.1.4.3.3" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3.3.cmml">2</mn></msup></mfrac><mo id="S3.SS2.p2.2.2.m2.1.1.1.2b" xref="S3.SS2.p2.2.2.m2.1.1.1.2.cmml">â¢</mo><mi id="S3.SS2.p2.2.2.m2.1.1.1.5" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.1.5.cmml">L</mi></mrow><mo id="S3.SS2.p2.2.2.m2.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.2.cmml">â‰ˆ</mo><mrow id="S3.SS2.p2.2.2.m2.1.1.3" xref="S3.SS2.p2.2.2.m2.1.1.3.cmml"><mn id="S3.SS2.p2.2.2.m2.1.1.3.2" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.3.2.cmml">2</mn><mo id="S3.SS2.p2.2.2.m2.1.1.3.1" xref="S3.SS2.p2.2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p2.2.2.m2.1.1.3.3" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.3.3.cmml">V</mi><mo id="S3.SS2.p2.2.2.m2.1.1.3.1a" xref="S3.SS2.p2.2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p2.2.2.m2.1.1.3.4" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.3.4.cmml">D</mi><mo id="S3.SS2.p2.2.2.m2.1.1.3.1b" xref="S3.SS2.p2.2.2.m2.1.1.3.1.cmml">â¢</mo><mi id="S3.SS2.p2.2.2.m2.1.1.3.5" mathcolor="#000000" xref="S3.SS2.p2.2.2.m2.1.1.3.5.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.2.m2.1b"><apply id="S3.SS2.p2.2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1"><approx id="S3.SS2.p2.2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.2"></approx><apply id="S3.SS2.p2.2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1"><times id="S3.SS2.p2.2.2.m2.1.1.1.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.2"></times><apply id="S3.SS2.p2.2.2.m2.1.1.1.3.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.3"><times id="S3.SS2.p2.2.2.m2.1.1.1.3.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.3.1"></times><ci id="S3.SS2.p2.2.2.m2.1.1.1.3.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.3.2">ğ‘</ci><cn id="S3.SS2.p2.2.2.m2.1.1.1.3.3.cmml" type="integer" xref="S3.SS2.p2.2.2.m2.1.1.1.3.3">2</cn></apply><apply id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1"><minus id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.1"></minus><ci id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.2">ğ‘</ci><cn id="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p2.2.2.m2.1.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.p2.2.2.m2.1.1.1.4.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4"><divide id="S3.SS2.p2.2.2.m2.1.1.1.4.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4"></divide><apply id="S3.SS2.p2.2.2.m2.1.1.1.4.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2"><times id="S3.SS2.p2.2.2.m2.1.1.1.4.2.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.1"></times><ci id="S3.SS2.p2.2.2.m2.1.1.1.4.2.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.2">ğ‘‰</ci><ci id="S3.SS2.p2.2.2.m2.1.1.1.4.2.3.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.2.3">ğ·</ci></apply><apply id="S3.SS2.p2.2.2.m2.1.1.1.4.3.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3"><csymbol cd="ambiguous" id="S3.SS2.p2.2.2.m2.1.1.1.4.3.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3">superscript</csymbol><ci id="S3.SS2.p2.2.2.m2.1.1.1.4.3.2.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3.2">ğ‘</ci><cn id="S3.SS2.p2.2.2.m2.1.1.1.4.3.3.cmml" type="integer" xref="S3.SS2.p2.2.2.m2.1.1.1.4.3.3">2</cn></apply></apply><ci id="S3.SS2.p2.2.2.m2.1.1.1.5.cmml" xref="S3.SS2.p2.2.2.m2.1.1.1.5">ğ¿</ci></apply><apply id="S3.SS2.p2.2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.2.m2.1.1.3"><times id="S3.SS2.p2.2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.2.m2.1.1.3.1"></times><cn id="S3.SS2.p2.2.2.m2.1.1.3.2.cmml" type="integer" xref="S3.SS2.p2.2.2.m2.1.1.3.2">2</cn><ci id="S3.SS2.p2.2.2.m2.1.1.3.3.cmml" xref="S3.SS2.p2.2.2.m2.1.1.3.3">ğ‘‰</ci><ci id="S3.SS2.p2.2.2.m2.1.1.3.4.cmml" xref="S3.SS2.p2.2.2.m2.1.1.3.4">ğ·</ci><ci id="S3.SS2.p2.2.2.m2.1.1.3.5.cmml" xref="S3.SS2.p2.2.2.m2.1.1.3.5">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.2.m2.1c">N\times 2(N-1)\frac{VD}{N^{2}}L\approx 2VDL</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.2.m2.1d">italic_N Ã— 2 ( italic_N - 1 ) divide start_ARG italic_V italic_D end_ARG start_ARG italic_N start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT end_ARG italic_L â‰ˆ 2 italic_V italic_D italic_L</annotation></semantics></math>, where <math alttext="L" class="ltx_Math" display="inline" id="S3.SS2.p2.3.3.m3.1"><semantics id="S3.SS2.p2.3.3.m3.1a"><mi id="S3.SS2.p2.3.3.m3.1.1" mathcolor="#000000" xref="S3.SS2.p2.3.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.3.m3.1b"><ci id="S3.SS2.p2.3.3.m3.1.1.cmml" xref="S3.SS2.p2.3.3.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.3.m3.1c">L</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.3.m3.1d">italic_L</annotation></semantics></math> denotes the number of model layers. The total communication load of GNN data parallelism is <math alttext="{\textstyle\sum_{i=1}^{N}}|R_{i}|DL" class="ltx_Math" display="inline" id="S3.SS2.p2.4.4.m4.1"><semantics id="S3.SS2.p2.4.4.m4.1a"><mrow id="S3.SS2.p2.4.4.m4.1.1" xref="S3.SS2.p2.4.4.m4.1.1.cmml"><msubsup id="S3.SS2.p2.4.4.m4.1.1.2" xref="S3.SS2.p2.4.4.m4.1.1.2.cmml"><mo id="S3.SS2.p2.4.4.m4.1.1.2.2.2" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.SS2.p2.4.4.m4.1.1.2.2.3" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.cmml"><mi id="S3.SS2.p2.4.4.m4.1.1.2.2.3.2" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.2.cmml">i</mi><mo id="S3.SS2.p2.4.4.m4.1.1.2.2.3.1" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS2.p2.4.4.m4.1.1.2.2.3.3" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p2.4.4.m4.1.1.2.3" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.SS2.p2.4.4.m4.1.1.1" xref="S3.SS2.p2.4.4.m4.1.1.1.cmml"><mrow id="S3.SS2.p2.4.4.m4.1.1.1.1.1" xref="S3.SS2.p2.4.4.m4.1.1.1.1.2.cmml"><mo id="S3.SS2.p2.4.4.m4.1.1.1.1.1.2" lspace="0em" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.4.4.m4.1.1.1.1.2.1.cmml">|</mo><msub id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.2.cmml">R</mi><mi id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.4.4.m4.1.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.4.4.m4.1.1.1.1.2.1.cmml">|</mo></mrow><mo id="S3.SS2.p2.4.4.m4.1.1.1.2" xref="S3.SS2.p2.4.4.m4.1.1.1.2.cmml">â¢</mo><mi id="S3.SS2.p2.4.4.m4.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.1.3.cmml">D</mi><mo id="S3.SS2.p2.4.4.m4.1.1.1.2a" xref="S3.SS2.p2.4.4.m4.1.1.1.2.cmml">â¢</mo><mi id="S3.SS2.p2.4.4.m4.1.1.1.4" mathcolor="#000000" xref="S3.SS2.p2.4.4.m4.1.1.1.4.cmml">L</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.4.m4.1b"><apply id="S3.SS2.p2.4.4.m4.1.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1"><apply id="S3.SS2.p2.4.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2">superscript</csymbol><apply id="S3.SS2.p2.4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.4.m4.1.1.2.2.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2">subscript</csymbol><sum id="S3.SS2.p2.4.4.m4.1.1.2.2.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2.2.2"></sum><apply id="S3.SS2.p2.4.4.m4.1.1.2.2.3.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3"><eq id="S3.SS2.p2.4.4.m4.1.1.2.2.3.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.1"></eq><ci id="S3.SS2.p2.4.4.m4.1.1.2.2.3.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.2">ğ‘–</ci><cn id="S3.SS2.p2.4.4.m4.1.1.2.2.3.3.cmml" type="integer" xref="S3.SS2.p2.4.4.m4.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.SS2.p2.4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p2.4.4.m4.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p2.4.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1"><times id="S3.SS2.p2.4.4.m4.1.1.1.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.2"></times><apply id="S3.SS2.p2.4.4.m4.1.1.1.1.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1"><abs id="S3.SS2.p2.4.4.m4.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.2"></abs><apply id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.2">ğ‘…</ci><ci id="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.1.1.1.3">ğ‘–</ci></apply></apply><ci id="S3.SS2.p2.4.4.m4.1.1.1.3.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.3">ğ·</ci><ci id="S3.SS2.p2.4.4.m4.1.1.1.4.cmml" xref="S3.SS2.p2.4.4.m4.1.1.1.4">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.4.m4.1c">{\textstyle\sum_{i=1}^{N}}|R_{i}|DL</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.4.m4.1d">âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT | italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_D italic_L</annotation></semantics></math>, where <math alttext="R_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.5.m5.1"><semantics id="S3.SS2.p2.5.5.m5.1a"><msub id="S3.SS2.p2.5.5.m5.1.1" xref="S3.SS2.p2.5.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.5.m5.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.5.5.m5.1.1.2.cmml">R</mi><mi id="S3.SS2.p2.5.5.m5.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.5.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.5.m5.1b"><apply id="S3.SS2.p2.5.5.m5.1.1.cmml" xref="S3.SS2.p2.5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.5.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p2.5.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.5.m5.1.1.2">ğ‘…</ci><ci id="S3.SS2.p2.5.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.5.m5.1c">R_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.5.m5.1d">italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes the remote vertices of worker <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p2.6.6.m6.1"><semantics id="S3.SS2.p2.6.6.m6.1a"><mi id="S3.SS2.p2.6.6.m6.1.1" mathcolor="#000000" xref="S3.SS2.p2.6.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.6.m6.1b"><ci id="S3.SS2.p2.6.6.m6.1.1.cmml" xref="S3.SS2.p2.6.6.m6.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.6.m6.1d">italic_i</annotation></semantics></math>. As the number of workers increases, the remote vertices (<math alttext="{\textstyle\sum_{i=1}^{N}}|R_{i}|" class="ltx_Math" display="inline" id="S3.SS2.p2.7.7.m7.1"><semantics id="S3.SS2.p2.7.7.m7.1a"><mrow id="S3.SS2.p2.7.7.m7.1.1" xref="S3.SS2.p2.7.7.m7.1.1.cmml"><msubsup id="S3.SS2.p2.7.7.m7.1.1.2" xref="S3.SS2.p2.7.7.m7.1.1.2.cmml"><mo id="S3.SS2.p2.7.7.m7.1.1.2.2.2" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.2.2.2.cmml">âˆ‘</mo><mrow id="S3.SS2.p2.7.7.m7.1.1.2.2.3" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.cmml"><mi id="S3.SS2.p2.7.7.m7.1.1.2.2.3.2" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.2.cmml">i</mi><mo id="S3.SS2.p2.7.7.m7.1.1.2.2.3.1" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.1.cmml">=</mo><mn id="S3.SS2.p2.7.7.m7.1.1.2.2.3.3" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.SS2.p2.7.7.m7.1.1.2.3" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.2.3.cmml">N</mi></msubsup><mrow id="S3.SS2.p2.7.7.m7.1.1.1.1" xref="S3.SS2.p2.7.7.m7.1.1.1.2.cmml"><mo id="S3.SS2.p2.7.7.m7.1.1.1.1.2" lspace="0em" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.7.7.m7.1.1.1.2.1.cmml">|</mo><msub id="S3.SS2.p2.7.7.m7.1.1.1.1.1" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.7.7.m7.1.1.1.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1.2.cmml">R</mi><mi id="S3.SS2.p2.7.7.m7.1.1.1.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.7.7.m7.1.1.1.1.3" mathcolor="#000000" stretchy="false" xref="S3.SS2.p2.7.7.m7.1.1.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.7.m7.1b"><apply id="S3.SS2.p2.7.7.m7.1.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1"><apply id="S3.SS2.p2.7.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.7.m7.1.1.2.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2">superscript</csymbol><apply id="S3.SS2.p2.7.7.m7.1.1.2.2.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.7.7.m7.1.1.2.2.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2">subscript</csymbol><sum id="S3.SS2.p2.7.7.m7.1.1.2.2.2.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2.2.2"></sum><apply id="S3.SS2.p2.7.7.m7.1.1.2.2.3.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3"><eq id="S3.SS2.p2.7.7.m7.1.1.2.2.3.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.1"></eq><ci id="S3.SS2.p2.7.7.m7.1.1.2.2.3.2.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.2">ğ‘–</ci><cn id="S3.SS2.p2.7.7.m7.1.1.2.2.3.3.cmml" type="integer" xref="S3.SS2.p2.7.7.m7.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.SS2.p2.7.7.m7.1.1.2.3.cmml" xref="S3.SS2.p2.7.7.m7.1.1.2.3">ğ‘</ci></apply><apply id="S3.SS2.p2.7.7.m7.1.1.1.2.cmml" xref="S3.SS2.p2.7.7.m7.1.1.1.1"><abs id="S3.SS2.p2.7.7.m7.1.1.1.2.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1.1.1.2"></abs><apply id="S3.SS2.p2.7.7.m7.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.7.m7.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.7.7.m7.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1.2">ğ‘…</ci><ci id="S3.SS2.p2.7.7.m7.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.7.7.m7.1.1.1.1.1.3">ğ‘–</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.7.m7.1c">{\textstyle\sum_{i=1}^{N}}|R_{i}|</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.7.m7.1d">âˆ‘ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT | italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT |</annotation></semantics></math>) rise significantly, often exceeding <math alttext="2V" class="ltx_Math" display="inline" id="S3.SS2.p2.8.8.m8.1"><semantics id="S3.SS2.p2.8.8.m8.1a"><mrow id="S3.SS2.p2.8.8.m8.1.1" xref="S3.SS2.p2.8.8.m8.1.1.cmml"><mn id="S3.SS2.p2.8.8.m8.1.1.2" mathcolor="#000000" xref="S3.SS2.p2.8.8.m8.1.1.2.cmml">2</mn><mo id="S3.SS2.p2.8.8.m8.1.1.1" xref="S3.SS2.p2.8.8.m8.1.1.1.cmml">â¢</mo><mi id="S3.SS2.p2.8.8.m8.1.1.3" mathcolor="#000000" xref="S3.SS2.p2.8.8.m8.1.1.3.cmml">V</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.8.m8.1b"><apply id="S3.SS2.p2.8.8.m8.1.1.cmml" xref="S3.SS2.p2.8.8.m8.1.1"><times id="S3.SS2.p2.8.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.8.m8.1.1.1"></times><cn id="S3.SS2.p2.8.8.m8.1.1.2.cmml" type="integer" xref="S3.SS2.p2.8.8.m8.1.1.2">2</cn><ci id="S3.SS2.p2.8.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.8.m8.1.1.3">ğ‘‰</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.8.m8.1c">2V</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.8.8.m8.1d">2 italic_V</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>)</cite>. In contrast, the total communication volume in GNN tensor parallelism remains relatively constant with worker increases, typically having a lower communication load than data parallelism.
</span></p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text" id="S3.SS2.p3.1.1" style="color:#000000;">In GNN tensor parallelism, more memory is used to replicate the graph structure to eliminate cross-worker vertex dependencies and ensure load balancing. This overhead is generally acceptable since the primary memory consumption in GNN training comes from vertex data, including features, embeddings, and gradients <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>)</cite>. For example, in the Ogbn-paper dataset, the graph topology size is 6.4 GB, while vertex features occupy 82.7 GB. GNN tensor parallelism distributes all vertex data across different workers by either dimension or vertex count.</span></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Challenges</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The benefits of GNN tensor parallelism come with challenges that must be overcome to fully exploit acceleration opportunities.
</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Challenge #1: Frequent collective communication. </span>
Compared to GNN data parallelism, GNN tensor parallelism involves more rounds of communication (i.e., twice per layer) to gather and split vertex embeddings. This frequent communication may impact computation efficiency due to substantial layer-wise synchronization. Therefore, reducing the overall communication frequency is crucial for effectively implementing GNN tensor parallelism.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Challenge #2: Processing the entire graph on a single worker. </span>
GNN tensor parallelism becomes impractical when a single GPU memory cannot accommodate the entire graph and corresponding embedding slices.
To support the training of large-scale graphs, we need to offload the training data to the CPU main memory. This requires the further design of a task scheduling strategy and consideration of integration with pipeline techniques to minimize latency when accessing data in CPU main memory.
</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>The NeutronTP</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We present NeutronTP, a distributed system for full-graph GNN training that utilizes tensor parallelism and addresses the challenges outlined in Section 3.3 through two critical functions. Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.F7" title="Figure 7 â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">7</span></a> provides an architectural overview of NeutronTP.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Generalized decoupled training method.  </span>
The main reason for challenge #1 lies in the coupled training patterns of NN and graph aggregation operations, which frequently switch between using complete embeddings and embedding slices.
Therefore, we decouple NN operations from graph aggregation operations, restricting collective communication to the beginning and end of consecutive graph operations, thereby reducing communication frequency.
To address the issue that existing decoupling training methods <cite class="ltx_cite ltx_citemacro_citep">(Bojchevski etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib5" title="">2020</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib57" title="">2023</a>)</cite> do not support complex GNN models involving edge-associated NN operations, we further explore a decoupling approach for these operations, providing a generalized decoupling training method.
Specifically, before initiating the graph aggregation, we precompute edge-associated NN operations for each edge.</p>
</div>
<figure class="ltx_figure" id="S4.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="236" id="S4.F7.g1" src="x7.png" width="381"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>NeutronTP system overview.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Memory-efficient task scheduling strategy.  </span>
To address challenge #2, we further partition subtasks within each worker to perform fine-grained GNN training. NeutronTP employs a memory-efficient task scheduling strategy that reduces runtime memory consumption through chunk-based task scheduling and further enhances performance by inter-chunk pipeline. Specifically, within each worker, we partition the entire graph logically into multiple chunks that can fit into GPU memory, with each chunk containing a set of vertices with contiguous IDs along with all their incoming edges. During training, each worker schedules chunks onto the GPU in the same order, maintaining load balance for GNN tensor parallelism. Without compromising the layer-wise synchronization barrier, the inter-chunk pipeline overlaps the computation and communication of different chunks.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Generalized Decoupled Training Method</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text" id="S4.SS1.p1.1.1" style="color:#000000;">GNN tensor parallelism requires frequent collective communication for gathering and splitting embeddings by dimensions between NN computation (requiring the embedding split by vertices) and graph propagation (requiring the embedding split by dimensions), which results in substantial layer-wise data synchronization overhead. To improve communication efficiency for high performance training, NeutronTP employs a decoupled training method that reorganizes the execution order by moving NN computation to the beginning or end of the computation graph. This design reduces the collective communication of switching data organizations.
</span></p>
</div>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1. </span>Decoupled GNN Training Approaches</h4>
<div class="ltx_para" id="S4.SS1.SSS1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.p1.1">Previous works <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib14" title="">2020</a>; Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib46" title="">2019</a>; Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib53" title="">2022</a>)</cite> have indicated that the expressive power of GNNs originates
from NN operations and graph operations themselves, not their coupling execution. Moreover, the coupling execution of graph aggregation and NN operations may lead to over-smoothing problems when training deep GNN models <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib53" title="">2022</a>; Klicpera etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib20" title="">2019</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>)</cite>. Therefore, some decoupled GNN approaches <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib46" title="">2019</a>; Rossi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib31" title="">2020</a>; Klicpera etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib20" title="">2019</a>; Spinelli etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib35" title="">2021</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>)</cite> advocate separating NN operations from graph aggregation. This decoupling method has been shown to effectively enhance both model accuracy and scalability in deep model training. A recent study <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib57" title="">2023</a>)</cite> has also applied decoupled training methods to dynamic GNN training, achieving significant scalability and performance.
However, existing decoupling training methods <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib46" title="">2019</a>; Rossi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib31" title="">2020</a>; Klicpera etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib20" title="">2019</a>; Spinelli etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib35" title="">2021</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>)</cite> typically focus only on decoupling vertex-associated NN operations and do not support decoupling edge-associated NN operations. For complex models incorporating edge-associated NN operations, such as GAT <cite class="ltx_cite ltx_citemacro_citep">(Velickovic etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib38" title="">2018</a>)</cite>, graph aggregation in itself may introduce non-linear operations that cannot be partially computed.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.p2">
<p class="ltx_p" id="S4.SS1.SSS1.p2.1">We extend the decoupled GNN training method by precomputing all the attention coefficients required for each edge. This approach further decouples edge-associated NN operations from graph aggregation, thereby supporting the training of complex models.
Specifically, before the graph aggregation operation starts in this round, it computes attention coefficients using data parallelism. Since the computation of edge attention coefficients requires complete vertex embeddings and involves all edges, we employ data parallelism to compute attention coefficients for all incoming edges of local vertices on each worker. After the computation is completed, the attention coefficients are shared among all workers.
For other stages, the approach remains consistent with simple GNN models, allowing the use of GNN tensor parallelism. With the above design, we can perform edge-associated NN computations before initiating the graph aggregation operation.
</p>
</div>
<figure class="ltx_figure" id="S4.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="506" id="S4.F8.g1" src="x8.png" width="788"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>An illustrative example for showing communication frequency of naive GNN tensor parallelism and decoupled GNN tensor parallelism (3-layer GNN).</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2. </span>Decoupled GNN Tensor Parallelism</h4>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.5">For the given input GNN model, NeutronTP provides its corresponding decoupled training mode and applies tensor parallelism for training. Specifically, after specifying the model layers <math alttext="L" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p1.1.m1.1"><semantics id="S4.SS1.SSS2.p1.1.m1.1a"><mi id="S4.SS1.SSS2.p1.1.m1.1.1" xref="S4.SS1.SSS2.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.1.m1.1b"><ci id="S4.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.1.m1.1d">italic_L</annotation></semantics></math>, in each epoch, NeutronTP first performs <math alttext="L" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p1.2.m2.1"><semantics id="S4.SS1.SSS2.p1.2.m2.1a"><mi id="S4.SS1.SSS2.p1.2.m2.1.1" xref="S4.SS1.SSS2.p1.2.m2.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.2.m2.1b"><ci id="S4.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.2.m2.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.2.m2.1d">italic_L</annotation></semantics></math> rounds of NN operations on each vertex to obtain the low-dimensional vertex embeddings. For complex models incorporating edge-associated NN operations, NeutronTP further computes attention coefficients for all edges to be used in subsequent graph aggregation operations. Upon completing the <math alttext="L" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p1.3.m3.1"><semantics id="S4.SS1.SSS2.p1.3.m3.1a"><mi id="S4.SS1.SSS2.p1.3.m3.1.1" xref="S4.SS1.SSS2.p1.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.3.m3.1b"><ci id="S4.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS2.p1.3.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.3.m3.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.3.m3.1d">italic_L</annotation></semantics></math> rounds of NN operations, NeutronTP performs a <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p1.5.1">split</span> operation to restore tensor parallelism, where each worker holds partial embedding dimensions for all vertices. Subsequently, each worker utilizes embedding slices to complete <math alttext="L" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p1.4.m4.1"><semantics id="S4.SS1.SSS2.p1.4.m4.1a"><mi id="S4.SS1.SSS2.p1.4.m4.1.1" xref="S4.SS1.SSS2.p1.4.m4.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.4.m4.1b"><ci id="S4.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS2.p1.4.m4.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.4.m4.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.4.m4.1d">italic_L</annotation></semantics></math> rounds of full-graph aggregation operations. Upon completion of the graph aggregation operations, the forward propagation is executed, followed by a <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p1.5.2">gather</span> operation to collect complete vertex embedding to ensure the correct execution of the loss function. Backward propagation follows the inverse process of forward propagation, where NeutronTP still needs to perform <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p1.5.3">split</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS2.p1.5.4">gather</span> operations before and after <math alttext="L" class="ltx_Math" display="inline" id="S4.SS1.SSS2.p1.5.m5.1"><semantics id="S4.SS1.SSS2.p1.5.m5.1a"><mi id="S4.SS1.SSS2.p1.5.m5.1.1" xref="S4.SS1.SSS2.p1.5.m5.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.5.m5.1b"><ci id="S4.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS2.p1.5.m5.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.5.m5.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.5.m5.1d">italic_L</annotation></semantics></math> rounds of graph aggregation operations, respectively.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.F8" title="Figure 8 â€£ 4.1.1. Decoupled GNN Training Approaches â€£ 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">8</span></a> illustrates the comparison in overall communication frequency between naive GNN tensor parallelism and decoupled GNN tensor parallelism. For a 3-layer GNN model, the naive GNN tensor parallelism requires 10 rounds of collective communication, and the frequency of communication increases linearly as the number of model layers increases. In contrast, the decoupled GNN tensor parallelism only requires 4 rounds of collective communication, regardless of the number of model layers. Additionally, after multiple NN operations, the vertex embeddings involved in graph aggregation typically have lower dimensions compared to the raw features, further reducing the collective communication overhead.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p3">
<p class="ltx_p" id="S4.SS1.SSS2.p3.1"><span class="ltx_text" id="S4.SS1.SSS2.p3.1.1" style="color:#000000;">Decoupled GNN tensor parallelism is particularly effective for message-passing based GNNs such as GCN <cite class="ltx_cite ltx_citemacro_citep">(Kipf and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib19" title="">2017</a>)</cite>, GraphSAGE <cite class="ltx_cite ltx_citemacro_citep">(Hamilton etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib13" title="">2017</a>)</cite>, GAT <cite class="ltx_cite ltx_citemacro_citep">(Velickovic etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib38" title="">2018</a>)</cite>, and GIN <cite class="ltx_cite ltx_citemacro_citep">(Xu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib47" title="">2019</a>)</cite>. These models rely on updating and aggregating vertex features across the graph, making them ideal for GNN tensor parallelism, which efficiently partitions features and balances loads. The decoupled training method reduces communication overhead by decoupling update and aggregation processes. However, our approach may not directly benefit GNNs that do not rely on message passing, such as spectral-based GNNs (e.g., ChebNet <cite class="ltx_cite ltx_citemacro_citep">(Tang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib36" title="">2019</a>)</cite>) and GNNs with global attention mechanisms (e.g., Graph Transformer <cite class="ltx_cite ltx_citemacro_citep">(Dwivedi and Bresson, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib8" title="">2020</a>)</cite>). By focusing on message-passing based GNNs, NeutronTP enhances training efficiency and scalability, demonstrating broad applicability within widely-used GNN models.</span></p>
</div>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="125" id="S4.F9.g1" src="x9.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>(a) An example of graph data partitioned into four chunks. (b) An example of the sequential execution of different phases. (forward computation for a 2-layer GNN) (c) An example of inter-chunk pipelining. (forward computation for a 2-layer GNN) (d) An example of partitioning the <span class="ltx_text ltx_font_typewriter" id="S4.F9.2.1">split</span> operation into chunk-level communication tasks.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3. </span>Convergence Analysis</h4>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">In this section, we provide a theoretical analysis of convergence guarantees for NeutronTP.
Decoupled GNN training methods have been widely used by machine learning systems <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib46" title="">2019</a>; Rossi etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib31" title="">2020</a>; Klicpera etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib20" title="">2019</a>; Spinelli etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib35" title="">2021</a>; Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>)</cite>, and we present the theoretical analysis referring to the APPNP <cite class="ltx_cite ltx_citemacro_citep">(Klicpera etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib20" title="">2019</a>)</cite> and DAGNN <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>)</cite>.
<span class="ltx_text" id="S4.SS1.SSS3.p1.1.1" style="color:#000000;">The expressive power of GNNs originates from NN operations and graph operations themselves, not their coupled execution. Thus, the decoupled GNN training method separates and sequentially executes these operations while maintaining comparable expressive power to original GNNs. Experimental results from DAGNN <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib24" title="">2020</a>)</cite> demonstrate that training on the input vertex feature with NN operations can achieve a certain level of accuracy in node classification and applying graph aggregations in a decoupled manner can further enhance the performance. Therefore, we provide Assumption 1 as follows:</span></p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Assumption 1</span> The initial features have sufficient information for the machine learning task, and the graph aggregation operation can help the model learn structural information.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Theorem 1</span> <span class="ltx_text" id="S4.I1.i2.p1.1.2" style="color:#000000;">Under Assumption 1, the decoupled GNN training method separates graph operations from NN operations. The convergence of the decoupled GNN training can be guaranteed by the convergence of the NN and graph operations.</span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p3">
<p class="ltx_p" id="S4.SS1.SSS3.p3.1">Decoupled GNN training uses the iterative equation</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx7">
<tbody id="S4.E7"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(7)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\hat{L}" class="ltx_Math" display="inline" id="S4.E7.m1.1"><semantics id="S4.E7.m1.1a"><mover accent="true" id="S4.E7.m1.1.1" xref="S4.E7.m1.1.1.cmml"><mi id="S4.E7.m1.1.1.2" xref="S4.E7.m1.1.1.2.cmml">L</mi><mo id="S4.E7.m1.1.1.1" xref="S4.E7.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.E7.m1.1b"><apply id="S4.E7.m1.1.1.cmml" xref="S4.E7.m1.1.1"><ci id="S4.E7.m1.1.1.1.cmml" xref="S4.E7.m1.1.1.1">^</ci><ci id="S4.E7.m1.1.1.2.cmml" xref="S4.E7.m1.1.1.2">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m1.1c">\displaystyle\hat{L}</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m1.1d">over^ start_ARG italic_L end_ARG</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle={\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}UPDATE(X)}=MLP^{k}%
(X)," class="ltx_Math" display="inline" id="S4.E7.m2.3"><semantics id="S4.E7.m2.3a"><mrow id="S4.E7.m2.3.3.1" xref="S4.E7.m2.3.3.1.1.cmml"><mrow id="S4.E7.m2.3.3.1.1" xref="S4.E7.m2.3.3.1.1.cmml"><mi id="S4.E7.m2.3.3.1.1.2" xref="S4.E7.m2.3.3.1.1.2.cmml"></mi><mo id="S4.E7.m2.3.3.1.1.3" xref="S4.E7.m2.3.3.1.1.3.cmml">=</mo><mrow id="S4.E7.m2.3.3.1.1.4" xref="S4.E7.m2.3.3.1.1.4.cmml"><mi id="S4.E7.m2.3.3.1.1.4.2" mathcolor="#000000" xref="S4.E7.m2.3.3.1.1.4.2.cmml">U</mi><mo id="S4.E7.m2.3.3.1.1.4.1" xref="S4.E7.m2.3.3.1.1.4.1.cmml">â¢</mo><mi id="S4.E7.m2.3.3.1.1.4.3" mathcolor="#000000" xref="S4.E7.m2.3.3.1.1.4.3.cmml">P</mi><mo id="S4.E7.m2.3.3.1.1.4.1a" xref="S4.E7.m2.3.3.1.1.4.1.cmml">â¢</mo><mi id="S4.E7.m2.3.3.1.1.4.4" mathcolor="#000000" xref="S4.E7.m2.3.3.1.1.4.4.cmml">D</mi><mo id="S4.E7.m2.3.3.1.1.4.1b" xref="S4.E7.m2.3.3.1.1.4.1.cmml">â¢</mo><mi id="S4.E7.m2.3.3.1.1.4.5" mathcolor="#000000" xref="S4.E7.m2.3.3.1.1.4.5.cmml">A</mi><mo id="S4.E7.m2.3.3.1.1.4.1c" xref="S4.E7.m2.3.3.1.1.4.1.cmml">â¢</mo><mi id="S4.E7.m2.3.3.1.1.4.6" mathcolor="#000000" xref="S4.E7.m2.3.3.1.1.4.6.cmml">T</mi><mo id="S4.E7.m2.3.3.1.1.4.1d" xref="S4.E7.m2.3.3.1.1.4.1.cmml">â¢</mo><mi id="S4.E7.m2.3.3.1.1.4.7" mathcolor="#000000" xref="S4.E7.m2.3.3.1.1.4.7.cmml">E</mi><mo id="S4.E7.m2.3.3.1.1.4.1e" xref="S4.E7.m2.3.3.1.1.4.1.cmml">â¢</mo><mrow id="S4.E7.m2.3.3.1.1.4.8.2" xref="S4.E7.m2.3.3.1.1.4.cmml"><mo id="S4.E7.m2.3.3.1.1.4.8.2.1" mathcolor="#000000" stretchy="false" xref="S4.E7.m2.3.3.1.1.4.cmml">(</mo><mi id="S4.E7.m2.1.1" mathcolor="#000000" xref="S4.E7.m2.1.1.cmml">X</mi><mo id="S4.E7.m2.3.3.1.1.4.8.2.2" mathcolor="#000000" stretchy="false" xref="S4.E7.m2.3.3.1.1.4.cmml">)</mo></mrow></mrow><mo id="S4.E7.m2.3.3.1.1.5" xref="S4.E7.m2.3.3.1.1.5.cmml">=</mo><mrow id="S4.E7.m2.3.3.1.1.6" xref="S4.E7.m2.3.3.1.1.6.cmml"><mi id="S4.E7.m2.3.3.1.1.6.2" xref="S4.E7.m2.3.3.1.1.6.2.cmml">M</mi><mo id="S4.E7.m2.3.3.1.1.6.1" xref="S4.E7.m2.3.3.1.1.6.1.cmml">â¢</mo><mi id="S4.E7.m2.3.3.1.1.6.3" xref="S4.E7.m2.3.3.1.1.6.3.cmml">L</mi><mo id="S4.E7.m2.3.3.1.1.6.1a" xref="S4.E7.m2.3.3.1.1.6.1.cmml">â¢</mo><msup id="S4.E7.m2.3.3.1.1.6.4" xref="S4.E7.m2.3.3.1.1.6.4.cmml"><mi id="S4.E7.m2.3.3.1.1.6.4.2" xref="S4.E7.m2.3.3.1.1.6.4.2.cmml">P</mi><mi id="S4.E7.m2.3.3.1.1.6.4.3" xref="S4.E7.m2.3.3.1.1.6.4.3.cmml">k</mi></msup><mo id="S4.E7.m2.3.3.1.1.6.1b" xref="S4.E7.m2.3.3.1.1.6.1.cmml">â¢</mo><mrow id="S4.E7.m2.3.3.1.1.6.5.2" xref="S4.E7.m2.3.3.1.1.6.cmml"><mo id="S4.E7.m2.3.3.1.1.6.5.2.1" stretchy="false" xref="S4.E7.m2.3.3.1.1.6.cmml">(</mo><mi id="S4.E7.m2.2.2" xref="S4.E7.m2.2.2.cmml">X</mi><mo id="S4.E7.m2.3.3.1.1.6.5.2.2" stretchy="false" xref="S4.E7.m2.3.3.1.1.6.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E7.m2.3.3.1.2" xref="S4.E7.m2.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E7.m2.3b"><apply id="S4.E7.m2.3.3.1.1.cmml" xref="S4.E7.m2.3.3.1"><and id="S4.E7.m2.3.3.1.1a.cmml" xref="S4.E7.m2.3.3.1"></and><apply id="S4.E7.m2.3.3.1.1b.cmml" xref="S4.E7.m2.3.3.1"><eq id="S4.E7.m2.3.3.1.1.3.cmml" xref="S4.E7.m2.3.3.1.1.3"></eq><csymbol cd="latexml" id="S4.E7.m2.3.3.1.1.2.cmml" xref="S4.E7.m2.3.3.1.1.2">absent</csymbol><apply id="S4.E7.m2.3.3.1.1.4.cmml" xref="S4.E7.m2.3.3.1.1.4"><times id="S4.E7.m2.3.3.1.1.4.1.cmml" xref="S4.E7.m2.3.3.1.1.4.1"></times><ci id="S4.E7.m2.3.3.1.1.4.2.cmml" xref="S4.E7.m2.3.3.1.1.4.2">ğ‘ˆ</ci><ci id="S4.E7.m2.3.3.1.1.4.3.cmml" xref="S4.E7.m2.3.3.1.1.4.3">ğ‘ƒ</ci><ci id="S4.E7.m2.3.3.1.1.4.4.cmml" xref="S4.E7.m2.3.3.1.1.4.4">ğ·</ci><ci id="S4.E7.m2.3.3.1.1.4.5.cmml" xref="S4.E7.m2.3.3.1.1.4.5">ğ´</ci><ci id="S4.E7.m2.3.3.1.1.4.6.cmml" xref="S4.E7.m2.3.3.1.1.4.6">ğ‘‡</ci><ci id="S4.E7.m2.3.3.1.1.4.7.cmml" xref="S4.E7.m2.3.3.1.1.4.7">ğ¸</ci><ci id="S4.E7.m2.1.1.cmml" xref="S4.E7.m2.1.1">ğ‘‹</ci></apply></apply><apply id="S4.E7.m2.3.3.1.1c.cmml" xref="S4.E7.m2.3.3.1"><eq id="S4.E7.m2.3.3.1.1.5.cmml" xref="S4.E7.m2.3.3.1.1.5"></eq><share href="https://arxiv.org/html/2412.20379v1#S4.E7.m2.3.3.1.1.4.cmml" id="S4.E7.m2.3.3.1.1d.cmml" xref="S4.E7.m2.3.3.1"></share><apply id="S4.E7.m2.3.3.1.1.6.cmml" xref="S4.E7.m2.3.3.1.1.6"><times id="S4.E7.m2.3.3.1.1.6.1.cmml" xref="S4.E7.m2.3.3.1.1.6.1"></times><ci id="S4.E7.m2.3.3.1.1.6.2.cmml" xref="S4.E7.m2.3.3.1.1.6.2">ğ‘€</ci><ci id="S4.E7.m2.3.3.1.1.6.3.cmml" xref="S4.E7.m2.3.3.1.1.6.3">ğ¿</ci><apply id="S4.E7.m2.3.3.1.1.6.4.cmml" xref="S4.E7.m2.3.3.1.1.6.4"><csymbol cd="ambiguous" id="S4.E7.m2.3.3.1.1.6.4.1.cmml" xref="S4.E7.m2.3.3.1.1.6.4">superscript</csymbol><ci id="S4.E7.m2.3.3.1.1.6.4.2.cmml" xref="S4.E7.m2.3.3.1.1.6.4.2">ğ‘ƒ</ci><ci id="S4.E7.m2.3.3.1.1.6.4.3.cmml" xref="S4.E7.m2.3.3.1.1.6.4.3">ğ‘˜</ci></apply><ci id="S4.E7.m2.2.2.cmml" xref="S4.E7.m2.2.2">ğ‘‹</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E7.m2.3c">\displaystyle={\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}UPDATE(X)}=MLP^{k}%
(X),</annotation><annotation encoding="application/x-llamapun" id="S4.E7.m2.3d">= italic_U italic_P italic_D italic_A italic_T italic_E ( italic_X ) = italic_M italic_L italic_P start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_X ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.E8"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(8)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Z^{0}" class="ltx_Math" display="inline" id="S4.E8.m1.1"><semantics id="S4.E8.m1.1a"><msup id="S4.E8.m1.1.1" xref="S4.E8.m1.1.1.cmml"><mi id="S4.E8.m1.1.1.2" xref="S4.E8.m1.1.1.2.cmml">Z</mi><mn id="S4.E8.m1.1.1.3" xref="S4.E8.m1.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="S4.E8.m1.1b"><apply id="S4.E8.m1.1.1.cmml" xref="S4.E8.m1.1.1"><csymbol cd="ambiguous" id="S4.E8.m1.1.1.1.cmml" xref="S4.E8.m1.1.1">superscript</csymbol><ci id="S4.E8.m1.1.1.2.cmml" xref="S4.E8.m1.1.1.2">ğ‘</ci><cn id="S4.E8.m1.1.1.3.cmml" type="integer" xref="S4.E8.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m1.1c">\displaystyle Z^{0}</annotation><annotation encoding="application/x-llamapun" id="S4.E8.m1.1d">italic_Z start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle=\hat{L}," class="ltx_Math" display="inline" id="S4.E8.m2.1"><semantics id="S4.E8.m2.1a"><mrow id="S4.E8.m2.1.1.1" xref="S4.E8.m2.1.1.1.1.cmml"><mrow id="S4.E8.m2.1.1.1.1" xref="S4.E8.m2.1.1.1.1.cmml"><mi id="S4.E8.m2.1.1.1.1.2" xref="S4.E8.m2.1.1.1.1.2.cmml"></mi><mo id="S4.E8.m2.1.1.1.1.1" xref="S4.E8.m2.1.1.1.1.1.cmml">=</mo><mover accent="true" id="S4.E8.m2.1.1.1.1.3" xref="S4.E8.m2.1.1.1.1.3.cmml"><mi id="S4.E8.m2.1.1.1.1.3.2" xref="S4.E8.m2.1.1.1.1.3.2.cmml">L</mi><mo id="S4.E8.m2.1.1.1.1.3.1" xref="S4.E8.m2.1.1.1.1.3.1.cmml">^</mo></mover></mrow><mo id="S4.E8.m2.1.1.1.2" xref="S4.E8.m2.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E8.m2.1b"><apply id="S4.E8.m2.1.1.1.1.cmml" xref="S4.E8.m2.1.1.1"><eq id="S4.E8.m2.1.1.1.1.1.cmml" xref="S4.E8.m2.1.1.1.1.1"></eq><csymbol cd="latexml" id="S4.E8.m2.1.1.1.1.2.cmml" xref="S4.E8.m2.1.1.1.1.2">absent</csymbol><apply id="S4.E8.m2.1.1.1.1.3.cmml" xref="S4.E8.m2.1.1.1.1.3"><ci id="S4.E8.m2.1.1.1.1.3.1.cmml" xref="S4.E8.m2.1.1.1.1.3.1">^</ci><ci id="S4.E8.m2.1.1.1.1.3.2.cmml" xref="S4.E8.m2.1.1.1.1.3.2">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E8.m2.1c">\displaystyle=\hat{L},</annotation><annotation encoding="application/x-llamapun" id="S4.E8.m2.1d">= over^ start_ARG italic_L end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S4.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(9)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Z^{k}" class="ltx_Math" display="inline" id="S4.E9.m1.1"><semantics id="S4.E9.m1.1a"><msup id="S4.E9.m1.1.1" xref="S4.E9.m1.1.1.cmml"><mi id="S4.E9.m1.1.1.2" xref="S4.E9.m1.1.1.2.cmml">Z</mi><mi id="S4.E9.m1.1.1.3" xref="S4.E9.m1.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S4.E9.m1.1b"><apply id="S4.E9.m1.1.1.cmml" xref="S4.E9.m1.1.1"><csymbol cd="ambiguous" id="S4.E9.m1.1.1.1.cmml" xref="S4.E9.m1.1.1">superscript</csymbol><ci id="S4.E9.m1.1.1.2.cmml" xref="S4.E9.m1.1.1.2">ğ‘</ci><ci id="S4.E9.m1.1.1.3.cmml" xref="S4.E9.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m1.1c">\displaystyle Z^{k}</annotation><annotation encoding="application/x-llamapun" id="S4.E9.m1.1d">italic_Z start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle={\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}AGG(Z)}=\gamma\hat%
{A}Z^{k-1}," class="ltx_Math" display="inline" id="S4.E9.m2.2"><semantics id="S4.E9.m2.2a"><mrow id="S4.E9.m2.2.2.1" xref="S4.E9.m2.2.2.1.1.cmml"><mrow id="S4.E9.m2.2.2.1.1" xref="S4.E9.m2.2.2.1.1.cmml"><mi id="S4.E9.m2.2.2.1.1.2" xref="S4.E9.m2.2.2.1.1.2.cmml"></mi><mo id="S4.E9.m2.2.2.1.1.3" xref="S4.E9.m2.2.2.1.1.3.cmml">=</mo><mrow id="S4.E9.m2.2.2.1.1.4" xref="S4.E9.m2.2.2.1.1.4.cmml"><mi id="S4.E9.m2.2.2.1.1.4.2" mathcolor="#000000" xref="S4.E9.m2.2.2.1.1.4.2.cmml">A</mi><mo id="S4.E9.m2.2.2.1.1.4.1" xref="S4.E9.m2.2.2.1.1.4.1.cmml">â¢</mo><mi id="S4.E9.m2.2.2.1.1.4.3" mathcolor="#000000" xref="S4.E9.m2.2.2.1.1.4.3.cmml">G</mi><mo id="S4.E9.m2.2.2.1.1.4.1a" xref="S4.E9.m2.2.2.1.1.4.1.cmml">â¢</mo><mi id="S4.E9.m2.2.2.1.1.4.4" mathcolor="#000000" xref="S4.E9.m2.2.2.1.1.4.4.cmml">G</mi><mo id="S4.E9.m2.2.2.1.1.4.1b" xref="S4.E9.m2.2.2.1.1.4.1.cmml">â¢</mo><mrow id="S4.E9.m2.2.2.1.1.4.5.2" xref="S4.E9.m2.2.2.1.1.4.cmml"><mo id="S4.E9.m2.2.2.1.1.4.5.2.1" mathcolor="#000000" stretchy="false" xref="S4.E9.m2.2.2.1.1.4.cmml">(</mo><mi id="S4.E9.m2.1.1" mathcolor="#000000" xref="S4.E9.m2.1.1.cmml">Z</mi><mo id="S4.E9.m2.2.2.1.1.4.5.2.2" mathcolor="#000000" stretchy="false" xref="S4.E9.m2.2.2.1.1.4.cmml">)</mo></mrow></mrow><mo id="S4.E9.m2.2.2.1.1.5" xref="S4.E9.m2.2.2.1.1.5.cmml">=</mo><mrow id="S4.E9.m2.2.2.1.1.6" xref="S4.E9.m2.2.2.1.1.6.cmml"><mi id="S4.E9.m2.2.2.1.1.6.2" xref="S4.E9.m2.2.2.1.1.6.2.cmml">Î³</mi><mo id="S4.E9.m2.2.2.1.1.6.1" xref="S4.E9.m2.2.2.1.1.6.1.cmml">â¢</mo><mover accent="true" id="S4.E9.m2.2.2.1.1.6.3" xref="S4.E9.m2.2.2.1.1.6.3.cmml"><mi id="S4.E9.m2.2.2.1.1.6.3.2" xref="S4.E9.m2.2.2.1.1.6.3.2.cmml">A</mi><mo id="S4.E9.m2.2.2.1.1.6.3.1" xref="S4.E9.m2.2.2.1.1.6.3.1.cmml">^</mo></mover><mo id="S4.E9.m2.2.2.1.1.6.1a" xref="S4.E9.m2.2.2.1.1.6.1.cmml">â¢</mo><msup id="S4.E9.m2.2.2.1.1.6.4" xref="S4.E9.m2.2.2.1.1.6.4.cmml"><mi id="S4.E9.m2.2.2.1.1.6.4.2" xref="S4.E9.m2.2.2.1.1.6.4.2.cmml">Z</mi><mrow id="S4.E9.m2.2.2.1.1.6.4.3" xref="S4.E9.m2.2.2.1.1.6.4.3.cmml"><mi id="S4.E9.m2.2.2.1.1.6.4.3.2" xref="S4.E9.m2.2.2.1.1.6.4.3.2.cmml">k</mi><mo id="S4.E9.m2.2.2.1.1.6.4.3.1" xref="S4.E9.m2.2.2.1.1.6.4.3.1.cmml">âˆ’</mo><mn id="S4.E9.m2.2.2.1.1.6.4.3.3" xref="S4.E9.m2.2.2.1.1.6.4.3.3.cmml">1</mn></mrow></msup></mrow></mrow><mo id="S4.E9.m2.2.2.1.2" xref="S4.E9.m2.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E9.m2.2b"><apply id="S4.E9.m2.2.2.1.1.cmml" xref="S4.E9.m2.2.2.1"><and id="S4.E9.m2.2.2.1.1a.cmml" xref="S4.E9.m2.2.2.1"></and><apply id="S4.E9.m2.2.2.1.1b.cmml" xref="S4.E9.m2.2.2.1"><eq id="S4.E9.m2.2.2.1.1.3.cmml" xref="S4.E9.m2.2.2.1.1.3"></eq><csymbol cd="latexml" id="S4.E9.m2.2.2.1.1.2.cmml" xref="S4.E9.m2.2.2.1.1.2">absent</csymbol><apply id="S4.E9.m2.2.2.1.1.4.cmml" xref="S4.E9.m2.2.2.1.1.4"><times id="S4.E9.m2.2.2.1.1.4.1.cmml" xref="S4.E9.m2.2.2.1.1.4.1"></times><ci id="S4.E9.m2.2.2.1.1.4.2.cmml" xref="S4.E9.m2.2.2.1.1.4.2">ğ´</ci><ci id="S4.E9.m2.2.2.1.1.4.3.cmml" xref="S4.E9.m2.2.2.1.1.4.3">ğº</ci><ci id="S4.E9.m2.2.2.1.1.4.4.cmml" xref="S4.E9.m2.2.2.1.1.4.4">ğº</ci><ci id="S4.E9.m2.1.1.cmml" xref="S4.E9.m2.1.1">ğ‘</ci></apply></apply><apply id="S4.E9.m2.2.2.1.1c.cmml" xref="S4.E9.m2.2.2.1"><eq id="S4.E9.m2.2.2.1.1.5.cmml" xref="S4.E9.m2.2.2.1.1.5"></eq><share href="https://arxiv.org/html/2412.20379v1#S4.E9.m2.2.2.1.1.4.cmml" id="S4.E9.m2.2.2.1.1d.cmml" xref="S4.E9.m2.2.2.1"></share><apply id="S4.E9.m2.2.2.1.1.6.cmml" xref="S4.E9.m2.2.2.1.1.6"><times id="S4.E9.m2.2.2.1.1.6.1.cmml" xref="S4.E9.m2.2.2.1.1.6.1"></times><ci id="S4.E9.m2.2.2.1.1.6.2.cmml" xref="S4.E9.m2.2.2.1.1.6.2">ğ›¾</ci><apply id="S4.E9.m2.2.2.1.1.6.3.cmml" xref="S4.E9.m2.2.2.1.1.6.3"><ci id="S4.E9.m2.2.2.1.1.6.3.1.cmml" xref="S4.E9.m2.2.2.1.1.6.3.1">^</ci><ci id="S4.E9.m2.2.2.1.1.6.3.2.cmml" xref="S4.E9.m2.2.2.1.1.6.3.2">ğ´</ci></apply><apply id="S4.E9.m2.2.2.1.1.6.4.cmml" xref="S4.E9.m2.2.2.1.1.6.4"><csymbol cd="ambiguous" id="S4.E9.m2.2.2.1.1.6.4.1.cmml" xref="S4.E9.m2.2.2.1.1.6.4">superscript</csymbol><ci id="S4.E9.m2.2.2.1.1.6.4.2.cmml" xref="S4.E9.m2.2.2.1.1.6.4.2">ğ‘</ci><apply id="S4.E9.m2.2.2.1.1.6.4.3.cmml" xref="S4.E9.m2.2.2.1.1.6.4.3"><minus id="S4.E9.m2.2.2.1.1.6.4.3.1.cmml" xref="S4.E9.m2.2.2.1.1.6.4.3.1"></minus><ci id="S4.E9.m2.2.2.1.1.6.4.3.2.cmml" xref="S4.E9.m2.2.2.1.1.6.4.3.2">ğ‘˜</ci><cn id="S4.E9.m2.2.2.1.1.6.4.3.3.cmml" type="integer" xref="S4.E9.m2.2.2.1.1.6.4.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E9.m2.2c">\displaystyle={\color[rgb]{0,0,0}\definecolor[named]{pgfstrokecolor}{rgb}{%
0,0,0}\pgfsys@color@gray@stroke{0}\pgfsys@color@gray@fill{0}AGG(Z)}=\gamma\hat%
{A}Z^{k-1},</annotation><annotation encoding="application/x-llamapun" id="S4.E9.m2.2d">= italic_A italic_G italic_G ( italic_Z ) = italic_Î³ over^ start_ARG italic_A end_ARG italic_Z start_POSTSUPERSCRIPT italic_k - 1 end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS3.p4">
<p class="ltx_p" id="S4.SS1.SSS3.p4.17"><span class="ltx_text" id="S4.SS1.SSS3.p4.17.17" style="color:#000000;">where <math alttext="k" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.1.1.m1.1"><semantics id="S4.SS1.SSS3.p4.1.1.m1.1a"><mi id="S4.SS1.SSS3.p4.1.1.m1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.1.1.m1.1b"><ci id="S4.SS1.SSS3.p4.1.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p4.1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.1.1.m1.1d">italic_k</annotation></semantics></math> represents the number of times the NN operations and graph operations are executed, <math alttext="X" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.2.2.m2.1"><semantics id="S4.SS1.SSS3.p4.2.2.m2.1a"><mi id="S4.SS1.SSS3.p4.2.2.m2.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.2.2.m2.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.2.2.m2.1b"><ci id="S4.SS1.SSS3.p4.2.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p4.2.2.m2.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.2.2.m2.1c">X</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.2.2.m2.1d">italic_X</annotation></semantics></math> is input features. <math alttext="UPDATE(\cdot)" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.3.3.m3.1"><semantics id="S4.SS1.SSS3.p4.3.3.m3.1a"><mrow id="S4.SS1.SSS3.p4.3.3.m3.1.2" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.cmml"><mi id="S4.SS1.SSS3.p4.3.3.m3.1.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.2.cmml">U</mi><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.1" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.3.3.m3.1.2.3" mathcolor="#000000" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.3.cmml">P</mi><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.1a" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.3.3.m3.1.2.4" mathcolor="#000000" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.4.cmml">D</mi><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.1b" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.3.3.m3.1.2.5" mathcolor="#000000" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.5.cmml">A</mi><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.1c" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.3.3.m3.1.2.6" mathcolor="#000000" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.6.cmml">T</mi><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.1d" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.3.3.m3.1.2.7" mathcolor="#000000" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.7.cmml">E</mi><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.1e" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.SSS3.p4.3.3.m3.1.2.8.2" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.cmml"><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.8.2.1" mathcolor="#000000" stretchy="false" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.cmml">(</mo><mo id="S4.SS1.SSS3.p4.3.3.m3.1.1" lspace="0em" mathcolor="#000000" rspace="0em" xref="S4.SS1.SSS3.p4.3.3.m3.1.1.cmml">â‹…</mo><mo id="S4.SS1.SSS3.p4.3.3.m3.1.2.8.2.2" mathcolor="#000000" stretchy="false" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.3.3.m3.1b"><apply id="S4.SS1.SSS3.p4.3.3.m3.1.2.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2"><times id="S4.SS1.SSS3.p4.3.3.m3.1.2.1.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.1"></times><ci id="S4.SS1.SSS3.p4.3.3.m3.1.2.2.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.2">ğ‘ˆ</ci><ci id="S4.SS1.SSS3.p4.3.3.m3.1.2.3.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.3">ğ‘ƒ</ci><ci id="S4.SS1.SSS3.p4.3.3.m3.1.2.4.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.4">ğ·</ci><ci id="S4.SS1.SSS3.p4.3.3.m3.1.2.5.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.5">ğ´</ci><ci id="S4.SS1.SSS3.p4.3.3.m3.1.2.6.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.6">ğ‘‡</ci><ci id="S4.SS1.SSS3.p4.3.3.m3.1.2.7.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.2.7">ğ¸</ci><ci id="S4.SS1.SSS3.p4.3.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p4.3.3.m3.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.3.3.m3.1c">UPDATE(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.3.3.m3.1d">italic_U italic_P italic_D italic_A italic_T italic_E ( â‹… )</annotation></semantics></math> represents NN operation, i.e., <math alttext="X" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.4.4.m4.1"><semantics id="S4.SS1.SSS3.p4.4.4.m4.1a"><mi id="S4.SS1.SSS3.p4.4.4.m4.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.4.4.m4.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.4.4.m4.1b"><ci id="S4.SS1.SSS3.p4.4.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p4.4.4.m4.1.1">ğ‘‹</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.4.4.m4.1c">X</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.4.4.m4.1d">italic_X</annotation></semantics></math> is fed into a multi-layer neural network to obtain the embeddings <math alttext="\hat{L}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.5.5.m5.1"><semantics id="S4.SS1.SSS3.p4.5.5.m5.1a"><mover accent="true" id="S4.SS1.SSS3.p4.5.5.m5.1.1" xref="S4.SS1.SSS3.p4.5.5.m5.1.1.cmml"><mi id="S4.SS1.SSS3.p4.5.5.m5.1.1.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.5.5.m5.1.1.2.cmml">L</mi><mo id="S4.SS1.SSS3.p4.5.5.m5.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.5.5.m5.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.5.5.m5.1b"><apply id="S4.SS1.SSS3.p4.5.5.m5.1.1.cmml" xref="S4.SS1.SSS3.p4.5.5.m5.1.1"><ci id="S4.SS1.SSS3.p4.5.5.m5.1.1.1.cmml" xref="S4.SS1.SSS3.p4.5.5.m5.1.1.1">^</ci><ci id="S4.SS1.SSS3.p4.5.5.m5.1.1.2.cmml" xref="S4.SS1.SSS3.p4.5.5.m5.1.1.2">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.5.5.m5.1c">\hat{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.5.5.m5.1d">over^ start_ARG italic_L end_ARG</annotation></semantics></math>. To learn the structural information of the graph, decoupled GNN training performs multi-layer graph operations, i.e., <math alttext="AGG(\cdot)" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.6.6.m6.1"><semantics id="S4.SS1.SSS3.p4.6.6.m6.1a"><mrow id="S4.SS1.SSS3.p4.6.6.m6.1.2" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.cmml"><mi id="S4.SS1.SSS3.p4.6.6.m6.1.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.2.cmml">A</mi><mo id="S4.SS1.SSS3.p4.6.6.m6.1.2.1" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.6.6.m6.1.2.3" mathcolor="#000000" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.3.cmml">G</mi><mo id="S4.SS1.SSS3.p4.6.6.m6.1.2.1a" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p4.6.6.m6.1.2.4" mathcolor="#000000" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.4.cmml">G</mi><mo id="S4.SS1.SSS3.p4.6.6.m6.1.2.1b" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.SSS3.p4.6.6.m6.1.2.5.2" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.cmml"><mo id="S4.SS1.SSS3.p4.6.6.m6.1.2.5.2.1" mathcolor="#000000" stretchy="false" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.cmml">(</mo><mo id="S4.SS1.SSS3.p4.6.6.m6.1.1" lspace="0em" mathcolor="#000000" rspace="0em" xref="S4.SS1.SSS3.p4.6.6.m6.1.1.cmml">â‹…</mo><mo id="S4.SS1.SSS3.p4.6.6.m6.1.2.5.2.2" mathcolor="#000000" stretchy="false" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.6.6.m6.1b"><apply id="S4.SS1.SSS3.p4.6.6.m6.1.2.cmml" xref="S4.SS1.SSS3.p4.6.6.m6.1.2"><times id="S4.SS1.SSS3.p4.6.6.m6.1.2.1.cmml" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.1"></times><ci id="S4.SS1.SSS3.p4.6.6.m6.1.2.2.cmml" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.2">ğ´</ci><ci id="S4.SS1.SSS3.p4.6.6.m6.1.2.3.cmml" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.3">ğº</ci><ci id="S4.SS1.SSS3.p4.6.6.m6.1.2.4.cmml" xref="S4.SS1.SSS3.p4.6.6.m6.1.2.4">ğº</ci><ci id="S4.SS1.SSS3.p4.6.6.m6.1.1.cmml" xref="S4.SS1.SSS3.p4.6.6.m6.1.1">â‹…</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.6.6.m6.1c">AGG(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.6.6.m6.1d">italic_A italic_G italic_G ( â‹… )</annotation></semantics></math>.
<math alttext="\hat{A}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.7.7.m7.1"><semantics id="S4.SS1.SSS3.p4.7.7.m7.1a"><mover accent="true" id="S4.SS1.SSS3.p4.7.7.m7.1.1" xref="S4.SS1.SSS3.p4.7.7.m7.1.1.cmml"><mi id="S4.SS1.SSS3.p4.7.7.m7.1.1.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.7.7.m7.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS3.p4.7.7.m7.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.7.7.m7.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.7.7.m7.1b"><apply id="S4.SS1.SSS3.p4.7.7.m7.1.1.cmml" xref="S4.SS1.SSS3.p4.7.7.m7.1.1"><ci id="S4.SS1.SSS3.p4.7.7.m7.1.1.1.cmml" xref="S4.SS1.SSS3.p4.7.7.m7.1.1.1">^</ci><ci id="S4.SS1.SSS3.p4.7.7.m7.1.1.2.cmml" xref="S4.SS1.SSS3.p4.7.7.m7.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.7.7.m7.1c">\hat{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.7.7.m7.1d">over^ start_ARG italic_A end_ARG</annotation></semantics></math> is symmetrically normalized adjacency matrix
(<math alttext="\hat{A}=\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.8.8.m8.1"><semantics id="S4.SS1.SSS3.p4.8.8.m8.1a"><mrow id="S4.SS1.SSS3.p4.8.8.m8.1.1" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.cmml"><mover accent="true" id="S4.SS1.SSS3.p4.8.8.m8.1.1.2" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.2.cmml"><mi id="S4.SS1.SSS3.p4.8.8.m8.1.1.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.2.2.cmml">A</mi><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.2.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.2.1.cmml">^</mo></mover><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.1.cmml">=</mo><mrow id="S4.SS1.SSS3.p4.8.8.m8.1.1.3" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.cmml"><msup id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.cmml"><mover accent="true" id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.cmml"><mi id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.2.cmml">D</mi><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.1.cmml">~</mo></mover><mrow id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.cmml"><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3a" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.cmml">âˆ’</mo><mfrac id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.cmml"><mn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.2.cmml">1</mn><mn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.3" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.3.cmml">2</mn></mfrac></mrow></msup><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.1" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.1.cmml">â¢</mo><mover accent="true" id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.cmml"><mi id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.2.cmml">A</mi><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.1.cmml">~</mo></mover><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.1a" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.1.cmml">â¢</mo><msup id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.cmml"><mover accent="true" id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.cmml"><mi id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.2.cmml">D</mi><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.1.cmml">~</mo></mover><mrow id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.cmml"><mo id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3a" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.cmml">âˆ’</mo><mfrac id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.cmml"><mn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.2.cmml">1</mn><mn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.3" mathcolor="#000000" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.3.cmml">2</mn></mfrac></mrow></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.8.8.m8.1b"><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1"><eq id="S4.SS1.SSS3.p4.8.8.m8.1.1.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.1"></eq><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.2"><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.2.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.2.1">^</ci><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.2.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.2.2">ğ´</ci></apply><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3"><times id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.1"></times><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2">superscript</csymbol><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2"><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.1">~</ci><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.2.2">ğ·</ci></apply><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3"><minus id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3"></minus><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2"><divide id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2"></divide><cn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.2.cmml" type="integer" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.2">1</cn><cn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.3.cmml" type="integer" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.2.3.2.3">2</cn></apply></apply></apply><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3"><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.1">~</ci><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.3.2">ğ´</ci></apply><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4">superscript</csymbol><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2"><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.1">~</ci><ci id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.2.2">ğ·</ci></apply><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3"><minus id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3"></minus><apply id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2"><divide id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.1.cmml" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2"></divide><cn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.2.cmml" type="integer" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.2">1</cn><cn id="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.3.cmml" type="integer" xref="S4.SS1.SSS3.p4.8.8.m8.1.1.3.4.3.2.3">2</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.8.8.m8.1c">\hat{A}=\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.8.8.m8.1d">over^ start_ARG italic_A end_ARG = over~ start_ARG italic_D end_ARG start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT over~ start_ARG italic_A end_ARG over~ start_ARG italic_D end_ARG start_POSTSUPERSCRIPT - divide start_ARG 1 end_ARG start_ARG 2 end_ARG end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="A" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.9.9.m9.1"><semantics id="S4.SS1.SSS3.p4.9.9.m9.1a"><mi id="S4.SS1.SSS3.p4.9.9.m9.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.9.9.m9.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.9.9.m9.1b"><ci id="S4.SS1.SSS3.p4.9.9.m9.1.1.cmml" xref="S4.SS1.SSS3.p4.9.9.m9.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.9.9.m9.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.9.9.m9.1d">italic_A</annotation></semantics></math> represents the adjacency matrix, <math alttext="D" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.10.10.m10.1"><semantics id="S4.SS1.SSS3.p4.10.10.m10.1a"><mi id="S4.SS1.SSS3.p4.10.10.m10.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.10.10.m10.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.10.10.m10.1b"><ci id="S4.SS1.SSS3.p4.10.10.m10.1.1.cmml" xref="S4.SS1.SSS3.p4.10.10.m10.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.10.10.m10.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.10.10.m10.1d">italic_D</annotation></semantics></math> represents the degree matrix. Here, <math alttext="\tilde{A}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.11.11.m11.1"><semantics id="S4.SS1.SSS3.p4.11.11.m11.1a"><mover accent="true" id="S4.SS1.SSS3.p4.11.11.m11.1.1" xref="S4.SS1.SSS3.p4.11.11.m11.1.1.cmml"><mi id="S4.SS1.SSS3.p4.11.11.m11.1.1.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.11.11.m11.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS3.p4.11.11.m11.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.11.11.m11.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.11.11.m11.1b"><apply id="S4.SS1.SSS3.p4.11.11.m11.1.1.cmml" xref="S4.SS1.SSS3.p4.11.11.m11.1.1"><ci id="S4.SS1.SSS3.p4.11.11.m11.1.1.1.cmml" xref="S4.SS1.SSS3.p4.11.11.m11.1.1.1">~</ci><ci id="S4.SS1.SSS3.p4.11.11.m11.1.1.2.cmml" xref="S4.SS1.SSS3.p4.11.11.m11.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.11.11.m11.1c">\tilde{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.11.11.m11.1d">over~ start_ARG italic_A end_ARG</annotation></semantics></math> and <math alttext="\tilde{D}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.12.12.m12.1"><semantics id="S4.SS1.SSS3.p4.12.12.m12.1a"><mover accent="true" id="S4.SS1.SSS3.p4.12.12.m12.1.1" xref="S4.SS1.SSS3.p4.12.12.m12.1.1.cmml"><mi id="S4.SS1.SSS3.p4.12.12.m12.1.1.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.12.12.m12.1.1.2.cmml">D</mi><mo id="S4.SS1.SSS3.p4.12.12.m12.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.12.12.m12.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.12.12.m12.1b"><apply id="S4.SS1.SSS3.p4.12.12.m12.1.1.cmml" xref="S4.SS1.SSS3.p4.12.12.m12.1.1"><ci id="S4.SS1.SSS3.p4.12.12.m12.1.1.1.cmml" xref="S4.SS1.SSS3.p4.12.12.m12.1.1.1">~</ci><ci id="S4.SS1.SSS3.p4.12.12.m12.1.1.2.cmml" xref="S4.SS1.SSS3.p4.12.12.m12.1.1.2">ğ·</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.12.12.m12.1c">\tilde{D}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.12.12.m12.1d">over~ start_ARG italic_D end_ARG</annotation></semantics></math> correspond to <math alttext="A+I" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.13.13.m13.1"><semantics id="S4.SS1.SSS3.p4.13.13.m13.1a"><mrow id="S4.SS1.SSS3.p4.13.13.m13.1.1" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.cmml"><mi id="S4.SS1.SSS3.p4.13.13.m13.1.1.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS3.p4.13.13.m13.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.1.cmml">+</mo><mi id="S4.SS1.SSS3.p4.13.13.m13.1.1.3" mathcolor="#000000" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.3.cmml">I</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.13.13.m13.1b"><apply id="S4.SS1.SSS3.p4.13.13.m13.1.1.cmml" xref="S4.SS1.SSS3.p4.13.13.m13.1.1"><plus id="S4.SS1.SSS3.p4.13.13.m13.1.1.1.cmml" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.1"></plus><ci id="S4.SS1.SSS3.p4.13.13.m13.1.1.2.cmml" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.2">ğ´</ci><ci id="S4.SS1.SSS3.p4.13.13.m13.1.1.3.cmml" xref="S4.SS1.SSS3.p4.13.13.m13.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.13.13.m13.1c">A+I</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.13.13.m13.1d">italic_A + italic_I</annotation></semantics></math> and <math alttext="D+I" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.14.14.m14.1"><semantics id="S4.SS1.SSS3.p4.14.14.m14.1a"><mrow id="S4.SS1.SSS3.p4.14.14.m14.1.1" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.cmml"><mi id="S4.SS1.SSS3.p4.14.14.m14.1.1.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.2.cmml">D</mi><mo id="S4.SS1.SSS3.p4.14.14.m14.1.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.1.cmml">+</mo><mi id="S4.SS1.SSS3.p4.14.14.m14.1.1.3" mathcolor="#000000" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.3.cmml">I</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.14.14.m14.1b"><apply id="S4.SS1.SSS3.p4.14.14.m14.1.1.cmml" xref="S4.SS1.SSS3.p4.14.14.m14.1.1"><plus id="S4.SS1.SSS3.p4.14.14.m14.1.1.1.cmml" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.1"></plus><ci id="S4.SS1.SSS3.p4.14.14.m14.1.1.2.cmml" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.2">ğ·</ci><ci id="S4.SS1.SSS3.p4.14.14.m14.1.1.3.cmml" xref="S4.SS1.SSS3.p4.14.14.m14.1.1.3">ğ¼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.14.14.m14.1c">D+I</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.14.14.m14.1d">italic_D + italic_I</annotation></semantics></math>, respectively, with <math alttext="I" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.15.15.m15.1"><semantics id="S4.SS1.SSS3.p4.15.15.m15.1a"><mi id="S4.SS1.SSS3.p4.15.15.m15.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.15.15.m15.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.15.15.m15.1b"><ci id="S4.SS1.SSS3.p4.15.15.m15.1.1.cmml" xref="S4.SS1.SSS3.p4.15.15.m15.1.1">ğ¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.15.15.m15.1c">I</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.15.15.m15.1d">italic_I</annotation></semantics></math> being the identity matrix).
<math alttext="\gamma" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.16.16.m16.1"><semantics id="S4.SS1.SSS3.p4.16.16.m16.1a"><mi id="S4.SS1.SSS3.p4.16.16.m16.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.16.16.m16.1.1.cmml">Î³</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.16.16.m16.1b"><ci id="S4.SS1.SSS3.p4.16.16.m16.1.1.cmml" xref="S4.SS1.SSS3.p4.16.16.m16.1.1">ğ›¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.16.16.m16.1c">\gamma</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.16.16.m16.1d">italic_Î³</annotation></semantics></math> (<math alttext="\gamma\in(0,1]" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.17.17.m17.2"><semantics id="S4.SS1.SSS3.p4.17.17.m17.2a"><mrow id="S4.SS1.SSS3.p4.17.17.m17.2.3" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.cmml"><mi id="S4.SS1.SSS3.p4.17.17.m17.2.3.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.2.cmml">Î³</mi><mo id="S4.SS1.SSS3.p4.17.17.m17.2.3.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.1.cmml">âˆˆ</mo><mrow id="S4.SS1.SSS3.p4.17.17.m17.2.3.3.2" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.3.1.cmml"><mo id="S4.SS1.SSS3.p4.17.17.m17.2.3.3.2.1" mathcolor="#000000" stretchy="false" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.3.1.cmml">(</mo><mn id="S4.SS1.SSS3.p4.17.17.m17.1.1" mathcolor="#000000" xref="S4.SS1.SSS3.p4.17.17.m17.1.1.cmml">0</mn><mo id="S4.SS1.SSS3.p4.17.17.m17.2.3.3.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.3.1.cmml">,</mo><mn id="S4.SS1.SSS3.p4.17.17.m17.2.2" mathcolor="#000000" xref="S4.SS1.SSS3.p4.17.17.m17.2.2.cmml">1</mn><mo id="S4.SS1.SSS3.p4.17.17.m17.2.3.3.2.3" mathcolor="#000000" stretchy="false" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.17.17.m17.2b"><apply id="S4.SS1.SSS3.p4.17.17.m17.2.3.cmml" xref="S4.SS1.SSS3.p4.17.17.m17.2.3"><in id="S4.SS1.SSS3.p4.17.17.m17.2.3.1.cmml" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.1"></in><ci id="S4.SS1.SSS3.p4.17.17.m17.2.3.2.cmml" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.2">ğ›¾</ci><interval closure="open-closed" id="S4.SS1.SSS3.p4.17.17.m17.2.3.3.1.cmml" xref="S4.SS1.SSS3.p4.17.17.m17.2.3.3.2"><cn id="S4.SS1.SSS3.p4.17.17.m17.1.1.cmml" type="integer" xref="S4.SS1.SSS3.p4.17.17.m17.1.1">0</cn><cn id="S4.SS1.SSS3.p4.17.17.m17.2.2.cmml" type="integer" xref="S4.SS1.SSS3.p4.17.17.m17.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.17.17.m17.2c">\gamma\in(0,1]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.17.17.m17.2d">italic_Î³ âˆˆ ( 0 , 1 ]</annotation></semantics></math>) is the weight of edges, which can be computed through a self-attention mechanism as in GAT or weighted neighbor convolution as in GCN.</span></p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p5">
<p class="ltx_p" id="S4.SS1.SSS3.p5.3"><math alttext="MLP^{k}(X)" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p5.1.m1.1"><semantics id="S4.SS1.SSS3.p5.1.m1.1a"><mrow id="S4.SS1.SSS3.p5.1.m1.1.2" xref="S4.SS1.SSS3.p5.1.m1.1.2.cmml"><mi id="S4.SS1.SSS3.p5.1.m1.1.2.2" xref="S4.SS1.SSS3.p5.1.m1.1.2.2.cmml">M</mi><mo id="S4.SS1.SSS3.p5.1.m1.1.2.1" xref="S4.SS1.SSS3.p5.1.m1.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p5.1.m1.1.2.3" xref="S4.SS1.SSS3.p5.1.m1.1.2.3.cmml">L</mi><mo id="S4.SS1.SSS3.p5.1.m1.1.2.1a" xref="S4.SS1.SSS3.p5.1.m1.1.2.1.cmml">â¢</mo><msup id="S4.SS1.SSS3.p5.1.m1.1.2.4" xref="S4.SS1.SSS3.p5.1.m1.1.2.4.cmml"><mi id="S4.SS1.SSS3.p5.1.m1.1.2.4.2" xref="S4.SS1.SSS3.p5.1.m1.1.2.4.2.cmml">P</mi><mi id="S4.SS1.SSS3.p5.1.m1.1.2.4.3" xref="S4.SS1.SSS3.p5.1.m1.1.2.4.3.cmml">k</mi></msup><mo id="S4.SS1.SSS3.p5.1.m1.1.2.1b" xref="S4.SS1.SSS3.p5.1.m1.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.SSS3.p5.1.m1.1.2.5.2" xref="S4.SS1.SSS3.p5.1.m1.1.2.cmml"><mo id="S4.SS1.SSS3.p5.1.m1.1.2.5.2.1" stretchy="false" xref="S4.SS1.SSS3.p5.1.m1.1.2.cmml">(</mo><mi id="S4.SS1.SSS3.p5.1.m1.1.1" xref="S4.SS1.SSS3.p5.1.m1.1.1.cmml">X</mi><mo id="S4.SS1.SSS3.p5.1.m1.1.2.5.2.2" stretchy="false" xref="S4.SS1.SSS3.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p5.1.m1.1b"><apply id="S4.SS1.SSS3.p5.1.m1.1.2.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2"><times id="S4.SS1.SSS3.p5.1.m1.1.2.1.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.1"></times><ci id="S4.SS1.SSS3.p5.1.m1.1.2.2.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.2">ğ‘€</ci><ci id="S4.SS1.SSS3.p5.1.m1.1.2.3.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.3">ğ¿</ci><apply id="S4.SS1.SSS3.p5.1.m1.1.2.4.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.4"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p5.1.m1.1.2.4.1.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.4">superscript</csymbol><ci id="S4.SS1.SSS3.p5.1.m1.1.2.4.2.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.4.2">ğ‘ƒ</ci><ci id="S4.SS1.SSS3.p5.1.m1.1.2.4.3.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.2.4.3">ğ‘˜</ci></apply><ci id="S4.SS1.SSS3.p5.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p5.1.m1.1.1">ğ‘‹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p5.1.m1.1c">MLP^{k}(X)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p5.1.m1.1d">italic_M italic_L italic_P start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ( italic_X )</annotation></semantics></math> is the convergent function. <span class="ltx_text" id="S4.SS1.SSS3.p5.3.1" style="color:#000000;">This is because multiple NN operations can be viewed as a traditional deep neural network model (i.e., multi-layer perceptron), whose convergence properties are well-established <cite class="ltx_cite ltx_citemacro_citep">(Baker and Patil, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib2" title="">1998</a>; Nishijima, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib28" title="">2021</a>)</cite>.</span> Therefore, we only need to consider <math alttext="AGG(Z)" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p5.2.m2.1"><semantics id="S4.SS1.SSS3.p5.2.m2.1a"><mrow id="S4.SS1.SSS3.p5.2.m2.1.2" xref="S4.SS1.SSS3.p5.2.m2.1.2.cmml"><mi id="S4.SS1.SSS3.p5.2.m2.1.2.2" xref="S4.SS1.SSS3.p5.2.m2.1.2.2.cmml">A</mi><mo id="S4.SS1.SSS3.p5.2.m2.1.2.1" xref="S4.SS1.SSS3.p5.2.m2.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p5.2.m2.1.2.3" xref="S4.SS1.SSS3.p5.2.m2.1.2.3.cmml">G</mi><mo id="S4.SS1.SSS3.p5.2.m2.1.2.1a" xref="S4.SS1.SSS3.p5.2.m2.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p5.2.m2.1.2.4" xref="S4.SS1.SSS3.p5.2.m2.1.2.4.cmml">G</mi><mo id="S4.SS1.SSS3.p5.2.m2.1.2.1b" xref="S4.SS1.SSS3.p5.2.m2.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.SSS3.p5.2.m2.1.2.5.2" xref="S4.SS1.SSS3.p5.2.m2.1.2.cmml"><mo id="S4.SS1.SSS3.p5.2.m2.1.2.5.2.1" stretchy="false" xref="S4.SS1.SSS3.p5.2.m2.1.2.cmml">(</mo><mi id="S4.SS1.SSS3.p5.2.m2.1.1" xref="S4.SS1.SSS3.p5.2.m2.1.1.cmml">Z</mi><mo id="S4.SS1.SSS3.p5.2.m2.1.2.5.2.2" stretchy="false" xref="S4.SS1.SSS3.p5.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p5.2.m2.1b"><apply id="S4.SS1.SSS3.p5.2.m2.1.2.cmml" xref="S4.SS1.SSS3.p5.2.m2.1.2"><times id="S4.SS1.SSS3.p5.2.m2.1.2.1.cmml" xref="S4.SS1.SSS3.p5.2.m2.1.2.1"></times><ci id="S4.SS1.SSS3.p5.2.m2.1.2.2.cmml" xref="S4.SS1.SSS3.p5.2.m2.1.2.2">ğ´</ci><ci id="S4.SS1.SSS3.p5.2.m2.1.2.3.cmml" xref="S4.SS1.SSS3.p5.2.m2.1.2.3">ğº</ci><ci id="S4.SS1.SSS3.p5.2.m2.1.2.4.cmml" xref="S4.SS1.SSS3.p5.2.m2.1.2.4">ğº</ci><ci id="S4.SS1.SSS3.p5.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p5.2.m2.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p5.2.m2.1c">AGG(Z)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p5.2.m2.1d">italic_A italic_G italic_G ( italic_Z )</annotation></semantics></math>. After k iterations of graph propagation, <math alttext="AGG(Z)" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p5.3.m3.1"><semantics id="S4.SS1.SSS3.p5.3.m3.1a"><mrow id="S4.SS1.SSS3.p5.3.m3.1.2" xref="S4.SS1.SSS3.p5.3.m3.1.2.cmml"><mi id="S4.SS1.SSS3.p5.3.m3.1.2.2" xref="S4.SS1.SSS3.p5.3.m3.1.2.2.cmml">A</mi><mo id="S4.SS1.SSS3.p5.3.m3.1.2.1" xref="S4.SS1.SSS3.p5.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p5.3.m3.1.2.3" xref="S4.SS1.SSS3.p5.3.m3.1.2.3.cmml">G</mi><mo id="S4.SS1.SSS3.p5.3.m3.1.2.1a" xref="S4.SS1.SSS3.p5.3.m3.1.2.1.cmml">â¢</mo><mi id="S4.SS1.SSS3.p5.3.m3.1.2.4" xref="S4.SS1.SSS3.p5.3.m3.1.2.4.cmml">G</mi><mo id="S4.SS1.SSS3.p5.3.m3.1.2.1b" xref="S4.SS1.SSS3.p5.3.m3.1.2.1.cmml">â¢</mo><mrow id="S4.SS1.SSS3.p5.3.m3.1.2.5.2" xref="S4.SS1.SSS3.p5.3.m3.1.2.cmml"><mo id="S4.SS1.SSS3.p5.3.m3.1.2.5.2.1" stretchy="false" xref="S4.SS1.SSS3.p5.3.m3.1.2.cmml">(</mo><mi id="S4.SS1.SSS3.p5.3.m3.1.1" xref="S4.SS1.SSS3.p5.3.m3.1.1.cmml">Z</mi><mo id="S4.SS1.SSS3.p5.3.m3.1.2.5.2.2" stretchy="false" xref="S4.SS1.SSS3.p5.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p5.3.m3.1b"><apply id="S4.SS1.SSS3.p5.3.m3.1.2.cmml" xref="S4.SS1.SSS3.p5.3.m3.1.2"><times id="S4.SS1.SSS3.p5.3.m3.1.2.1.cmml" xref="S4.SS1.SSS3.p5.3.m3.1.2.1"></times><ci id="S4.SS1.SSS3.p5.3.m3.1.2.2.cmml" xref="S4.SS1.SSS3.p5.3.m3.1.2.2">ğ´</ci><ci id="S4.SS1.SSS3.p5.3.m3.1.2.3.cmml" xref="S4.SS1.SSS3.p5.3.m3.1.2.3">ğº</ci><ci id="S4.SS1.SSS3.p5.3.m3.1.2.4.cmml" xref="S4.SS1.SSS3.p5.3.m3.1.2.4">ğº</ci><ci id="S4.SS1.SSS3.p5.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p5.3.m3.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p5.3.m3.1c">AGG(Z)</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p5.3.m3.1d">italic_A italic_G italic_G ( italic_Z )</annotation></semantics></math> can be expressed as:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx8">
<tbody id="S4.E10"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(10)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Z^{k}=\gamma^{k}\hat{A}^{k}\hat{L}." class="ltx_Math" display="inline" id="S4.E10.m1.1"><semantics id="S4.E10.m1.1a"><mrow id="S4.E10.m1.1.1.1" xref="S4.E10.m1.1.1.1.1.cmml"><mrow id="S4.E10.m1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.cmml"><msup id="S4.E10.m1.1.1.1.1.2" xref="S4.E10.m1.1.1.1.1.2.cmml"><mi id="S4.E10.m1.1.1.1.1.2.2" xref="S4.E10.m1.1.1.1.1.2.2.cmml">Z</mi><mi id="S4.E10.m1.1.1.1.1.2.3" xref="S4.E10.m1.1.1.1.1.2.3.cmml">k</mi></msup><mo id="S4.E10.m1.1.1.1.1.1" xref="S4.E10.m1.1.1.1.1.1.cmml">=</mo><mrow id="S4.E10.m1.1.1.1.1.3" xref="S4.E10.m1.1.1.1.1.3.cmml"><msup id="S4.E10.m1.1.1.1.1.3.2" xref="S4.E10.m1.1.1.1.1.3.2.cmml"><mi id="S4.E10.m1.1.1.1.1.3.2.2" xref="S4.E10.m1.1.1.1.1.3.2.2.cmml">Î³</mi><mi id="S4.E10.m1.1.1.1.1.3.2.3" xref="S4.E10.m1.1.1.1.1.3.2.3.cmml">k</mi></msup><mo id="S4.E10.m1.1.1.1.1.3.1" xref="S4.E10.m1.1.1.1.1.3.1.cmml">â¢</mo><msup id="S4.E10.m1.1.1.1.1.3.3" xref="S4.E10.m1.1.1.1.1.3.3.cmml"><mover accent="true" id="S4.E10.m1.1.1.1.1.3.3.2" xref="S4.E10.m1.1.1.1.1.3.3.2.cmml"><mi id="S4.E10.m1.1.1.1.1.3.3.2.2" xref="S4.E10.m1.1.1.1.1.3.3.2.2.cmml">A</mi><mo id="S4.E10.m1.1.1.1.1.3.3.2.1" xref="S4.E10.m1.1.1.1.1.3.3.2.1.cmml">^</mo></mover><mi id="S4.E10.m1.1.1.1.1.3.3.3" xref="S4.E10.m1.1.1.1.1.3.3.3.cmml">k</mi></msup><mo id="S4.E10.m1.1.1.1.1.3.1a" xref="S4.E10.m1.1.1.1.1.3.1.cmml">â¢</mo><mover accent="true" id="S4.E10.m1.1.1.1.1.3.4" xref="S4.E10.m1.1.1.1.1.3.4.cmml"><mi id="S4.E10.m1.1.1.1.1.3.4.2" xref="S4.E10.m1.1.1.1.1.3.4.2.cmml">L</mi><mo id="S4.E10.m1.1.1.1.1.3.4.1" xref="S4.E10.m1.1.1.1.1.3.4.1.cmml">^</mo></mover></mrow></mrow><mo id="S4.E10.m1.1.1.1.2" lspace="0em" xref="S4.E10.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E10.m1.1b"><apply id="S4.E10.m1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1"><eq id="S4.E10.m1.1.1.1.1.1.cmml" xref="S4.E10.m1.1.1.1.1.1"></eq><apply id="S4.E10.m1.1.1.1.1.2.cmml" xref="S4.E10.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.1.1.2.1.cmml" xref="S4.E10.m1.1.1.1.1.2">superscript</csymbol><ci id="S4.E10.m1.1.1.1.1.2.2.cmml" xref="S4.E10.m1.1.1.1.1.2.2">ğ‘</ci><ci id="S4.E10.m1.1.1.1.1.2.3.cmml" xref="S4.E10.m1.1.1.1.1.2.3">ğ‘˜</ci></apply><apply id="S4.E10.m1.1.1.1.1.3.cmml" xref="S4.E10.m1.1.1.1.1.3"><times id="S4.E10.m1.1.1.1.1.3.1.cmml" xref="S4.E10.m1.1.1.1.1.3.1"></times><apply id="S4.E10.m1.1.1.1.1.3.2.cmml" xref="S4.E10.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.1.1.3.2.1.cmml" xref="S4.E10.m1.1.1.1.1.3.2">superscript</csymbol><ci id="S4.E10.m1.1.1.1.1.3.2.2.cmml" xref="S4.E10.m1.1.1.1.1.3.2.2">ğ›¾</ci><ci id="S4.E10.m1.1.1.1.1.3.2.3.cmml" xref="S4.E10.m1.1.1.1.1.3.2.3">ğ‘˜</ci></apply><apply id="S4.E10.m1.1.1.1.1.3.3.cmml" xref="S4.E10.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="S4.E10.m1.1.1.1.1.3.3.1.cmml" xref="S4.E10.m1.1.1.1.1.3.3">superscript</csymbol><apply id="S4.E10.m1.1.1.1.1.3.3.2.cmml" xref="S4.E10.m1.1.1.1.1.3.3.2"><ci id="S4.E10.m1.1.1.1.1.3.3.2.1.cmml" xref="S4.E10.m1.1.1.1.1.3.3.2.1">^</ci><ci id="S4.E10.m1.1.1.1.1.3.3.2.2.cmml" xref="S4.E10.m1.1.1.1.1.3.3.2.2">ğ´</ci></apply><ci id="S4.E10.m1.1.1.1.1.3.3.3.cmml" xref="S4.E10.m1.1.1.1.1.3.3.3">ğ‘˜</ci></apply><apply id="S4.E10.m1.1.1.1.1.3.4.cmml" xref="S4.E10.m1.1.1.1.1.3.4"><ci id="S4.E10.m1.1.1.1.1.3.4.1.cmml" xref="S4.E10.m1.1.1.1.1.3.4.1">^</ci><ci id="S4.E10.m1.1.1.1.1.3.4.2.cmml" xref="S4.E10.m1.1.1.1.1.3.4.2">ğ¿</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E10.m1.1c">\displaystyle Z^{k}=\gamma^{k}\hat{A}^{k}\hat{L}.</annotation><annotation encoding="application/x-llamapun" id="S4.E10.m1.1d">italic_Z start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT = italic_Î³ start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT over^ start_ARG italic_A end_ARG start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT over^ start_ARG italic_L end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p6">
<p class="ltx_p" id="S4.SS1.SSS3.p6.6">If we take the limit <math alttext="k\to\infty" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.1.m1.1"><semantics id="S4.SS1.SSS3.p6.1.m1.1a"><mrow id="S4.SS1.SSS3.p6.1.m1.1.1" xref="S4.SS1.SSS3.p6.1.m1.1.1.cmml"><mi id="S4.SS1.SSS3.p6.1.m1.1.1.2" xref="S4.SS1.SSS3.p6.1.m1.1.1.2.cmml">k</mi><mo id="S4.SS1.SSS3.p6.1.m1.1.1.1" stretchy="false" xref="S4.SS1.SSS3.p6.1.m1.1.1.1.cmml">â†’</mo><mi id="S4.SS1.SSS3.p6.1.m1.1.1.3" mathvariant="normal" xref="S4.SS1.SSS3.p6.1.m1.1.1.3.cmml">âˆ</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.1.m1.1b"><apply id="S4.SS1.SSS3.p6.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p6.1.m1.1.1"><ci id="S4.SS1.SSS3.p6.1.m1.1.1.1.cmml" xref="S4.SS1.SSS3.p6.1.m1.1.1.1">â†’</ci><ci id="S4.SS1.SSS3.p6.1.m1.1.1.2.cmml" xref="S4.SS1.SSS3.p6.1.m1.1.1.2">ğ‘˜</ci><infinity id="S4.SS1.SSS3.p6.1.m1.1.1.3.cmml" xref="S4.SS1.SSS3.p6.1.m1.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.1.m1.1c">k\to\infty</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p6.1.m1.1d">italic_k â†’ âˆ</annotation></semantics></math> in Formulation <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.E10" title="In 4.1.3. Convergence Analysis â€£ 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">10</span></a>, the result tends to 0 since <math alttext="\gamma_{k}\in(0,1]" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.2.m2.2"><semantics id="S4.SS1.SSS3.p6.2.m2.2a"><mrow id="S4.SS1.SSS3.p6.2.m2.2.3" xref="S4.SS1.SSS3.p6.2.m2.2.3.cmml"><msub id="S4.SS1.SSS3.p6.2.m2.2.3.2" xref="S4.SS1.SSS3.p6.2.m2.2.3.2.cmml"><mi id="S4.SS1.SSS3.p6.2.m2.2.3.2.2" xref="S4.SS1.SSS3.p6.2.m2.2.3.2.2.cmml">Î³</mi><mi id="S4.SS1.SSS3.p6.2.m2.2.3.2.3" xref="S4.SS1.SSS3.p6.2.m2.2.3.2.3.cmml">k</mi></msub><mo id="S4.SS1.SSS3.p6.2.m2.2.3.1" xref="S4.SS1.SSS3.p6.2.m2.2.3.1.cmml">âˆˆ</mo><mrow id="S4.SS1.SSS3.p6.2.m2.2.3.3.2" xref="S4.SS1.SSS3.p6.2.m2.2.3.3.1.cmml"><mo id="S4.SS1.SSS3.p6.2.m2.2.3.3.2.1" stretchy="false" xref="S4.SS1.SSS3.p6.2.m2.2.3.3.1.cmml">(</mo><mn id="S4.SS1.SSS3.p6.2.m2.1.1" xref="S4.SS1.SSS3.p6.2.m2.1.1.cmml">0</mn><mo id="S4.SS1.SSS3.p6.2.m2.2.3.3.2.2" xref="S4.SS1.SSS3.p6.2.m2.2.3.3.1.cmml">,</mo><mn id="S4.SS1.SSS3.p6.2.m2.2.2" xref="S4.SS1.SSS3.p6.2.m2.2.2.cmml">1</mn><mo id="S4.SS1.SSS3.p6.2.m2.2.3.3.2.3" stretchy="false" xref="S4.SS1.SSS3.p6.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.2.m2.2b"><apply id="S4.SS1.SSS3.p6.2.m2.2.3.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3"><in id="S4.SS1.SSS3.p6.2.m2.2.3.1.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3.1"></in><apply id="S4.SS1.SSS3.p6.2.m2.2.3.2.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3.2"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p6.2.m2.2.3.2.1.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3.2">subscript</csymbol><ci id="S4.SS1.SSS3.p6.2.m2.2.3.2.2.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3.2.2">ğ›¾</ci><ci id="S4.SS1.SSS3.p6.2.m2.2.3.2.3.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3.2.3">ğ‘˜</ci></apply><interval closure="open-closed" id="S4.SS1.SSS3.p6.2.m2.2.3.3.1.cmml" xref="S4.SS1.SSS3.p6.2.m2.2.3.3.2"><cn id="S4.SS1.SSS3.p6.2.m2.1.1.cmml" type="integer" xref="S4.SS1.SSS3.p6.2.m2.1.1">0</cn><cn id="S4.SS1.SSS3.p6.2.m2.2.2.cmml" type="integer" xref="S4.SS1.SSS3.p6.2.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.2.m2.2c">\gamma_{k}\in(0,1]</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p6.2.m2.2d">italic_Î³ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT âˆˆ ( 0 , 1 ]</annotation></semantics></math>, the eigenvalues of <math alttext="\hat{A}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.3.m3.1"><semantics id="S4.SS1.SSS3.p6.3.m3.1a"><mover accent="true" id="S4.SS1.SSS3.p6.3.m3.1.1" xref="S4.SS1.SSS3.p6.3.m3.1.1.cmml"><mi id="S4.SS1.SSS3.p6.3.m3.1.1.2" xref="S4.SS1.SSS3.p6.3.m3.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS3.p6.3.m3.1.1.1" xref="S4.SS1.SSS3.p6.3.m3.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.3.m3.1b"><apply id="S4.SS1.SSS3.p6.3.m3.1.1.cmml" xref="S4.SS1.SSS3.p6.3.m3.1.1"><ci id="S4.SS1.SSS3.p6.3.m3.1.1.1.cmml" xref="S4.SS1.SSS3.p6.3.m3.1.1.1">^</ci><ci id="S4.SS1.SSS3.p6.3.m3.1.1.2.cmml" xref="S4.SS1.SSS3.p6.3.m3.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.3.m3.1c">\hat{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p6.3.m3.1d">over^ start_ARG italic_A end_ARG</annotation></semantics></math> are the same as those of <math alttext="\tilde{A}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.4.m4.1"><semantics id="S4.SS1.SSS3.p6.4.m4.1a"><mover accent="true" id="S4.SS1.SSS3.p6.4.m4.1.1" xref="S4.SS1.SSS3.p6.4.m4.1.1.cmml"><mi id="S4.SS1.SSS3.p6.4.m4.1.1.2" xref="S4.SS1.SSS3.p6.4.m4.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS3.p6.4.m4.1.1.1" xref="S4.SS1.SSS3.p6.4.m4.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.4.m4.1b"><apply id="S4.SS1.SSS3.p6.4.m4.1.1.cmml" xref="S4.SS1.SSS3.p6.4.m4.1.1"><ci id="S4.SS1.SSS3.p6.4.m4.1.1.1.cmml" xref="S4.SS1.SSS3.p6.4.m4.1.1.1">~</ci><ci id="S4.SS1.SSS3.p6.4.m4.1.1.2.cmml" xref="S4.SS1.SSS3.p6.4.m4.1.1.2">ğ´</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.4.m4.1c">\tilde{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p6.4.m4.1d">over~ start_ARG italic_A end_ARG</annotation></semantics></math>, which can be proven through Gershgorin circle theorem <cite class="ltx_cite ltx_citemacro_citep">(Weisstein, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib45" title="">2003</a>)</cite> that the maximum eigenvalue is 1, i.e., <math alttext="\|\hat{A}\|\leq 1" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.5.m5.1"><semantics id="S4.SS1.SSS3.p6.5.m5.1a"><mrow id="S4.SS1.SSS3.p6.5.m5.1.2" xref="S4.SS1.SSS3.p6.5.m5.1.2.cmml"><mrow id="S4.SS1.SSS3.p6.5.m5.1.2.2.2" xref="S4.SS1.SSS3.p6.5.m5.1.2.2.1.cmml"><mo id="S4.SS1.SSS3.p6.5.m5.1.2.2.2.1" stretchy="false" xref="S4.SS1.SSS3.p6.5.m5.1.2.2.1.1.cmml">â€–</mo><mover accent="true" id="S4.SS1.SSS3.p6.5.m5.1.1" xref="S4.SS1.SSS3.p6.5.m5.1.1.cmml"><mi id="S4.SS1.SSS3.p6.5.m5.1.1.2" xref="S4.SS1.SSS3.p6.5.m5.1.1.2.cmml">A</mi><mo id="S4.SS1.SSS3.p6.5.m5.1.1.1" xref="S4.SS1.SSS3.p6.5.m5.1.1.1.cmml">^</mo></mover><mo id="S4.SS1.SSS3.p6.5.m5.1.2.2.2.2" stretchy="false" xref="S4.SS1.SSS3.p6.5.m5.1.2.2.1.1.cmml">â€–</mo></mrow><mo id="S4.SS1.SSS3.p6.5.m5.1.2.1" xref="S4.SS1.SSS3.p6.5.m5.1.2.1.cmml">â‰¤</mo><mn id="S4.SS1.SSS3.p6.5.m5.1.2.3" xref="S4.SS1.SSS3.p6.5.m5.1.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.5.m5.1b"><apply id="S4.SS1.SSS3.p6.5.m5.1.2.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.2"><leq id="S4.SS1.SSS3.p6.5.m5.1.2.1.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.2.1"></leq><apply id="S4.SS1.SSS3.p6.5.m5.1.2.2.1.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.2.2.2"><csymbol cd="latexml" id="S4.SS1.SSS3.p6.5.m5.1.2.2.1.1.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.2.2.2.1">norm</csymbol><apply id="S4.SS1.SSS3.p6.5.m5.1.1.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.1"><ci id="S4.SS1.SSS3.p6.5.m5.1.1.1.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.1.1">^</ci><ci id="S4.SS1.SSS3.p6.5.m5.1.1.2.cmml" xref="S4.SS1.SSS3.p6.5.m5.1.1.2">ğ´</ci></apply></apply><cn id="S4.SS1.SSS3.p6.5.m5.1.2.3.cmml" type="integer" xref="S4.SS1.SSS3.p6.5.m5.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.5.m5.1c">\|\hat{A}\|\leq 1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p6.5.m5.1d">âˆ¥ over^ start_ARG italic_A end_ARG âˆ¥ â‰¤ 1</annotation></semantics></math>, and <math alttext="\hat{L}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p6.6.m6.1"><semantics id="S4.SS1.SSS3.p6.6.m6.1a"><mover accent="true" id="S4.SS1.SSS3.p6.6.m6.1.1" xref="S4.SS1.SSS3.p6.6.m6.1.1.cmml"><mi id="S4.SS1.SSS3.p6.6.m6.1.1.2" xref="S4.SS1.SSS3.p6.6.m6.1.1.2.cmml">L</mi><mo id="S4.SS1.SSS3.p6.6.m6.1.1.1" xref="S4.SS1.SSS3.p6.6.m6.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p6.6.m6.1b"><apply id="S4.SS1.SSS3.p6.6.m6.1.1.cmml" xref="S4.SS1.SSS3.p6.6.m6.1.1"><ci id="S4.SS1.SSS3.p6.6.m6.1.1.1.cmml" xref="S4.SS1.SSS3.p6.6.m6.1.1.1">^</ci><ci id="S4.SS1.SSS3.p6.6.m6.1.1.2.cmml" xref="S4.SS1.SSS3.p6.6.m6.1.1.2">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p6.6.m6.1c">\hat{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p6.6.m6.1d">over^ start_ARG italic_L end_ARG</annotation></semantics></math> is convergent, resulting in</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S7.EGx9">
<tbody id="S4.E11"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(11)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle Z^{\infty}=\gamma^{\infty}\hat{A}^{\infty}\hat{L}\to 0," class="ltx_Math" display="inline" id="S4.E11.m1.1"><semantics id="S4.E11.m1.1a"><mrow id="S4.E11.m1.1.1.1" xref="S4.E11.m1.1.1.1.1.cmml"><mrow id="S4.E11.m1.1.1.1.1" xref="S4.E11.m1.1.1.1.1.cmml"><msup id="S4.E11.m1.1.1.1.1.2" xref="S4.E11.m1.1.1.1.1.2.cmml"><mi id="S4.E11.m1.1.1.1.1.2.2" xref="S4.E11.m1.1.1.1.1.2.2.cmml">Z</mi><mi id="S4.E11.m1.1.1.1.1.2.3" mathvariant="normal" xref="S4.E11.m1.1.1.1.1.2.3.cmml">âˆ</mi></msup><mo id="S4.E11.m1.1.1.1.1.3" xref="S4.E11.m1.1.1.1.1.3.cmml">=</mo><mrow id="S4.E11.m1.1.1.1.1.4" xref="S4.E11.m1.1.1.1.1.4.cmml"><msup id="S4.E11.m1.1.1.1.1.4.2" xref="S4.E11.m1.1.1.1.1.4.2.cmml"><mi id="S4.E11.m1.1.1.1.1.4.2.2" xref="S4.E11.m1.1.1.1.1.4.2.2.cmml">Î³</mi><mi id="S4.E11.m1.1.1.1.1.4.2.3" mathvariant="normal" xref="S4.E11.m1.1.1.1.1.4.2.3.cmml">âˆ</mi></msup><mo id="S4.E11.m1.1.1.1.1.4.1" xref="S4.E11.m1.1.1.1.1.4.1.cmml">â¢</mo><msup id="S4.E11.m1.1.1.1.1.4.3" xref="S4.E11.m1.1.1.1.1.4.3.cmml"><mover accent="true" id="S4.E11.m1.1.1.1.1.4.3.2" xref="S4.E11.m1.1.1.1.1.4.3.2.cmml"><mi id="S4.E11.m1.1.1.1.1.4.3.2.2" xref="S4.E11.m1.1.1.1.1.4.3.2.2.cmml">A</mi><mo id="S4.E11.m1.1.1.1.1.4.3.2.1" xref="S4.E11.m1.1.1.1.1.4.3.2.1.cmml">^</mo></mover><mi id="S4.E11.m1.1.1.1.1.4.3.3" mathvariant="normal" xref="S4.E11.m1.1.1.1.1.4.3.3.cmml">âˆ</mi></msup><mo id="S4.E11.m1.1.1.1.1.4.1a" xref="S4.E11.m1.1.1.1.1.4.1.cmml">â¢</mo><mover accent="true" id="S4.E11.m1.1.1.1.1.4.4" xref="S4.E11.m1.1.1.1.1.4.4.cmml"><mi id="S4.E11.m1.1.1.1.1.4.4.2" xref="S4.E11.m1.1.1.1.1.4.4.2.cmml">L</mi><mo id="S4.E11.m1.1.1.1.1.4.4.1" xref="S4.E11.m1.1.1.1.1.4.4.1.cmml">^</mo></mover></mrow><mo id="S4.E11.m1.1.1.1.1.5" stretchy="false" xref="S4.E11.m1.1.1.1.1.5.cmml">â†’</mo><mn id="S4.E11.m1.1.1.1.1.6" xref="S4.E11.m1.1.1.1.1.6.cmml">0</mn></mrow><mo id="S4.E11.m1.1.1.1.2" xref="S4.E11.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E11.m1.1b"><apply id="S4.E11.m1.1.1.1.1.cmml" xref="S4.E11.m1.1.1.1"><and id="S4.E11.m1.1.1.1.1a.cmml" xref="S4.E11.m1.1.1.1"></and><apply id="S4.E11.m1.1.1.1.1b.cmml" xref="S4.E11.m1.1.1.1"><eq id="S4.E11.m1.1.1.1.1.3.cmml" xref="S4.E11.m1.1.1.1.1.3"></eq><apply id="S4.E11.m1.1.1.1.1.2.cmml" xref="S4.E11.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.E11.m1.1.1.1.1.2.1.cmml" xref="S4.E11.m1.1.1.1.1.2">superscript</csymbol><ci id="S4.E11.m1.1.1.1.1.2.2.cmml" xref="S4.E11.m1.1.1.1.1.2.2">ğ‘</ci><infinity id="S4.E11.m1.1.1.1.1.2.3.cmml" xref="S4.E11.m1.1.1.1.1.2.3"></infinity></apply><apply id="S4.E11.m1.1.1.1.1.4.cmml" xref="S4.E11.m1.1.1.1.1.4"><times id="S4.E11.m1.1.1.1.1.4.1.cmml" xref="S4.E11.m1.1.1.1.1.4.1"></times><apply id="S4.E11.m1.1.1.1.1.4.2.cmml" xref="S4.E11.m1.1.1.1.1.4.2"><csymbol cd="ambiguous" id="S4.E11.m1.1.1.1.1.4.2.1.cmml" xref="S4.E11.m1.1.1.1.1.4.2">superscript</csymbol><ci id="S4.E11.m1.1.1.1.1.4.2.2.cmml" xref="S4.E11.m1.1.1.1.1.4.2.2">ğ›¾</ci><infinity id="S4.E11.m1.1.1.1.1.4.2.3.cmml" xref="S4.E11.m1.1.1.1.1.4.2.3"></infinity></apply><apply id="S4.E11.m1.1.1.1.1.4.3.cmml" xref="S4.E11.m1.1.1.1.1.4.3"><csymbol cd="ambiguous" id="S4.E11.m1.1.1.1.1.4.3.1.cmml" xref="S4.E11.m1.1.1.1.1.4.3">superscript</csymbol><apply id="S4.E11.m1.1.1.1.1.4.3.2.cmml" xref="S4.E11.m1.1.1.1.1.4.3.2"><ci id="S4.E11.m1.1.1.1.1.4.3.2.1.cmml" xref="S4.E11.m1.1.1.1.1.4.3.2.1">^</ci><ci id="S4.E11.m1.1.1.1.1.4.3.2.2.cmml" xref="S4.E11.m1.1.1.1.1.4.3.2.2">ğ´</ci></apply><infinity id="S4.E11.m1.1.1.1.1.4.3.3.cmml" xref="S4.E11.m1.1.1.1.1.4.3.3"></infinity></apply><apply id="S4.E11.m1.1.1.1.1.4.4.cmml" xref="S4.E11.m1.1.1.1.1.4.4"><ci id="S4.E11.m1.1.1.1.1.4.4.1.cmml" xref="S4.E11.m1.1.1.1.1.4.4.1">^</ci><ci id="S4.E11.m1.1.1.1.1.4.4.2.cmml" xref="S4.E11.m1.1.1.1.1.4.4.2">ğ¿</ci></apply></apply></apply><apply id="S4.E11.m1.1.1.1.1c.cmml" xref="S4.E11.m1.1.1.1"><ci id="S4.E11.m1.1.1.1.1.5.cmml" xref="S4.E11.m1.1.1.1.1.5">â†’</ci><share href="https://arxiv.org/html/2412.20379v1#S4.E11.m1.1.1.1.1.4.cmml" id="S4.E11.m1.1.1.1.1d.cmml" xref="S4.E11.m1.1.1.1"></share><cn id="S4.E11.m1.1.1.1.1.6.cmml" type="integer" xref="S4.E11.m1.1.1.1.1.6">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E11.m1.1c">\displaystyle Z^{\infty}=\gamma^{\infty}\hat{A}^{\infty}\hat{L}\to 0,</annotation><annotation encoding="application/x-llamapun" id="S4.E11.m1.1d">italic_Z start_POSTSUPERSCRIPT âˆ end_POSTSUPERSCRIPT = italic_Î³ start_POSTSUPERSCRIPT âˆ end_POSTSUPERSCRIPT over^ start_ARG italic_A end_ARG start_POSTSUPERSCRIPT âˆ end_POSTSUPERSCRIPT over^ start_ARG italic_L end_ARG â†’ 0 ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.SS1.SSS3.p6.7">the above concludes that the convergence is guaranteed.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p7">
<p class="ltx_p" id="S4.SS1.SSS3.p7.1">In Section 5.7, we also evaluate the accuracy of decoupled GNN training, which performs comparably to coupled GNN training across different datasets.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Memory-efficient Task Scheduling Strategy</h3>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Chunk-based task Scheduling</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1"><span class="ltx_text" id="S4.SS2.SSS1.p1.1.1" style="color:#000000;">To address challenge #2, NeutronTP employs chunk-based task scheduling, where the global graph topology is partitioned on each worker, and different workers simultaneously schedule the same subgraph. This does not incur cross-worker vertex dependencies, as each worker partitions the entire graph locally using the same strategy. All workers execute communication and computation tasks for each chunk in the same order to ensure load balancing. </span>
As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.F9" title="Figure 9 â€£ 4.1.2. Decoupled GNN Tensor Parallelism â€£ 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">9</span></a> (a), each chunk comprises a subset of destination vertices with contiguous vertex IDs and all in-edges for each vertex, facilitating independent full-neighbor aggregation for each chunk.
In GNN tensor parallelism, using chunk-based partitioning offers two advantages. Firstly, using chunk-based partitioning to obtain subgraphs is lightweight, as the graph topology only needs to be logically partitioned within local workers without modifying any physical storage locations.
Secondly, ensuring load balancing merely requires scheduling chunks for computation in the same order across all workers, thus eliminating the need to handle load balancing between chunks.
</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p2">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1">It is worth mentioning that we only need to group the in-edges of destinations, as complex aggregations are performed only during the forward pass. During the backward pass, source vertices can accumulate gradients along out-edges through summation. Leveraging the associativity of summation operations, multiple copies of source vertices in different chunks can independently compute gradients and then be summed afterward. During the actual partitioning process, unlike traditional distributed training systems where chunks are divided among multiple workers, we do not specify a predetermined number of chunks to partition. Generally, to better utilize GPU resources and reduce scheduling overhead, we should aim to make each chunk as large as possible.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS1.p3">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1">When using chunks as the scheduling unit, full-graph GNN training requires consideration of intermediate result management. Intermediate results are generated during forward computation and consumed in the gradient computation during backward pass <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>)</cite>. To avoid exceeding the GPU memory capacity with intermediate results, they need to be sent back to CPU memory after forward computation and returned to GPU during backward computation. This frequent host-GPU data exchange may impact overall performance. Fortunately, benefiting from the decoupled GNN training approach, NeutronTP avoids generating intermediate results during consecutive graph aggregation operations. Thus, we only need to handle intermediate results produced during the NN operations. Considering that the computational overhead of GNN training typically lies in graph aggregation operations rather than NN operations <cite class="ltx_cite ltx_citemacro_citep">(Yuan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib51" title="">2023</a>)</cite>, we push down NN operations to be executed on the CPU. This not only reduces a significant amount of host-GPU communication for intermediate results but also leverages CPU resources.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2. </span>Inter-chunk Pipelining</h4>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.4.1.1">Algorithm 1</span> </span> Workflow of NeutronTP for a single epoch</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.5">
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span><span class="ltx_text" id="alg1.l1.2" style="font-size:90%;">Graph </span><math alttext="G(V,E)" class="ltx_Math" display="inline" id="alg1.l1.m1.2"><semantics id="alg1.l1.m1.2a"><mrow id="alg1.l1.m1.2.3" xref="alg1.l1.m1.2.3.cmml"><mi id="alg1.l1.m1.2.3.2" mathsize="90%" xref="alg1.l1.m1.2.3.2.cmml">G</mi><mo id="alg1.l1.m1.2.3.1" xref="alg1.l1.m1.2.3.1.cmml">â¢</mo><mrow id="alg1.l1.m1.2.3.3.2" xref="alg1.l1.m1.2.3.3.1.cmml"><mo id="alg1.l1.m1.2.3.3.2.1" maxsize="90%" minsize="90%" xref="alg1.l1.m1.2.3.3.1.cmml">(</mo><mi id="alg1.l1.m1.1.1" mathsize="90%" xref="alg1.l1.m1.1.1.cmml">V</mi><mo id="alg1.l1.m1.2.3.3.2.2" mathsize="90%" xref="alg1.l1.m1.2.3.3.1.cmml">,</mo><mi id="alg1.l1.m1.2.2" mathsize="90%" xref="alg1.l1.m1.2.2.cmml">E</mi><mo id="alg1.l1.m1.2.3.3.2.3" maxsize="90%" minsize="90%" xref="alg1.l1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.2b"><apply id="alg1.l1.m1.2.3.cmml" xref="alg1.l1.m1.2.3"><times id="alg1.l1.m1.2.3.1.cmml" xref="alg1.l1.m1.2.3.1"></times><ci id="alg1.l1.m1.2.3.2.cmml" xref="alg1.l1.m1.2.3.2">ğº</ci><interval closure="open" id="alg1.l1.m1.2.3.3.1.cmml" xref="alg1.l1.m1.2.3.3.2"><ci id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1">ğ‘‰</ci><ci id="alg1.l1.m1.2.2.cmml" xref="alg1.l1.m1.2.2">ğ¸</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.2c">G(V,E)</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.2d">italic_G ( italic_V , italic_E )</annotation></semantics></math><span class="ltx_text" id="alg1.l1.3" style="font-size:90%;">, Feature </span><math alttext="\textbf{h}^{0}" class="ltx_Math" display="inline" id="alg1.l1.m2.1"><semantics id="alg1.l1.m2.1a"><msup id="alg1.l1.m2.1.1" xref="alg1.l1.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m2.1.1.2" mathsize="90%" xref="alg1.l1.m2.1.1.2a.cmml">h</mtext><mn id="alg1.l1.m2.1.1.3" mathsize="90%" xref="alg1.l1.m2.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="alg1.l1.m2.1b"><apply id="alg1.l1.m2.1.1.cmml" xref="alg1.l1.m2.1.1"><csymbol cd="ambiguous" id="alg1.l1.m2.1.1.1.cmml" xref="alg1.l1.m2.1.1">superscript</csymbol><ci id="alg1.l1.m2.1.1.2a.cmml" xref="alg1.l1.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m2.1.1.2.cmml" mathsize="90%" xref="alg1.l1.m2.1.1.2">h</mtext></ci><cn id="alg1.l1.m2.1.1.3.cmml" type="integer" xref="alg1.l1.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m2.1c">\textbf{h}^{0}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m2.1d">h start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l1.4" style="font-size:90%;">,
Initial parameterized GNN layers </span><math alttext="\{\textbf{W}^{0},\textbf{W}^{1}\ldots\textbf{W}^{L-1}\}" class="ltx_Math" display="inline" id="alg1.l1.m3.2"><semantics id="alg1.l1.m3.2a"><mrow id="alg1.l1.m3.2.2.2" xref="alg1.l1.m3.2.2.3.cmml"><mo id="alg1.l1.m3.2.2.2.3" maxsize="90%" minsize="90%" xref="alg1.l1.m3.2.2.3.cmml">{</mo><msup id="alg1.l1.m3.1.1.1.1" xref="alg1.l1.m3.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m3.1.1.1.1.2" mathsize="90%" xref="alg1.l1.m3.1.1.1.1.2a.cmml">W</mtext><mn id="alg1.l1.m3.1.1.1.1.3" mathsize="90%" xref="alg1.l1.m3.1.1.1.1.3.cmml">0</mn></msup><mo id="alg1.l1.m3.2.2.2.4" mathsize="90%" xref="alg1.l1.m3.2.2.3.cmml">,</mo><mrow id="alg1.l1.m3.2.2.2.2" xref="alg1.l1.m3.2.2.2.2.cmml"><msup id="alg1.l1.m3.2.2.2.2.2" xref="alg1.l1.m3.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m3.2.2.2.2.2.2" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.2.2a.cmml">W</mtext><mn id="alg1.l1.m3.2.2.2.2.2.3" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.2.3.cmml">1</mn></msup><mo id="alg1.l1.m3.2.2.2.2.1" xref="alg1.l1.m3.2.2.2.2.1.cmml">â¢</mo><mi id="alg1.l1.m3.2.2.2.2.3" mathsize="90%" mathvariant="normal" xref="alg1.l1.m3.2.2.2.2.3.cmml">â€¦</mi><mo id="alg1.l1.m3.2.2.2.2.1a" xref="alg1.l1.m3.2.2.2.2.1.cmml">â¢</mo><msup id="alg1.l1.m3.2.2.2.2.4" xref="alg1.l1.m3.2.2.2.2.4.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m3.2.2.2.2.4.2" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.4.2a.cmml">W</mtext><mrow id="alg1.l1.m3.2.2.2.2.4.3" xref="alg1.l1.m3.2.2.2.2.4.3.cmml"><mi id="alg1.l1.m3.2.2.2.2.4.3.2" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.4.3.2.cmml">L</mi><mo id="alg1.l1.m3.2.2.2.2.4.3.1" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.4.3.1.cmml">âˆ’</mo><mn id="alg1.l1.m3.2.2.2.2.4.3.3" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.4.3.3.cmml">1</mn></mrow></msup></mrow><mo id="alg1.l1.m3.2.2.2.5" maxsize="90%" minsize="90%" xref="alg1.l1.m3.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m3.2b"><set id="alg1.l1.m3.2.2.3.cmml" xref="alg1.l1.m3.2.2.2"><apply id="alg1.l1.m3.1.1.1.1.cmml" xref="alg1.l1.m3.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m3.1.1.1.1.1.cmml" xref="alg1.l1.m3.1.1.1.1">superscript</csymbol><ci id="alg1.l1.m3.1.1.1.1.2a.cmml" xref="alg1.l1.m3.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m3.1.1.1.1.2.cmml" mathsize="90%" xref="alg1.l1.m3.1.1.1.1.2">W</mtext></ci><cn id="alg1.l1.m3.1.1.1.1.3.cmml" type="integer" xref="alg1.l1.m3.1.1.1.1.3">0</cn></apply><apply id="alg1.l1.m3.2.2.2.2.cmml" xref="alg1.l1.m3.2.2.2.2"><times id="alg1.l1.m3.2.2.2.2.1.cmml" xref="alg1.l1.m3.2.2.2.2.1"></times><apply id="alg1.l1.m3.2.2.2.2.2.cmml" xref="alg1.l1.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l1.m3.2.2.2.2.2.1.cmml" xref="alg1.l1.m3.2.2.2.2.2">superscript</csymbol><ci id="alg1.l1.m3.2.2.2.2.2.2a.cmml" xref="alg1.l1.m3.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m3.2.2.2.2.2.2.cmml" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.2.2">W</mtext></ci><cn id="alg1.l1.m3.2.2.2.2.2.3.cmml" type="integer" xref="alg1.l1.m3.2.2.2.2.2.3">1</cn></apply><ci id="alg1.l1.m3.2.2.2.2.3.cmml" xref="alg1.l1.m3.2.2.2.2.3">â€¦</ci><apply id="alg1.l1.m3.2.2.2.2.4.cmml" xref="alg1.l1.m3.2.2.2.2.4"><csymbol cd="ambiguous" id="alg1.l1.m3.2.2.2.2.4.1.cmml" xref="alg1.l1.m3.2.2.2.2.4">superscript</csymbol><ci id="alg1.l1.m3.2.2.2.2.4.2a.cmml" xref="alg1.l1.m3.2.2.2.2.4.2"><mtext class="ltx_mathvariant_bold" id="alg1.l1.m3.2.2.2.2.4.2.cmml" mathsize="90%" xref="alg1.l1.m3.2.2.2.2.4.2">W</mtext></ci><apply id="alg1.l1.m3.2.2.2.2.4.3.cmml" xref="alg1.l1.m3.2.2.2.2.4.3"><minus id="alg1.l1.m3.2.2.2.2.4.3.1.cmml" xref="alg1.l1.m3.2.2.2.2.4.3.1"></minus><ci id="alg1.l1.m3.2.2.2.2.4.3.2.cmml" xref="alg1.l1.m3.2.2.2.2.4.3.2">ğ¿</ci><cn id="alg1.l1.m3.2.2.2.2.4.3.3.cmml" type="integer" xref="alg1.l1.m3.2.2.2.2.4.3.3">1</cn></apply></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m3.2c">\{\textbf{W}^{0},\textbf{W}^{1}\ldots\textbf{W}^{L-1}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m3.2d">{ W start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT , W start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT â€¦ W start_POSTSUPERSCRIPT italic_L - 1 end_POSTSUPERSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg1.l1.5" style="font-size:90%;">, cluster size </span><math alttext="m" class="ltx_Math" display="inline" id="alg1.l1.m4.1"><semantics id="alg1.l1.m4.1a"><mi id="alg1.l1.m4.1.1" mathsize="90%" xref="alg1.l1.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m4.1b"><ci id="alg1.l1.m4.1.1.cmml" xref="alg1.l1.m4.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m4.1c">m</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m4.1d">italic_m</annotation></semantics></math><span class="ltx_text" id="alg1.l1.6" style="font-size:90%;">, chunk number </span><math alttext="n" class="ltx_Math" display="inline" id="alg1.l1.m5.1"><semantics id="alg1.l1.m5.1a"><mi id="alg1.l1.m5.1.1" mathsize="90%" xref="alg1.l1.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg1.l1.m5.1b"><ci id="alg1.l1.m5.1.1.cmml" xref="alg1.l1.m5.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m5.1d">italic_n</annotation></semantics></math><span class="ltx_text" id="alg1.l1.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span><span class="ltx_text" id="alg1.l2.2" style="font-size:90%;">Updated parameterized GNN layers </span><math alttext="\{\textbf{W}^{0},\textbf{W}^{1}\ldots\textbf{W}^{L-1}\}" class="ltx_Math" display="inline" id="alg1.l2.m1.2"><semantics id="alg1.l2.m1.2a"><mrow id="alg1.l2.m1.2.2.2" xref="alg1.l2.m1.2.2.3.cmml"><mo id="alg1.l2.m1.2.2.2.3" maxsize="90%" minsize="90%" xref="alg1.l2.m1.2.2.3.cmml">{</mo><msup id="alg1.l2.m1.1.1.1.1" xref="alg1.l2.m1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l2.m1.1.1.1.1.2" mathsize="90%" xref="alg1.l2.m1.1.1.1.1.2a.cmml">W</mtext><mn id="alg1.l2.m1.1.1.1.1.3" mathsize="90%" xref="alg1.l2.m1.1.1.1.1.3.cmml">0</mn></msup><mo id="alg1.l2.m1.2.2.2.4" mathsize="90%" xref="alg1.l2.m1.2.2.3.cmml">,</mo><mrow id="alg1.l2.m1.2.2.2.2" xref="alg1.l2.m1.2.2.2.2.cmml"><msup id="alg1.l2.m1.2.2.2.2.2" xref="alg1.l2.m1.2.2.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l2.m1.2.2.2.2.2.2" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.2.2a.cmml">W</mtext><mn id="alg1.l2.m1.2.2.2.2.2.3" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.2.3.cmml">1</mn></msup><mo id="alg1.l2.m1.2.2.2.2.1" xref="alg1.l2.m1.2.2.2.2.1.cmml">â¢</mo><mi id="alg1.l2.m1.2.2.2.2.3" mathsize="90%" mathvariant="normal" xref="alg1.l2.m1.2.2.2.2.3.cmml">â€¦</mi><mo id="alg1.l2.m1.2.2.2.2.1a" xref="alg1.l2.m1.2.2.2.2.1.cmml">â¢</mo><msup id="alg1.l2.m1.2.2.2.2.4" xref="alg1.l2.m1.2.2.2.2.4.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l2.m1.2.2.2.2.4.2" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.4.2a.cmml">W</mtext><mrow id="alg1.l2.m1.2.2.2.2.4.3" xref="alg1.l2.m1.2.2.2.2.4.3.cmml"><mi id="alg1.l2.m1.2.2.2.2.4.3.2" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.4.3.2.cmml">L</mi><mo id="alg1.l2.m1.2.2.2.2.4.3.1" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.4.3.1.cmml">âˆ’</mo><mn id="alg1.l2.m1.2.2.2.2.4.3.3" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.4.3.3.cmml">1</mn></mrow></msup></mrow><mo id="alg1.l2.m1.2.2.2.5" maxsize="90%" minsize="90%" xref="alg1.l2.m1.2.2.3.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.2b"><set id="alg1.l2.m1.2.2.3.cmml" xref="alg1.l2.m1.2.2.2"><apply id="alg1.l2.m1.1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.1.1.cmml" xref="alg1.l2.m1.1.1.1.1">superscript</csymbol><ci id="alg1.l2.m1.1.1.1.1.2a.cmml" xref="alg1.l2.m1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l2.m1.1.1.1.1.2.cmml" mathsize="90%" xref="alg1.l2.m1.1.1.1.1.2">W</mtext></ci><cn id="alg1.l2.m1.1.1.1.1.3.cmml" type="integer" xref="alg1.l2.m1.1.1.1.1.3">0</cn></apply><apply id="alg1.l2.m1.2.2.2.2.cmml" xref="alg1.l2.m1.2.2.2.2"><times id="alg1.l2.m1.2.2.2.2.1.cmml" xref="alg1.l2.m1.2.2.2.2.1"></times><apply id="alg1.l2.m1.2.2.2.2.2.cmml" xref="alg1.l2.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="alg1.l2.m1.2.2.2.2.2.1.cmml" xref="alg1.l2.m1.2.2.2.2.2">superscript</csymbol><ci id="alg1.l2.m1.2.2.2.2.2.2a.cmml" xref="alg1.l2.m1.2.2.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l2.m1.2.2.2.2.2.2.cmml" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.2.2">W</mtext></ci><cn id="alg1.l2.m1.2.2.2.2.2.3.cmml" type="integer" xref="alg1.l2.m1.2.2.2.2.2.3">1</cn></apply><ci id="alg1.l2.m1.2.2.2.2.3.cmml" xref="alg1.l2.m1.2.2.2.2.3">â€¦</ci><apply id="alg1.l2.m1.2.2.2.2.4.cmml" xref="alg1.l2.m1.2.2.2.2.4"><csymbol cd="ambiguous" id="alg1.l2.m1.2.2.2.2.4.1.cmml" xref="alg1.l2.m1.2.2.2.2.4">superscript</csymbol><ci id="alg1.l2.m1.2.2.2.2.4.2a.cmml" xref="alg1.l2.m1.2.2.2.2.4.2"><mtext class="ltx_mathvariant_bold" id="alg1.l2.m1.2.2.2.2.4.2.cmml" mathsize="90%" xref="alg1.l2.m1.2.2.2.2.4.2">W</mtext></ci><apply id="alg1.l2.m1.2.2.2.2.4.3.cmml" xref="alg1.l2.m1.2.2.2.2.4.3"><minus id="alg1.l2.m1.2.2.2.2.4.3.1.cmml" xref="alg1.l2.m1.2.2.2.2.4.3.1"></minus><ci id="alg1.l2.m1.2.2.2.2.4.3.2.cmml" xref="alg1.l2.m1.2.2.2.2.4.3.2">ğ¿</ci><cn id="alg1.l2.m1.2.2.2.2.4.3.3.cmml" type="integer" xref="alg1.l2.m1.2.2.2.2.4.3.3">1</cn></apply></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.2c">\{\textbf{W}^{0},\textbf{W}^{1}\ldots\textbf{W}^{L-1}\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.2d">{ W start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT , W start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT â€¦ W start_POSTSUPERSCRIPT italic_L - 1 end_POSTSUPERSCRIPT }</annotation></semantics></math><span class="ltx_text" id="alg1.l2.3" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span><math alttext="\{G_{j}" class="ltx_math_unparsed" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1b"><mo id="alg1.l3.m1.1.1" maxsize="90%" minsize="90%">{</mo><msub id="alg1.l3.m1.1.2"><mi id="alg1.l3.m1.1.2.2" mathsize="90%">G</mi><mi id="alg1.l3.m1.1.2.3" mathsize="90%">j</mi></msub></mrow><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">\{G_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">{ italic_G start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><math alttext="\mid" class="ltx_Math" display="inline" id="alg1.l3.m2.1"><semantics id="alg1.l3.m2.1a"><mo id="alg1.l3.m2.1.1" mathsize="90%" xref="alg1.l3.m2.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">\mid</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.1d">âˆ£</annotation></semantics></math><math alttext="0" class="ltx_Math" display="inline" id="alg1.l3.m3.1"><semantics id="alg1.l3.m3.1a"><mn id="alg1.l3.m3.1.1" mathsize="90%" xref="alg1.l3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l3.m3.1b"><cn id="alg1.l3.m3.1.1.cmml" type="integer" xref="alg1.l3.m3.1.1">0</cn></annotation-xml></semantics></math><math alttext="\leq" class="ltx_Math" display="inline" id="alg1.l3.m4.1"><semantics id="alg1.l3.m4.1a"><mo id="alg1.l3.m4.1.1" mathsize="90%" xref="alg1.l3.m4.1.1.cmml">â‰¤</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.m4.1b"><leq id="alg1.l3.m4.1.1.cmml" xref="alg1.l3.m4.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m4.1c">\leq</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m4.1d">â‰¤</annotation></semantics></math><math alttext="j" class="ltx_Math" display="inline" id="alg1.l3.m5.1"><semantics id="alg1.l3.m5.1a"><mi id="alg1.l3.m5.1.1" mathsize="90%" xref="alg1.l3.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m5.1b"><ci id="alg1.l3.m5.1.1.cmml" xref="alg1.l3.m5.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m5.1c">j</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m5.1d">italic_j</annotation></semantics></math><math alttext="&lt;" class="ltx_Math" display="inline" id="alg1.l3.m6.1"><semantics id="alg1.l3.m6.1a"><mo id="alg1.l3.m6.1.1" mathsize="90%" xref="alg1.l3.m6.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="alg1.l3.m6.1b"><lt id="alg1.l3.m6.1.1.cmml" xref="alg1.l3.m6.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m6.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m6.1d">&lt;</annotation></semantics></math><math alttext="n\}" class="ltx_math_unparsed" display="inline" id="alg1.l3.m7.1"><semantics id="alg1.l3.m7.1a"><mrow id="alg1.l3.m7.1b"><mi id="alg1.l3.m7.1.1" mathsize="90%">n</mi><mo id="alg1.l3.m7.1.2" maxsize="90%" minsize="90%">}</mo></mrow><annotation encoding="application/x-tex" id="alg1.l3.m7.1c">n\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m7.1d">italic_n }</annotation></semantics></math><span class="ltx_text" id="alg1.l3.2" style="font-size:90%;">=</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.l3.3" style="font-size:90%;">chunk_partition</span><span class="ltx_text" id="alg1.l3.4" style="font-size:90%;">(</span><math alttext="G" class="ltx_Math" display="inline" id="alg1.l3.m8.1"><semantics id="alg1.l3.m8.1a"><mi id="alg1.l3.m8.1.1" mathsize="90%" xref="alg1.l3.m8.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m8.1b"><ci id="alg1.l3.m8.1.1.cmml" xref="alg1.l3.m8.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m8.1c">G</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m8.1d">italic_G</annotation></semantics></math><span class="ltx_text" id="alg1.l3.5" style="font-size:90%;">, </span><math alttext="n" class="ltx_Math" display="inline" id="alg1.l3.m9.1"><semantics id="alg1.l3.m9.1a"><mi id="alg1.l3.m9.1.1" mathsize="90%" xref="alg1.l3.m9.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m9.1b"><ci id="alg1.l3.m9.1.1.cmml" xref="alg1.l3.m9.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m9.1c">n</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m9.1d">italic_n</annotation></semantics></math><span class="ltx_text" id="alg1.l3.6" style="font-size:90%;">)
</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span><math alttext="\{V_{i},\textbf{h}_{i}^{0}" class="ltx_math_unparsed" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><mrow id="alg1.l4.m1.1b"><mo id="alg1.l4.m1.1.1" maxsize="90%" minsize="90%">{</mo><msub id="alg1.l4.m1.1.2"><mi id="alg1.l4.m1.1.2.2" mathsize="90%">V</mi><mi id="alg1.l4.m1.1.2.3" mathsize="90%">i</mi></msub><mo id="alg1.l4.m1.1.3" mathsize="90%">,</mo><msubsup id="alg1.l4.m1.1.4"><mtext class="ltx_mathvariant_bold" id="alg1.l4.m1.1.4.2.2" mathsize="90%">h</mtext><mi id="alg1.l4.m1.1.4.2.3" mathsize="90%">i</mi><mn id="alg1.l4.m1.1.4.3" mathsize="90%">0</mn></msubsup></mrow><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\{V_{i},\textbf{h}_{i}^{0}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">{ italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , h start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math><math alttext="\mid" class="ltx_Math" display="inline" id="alg1.l4.m2.1"><semantics id="alg1.l4.m2.1a"><mo id="alg1.l4.m2.1.1" mathsize="90%" xref="alg1.l4.m2.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><ci id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">\mid</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m2.1d">âˆ£</annotation></semantics></math><math alttext="0" class="ltx_Math" display="inline" id="alg1.l4.m3.1"><semantics id="alg1.l4.m3.1a"><mn id="alg1.l4.m3.1.1" mathsize="90%" xref="alg1.l4.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l4.m3.1b"><cn id="alg1.l4.m3.1.1.cmml" type="integer" xref="alg1.l4.m3.1.1">0</cn></annotation-xml></semantics></math><math alttext="\leq" class="ltx_Math" display="inline" id="alg1.l4.m4.1"><semantics id="alg1.l4.m4.1a"><mo id="alg1.l4.m4.1.1" mathsize="90%" xref="alg1.l4.m4.1.1.cmml">â‰¤</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.m4.1b"><leq id="alg1.l4.m4.1.1.cmml" xref="alg1.l4.m4.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m4.1c">\leq</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m4.1d">â‰¤</annotation></semantics></math><math alttext="i" class="ltx_Math" display="inline" id="alg1.l4.m5.1"><semantics id="alg1.l4.m5.1a"><mi id="alg1.l4.m5.1.1" mathsize="90%" xref="alg1.l4.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m5.1b"><ci id="alg1.l4.m5.1.1.cmml" xref="alg1.l4.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m5.1d">italic_i</annotation></semantics></math><math alttext="&lt;" class="ltx_Math" display="inline" id="alg1.l4.m6.1"><semantics id="alg1.l4.m6.1a"><mo id="alg1.l4.m6.1.1" mathsize="90%" xref="alg1.l4.m6.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.m6.1b"><lt id="alg1.l4.m6.1.1.cmml" xref="alg1.l4.m6.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m6.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m6.1d">&lt;</annotation></semantics></math><math alttext="m\}" class="ltx_math_unparsed" display="inline" id="alg1.l4.m7.1"><semantics id="alg1.l4.m7.1a"><mrow id="alg1.l4.m7.1b"><mi id="alg1.l4.m7.1.1" mathsize="90%">m</mi><mo id="alg1.l4.m7.1.2" maxsize="90%" minsize="90%">}</mo></mrow><annotation encoding="application/x-tex" id="alg1.l4.m7.1c">m\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m7.1d">italic_m }</annotation></semantics></math><span class="ltx_text" id="alg1.l4.2" style="font-size:90%;">=</span><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.l4.3" style="font-size:90%;">distribute_vertex</span><span class="ltx_text" id="alg1.l4.4" style="font-size:90%;">(</span><math alttext="\{G_{j}" class="ltx_math_unparsed" display="inline" id="alg1.l4.m8.1"><semantics id="alg1.l4.m8.1a"><mrow id="alg1.l4.m8.1b"><mo id="alg1.l4.m8.1.1" maxsize="90%" minsize="90%">{</mo><msub id="alg1.l4.m8.1.2"><mi id="alg1.l4.m8.1.2.2" mathsize="90%">G</mi><mi id="alg1.l4.m8.1.2.3" mathsize="90%">j</mi></msub></mrow><annotation encoding="application/x-tex" id="alg1.l4.m8.1c">\{G_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m8.1d">{ italic_G start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><math alttext="\mid" class="ltx_Math" display="inline" id="alg1.l4.m9.1"><semantics id="alg1.l4.m9.1a"><mo id="alg1.l4.m9.1.1" mathsize="90%" xref="alg1.l4.m9.1.1.cmml">âˆ£</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.m9.1b"><ci id="alg1.l4.m9.1.1.cmml" xref="alg1.l4.m9.1.1">âˆ£</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m9.1c">\mid</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m9.1d">âˆ£</annotation></semantics></math><math alttext="0" class="ltx_Math" display="inline" id="alg1.l4.m10.1"><semantics id="alg1.l4.m10.1a"><mn id="alg1.l4.m10.1.1" mathsize="90%" xref="alg1.l4.m10.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l4.m10.1b"><cn id="alg1.l4.m10.1.1.cmml" type="integer" xref="alg1.l4.m10.1.1">0</cn></annotation-xml></semantics></math><math alttext="\leq" class="ltx_Math" display="inline" id="alg1.l4.m11.1"><semantics id="alg1.l4.m11.1a"><mo id="alg1.l4.m11.1.1" mathsize="90%" xref="alg1.l4.m11.1.1.cmml">â‰¤</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.m11.1b"><leq id="alg1.l4.m11.1.1.cmml" xref="alg1.l4.m11.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m11.1c">\leq</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m11.1d">â‰¤</annotation></semantics></math><math alttext="j" class="ltx_Math" display="inline" id="alg1.l4.m12.1"><semantics id="alg1.l4.m12.1a"><mi id="alg1.l4.m12.1.1" mathsize="90%" xref="alg1.l4.m12.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m12.1b"><ci id="alg1.l4.m12.1.1.cmml" xref="alg1.l4.m12.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m12.1c">j</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m12.1d">italic_j</annotation></semantics></math><math alttext="&lt;" class="ltx_Math" display="inline" id="alg1.l4.m13.1"><semantics id="alg1.l4.m13.1a"><mo id="alg1.l4.m13.1.1" mathsize="90%" xref="alg1.l4.m13.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="alg1.l4.m13.1b"><lt id="alg1.l4.m13.1.1.cmml" xref="alg1.l4.m13.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m13.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m13.1d">&lt;</annotation></semantics></math><math alttext="n\}" class="ltx_math_unparsed" display="inline" id="alg1.l4.m14.1"><semantics id="alg1.l4.m14.1a"><mrow id="alg1.l4.m14.1b"><mi id="alg1.l4.m14.1.1" mathsize="90%">n</mi><mo id="alg1.l4.m14.1.2" maxsize="90%" minsize="90%">}</mo></mrow><annotation encoding="application/x-tex" id="alg1.l4.m14.1c">n\}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m14.1d">italic_n }</annotation></semantics></math><span class="ltx_text" id="alg1.l4.5" style="font-size:90%;">, </span><math alttext="\textbf{h}^{0}" class="ltx_Math" display="inline" id="alg1.l4.m15.1"><semantics id="alg1.l4.m15.1a"><msup id="alg1.l4.m15.1.1" xref="alg1.l4.m15.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l4.m15.1.1.2" mathsize="90%" xref="alg1.l4.m15.1.1.2a.cmml">h</mtext><mn id="alg1.l4.m15.1.1.3" mathsize="90%" xref="alg1.l4.m15.1.1.3.cmml">0</mn></msup><annotation-xml encoding="MathML-Content" id="alg1.l4.m15.1b"><apply id="alg1.l4.m15.1.1.cmml" xref="alg1.l4.m15.1.1"><csymbol cd="ambiguous" id="alg1.l4.m15.1.1.1.cmml" xref="alg1.l4.m15.1.1">superscript</csymbol><ci id="alg1.l4.m15.1.1.2a.cmml" xref="alg1.l4.m15.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l4.m15.1.1.2.cmml" mathsize="90%" xref="alg1.l4.m15.1.1.2">h</mtext></ci><cn id="alg1.l4.m15.1.1.3.cmml" type="integer" xref="alg1.l4.m15.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m15.1c">\textbf{h}^{0}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m15.1d">h start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l4.6" style="font-size:90%;">, </span><math alttext="m" class="ltx_Math" display="inline" id="alg1.l4.m16.1"><semantics id="alg1.l4.m16.1a"><mi id="alg1.l4.m16.1.1" mathsize="90%" xref="alg1.l4.m16.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m16.1b"><ci id="alg1.l4.m16.1.1.cmml" xref="alg1.l4.m16.1.1">ğ‘š</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m16.1c">m</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m16.1d">italic_m</annotation></semantics></math><span class="ltx_text" id="alg1.l4.7" style="font-size:90%;">)
</span>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l5.2" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l5.3" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_typewriter" id="alg1.l5.4" style="font-size:90%;">worker</span><span class="ltx_text" id="alg1.l5.5" style="font-size:90%;"> </span><math alttext="i=0" class="ltx_Math" display="inline" id="alg1.l5.m1.1"><semantics id="alg1.l5.m1.1a"><mrow id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi id="alg1.l5.m1.1.1.2" mathsize="90%" xref="alg1.l5.m1.1.1.2.cmml">i</mi><mo id="alg1.l5.m1.1.1.1" mathsize="90%" xref="alg1.l5.m1.1.1.1.cmml">=</mo><mn id="alg1.l5.m1.1.1.3" mathsize="90%" xref="alg1.l5.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><eq id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1.1"></eq><ci id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2">ğ‘–</ci><cn id="alg1.l5.m1.1.1.3.cmml" type="integer" xref="alg1.l5.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">i=0</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m1.1d">italic_i = 0</annotation></semantics></math><span class="ltx_text" id="alg1.l5.6" style="font-size:90%;"> to </span><math alttext="m-1" class="ltx_Math" display="inline" id="alg1.l5.m2.1"><semantics id="alg1.l5.m2.1a"><mrow id="alg1.l5.m2.1.1" xref="alg1.l5.m2.1.1.cmml"><mi id="alg1.l5.m2.1.1.2" mathsize="90%" xref="alg1.l5.m2.1.1.2.cmml">m</mi><mo id="alg1.l5.m2.1.1.1" mathsize="90%" xref="alg1.l5.m2.1.1.1.cmml">âˆ’</mo><mn id="alg1.l5.m2.1.1.3" mathsize="90%" xref="alg1.l5.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l5.m2.1b"><apply id="alg1.l5.m2.1.1.cmml" xref="alg1.l5.m2.1.1"><minus id="alg1.l5.m2.1.1.1.cmml" xref="alg1.l5.m2.1.1.1"></minus><ci id="alg1.l5.m2.1.1.2.cmml" xref="alg1.l5.m2.1.1.2">ğ‘š</ci><cn id="alg1.l5.m2.1.1.3.cmml" type="integer" xref="alg1.l5.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m2.1c">m-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l5.m2.1d">italic_m - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l5.7" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l5.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l5.9" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l5.10" style="font-size:90%;">in parallel</span><span class="ltx_text" id="alg1.l5.11" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span><span class="ltx_text" id="alg1.l6.2" style="font-size:90%;">Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l6.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l6.4" style="font-size:90%;">Â layer </span><math alttext="l" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mi id="alg1.l6.m1.1.1" mathsize="90%" xref="alg1.l6.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg1.l6.5" style="font-size:90%;"> = </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l6.m2.1"><semantics id="alg1.l6.m2.1a"><mn id="alg1.l6.m2.1.1" mathsize="90%" xref="alg1.l6.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l6.m2.1b"><cn id="alg1.l6.m2.1.1.cmml" type="integer" xref="alg1.l6.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l6.6" style="font-size:90%;"> to </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l6.m3.1"><semantics id="alg1.l6.m3.1a"><mrow id="alg1.l6.m3.1.1" xref="alg1.l6.m3.1.1.cmml"><mi id="alg1.l6.m3.1.1.2" mathsize="90%" xref="alg1.l6.m3.1.1.2.cmml">L</mi><mo id="alg1.l6.m3.1.1.1" mathsize="90%" xref="alg1.l6.m3.1.1.1.cmml">âˆ’</mo><mn id="alg1.l6.m3.1.1.3" mathsize="90%" xref="alg1.l6.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m3.1b"><apply id="alg1.l6.m3.1.1.cmml" xref="alg1.l6.m3.1.1"><minus id="alg1.l6.m3.1.1.1.cmml" xref="alg1.l6.m3.1.1.1"></minus><ci id="alg1.l6.m3.1.1.2.cmml" xref="alg1.l6.m3.1.1.2">ğ¿</ci><cn id="alg1.l6.m3.1.1.3.cmml" type="integer" xref="alg1.l6.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m3.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m3.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l6.7" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l6.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l6.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.2.1.1" style="font-size:80%;">7:</span></span><span class="ltx_text" id="alg1.l7.3" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><math alttext="\textbf{h}^{l+1}" class="ltx_Math" display="inline" id="alg1.l7.m1.1"><semantics id="alg1.l7.m1.1a"><msup id="alg1.l7.m1.1.1" xref="alg1.l7.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l7.m1.1.1.2" mathsize="90%" xref="alg1.l7.m1.1.1.2a.cmml">h</mtext><mrow id="alg1.l7.m1.1.1.3" xref="alg1.l7.m1.1.1.3.cmml"><mi id="alg1.l7.m1.1.1.3.2" mathsize="90%" xref="alg1.l7.m1.1.1.3.2.cmml">l</mi><mo id="alg1.l7.m1.1.1.3.1" mathsize="90%" xref="alg1.l7.m1.1.1.3.1.cmml">+</mo><mn id="alg1.l7.m1.1.1.3.3" mathsize="90%" xref="alg1.l7.m1.1.1.3.3.cmml">1</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="alg1.l7.m1.1b"><apply id="alg1.l7.m1.1.1.cmml" xref="alg1.l7.m1.1.1"><csymbol cd="ambiguous" id="alg1.l7.m1.1.1.1.cmml" xref="alg1.l7.m1.1.1">superscript</csymbol><ci id="alg1.l7.m1.1.1.2a.cmml" xref="alg1.l7.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l7.m1.1.1.2.cmml" mathsize="90%" xref="alg1.l7.m1.1.1.2">h</mtext></ci><apply id="alg1.l7.m1.1.1.3.cmml" xref="alg1.l7.m1.1.1.3"><plus id="alg1.l7.m1.1.1.3.1.cmml" xref="alg1.l7.m1.1.1.3.1"></plus><ci id="alg1.l7.m1.1.1.3.2.cmml" xref="alg1.l7.m1.1.1.3.2">ğ‘™</ci><cn id="alg1.l7.m1.1.1.3.3.cmml" type="integer" xref="alg1.l7.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m1.1c">\textbf{h}^{l+1}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m1.1d">h start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l7.4" style="font-size:90%;"> of </span><math alttext="V_{i}" class="ltx_Math" display="inline" id="alg1.l7.m2.1"><semantics id="alg1.l7.m2.1a"><msub id="alg1.l7.m2.1.1" xref="alg1.l7.m2.1.1.cmml"><mi id="alg1.l7.m2.1.1.2" mathsize="90%" xref="alg1.l7.m2.1.1.2.cmml">V</mi><mi id="alg1.l7.m2.1.1.3" mathsize="90%" xref="alg1.l7.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m2.1b"><apply id="alg1.l7.m2.1.1.cmml" xref="alg1.l7.m2.1.1"><csymbol cd="ambiguous" id="alg1.l7.m2.1.1.1.cmml" xref="alg1.l7.m2.1.1">subscript</csymbol><ci id="alg1.l7.m2.1.1.2.cmml" xref="alg1.l7.m2.1.1.2">ğ‘‰</ci><ci id="alg1.l7.m2.1.1.3.cmml" xref="alg1.l7.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m2.1c">V_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m2.1d">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l7.5" style="font-size:90%;"> =â€‚</span><span class="ltx_text ltx_font_typewriter" id="alg1.l7.1" style="font-size:90%;">worker(<math alttext="i" class="ltx_Math" display="inline" id="alg1.l7.1.m1.1"><semantics id="alg1.l7.1.m1.1a"><mi id="alg1.l7.1.m1.1.1" xref="alg1.l7.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l7.1.m1.1b"><ci id="alg1.l7.1.m1.1.1.cmml" xref="alg1.l7.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.1.m1.1d">italic_i</annotation></semantics></math>).UPDATE</span><span class="ltx_text" id="alg1.l7.6" style="font-size:90%;">(</span><math alttext="\textbf{W}^{l}" class="ltx_Math" display="inline" id="alg1.l7.m3.1"><semantics id="alg1.l7.m3.1a"><msup id="alg1.l7.m3.1.1" xref="alg1.l7.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l7.m3.1.1.2" mathsize="90%" xref="alg1.l7.m3.1.1.2a.cmml">W</mtext><mi id="alg1.l7.m3.1.1.3" mathsize="90%" xref="alg1.l7.m3.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l7.m3.1b"><apply id="alg1.l7.m3.1.1.cmml" xref="alg1.l7.m3.1.1"><csymbol cd="ambiguous" id="alg1.l7.m3.1.1.1.cmml" xref="alg1.l7.m3.1.1">superscript</csymbol><ci id="alg1.l7.m3.1.1.2a.cmml" xref="alg1.l7.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l7.m3.1.1.2.cmml" mathsize="90%" xref="alg1.l7.m3.1.1.2">W</mtext></ci><ci id="alg1.l7.m3.1.1.3.cmml" xref="alg1.l7.m3.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m3.1c">\textbf{W}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m3.1d">W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l7.7" style="font-size:90%;">, </span><math alttext="\textbf{h}^{l}" class="ltx_Math" display="inline" id="alg1.l7.m4.1"><semantics id="alg1.l7.m4.1a"><msup id="alg1.l7.m4.1.1" xref="alg1.l7.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l7.m4.1.1.2" mathsize="90%" xref="alg1.l7.m4.1.1.2a.cmml">h</mtext><mi id="alg1.l7.m4.1.1.3" mathsize="90%" xref="alg1.l7.m4.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l7.m4.1b"><apply id="alg1.l7.m4.1.1.cmml" xref="alg1.l7.m4.1.1"><csymbol cd="ambiguous" id="alg1.l7.m4.1.1.1.cmml" xref="alg1.l7.m4.1.1">superscript</csymbol><ci id="alg1.l7.m4.1.1.2a.cmml" xref="alg1.l7.m4.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l7.m4.1.1.2.cmml" mathsize="90%" xref="alg1.l7.m4.1.1.2">h</mtext></ci><ci id="alg1.l7.m4.1.1.3.cmml" xref="alg1.l7.m4.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m4.1c">\textbf{h}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m4.1d">h start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l7.8" style="font-size:90%;"> of </span><math alttext="V_{i}" class="ltx_Math" display="inline" id="alg1.l7.m5.1"><semantics id="alg1.l7.m5.1a"><msub id="alg1.l7.m5.1.1" xref="alg1.l7.m5.1.1.cmml"><mi id="alg1.l7.m5.1.1.2" mathsize="90%" xref="alg1.l7.m5.1.1.2.cmml">V</mi><mi id="alg1.l7.m5.1.1.3" mathsize="90%" xref="alg1.l7.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l7.m5.1b"><apply id="alg1.l7.m5.1.1.cmml" xref="alg1.l7.m5.1.1"><csymbol cd="ambiguous" id="alg1.l7.m5.1.1.1.cmml" xref="alg1.l7.m5.1.1">subscript</csymbol><ci id="alg1.l7.m5.1.1.2.cmml" xref="alg1.l7.m5.1.1.2">ğ‘‰</ci><ci id="alg1.l7.m5.1.1.3.cmml" xref="alg1.l7.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l7.m5.1c">V_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l7.m5.1d">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l7.9" style="font-size:90%;">)
Â Â Â Â </span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span><span class="ltx_text" id="alg1.l8.2" style="font-size:90%;">Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l8.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l8.4" style="font-size:90%;">Â layer </span><math alttext="l" class="ltx_Math" display="inline" id="alg1.l8.m1.1"><semantics id="alg1.l8.m1.1a"><mi id="alg1.l8.m1.1.1" mathsize="90%" xref="alg1.l8.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg1.l8.m1.1b"><ci id="alg1.l8.m1.1.1.cmml" xref="alg1.l8.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m1.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg1.l8.5" style="font-size:90%;"> = </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l8.m2.1"><semantics id="alg1.l8.m2.1a"><mn id="alg1.l8.m2.1.1" mathsize="90%" xref="alg1.l8.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l8.m2.1b"><cn id="alg1.l8.m2.1.1.cmml" type="integer" xref="alg1.l8.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l8.6" style="font-size:90%;"> to </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l8.m3.1"><semantics id="alg1.l8.m3.1a"><mrow id="alg1.l8.m3.1.1" xref="alg1.l8.m3.1.1.cmml"><mi id="alg1.l8.m3.1.1.2" mathsize="90%" xref="alg1.l8.m3.1.1.2.cmml">L</mi><mo id="alg1.l8.m3.1.1.1" mathsize="90%" xref="alg1.l8.m3.1.1.1.cmml">âˆ’</mo><mn id="alg1.l8.m3.1.1.3" mathsize="90%" xref="alg1.l8.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l8.m3.1b"><apply id="alg1.l8.m3.1.1.cmml" xref="alg1.l8.m3.1.1"><minus id="alg1.l8.m3.1.1.1.cmml" xref="alg1.l8.m3.1.1.1"></minus><ci id="alg1.l8.m3.1.1.2.cmml" xref="alg1.l8.m3.1.1.2">ğ¿</ci><cn id="alg1.l8.m3.1.1.3.cmml" type="integer" xref="alg1.l8.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l8.m3.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l8.m3.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l8.7" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l8.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l8.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span><span class="ltx_text" id="alg1.l9.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l9.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l9.4" style="font-size:90%;">Â </span><em class="ltx_emph ltx_font_italic" id="alg1.l9.5" style="font-size:90%;">chunk</em><span class="ltx_text" id="alg1.l9.6" style="font-size:90%;"> with id </span><math alttext="j" class="ltx_Math" display="inline" id="alg1.l9.m1.1"><semantics id="alg1.l9.m1.1a"><mi id="alg1.l9.m1.1.1" mathsize="90%" xref="alg1.l9.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.l9.m1.1b"><ci id="alg1.l9.m1.1.1.cmml" xref="alg1.l9.m1.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m1.1c">j</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m1.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="alg1.l9.7" style="font-size:90%;"> = </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l9.m2.1"><semantics id="alg1.l9.m2.1a"><mn id="alg1.l9.m2.1.1" mathsize="90%" xref="alg1.l9.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l9.m2.1b"><cn id="alg1.l9.m2.1.1.cmml" type="integer" xref="alg1.l9.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l9.8" style="font-size:90%;"> to </span><math alttext="n-1" class="ltx_Math" display="inline" id="alg1.l9.m3.1"><semantics id="alg1.l9.m3.1a"><mrow id="alg1.l9.m3.1.1" xref="alg1.l9.m3.1.1.cmml"><mi id="alg1.l9.m3.1.1.2" mathsize="90%" xref="alg1.l9.m3.1.1.2.cmml">n</mi><mo id="alg1.l9.m3.1.1.1" mathsize="90%" xref="alg1.l9.m3.1.1.1.cmml">âˆ’</mo><mn id="alg1.l9.m3.1.1.3" mathsize="90%" xref="alg1.l9.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l9.m3.1b"><apply id="alg1.l9.m3.1.1.cmml" xref="alg1.l9.m3.1.1"><minus id="alg1.l9.m3.1.1.1.cmml" xref="alg1.l9.m3.1.1.1"></minus><ci id="alg1.l9.m3.1.1.2.cmml" xref="alg1.l9.m3.1.1.2">ğ‘›</ci><cn id="alg1.l9.m3.1.1.3.cmml" type="integer" xref="alg1.l9.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l9.m3.1c">n-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l9.m3.1d">italic_n - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l9.9" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l9.10" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l9.11" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span><span class="ltx_text" id="alg1.l10.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l10.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg1.l10.4" style="font-size:90%;">Â layer == </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><mn id="alg1.l10.m1.1.1" mathsize="90%" xref="alg1.l10.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><cn id="alg1.l10.m1.1.1.cmml" type="integer" xref="alg1.l10.m1.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l10.5" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l10.6" style="font-size:90%;">then</span><span class="ltx_text" id="alg1.l10.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span><span class="ltx_text" id="alg1.l11.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math alttext="\textbf{h\_cut}^{0}_{i}" class="ltx_Math" display="inline" id="alg1.l11.m1.1"><semantics id="alg1.l11.m1.1a"><msubsup id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l11.m1.1.1.2.2" mathsize="90%" xref="alg1.l11.m1.1.1.2.2a.cmml">h_cut</mtext><mi id="alg1.l11.m1.1.1.3" mathsize="90%" xref="alg1.l11.m1.1.1.3.cmml">i</mi><mn id="alg1.l11.m1.1.1.2.3" mathsize="90%" xref="alg1.l11.m1.1.1.2.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1">subscript</csymbol><apply id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.2.1.cmml" xref="alg1.l11.m1.1.1">superscript</csymbol><ci id="alg1.l11.m1.1.1.2.2a.cmml" xref="alg1.l11.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l11.m1.1.1.2.2.cmml" mathsize="90%" xref="alg1.l11.m1.1.1.2.2">h_cut</mtext></ci><cn id="alg1.l11.m1.1.1.2.3.cmml" type="integer" xref="alg1.l11.m1.1.1.2.3">0</cn></apply><ci id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">\textbf{h\_cut}^{0}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.1d">h_cut start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l11.3" style="font-size:90%;"> of </span><math alttext="{N_{j}}" class="ltx_Math" display="inline" id="alg1.l11.m2.1"><semantics id="alg1.l11.m2.1a"><msub id="alg1.l11.m2.1.1" xref="alg1.l11.m2.1.1.cmml"><mi id="alg1.l11.m2.1.1.2" mathsize="90%" xref="alg1.l11.m2.1.1.2.cmml">N</mi><mi id="alg1.l11.m2.1.1.3" mathsize="90%" xref="alg1.l11.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l11.m2.1b"><apply id="alg1.l11.m2.1.1.cmml" xref="alg1.l11.m2.1.1"><csymbol cd="ambiguous" id="alg1.l11.m2.1.1.1.cmml" xref="alg1.l11.m2.1.1">subscript</csymbol><ci id="alg1.l11.m2.1.1.2.cmml" xref="alg1.l11.m2.1.1.2">ğ‘</ci><ci id="alg1.l11.m2.1.1.3.cmml" xref="alg1.l11.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m2.1c">{N_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m2.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l11.m3.1"><semantics id="alg1.l11.m3.1a"><mo id="alg1.l11.m3.1.1" mathsize="90%" stretchy="false" xref="alg1.l11.m3.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l11.m3.1b"><ci id="alg1.l11.m3.1.1.cmml" xref="alg1.l11.m3.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m3.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m3.1d">â†</annotation></semantics></math><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.l11.4" style="font-size:90%;">Split</span><span class="ltx_text" id="alg1.l11.5" style="font-size:90%;">(</span><math alttext="\textbf{h}^{L}" class="ltx_Math" display="inline" id="alg1.l11.m4.1"><semantics id="alg1.l11.m4.1a"><msup id="alg1.l11.m4.1.1" xref="alg1.l11.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l11.m4.1.1.2" mathsize="90%" xref="alg1.l11.m4.1.1.2a.cmml">h</mtext><mi id="alg1.l11.m4.1.1.3" mathsize="90%" xref="alg1.l11.m4.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l11.m4.1b"><apply id="alg1.l11.m4.1.1.cmml" xref="alg1.l11.m4.1.1"><csymbol cd="ambiguous" id="alg1.l11.m4.1.1.1.cmml" xref="alg1.l11.m4.1.1">superscript</csymbol><ci id="alg1.l11.m4.1.1.2a.cmml" xref="alg1.l11.m4.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l11.m4.1.1.2.cmml" mathsize="90%" xref="alg1.l11.m4.1.1.2">h</mtext></ci><ci id="alg1.l11.m4.1.1.3.cmml" xref="alg1.l11.m4.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m4.1c">\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m4.1d">h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l11.6" style="font-size:90%;"> of </span><math alttext="{N_{j}}" class="ltx_Math" display="inline" id="alg1.l11.m5.1"><semantics id="alg1.l11.m5.1a"><msub id="alg1.l11.m5.1.1" xref="alg1.l11.m5.1.1.cmml"><mi id="alg1.l11.m5.1.1.2" mathsize="90%" xref="alg1.l11.m5.1.1.2.cmml">N</mi><mi id="alg1.l11.m5.1.1.3" mathsize="90%" xref="alg1.l11.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l11.m5.1b"><apply id="alg1.l11.m5.1.1.cmml" xref="alg1.l11.m5.1.1"><csymbol cd="ambiguous" id="alg1.l11.m5.1.1.1.cmml" xref="alg1.l11.m5.1.1">subscript</csymbol><ci id="alg1.l11.m5.1.1.2.cmml" xref="alg1.l11.m5.1.1.2">ğ‘</ci><ci id="alg1.l11.m5.1.1.3.cmml" xref="alg1.l11.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m5.1c">{N_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m5.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l11.7" style="font-size:90%;">)
Â Â Â Â Â Â Â Â Â Â Â Â Â </span>
</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.2.1.1" style="font-size:80%;">12:</span></span><span class="ltx_text" id="alg1.l12.3" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math alttext="\textbf{h\_cut}_{i}^{l+1}" class="ltx_Math" display="inline" id="alg1.l12.m1.1"><semantics id="alg1.l12.m1.1a"><msubsup id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l12.m1.1.1.2.2" mathsize="90%" xref="alg1.l12.m1.1.1.2.2a.cmml">h_cut</mtext><mi id="alg1.l12.m1.1.1.2.3" mathsize="90%" xref="alg1.l12.m1.1.1.2.3.cmml">i</mi><mrow id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml"><mi id="alg1.l12.m1.1.1.3.2" mathsize="90%" xref="alg1.l12.m1.1.1.3.2.cmml">l</mi><mo id="alg1.l12.m1.1.1.3.1" mathsize="90%" xref="alg1.l12.m1.1.1.3.1.cmml">+</mo><mn id="alg1.l12.m1.1.1.3.3" mathsize="90%" xref="alg1.l12.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1">superscript</csymbol><apply id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.1.cmml" xref="alg1.l12.m1.1.1">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.2a.cmml" xref="alg1.l12.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l12.m1.1.1.2.2.cmml" mathsize="90%" xref="alg1.l12.m1.1.1.2.2">h_cut</mtext></ci><ci id="alg1.l12.m1.1.1.2.3.cmml" xref="alg1.l12.m1.1.1.2.3">ğ‘–</ci></apply><apply id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3"><plus id="alg1.l12.m1.1.1.3.1.cmml" xref="alg1.l12.m1.1.1.3.1"></plus><ci id="alg1.l12.m1.1.1.3.2.cmml" xref="alg1.l12.m1.1.1.3.2">ğ‘™</ci><cn id="alg1.l12.m1.1.1.3.3.cmml" type="integer" xref="alg1.l12.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">\textbf{h\_cut}_{i}^{l+1}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.1d">h_cut start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l12.4" style="font-size:90%;"> of </span><math alttext="V_{j}" class="ltx_Math" display="inline" id="alg1.l12.m2.1"><semantics id="alg1.l12.m2.1a"><msub id="alg1.l12.m2.1.1" xref="alg1.l12.m2.1.1.cmml"><mi id="alg1.l12.m2.1.1.2" mathsize="90%" xref="alg1.l12.m2.1.1.2.cmml">V</mi><mi id="alg1.l12.m2.1.1.3" mathsize="90%" xref="alg1.l12.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l12.m2.1b"><apply id="alg1.l12.m2.1.1.cmml" xref="alg1.l12.m2.1.1"><csymbol cd="ambiguous" id="alg1.l12.m2.1.1.1.cmml" xref="alg1.l12.m2.1.1">subscript</csymbol><ci id="alg1.l12.m2.1.1.2.cmml" xref="alg1.l12.m2.1.1.2">ğ‘‰</ci><ci id="alg1.l12.m2.1.1.3.cmml" xref="alg1.l12.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m2.1c">V_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m2.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l12.5" style="font-size:90%;"> =â€‚</span><span class="ltx_text ltx_font_typewriter" id="alg1.l12.1" style="font-size:90%;">worker(<math alttext="i" class="ltx_Math" display="inline" id="alg1.l12.1.m1.1"><semantics id="alg1.l12.1.m1.1a"><mi id="alg1.l12.1.m1.1.1" xref="alg1.l12.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l12.1.m1.1b"><ci id="alg1.l12.1.m1.1.1.cmml" xref="alg1.l12.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.1.m1.1d">italic_i</annotation></semantics></math>).AGG</span><span class="ltx_text" id="alg1.l12.6" style="font-size:90%;">(</span><math alttext="\textbf{h\_cut}_{i}^{l}" class="ltx_Math" display="inline" id="alg1.l12.m3.1"><semantics id="alg1.l12.m3.1a"><msubsup id="alg1.l12.m3.1.1" xref="alg1.l12.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l12.m3.1.1.2.2" mathsize="90%" xref="alg1.l12.m3.1.1.2.2a.cmml">h_cut</mtext><mi id="alg1.l12.m3.1.1.2.3" mathsize="90%" xref="alg1.l12.m3.1.1.2.3.cmml">i</mi><mi id="alg1.l12.m3.1.1.3" mathsize="90%" xref="alg1.l12.m3.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l12.m3.1b"><apply id="alg1.l12.m3.1.1.cmml" xref="alg1.l12.m3.1.1"><csymbol cd="ambiguous" id="alg1.l12.m3.1.1.1.cmml" xref="alg1.l12.m3.1.1">superscript</csymbol><apply id="alg1.l12.m3.1.1.2.cmml" xref="alg1.l12.m3.1.1"><csymbol cd="ambiguous" id="alg1.l12.m3.1.1.2.1.cmml" xref="alg1.l12.m3.1.1">subscript</csymbol><ci id="alg1.l12.m3.1.1.2.2a.cmml" xref="alg1.l12.m3.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l12.m3.1.1.2.2.cmml" mathsize="90%" xref="alg1.l12.m3.1.1.2.2">h_cut</mtext></ci><ci id="alg1.l12.m3.1.1.2.3.cmml" xref="alg1.l12.m3.1.1.2.3">ğ‘–</ci></apply><ci id="alg1.l12.m3.1.1.3.cmml" xref="alg1.l12.m3.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m3.1c">\textbf{h\_cut}_{i}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m3.1d">h_cut start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l12.7" style="font-size:90%;"> of </span><math alttext="{N_{j}}" class="ltx_Math" display="inline" id="alg1.l12.m4.1"><semantics id="alg1.l12.m4.1a"><msub id="alg1.l12.m4.1.1" xref="alg1.l12.m4.1.1.cmml"><mi id="alg1.l12.m4.1.1.2" mathsize="90%" xref="alg1.l12.m4.1.1.2.cmml">N</mi><mi id="alg1.l12.m4.1.1.3" mathsize="90%" xref="alg1.l12.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l12.m4.1b"><apply id="alg1.l12.m4.1.1.cmml" xref="alg1.l12.m4.1.1"><csymbol cd="ambiguous" id="alg1.l12.m4.1.1.1.cmml" xref="alg1.l12.m4.1.1">subscript</csymbol><ci id="alg1.l12.m4.1.1.2.cmml" xref="alg1.l12.m4.1.1.2">ğ‘</ci><ci id="alg1.l12.m4.1.1.3.cmml" xref="alg1.l12.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m4.1c">{N_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m4.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l12.8" style="font-size:90%;">, </span><math alttext="{G_{j}}" class="ltx_Math" display="inline" id="alg1.l12.m5.1"><semantics id="alg1.l12.m5.1a"><msub id="alg1.l12.m5.1.1" xref="alg1.l12.m5.1.1.cmml"><mi id="alg1.l12.m5.1.1.2" mathsize="90%" xref="alg1.l12.m5.1.1.2.cmml">G</mi><mi id="alg1.l12.m5.1.1.3" mathsize="90%" xref="alg1.l12.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l12.m5.1b"><apply id="alg1.l12.m5.1.1.cmml" xref="alg1.l12.m5.1.1"><csymbol cd="ambiguous" id="alg1.l12.m5.1.1.1.cmml" xref="alg1.l12.m5.1.1">subscript</csymbol><ci id="alg1.l12.m5.1.1.2.cmml" xref="alg1.l12.m5.1.1.2">ğº</ci><ci id="alg1.l12.m5.1.1.3.cmml" xref="alg1.l12.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m5.1c">{G_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m5.1d">italic_G start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l12.9" style="font-size:90%;">)
</span>
</div>
<div class="ltx_listingline" id="alg1.l13">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l13.1.1.1" style="font-size:80%;">13:</span></span><span class="ltx_text" id="alg1.l13.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l13.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg1.l13.4" style="font-size:90%;">Â layer == </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l13.m1.1"><semantics id="alg1.l13.m1.1a"><mrow id="alg1.l13.m1.1.1" xref="alg1.l13.m1.1.1.cmml"><mi id="alg1.l13.m1.1.1.2" mathsize="90%" xref="alg1.l13.m1.1.1.2.cmml">L</mi><mo id="alg1.l13.m1.1.1.1" mathsize="90%" xref="alg1.l13.m1.1.1.1.cmml">âˆ’</mo><mn id="alg1.l13.m1.1.1.3" mathsize="90%" xref="alg1.l13.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l13.m1.1b"><apply id="alg1.l13.m1.1.1.cmml" xref="alg1.l13.m1.1.1"><minus id="alg1.l13.m1.1.1.1.cmml" xref="alg1.l13.m1.1.1.1"></minus><ci id="alg1.l13.m1.1.1.2.cmml" xref="alg1.l13.m1.1.1.2">ğ¿</ci><cn id="alg1.l13.m1.1.1.3.cmml" type="integer" xref="alg1.l13.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l13.m1.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l13.m1.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l13.5" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l13.6" style="font-size:90%;">then</span><span class="ltx_text" id="alg1.l13.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l14">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l14.1.1.1" style="font-size:80%;">14:</span></span><span class="ltx_text" id="alg1.l14.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math alttext="\textbf{h}^{L}" class="ltx_Math" display="inline" id="alg1.l14.m1.1"><semantics id="alg1.l14.m1.1a"><msup id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l14.m1.1.1.2" mathsize="90%" xref="alg1.l14.m1.1.1.2a.cmml">h</mtext><mi id="alg1.l14.m1.1.1.3" mathsize="90%" xref="alg1.l14.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><apply id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1"><csymbol cd="ambiguous" id="alg1.l14.m1.1.1.1.cmml" xref="alg1.l14.m1.1.1">superscript</csymbol><ci id="alg1.l14.m1.1.1.2a.cmml" xref="alg1.l14.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l14.m1.1.1.2.cmml" mathsize="90%" xref="alg1.l14.m1.1.1.2">h</mtext></ci><ci id="alg1.l14.m1.1.1.3.cmml" xref="alg1.l14.m1.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m1.1d">h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l14.3" style="font-size:90%;"> of </span><math alttext="V_{j}" class="ltx_Math" display="inline" id="alg1.l14.m2.1"><semantics id="alg1.l14.m2.1a"><msub id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml"><mi id="alg1.l14.m2.1.1.2" mathsize="90%" xref="alg1.l14.m2.1.1.2.cmml">V</mi><mi id="alg1.l14.m2.1.1.3" mathsize="90%" xref="alg1.l14.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l14.m2.1b"><apply id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1"><csymbol cd="ambiguous" id="alg1.l14.m2.1.1.1.cmml" xref="alg1.l14.m2.1.1">subscript</csymbol><ci id="alg1.l14.m2.1.1.2.cmml" xref="alg1.l14.m2.1.1.2">ğ‘‰</ci><ci id="alg1.l14.m2.1.1.3.cmml" xref="alg1.l14.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m2.1c">V_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m2.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l14.m3.1"><semantics id="alg1.l14.m3.1a"><mo id="alg1.l14.m3.1.1" mathsize="90%" stretchy="false" xref="alg1.l14.m3.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l14.m3.1b"><ci id="alg1.l14.m3.1.1.cmml" xref="alg1.l14.m3.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m3.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m3.1d">â†</annotation></semantics></math><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.l14.4" style="font-size:90%;">Gather</span><span class="ltx_text" id="alg1.l14.5" style="font-size:90%;">(</span><math alttext="\textbf{h\_cut}^{L}_{i}" class="ltx_Math" display="inline" id="alg1.l14.m4.1"><semantics id="alg1.l14.m4.1a"><msubsup id="alg1.l14.m4.1.1" xref="alg1.l14.m4.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l14.m4.1.1.2.2" mathsize="90%" xref="alg1.l14.m4.1.1.2.2a.cmml">h_cut</mtext><mi id="alg1.l14.m4.1.1.3" mathsize="90%" xref="alg1.l14.m4.1.1.3.cmml">i</mi><mi id="alg1.l14.m4.1.1.2.3" mathsize="90%" xref="alg1.l14.m4.1.1.2.3.cmml">L</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l14.m4.1b"><apply id="alg1.l14.m4.1.1.cmml" xref="alg1.l14.m4.1.1"><csymbol cd="ambiguous" id="alg1.l14.m4.1.1.1.cmml" xref="alg1.l14.m4.1.1">subscript</csymbol><apply id="alg1.l14.m4.1.1.2.cmml" xref="alg1.l14.m4.1.1"><csymbol cd="ambiguous" id="alg1.l14.m4.1.1.2.1.cmml" xref="alg1.l14.m4.1.1">superscript</csymbol><ci id="alg1.l14.m4.1.1.2.2a.cmml" xref="alg1.l14.m4.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l14.m4.1.1.2.2.cmml" mathsize="90%" xref="alg1.l14.m4.1.1.2.2">h_cut</mtext></ci><ci id="alg1.l14.m4.1.1.2.3.cmml" xref="alg1.l14.m4.1.1.2.3">ğ¿</ci></apply><ci id="alg1.l14.m4.1.1.3.cmml" xref="alg1.l14.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m4.1c">\textbf{h\_cut}^{L}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m4.1d">h_cut start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l14.6" style="font-size:90%;"> of </span><math alttext="V_{j}" class="ltx_Math" display="inline" id="alg1.l14.m5.1"><semantics id="alg1.l14.m5.1a"><msub id="alg1.l14.m5.1.1" xref="alg1.l14.m5.1.1.cmml"><mi id="alg1.l14.m5.1.1.2" mathsize="90%" xref="alg1.l14.m5.1.1.2.cmml">V</mi><mi id="alg1.l14.m5.1.1.3" mathsize="90%" xref="alg1.l14.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l14.m5.1b"><apply id="alg1.l14.m5.1.1.cmml" xref="alg1.l14.m5.1.1"><csymbol cd="ambiguous" id="alg1.l14.m5.1.1.1.cmml" xref="alg1.l14.m5.1.1">subscript</csymbol><ci id="alg1.l14.m5.1.1.2.cmml" xref="alg1.l14.m5.1.1.2">ğ‘‰</ci><ci id="alg1.l14.m5.1.1.3.cmml" xref="alg1.l14.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m5.1c">V_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l14.m5.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l14.7" style="font-size:90%;">)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span>
</div>
<div class="ltx_listingline" id="alg1.l15">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l15.1.1.1" style="font-size:80%;">15:</span></span><span class="ltx_text ltx_markedasmath ltx_font_bold" id="alg1.l15.2" style="font-size:90%;">loss</span><span class="ltx_text" id="alg1.l15.3" style="font-size:90%;"> = </span><span class="ltx_text ltx_font_typewriter" id="alg1.l15.4" style="font-size:90%;">downstream_task</span><span class="ltx_text" id="alg1.l15.5" style="font-size:90%;">(</span><math alttext="\textbf{h}^{L}" class="ltx_Math" display="inline" id="alg1.l15.m2.1"><semantics id="alg1.l15.m2.1a"><msup id="alg1.l15.m2.1.1" xref="alg1.l15.m2.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l15.m2.1.1.2" mathsize="90%" xref="alg1.l15.m2.1.1.2a.cmml">h</mtext><mi id="alg1.l15.m2.1.1.3" mathsize="90%" xref="alg1.l15.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l15.m2.1b"><apply id="alg1.l15.m2.1.1.cmml" xref="alg1.l15.m2.1.1"><csymbol cd="ambiguous" id="alg1.l15.m2.1.1.1.cmml" xref="alg1.l15.m2.1.1">superscript</csymbol><ci id="alg1.l15.m2.1.1.2a.cmml" xref="alg1.l15.m2.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l15.m2.1.1.2.cmml" mathsize="90%" xref="alg1.l15.m2.1.1.2">h</mtext></ci><ci id="alg1.l15.m2.1.1.3.cmml" xref="alg1.l15.m2.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m2.1c">\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="alg1.l15.m2.1d">h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l15.6" style="font-size:90%;">)
</span>
</div>
<div class="ltx_listingline" id="alg1.l16">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l16.1.1.1" style="font-size:80%;">16:</span></span><math alttext="\nabla\textbf{h}^{L}" class="ltx_Math" display="inline" id="alg1.l16.m1.1"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml"><mo id="alg1.l16.m1.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l16.m1.1.1.1.cmml">âˆ‡</mo><msup id="alg1.l16.m1.1.1.2" xref="alg1.l16.m1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l16.m1.1.1.2.2" mathsize="90%" xref="alg1.l16.m1.1.1.2.2a.cmml">h</mtext><mi id="alg1.l16.m1.1.1.2.3" mathsize="90%" xref="alg1.l16.m1.1.1.2.3.cmml">L</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1"><ci id="alg1.l16.m1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1">âˆ‡</ci><apply id="alg1.l16.m1.1.1.2.cmml" xref="alg1.l16.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l16.m1.1.1.2.1.cmml" xref="alg1.l16.m1.1.1.2">superscript</csymbol><ci id="alg1.l16.m1.1.1.2.2a.cmml" xref="alg1.l16.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l16.m1.1.1.2.2.cmml" mathsize="90%" xref="alg1.l16.m1.1.1.2.2">h</mtext></ci><ci id="alg1.l16.m1.1.1.2.3.cmml" xref="alg1.l16.m1.1.1.2.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">\nabla\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="alg1.l16.m1.1d">âˆ‡ h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l16.2" style="font-size:90%;"> = </span><span class="ltx_text ltx_markedasmath ltx_font_bold" id="alg1.l16.3" style="font-size:90%;">loss</span><span class="ltx_text ltx_font_typewriter" id="alg1.l16.4" style="font-size:90%;">.backward()</span><span class="ltx_text" id="alg1.l16.5" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l17">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l17.1.1.1" style="font-size:80%;">17:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l17.2" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l17.3" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_typewriter" id="alg1.l17.4" style="font-size:90%;">worker</span><span class="ltx_text" id="alg1.l17.5" style="font-size:90%;"> </span><math alttext="i=0" class="ltx_Math" display="inline" id="alg1.l17.m1.1"><semantics id="alg1.l17.m1.1a"><mrow id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml"><mi id="alg1.l17.m1.1.1.2" mathsize="90%" xref="alg1.l17.m1.1.1.2.cmml">i</mi><mo id="alg1.l17.m1.1.1.1" mathsize="90%" xref="alg1.l17.m1.1.1.1.cmml">=</mo><mn id="alg1.l17.m1.1.1.3" mathsize="90%" xref="alg1.l17.m1.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><apply id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1"><eq id="alg1.l17.m1.1.1.1.cmml" xref="alg1.l17.m1.1.1.1"></eq><ci id="alg1.l17.m1.1.1.2.cmml" xref="alg1.l17.m1.1.1.2">ğ‘–</ci><cn id="alg1.l17.m1.1.1.3.cmml" type="integer" xref="alg1.l17.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">i=0</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m1.1d">italic_i = 0</annotation></semantics></math><span class="ltx_text" id="alg1.l17.6" style="font-size:90%;"> to </span><math alttext="m-1" class="ltx_Math" display="inline" id="alg1.l17.m2.1"><semantics id="alg1.l17.m2.1a"><mrow id="alg1.l17.m2.1.1" xref="alg1.l17.m2.1.1.cmml"><mi id="alg1.l17.m2.1.1.2" mathsize="90%" xref="alg1.l17.m2.1.1.2.cmml">m</mi><mo id="alg1.l17.m2.1.1.1" mathsize="90%" xref="alg1.l17.m2.1.1.1.cmml">âˆ’</mo><mn id="alg1.l17.m2.1.1.3" mathsize="90%" xref="alg1.l17.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l17.m2.1b"><apply id="alg1.l17.m2.1.1.cmml" xref="alg1.l17.m2.1.1"><minus id="alg1.l17.m2.1.1.1.cmml" xref="alg1.l17.m2.1.1.1"></minus><ci id="alg1.l17.m2.1.1.2.cmml" xref="alg1.l17.m2.1.1.2">ğ‘š</ci><cn id="alg1.l17.m2.1.1.3.cmml" type="integer" xref="alg1.l17.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m2.1c">m-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l17.m2.1d">italic_m - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l17.7" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l17.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l17.9" style="font-size:90%;"> </span><span class="ltx_text ltx_font_bold" id="alg1.l17.10" style="font-size:90%;">in parallel</span><span class="ltx_text" id="alg1.l17.11" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l18">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l18.1.1.1" style="font-size:80%;">18:</span></span><span class="ltx_text" id="alg1.l18.2" style="font-size:90%;">Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l18.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l18.4" style="font-size:90%;">Â layer </span><math alttext="l" class="ltx_Math" display="inline" id="alg1.l18.m1.1"><semantics id="alg1.l18.m1.1a"><mi id="alg1.l18.m1.1.1" mathsize="90%" xref="alg1.l18.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.1b"><ci id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg1.l18.m1.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg1.l18.5" style="font-size:90%;"> = </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l18.m2.1"><semantics id="alg1.l18.m2.1a"><mrow id="alg1.l18.m2.1.1" xref="alg1.l18.m2.1.1.cmml"><mi id="alg1.l18.m2.1.1.2" mathsize="90%" xref="alg1.l18.m2.1.1.2.cmml">L</mi><mo id="alg1.l18.m2.1.1.1" mathsize="90%" xref="alg1.l18.m2.1.1.1.cmml">âˆ’</mo><mn id="alg1.l18.m2.1.1.3" mathsize="90%" xref="alg1.l18.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m2.1b"><apply id="alg1.l18.m2.1.1.cmml" xref="alg1.l18.m2.1.1"><minus id="alg1.l18.m2.1.1.1.cmml" xref="alg1.l18.m2.1.1.1"></minus><ci id="alg1.l18.m2.1.1.2.cmml" xref="alg1.l18.m2.1.1.2">ğ¿</ci><cn id="alg1.l18.m2.1.1.3.cmml" type="integer" xref="alg1.l18.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m2.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l18.m2.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l18.6" style="font-size:90%;"> to </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l18.m3.1"><semantics id="alg1.l18.m3.1a"><mn id="alg1.l18.m3.1.1" mathsize="90%" xref="alg1.l18.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l18.m3.1b"><cn id="alg1.l18.m3.1.1.cmml" type="integer" xref="alg1.l18.m3.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l18.7" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l18.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l18.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l19">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l19.1.1.1" style="font-size:80%;">19:</span></span><span class="ltx_text" id="alg1.l19.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l19.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l19.4" style="font-size:90%;">Â </span><em class="ltx_emph ltx_font_italic" id="alg1.l19.5" style="font-size:90%;">chunk</em><span class="ltx_text" id="alg1.l19.6" style="font-size:90%;"> with id </span><math alttext="j" class="ltx_Math" display="inline" id="alg1.l19.m1.1"><semantics id="alg1.l19.m1.1a"><mi id="alg1.l19.m1.1.1" mathsize="90%" xref="alg1.l19.m1.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><ci id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">j</annotation><annotation encoding="application/x-llamapun" id="alg1.l19.m1.1d">italic_j</annotation></semantics></math><span class="ltx_text" id="alg1.l19.7" style="font-size:90%;"> = </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l19.m2.1"><semantics id="alg1.l19.m2.1a"><mn id="alg1.l19.m2.1.1" mathsize="90%" xref="alg1.l19.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l19.m2.1b"><cn id="alg1.l19.m2.1.1.cmml" type="integer" xref="alg1.l19.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l19.8" style="font-size:90%;"> to </span><math alttext="n-1" class="ltx_Math" display="inline" id="alg1.l19.m3.1"><semantics id="alg1.l19.m3.1a"><mrow id="alg1.l19.m3.1.1" xref="alg1.l19.m3.1.1.cmml"><mi id="alg1.l19.m3.1.1.2" mathsize="90%" xref="alg1.l19.m3.1.1.2.cmml">n</mi><mo id="alg1.l19.m3.1.1.1" mathsize="90%" xref="alg1.l19.m3.1.1.1.cmml">âˆ’</mo><mn id="alg1.l19.m3.1.1.3" mathsize="90%" xref="alg1.l19.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l19.m3.1b"><apply id="alg1.l19.m3.1.1.cmml" xref="alg1.l19.m3.1.1"><minus id="alg1.l19.m3.1.1.1.cmml" xref="alg1.l19.m3.1.1.1"></minus><ci id="alg1.l19.m3.1.1.2.cmml" xref="alg1.l19.m3.1.1.2">ğ‘›</ci><cn id="alg1.l19.m3.1.1.3.cmml" type="integer" xref="alg1.l19.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m3.1c">n-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l19.m3.1d">italic_n - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l19.9" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l19.10" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l19.11" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l20">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l20.1.1.1" style="font-size:80%;">20:</span></span><span class="ltx_text" id="alg1.l20.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l20.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg1.l20.4" style="font-size:90%;">Â layer == </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l20.m1.1"><semantics id="alg1.l20.m1.1a"><mrow id="alg1.l20.m1.1.1" xref="alg1.l20.m1.1.1.cmml"><mi id="alg1.l20.m1.1.1.2" mathsize="90%" xref="alg1.l20.m1.1.1.2.cmml">L</mi><mo id="alg1.l20.m1.1.1.1" mathsize="90%" xref="alg1.l20.m1.1.1.1.cmml">âˆ’</mo><mn id="alg1.l20.m1.1.1.3" mathsize="90%" xref="alg1.l20.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l20.m1.1b"><apply id="alg1.l20.m1.1.1.cmml" xref="alg1.l20.m1.1.1"><minus id="alg1.l20.m1.1.1.1.cmml" xref="alg1.l20.m1.1.1.1"></minus><ci id="alg1.l20.m1.1.1.2.cmml" xref="alg1.l20.m1.1.1.2">ğ¿</ci><cn id="alg1.l20.m1.1.1.3.cmml" type="integer" xref="alg1.l20.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l20.m1.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l20.m1.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l20.5" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l20.6" style="font-size:90%;">then</span><span class="ltx_text" id="alg1.l20.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l21">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l21.1.1.1" style="font-size:80%;">21:</span></span><span class="ltx_text" id="alg1.l21.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math alttext="\nabla\textbf{h\_cut}^{0}_{i}" class="ltx_Math" display="inline" id="alg1.l21.m1.1"><semantics id="alg1.l21.m1.1a"><mrow id="alg1.l21.m1.1.1" xref="alg1.l21.m1.1.1.cmml"><mo id="alg1.l21.m1.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l21.m1.1.1.1.cmml">âˆ‡</mo><msubsup id="alg1.l21.m1.1.1.2" xref="alg1.l21.m1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l21.m1.1.1.2.2.2" mathsize="90%" xref="alg1.l21.m1.1.1.2.2.2a.cmml">h_cut</mtext><mi id="alg1.l21.m1.1.1.2.3" mathsize="90%" xref="alg1.l21.m1.1.1.2.3.cmml">i</mi><mn id="alg1.l21.m1.1.1.2.2.3" mathsize="90%" xref="alg1.l21.m1.1.1.2.2.3.cmml">0</mn></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l21.m1.1b"><apply id="alg1.l21.m1.1.1.cmml" xref="alg1.l21.m1.1.1"><ci id="alg1.l21.m1.1.1.1.cmml" xref="alg1.l21.m1.1.1.1">âˆ‡</ci><apply id="alg1.l21.m1.1.1.2.cmml" xref="alg1.l21.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l21.m1.1.1.2.1.cmml" xref="alg1.l21.m1.1.1.2">subscript</csymbol><apply id="alg1.l21.m1.1.1.2.2.cmml" xref="alg1.l21.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l21.m1.1.1.2.2.1.cmml" xref="alg1.l21.m1.1.1.2">superscript</csymbol><ci id="alg1.l21.m1.1.1.2.2.2a.cmml" xref="alg1.l21.m1.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l21.m1.1.1.2.2.2.cmml" mathsize="90%" xref="alg1.l21.m1.1.1.2.2.2">h_cut</mtext></ci><cn id="alg1.l21.m1.1.1.2.2.3.cmml" type="integer" xref="alg1.l21.m1.1.1.2.2.3">0</cn></apply><ci id="alg1.l21.m1.1.1.2.3.cmml" xref="alg1.l21.m1.1.1.2.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m1.1c">\nabla\textbf{h\_cut}^{0}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l21.m1.1d">âˆ‡ h_cut start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l21.3" style="font-size:90%;"> of </span><math alttext="{V_{j}}" class="ltx_Math" display="inline" id="alg1.l21.m2.1"><semantics id="alg1.l21.m2.1a"><msub id="alg1.l21.m2.1.1" xref="alg1.l21.m2.1.1.cmml"><mi id="alg1.l21.m2.1.1.2" mathsize="90%" xref="alg1.l21.m2.1.1.2.cmml">V</mi><mi id="alg1.l21.m2.1.1.3" mathsize="90%" xref="alg1.l21.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l21.m2.1b"><apply id="alg1.l21.m2.1.1.cmml" xref="alg1.l21.m2.1.1"><csymbol cd="ambiguous" id="alg1.l21.m2.1.1.1.cmml" xref="alg1.l21.m2.1.1">subscript</csymbol><ci id="alg1.l21.m2.1.1.2.cmml" xref="alg1.l21.m2.1.1.2">ğ‘‰</ci><ci id="alg1.l21.m2.1.1.3.cmml" xref="alg1.l21.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m2.1c">{V_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l21.m2.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l21.m3.1"><semantics id="alg1.l21.m3.1a"><mo id="alg1.l21.m3.1.1" mathsize="90%" stretchy="false" xref="alg1.l21.m3.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l21.m3.1b"><ci id="alg1.l21.m3.1.1.cmml" xref="alg1.l21.m3.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m3.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l21.m3.1d">â†</annotation></semantics></math><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.l21.4" style="font-size:90%;">Split</span><span class="ltx_text" id="alg1.l21.5" style="font-size:90%;">(</span><math alttext="\nabla\textbf{h}^{L}" class="ltx_Math" display="inline" id="alg1.l21.m4.1"><semantics id="alg1.l21.m4.1a"><mrow id="alg1.l21.m4.1.1" xref="alg1.l21.m4.1.1.cmml"><mo id="alg1.l21.m4.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l21.m4.1.1.1.cmml">âˆ‡</mo><msup id="alg1.l21.m4.1.1.2" xref="alg1.l21.m4.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l21.m4.1.1.2.2" mathsize="90%" xref="alg1.l21.m4.1.1.2.2a.cmml">h</mtext><mi id="alg1.l21.m4.1.1.2.3" mathsize="90%" xref="alg1.l21.m4.1.1.2.3.cmml">L</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l21.m4.1b"><apply id="alg1.l21.m4.1.1.cmml" xref="alg1.l21.m4.1.1"><ci id="alg1.l21.m4.1.1.1.cmml" xref="alg1.l21.m4.1.1.1">âˆ‡</ci><apply id="alg1.l21.m4.1.1.2.cmml" xref="alg1.l21.m4.1.1.2"><csymbol cd="ambiguous" id="alg1.l21.m4.1.1.2.1.cmml" xref="alg1.l21.m4.1.1.2">superscript</csymbol><ci id="alg1.l21.m4.1.1.2.2a.cmml" xref="alg1.l21.m4.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l21.m4.1.1.2.2.cmml" mathsize="90%" xref="alg1.l21.m4.1.1.2.2">h</mtext></ci><ci id="alg1.l21.m4.1.1.2.3.cmml" xref="alg1.l21.m4.1.1.2.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m4.1c">\nabla\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="alg1.l21.m4.1d">âˆ‡ h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l21.6" style="font-size:90%;"> of </span><math alttext="{V_{j}}" class="ltx_Math" display="inline" id="alg1.l21.m5.1"><semantics id="alg1.l21.m5.1a"><msub id="alg1.l21.m5.1.1" xref="alg1.l21.m5.1.1.cmml"><mi id="alg1.l21.m5.1.1.2" mathsize="90%" xref="alg1.l21.m5.1.1.2.cmml">V</mi><mi id="alg1.l21.m5.1.1.3" mathsize="90%" xref="alg1.l21.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l21.m5.1b"><apply id="alg1.l21.m5.1.1.cmml" xref="alg1.l21.m5.1.1"><csymbol cd="ambiguous" id="alg1.l21.m5.1.1.1.cmml" xref="alg1.l21.m5.1.1">subscript</csymbol><ci id="alg1.l21.m5.1.1.2.cmml" xref="alg1.l21.m5.1.1.2">ğ‘‰</ci><ci id="alg1.l21.m5.1.1.3.cmml" xref="alg1.l21.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m5.1c">{V_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l21.m5.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l21.7" style="font-size:90%;">)
Â Â Â Â Â Â Â Â Â Â Â Â Â </span>
</div>
<div class="ltx_listingline" id="alg1.l22">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l22.2.1.1" style="font-size:80%;">22:</span></span><span class="ltx_text" id="alg1.l22.3" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math alttext="\nabla\textbf{h\_cut}_{i}^{l}" class="ltx_Math" display="inline" id="alg1.l22.m1.1"><semantics id="alg1.l22.m1.1a"><mrow id="alg1.l22.m1.1.1" xref="alg1.l22.m1.1.1.cmml"><mo id="alg1.l22.m1.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l22.m1.1.1.1.cmml">âˆ‡</mo><msubsup id="alg1.l22.m1.1.1.2" xref="alg1.l22.m1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l22.m1.1.1.2.2.2" mathsize="90%" xref="alg1.l22.m1.1.1.2.2.2a.cmml">h_cut</mtext><mi id="alg1.l22.m1.1.1.2.2.3" mathsize="90%" xref="alg1.l22.m1.1.1.2.2.3.cmml">i</mi><mi id="alg1.l22.m1.1.1.2.3" mathsize="90%" xref="alg1.l22.m1.1.1.2.3.cmml">l</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l22.m1.1b"><apply id="alg1.l22.m1.1.1.cmml" xref="alg1.l22.m1.1.1"><ci id="alg1.l22.m1.1.1.1.cmml" xref="alg1.l22.m1.1.1.1">âˆ‡</ci><apply id="alg1.l22.m1.1.1.2.cmml" xref="alg1.l22.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l22.m1.1.1.2.1.cmml" xref="alg1.l22.m1.1.1.2">superscript</csymbol><apply id="alg1.l22.m1.1.1.2.2.cmml" xref="alg1.l22.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l22.m1.1.1.2.2.1.cmml" xref="alg1.l22.m1.1.1.2">subscript</csymbol><ci id="alg1.l22.m1.1.1.2.2.2a.cmml" xref="alg1.l22.m1.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l22.m1.1.1.2.2.2.cmml" mathsize="90%" xref="alg1.l22.m1.1.1.2.2.2">h_cut</mtext></ci><ci id="alg1.l22.m1.1.1.2.2.3.cmml" xref="alg1.l22.m1.1.1.2.2.3">ğ‘–</ci></apply><ci id="alg1.l22.m1.1.1.2.3.cmml" xref="alg1.l22.m1.1.1.2.3">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m1.1c">\nabla\textbf{h\_cut}_{i}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m1.1d">âˆ‡ h_cut start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l22.4" style="font-size:90%;"> of </span><math alttext="N_{j}" class="ltx_Math" display="inline" id="alg1.l22.m2.1"><semantics id="alg1.l22.m2.1a"><msub id="alg1.l22.m2.1.1" xref="alg1.l22.m2.1.1.cmml"><mi id="alg1.l22.m2.1.1.2" mathsize="90%" xref="alg1.l22.m2.1.1.2.cmml">N</mi><mi id="alg1.l22.m2.1.1.3" mathsize="90%" xref="alg1.l22.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l22.m2.1b"><apply id="alg1.l22.m2.1.1.cmml" xref="alg1.l22.m2.1.1"><csymbol cd="ambiguous" id="alg1.l22.m2.1.1.1.cmml" xref="alg1.l22.m2.1.1">subscript</csymbol><ci id="alg1.l22.m2.1.1.2.cmml" xref="alg1.l22.m2.1.1.2">ğ‘</ci><ci id="alg1.l22.m2.1.1.3.cmml" xref="alg1.l22.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m2.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m2.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l22.5" style="font-size:90%;"> =â€‚</span><span class="ltx_text ltx_font_typewriter" id="alg1.l22.1" style="font-size:90%;">worker(<math alttext="i" class="ltx_Math" display="inline" id="alg1.l22.1.m1.1"><semantics id="alg1.l22.1.m1.1a"><mi id="alg1.l22.1.m1.1.1" xref="alg1.l22.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l22.1.m1.1b"><ci id="alg1.l22.1.m1.1.1.cmml" xref="alg1.l22.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.1.m1.1d">italic_i</annotation></semantics></math>).AGG</span><span class="ltx_text" id="alg1.l22.6" style="font-size:90%;">(</span><math alttext="\nabla\textbf{h\_cut}_{i}^{l+1}" class="ltx_Math" display="inline" id="alg1.l22.m3.1"><semantics id="alg1.l22.m3.1a"><mrow id="alg1.l22.m3.1.1" xref="alg1.l22.m3.1.1.cmml"><mo id="alg1.l22.m3.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l22.m3.1.1.1.cmml">âˆ‡</mo><msubsup id="alg1.l22.m3.1.1.2" xref="alg1.l22.m3.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l22.m3.1.1.2.2.2" mathsize="90%" xref="alg1.l22.m3.1.1.2.2.2a.cmml">h_cut</mtext><mi id="alg1.l22.m3.1.1.2.2.3" mathsize="90%" xref="alg1.l22.m3.1.1.2.2.3.cmml">i</mi><mrow id="alg1.l22.m3.1.1.2.3" xref="alg1.l22.m3.1.1.2.3.cmml"><mi id="alg1.l22.m3.1.1.2.3.2" mathsize="90%" xref="alg1.l22.m3.1.1.2.3.2.cmml">l</mi><mo id="alg1.l22.m3.1.1.2.3.1" mathsize="90%" xref="alg1.l22.m3.1.1.2.3.1.cmml">+</mo><mn id="alg1.l22.m3.1.1.2.3.3" mathsize="90%" xref="alg1.l22.m3.1.1.2.3.3.cmml">1</mn></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l22.m3.1b"><apply id="alg1.l22.m3.1.1.cmml" xref="alg1.l22.m3.1.1"><ci id="alg1.l22.m3.1.1.1.cmml" xref="alg1.l22.m3.1.1.1">âˆ‡</ci><apply id="alg1.l22.m3.1.1.2.cmml" xref="alg1.l22.m3.1.1.2"><csymbol cd="ambiguous" id="alg1.l22.m3.1.1.2.1.cmml" xref="alg1.l22.m3.1.1.2">superscript</csymbol><apply id="alg1.l22.m3.1.1.2.2.cmml" xref="alg1.l22.m3.1.1.2"><csymbol cd="ambiguous" id="alg1.l22.m3.1.1.2.2.1.cmml" xref="alg1.l22.m3.1.1.2">subscript</csymbol><ci id="alg1.l22.m3.1.1.2.2.2a.cmml" xref="alg1.l22.m3.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l22.m3.1.1.2.2.2.cmml" mathsize="90%" xref="alg1.l22.m3.1.1.2.2.2">h_cut</mtext></ci><ci id="alg1.l22.m3.1.1.2.2.3.cmml" xref="alg1.l22.m3.1.1.2.2.3">ğ‘–</ci></apply><apply id="alg1.l22.m3.1.1.2.3.cmml" xref="alg1.l22.m3.1.1.2.3"><plus id="alg1.l22.m3.1.1.2.3.1.cmml" xref="alg1.l22.m3.1.1.2.3.1"></plus><ci id="alg1.l22.m3.1.1.2.3.2.cmml" xref="alg1.l22.m3.1.1.2.3.2">ğ‘™</ci><cn id="alg1.l22.m3.1.1.2.3.3.cmml" type="integer" xref="alg1.l22.m3.1.1.2.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m3.1c">\nabla\textbf{h\_cut}_{i}^{l+1}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m3.1d">âˆ‡ h_cut start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l22.7" style="font-size:90%;"> of </span><math alttext="{V_{j}}" class="ltx_Math" display="inline" id="alg1.l22.m4.1"><semantics id="alg1.l22.m4.1a"><msub id="alg1.l22.m4.1.1" xref="alg1.l22.m4.1.1.cmml"><mi id="alg1.l22.m4.1.1.2" mathsize="90%" xref="alg1.l22.m4.1.1.2.cmml">V</mi><mi id="alg1.l22.m4.1.1.3" mathsize="90%" xref="alg1.l22.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l22.m4.1b"><apply id="alg1.l22.m4.1.1.cmml" xref="alg1.l22.m4.1.1"><csymbol cd="ambiguous" id="alg1.l22.m4.1.1.1.cmml" xref="alg1.l22.m4.1.1">subscript</csymbol><ci id="alg1.l22.m4.1.1.2.cmml" xref="alg1.l22.m4.1.1.2">ğ‘‰</ci><ci id="alg1.l22.m4.1.1.3.cmml" xref="alg1.l22.m4.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m4.1c">{V_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m4.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l22.8" style="font-size:90%;">, </span><math alttext="{G_{j}}" class="ltx_Math" display="inline" id="alg1.l22.m5.1"><semantics id="alg1.l22.m5.1a"><msub id="alg1.l22.m5.1.1" xref="alg1.l22.m5.1.1.cmml"><mi id="alg1.l22.m5.1.1.2" mathsize="90%" xref="alg1.l22.m5.1.1.2.cmml">G</mi><mi id="alg1.l22.m5.1.1.3" mathsize="90%" xref="alg1.l22.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l22.m5.1b"><apply id="alg1.l22.m5.1.1.cmml" xref="alg1.l22.m5.1.1"><csymbol cd="ambiguous" id="alg1.l22.m5.1.1.1.cmml" xref="alg1.l22.m5.1.1">subscript</csymbol><ci id="alg1.l22.m5.1.1.2.cmml" xref="alg1.l22.m5.1.1.2">ğº</ci><ci id="alg1.l22.m5.1.1.3.cmml" xref="alg1.l22.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m5.1c">{G_{j}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l22.m5.1d">italic_G start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l22.9" style="font-size:90%;">)
</span>
</div>
<div class="ltx_listingline" id="alg1.l23">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l23.1.1.1" style="font-size:80%;">23:</span></span><span class="ltx_text" id="alg1.l23.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l23.3" style="font-size:90%;">if</span><span class="ltx_text" id="alg1.l23.4" style="font-size:90%;">Â layer == </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l23.m1.1"><semantics id="alg1.l23.m1.1a"><mn id="alg1.l23.m1.1.1" mathsize="90%" xref="alg1.l23.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l23.m1.1b"><cn id="alg1.l23.m1.1.1.cmml" type="integer" xref="alg1.l23.m1.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l23.5" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l23.6" style="font-size:90%;">then</span><span class="ltx_text" id="alg1.l23.7" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l24">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l24.1.1.1" style="font-size:80%;">24:</span></span><span class="ltx_text" id="alg1.l24.2" style="font-size:90%;">Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span><math alttext="\nabla\textbf{h}^{L}" class="ltx_Math" display="inline" id="alg1.l24.m1.1"><semantics id="alg1.l24.m1.1a"><mrow id="alg1.l24.m1.1.1" xref="alg1.l24.m1.1.1.cmml"><mo id="alg1.l24.m1.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l24.m1.1.1.1.cmml">âˆ‡</mo><msup id="alg1.l24.m1.1.1.2" xref="alg1.l24.m1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l24.m1.1.1.2.2" mathsize="90%" xref="alg1.l24.m1.1.1.2.2a.cmml">h</mtext><mi id="alg1.l24.m1.1.1.2.3" mathsize="90%" xref="alg1.l24.m1.1.1.2.3.cmml">L</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l24.m1.1b"><apply id="alg1.l24.m1.1.1.cmml" xref="alg1.l24.m1.1.1"><ci id="alg1.l24.m1.1.1.1.cmml" xref="alg1.l24.m1.1.1.1">âˆ‡</ci><apply id="alg1.l24.m1.1.1.2.cmml" xref="alg1.l24.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l24.m1.1.1.2.1.cmml" xref="alg1.l24.m1.1.1.2">superscript</csymbol><ci id="alg1.l24.m1.1.1.2.2a.cmml" xref="alg1.l24.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l24.m1.1.1.2.2.cmml" mathsize="90%" xref="alg1.l24.m1.1.1.2.2">h</mtext></ci><ci id="alg1.l24.m1.1.1.2.3.cmml" xref="alg1.l24.m1.1.1.2.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m1.1c">\nabla\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="alg1.l24.m1.1d">âˆ‡ h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l24.3" style="font-size:90%;"> of </span><math alttext="N_{j}" class="ltx_Math" display="inline" id="alg1.l24.m2.1"><semantics id="alg1.l24.m2.1a"><msub id="alg1.l24.m2.1.1" xref="alg1.l24.m2.1.1.cmml"><mi id="alg1.l24.m2.1.1.2" mathsize="90%" xref="alg1.l24.m2.1.1.2.cmml">N</mi><mi id="alg1.l24.m2.1.1.3" mathsize="90%" xref="alg1.l24.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l24.m2.1b"><apply id="alg1.l24.m2.1.1.cmml" xref="alg1.l24.m2.1.1"><csymbol cd="ambiguous" id="alg1.l24.m2.1.1.1.cmml" xref="alg1.l24.m2.1.1">subscript</csymbol><ci id="alg1.l24.m2.1.1.2.cmml" xref="alg1.l24.m2.1.1.2">ğ‘</ci><ci id="alg1.l24.m2.1.1.3.cmml" xref="alg1.l24.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m2.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l24.m2.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><math alttext="\leftarrow" class="ltx_Math" display="inline" id="alg1.l24.m3.1"><semantics id="alg1.l24.m3.1a"><mo id="alg1.l24.m3.1.1" mathsize="90%" stretchy="false" xref="alg1.l24.m3.1.1.cmml">â†</mo><annotation-xml encoding="MathML-Content" id="alg1.l24.m3.1b"><ci id="alg1.l24.m3.1.1.cmml" xref="alg1.l24.m3.1.1">â†</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m3.1c">\leftarrow</annotation><annotation encoding="application/x-llamapun" id="alg1.l24.m3.1d">â†</annotation></semantics></math><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="alg1.l24.4" style="font-size:90%;">Gather</span><span class="ltx_text" id="alg1.l24.5" style="font-size:90%;">(</span><math alttext="\nabla\textbf{h\_cut}^{L}_{i}" class="ltx_Math" display="inline" id="alg1.l24.m4.1"><semantics id="alg1.l24.m4.1a"><mrow id="alg1.l24.m4.1.1" xref="alg1.l24.m4.1.1.cmml"><mo id="alg1.l24.m4.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l24.m4.1.1.1.cmml">âˆ‡</mo><msubsup id="alg1.l24.m4.1.1.2" xref="alg1.l24.m4.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l24.m4.1.1.2.2.2" mathsize="90%" xref="alg1.l24.m4.1.1.2.2.2a.cmml">h_cut</mtext><mi id="alg1.l24.m4.1.1.2.3" mathsize="90%" xref="alg1.l24.m4.1.1.2.3.cmml">i</mi><mi id="alg1.l24.m4.1.1.2.2.3" mathsize="90%" xref="alg1.l24.m4.1.1.2.2.3.cmml">L</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l24.m4.1b"><apply id="alg1.l24.m4.1.1.cmml" xref="alg1.l24.m4.1.1"><ci id="alg1.l24.m4.1.1.1.cmml" xref="alg1.l24.m4.1.1.1">âˆ‡</ci><apply id="alg1.l24.m4.1.1.2.cmml" xref="alg1.l24.m4.1.1.2"><csymbol cd="ambiguous" id="alg1.l24.m4.1.1.2.1.cmml" xref="alg1.l24.m4.1.1.2">subscript</csymbol><apply id="alg1.l24.m4.1.1.2.2.cmml" xref="alg1.l24.m4.1.1.2"><csymbol cd="ambiguous" id="alg1.l24.m4.1.1.2.2.1.cmml" xref="alg1.l24.m4.1.1.2">superscript</csymbol><ci id="alg1.l24.m4.1.1.2.2.2a.cmml" xref="alg1.l24.m4.1.1.2.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l24.m4.1.1.2.2.2.cmml" mathsize="90%" xref="alg1.l24.m4.1.1.2.2.2">h_cut</mtext></ci><ci id="alg1.l24.m4.1.1.2.2.3.cmml" xref="alg1.l24.m4.1.1.2.2.3">ğ¿</ci></apply><ci id="alg1.l24.m4.1.1.2.3.cmml" xref="alg1.l24.m4.1.1.2.3">ğ‘–</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m4.1c">\nabla\textbf{h\_cut}^{L}_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l24.m4.1d">âˆ‡ h_cut start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l24.6" style="font-size:90%;"> of </span><math alttext="N_{j}" class="ltx_Math" display="inline" id="alg1.l24.m5.1"><semantics id="alg1.l24.m5.1a"><msub id="alg1.l24.m5.1.1" xref="alg1.l24.m5.1.1.cmml"><mi id="alg1.l24.m5.1.1.2" mathsize="90%" xref="alg1.l24.m5.1.1.2.cmml">N</mi><mi id="alg1.l24.m5.1.1.3" mathsize="90%" xref="alg1.l24.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l24.m5.1b"><apply id="alg1.l24.m5.1.1.cmml" xref="alg1.l24.m5.1.1"><csymbol cd="ambiguous" id="alg1.l24.m5.1.1.1.cmml" xref="alg1.l24.m5.1.1">subscript</csymbol><ci id="alg1.l24.m5.1.1.2.cmml" xref="alg1.l24.m5.1.1.2">ğ‘</ci><ci id="alg1.l24.m5.1.1.3.cmml" xref="alg1.l24.m5.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m5.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="alg1.l24.m5.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l24.7" style="font-size:90%;">)
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â </span>
</div>
<div class="ltx_listingline" id="alg1.l25">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l25.1.1.1" style="font-size:80%;">25:</span></span><span class="ltx_text" id="alg1.l25.2" style="font-size:90%;">Â Â Â Â </span><span class="ltx_text ltx_font_bold" id="alg1.l25.3" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l25.4" style="font-size:90%;">Â layer </span><math alttext="l" class="ltx_Math" display="inline" id="alg1.l25.m1.1"><semantics id="alg1.l25.m1.1a"><mi id="alg1.l25.m1.1.1" mathsize="90%" xref="alg1.l25.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg1.l25.m1.1b"><ci id="alg1.l25.m1.1.1.cmml" xref="alg1.l25.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l25.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg1.l25.m1.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg1.l25.5" style="font-size:90%;"> = </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l25.m2.1"><semantics id="alg1.l25.m2.1a"><mrow id="alg1.l25.m2.1.1" xref="alg1.l25.m2.1.1.cmml"><mi id="alg1.l25.m2.1.1.2" mathsize="90%" xref="alg1.l25.m2.1.1.2.cmml">L</mi><mo id="alg1.l25.m2.1.1.1" mathsize="90%" xref="alg1.l25.m2.1.1.1.cmml">âˆ’</mo><mn id="alg1.l25.m2.1.1.3" mathsize="90%" xref="alg1.l25.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l25.m2.1b"><apply id="alg1.l25.m2.1.1.cmml" xref="alg1.l25.m2.1.1"><minus id="alg1.l25.m2.1.1.1.cmml" xref="alg1.l25.m2.1.1.1"></minus><ci id="alg1.l25.m2.1.1.2.cmml" xref="alg1.l25.m2.1.1.2">ğ¿</ci><cn id="alg1.l25.m2.1.1.3.cmml" type="integer" xref="alg1.l25.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l25.m2.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l25.m2.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l25.6" style="font-size:90%;"> to </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l25.m3.1"><semantics id="alg1.l25.m3.1a"><mn id="alg1.l25.m3.1.1" mathsize="90%" xref="alg1.l25.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l25.m3.1b"><cn id="alg1.l25.m3.1.1.cmml" type="integer" xref="alg1.l25.m3.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l25.7" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l25.8" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l25.9" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l26">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l26.2.1.1" style="font-size:80%;">26:</span></span><span class="ltx_text" id="alg1.l26.3" style="font-size:90%;">Â Â Â Â Â Â Â Â Â </span><math alttext="\nabla\textbf{h}^{l+1}" class="ltx_Math" display="inline" id="alg1.l26.m1.1"><semantics id="alg1.l26.m1.1a"><mrow id="alg1.l26.m1.1.1" xref="alg1.l26.m1.1.1.cmml"><mo id="alg1.l26.m1.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l26.m1.1.1.1.cmml">âˆ‡</mo><msup id="alg1.l26.m1.1.1.2" xref="alg1.l26.m1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l26.m1.1.1.2.2" mathsize="90%" xref="alg1.l26.m1.1.1.2.2a.cmml">h</mtext><mrow id="alg1.l26.m1.1.1.2.3" xref="alg1.l26.m1.1.1.2.3.cmml"><mi id="alg1.l26.m1.1.1.2.3.2" mathsize="90%" xref="alg1.l26.m1.1.1.2.3.2.cmml">l</mi><mo id="alg1.l26.m1.1.1.2.3.1" mathsize="90%" xref="alg1.l26.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l26.m1.1.1.2.3.3" mathsize="90%" xref="alg1.l26.m1.1.1.2.3.3.cmml">1</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l26.m1.1b"><apply id="alg1.l26.m1.1.1.cmml" xref="alg1.l26.m1.1.1"><ci id="alg1.l26.m1.1.1.1.cmml" xref="alg1.l26.m1.1.1.1">âˆ‡</ci><apply id="alg1.l26.m1.1.1.2.cmml" xref="alg1.l26.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l26.m1.1.1.2.1.cmml" xref="alg1.l26.m1.1.1.2">superscript</csymbol><ci id="alg1.l26.m1.1.1.2.2a.cmml" xref="alg1.l26.m1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l26.m1.1.1.2.2.cmml" mathsize="90%" xref="alg1.l26.m1.1.1.2.2">h</mtext></ci><apply id="alg1.l26.m1.1.1.2.3.cmml" xref="alg1.l26.m1.1.1.2.3"><plus id="alg1.l26.m1.1.1.2.3.1.cmml" xref="alg1.l26.m1.1.1.2.3.1"></plus><ci id="alg1.l26.m1.1.1.2.3.2.cmml" xref="alg1.l26.m1.1.1.2.3.2">ğ‘™</ci><cn id="alg1.l26.m1.1.1.2.3.3.cmml" type="integer" xref="alg1.l26.m1.1.1.2.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.m1.1c">\nabla\textbf{h}^{l+1}</annotation><annotation encoding="application/x-llamapun" id="alg1.l26.m1.1d">âˆ‡ h start_POSTSUPERSCRIPT italic_l + 1 end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l26.4" style="font-size:90%;"> of </span><math alttext="V_{i}" class="ltx_Math" display="inline" id="alg1.l26.m2.1"><semantics id="alg1.l26.m2.1a"><msub id="alg1.l26.m2.1.1" xref="alg1.l26.m2.1.1.cmml"><mi id="alg1.l26.m2.1.1.2" mathsize="90%" xref="alg1.l26.m2.1.1.2.cmml">V</mi><mi id="alg1.l26.m2.1.1.3" mathsize="90%" xref="alg1.l26.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l26.m2.1b"><apply id="alg1.l26.m2.1.1.cmml" xref="alg1.l26.m2.1.1"><csymbol cd="ambiguous" id="alg1.l26.m2.1.1.1.cmml" xref="alg1.l26.m2.1.1">subscript</csymbol><ci id="alg1.l26.m2.1.1.2.cmml" xref="alg1.l26.m2.1.1.2">ğ‘‰</ci><ci id="alg1.l26.m2.1.1.3.cmml" xref="alg1.l26.m2.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.m2.1c">V_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l26.m2.1d">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l26.5" style="font-size:90%;"> =â€‚</span><span class="ltx_text ltx_font_typewriter" id="alg1.l26.1" style="font-size:90%;">worker(<math alttext="i" class="ltx_Math" display="inline" id="alg1.l26.1.m1.1"><semantics id="alg1.l26.1.m1.1a"><mi id="alg1.l26.1.m1.1.1" xref="alg1.l26.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg1.l26.1.m1.1b"><ci id="alg1.l26.1.m1.1.1.cmml" xref="alg1.l26.1.m1.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg1.l26.1.m1.1d">italic_i</annotation></semantics></math>).UPDATE</span><span class="ltx_text" id="alg1.l26.6" style="font-size:90%;">(</span><math alttext="\textbf{W}^{l}" class="ltx_Math" display="inline" id="alg1.l26.m3.1"><semantics id="alg1.l26.m3.1a"><msup id="alg1.l26.m3.1.1" xref="alg1.l26.m3.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l26.m3.1.1.2" mathsize="90%" xref="alg1.l26.m3.1.1.2a.cmml">W</mtext><mi id="alg1.l26.m3.1.1.3" mathsize="90%" xref="alg1.l26.m3.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l26.m3.1b"><apply id="alg1.l26.m3.1.1.cmml" xref="alg1.l26.m3.1.1"><csymbol cd="ambiguous" id="alg1.l26.m3.1.1.1.cmml" xref="alg1.l26.m3.1.1">superscript</csymbol><ci id="alg1.l26.m3.1.1.2a.cmml" xref="alg1.l26.m3.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l26.m3.1.1.2.cmml" mathsize="90%" xref="alg1.l26.m3.1.1.2">W</mtext></ci><ci id="alg1.l26.m3.1.1.3.cmml" xref="alg1.l26.m3.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.m3.1c">\textbf{W}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l26.m3.1d">W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l26.7" style="font-size:90%;">,</span><math alttext="\nabla\textbf{h}^{l}" class="ltx_Math" display="inline" id="alg1.l26.m4.1"><semantics id="alg1.l26.m4.1a"><mrow id="alg1.l26.m4.1.1" xref="alg1.l26.m4.1.1.cmml"><mo id="alg1.l26.m4.1.1.1" mathsize="90%" rspace="0.167em" xref="alg1.l26.m4.1.1.1.cmml">âˆ‡</mo><msup id="alg1.l26.m4.1.1.2" xref="alg1.l26.m4.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l26.m4.1.1.2.2" mathsize="90%" xref="alg1.l26.m4.1.1.2.2a.cmml">h</mtext><mi id="alg1.l26.m4.1.1.2.3" mathsize="90%" xref="alg1.l26.m4.1.1.2.3.cmml">l</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="alg1.l26.m4.1b"><apply id="alg1.l26.m4.1.1.cmml" xref="alg1.l26.m4.1.1"><ci id="alg1.l26.m4.1.1.1.cmml" xref="alg1.l26.m4.1.1.1">âˆ‡</ci><apply id="alg1.l26.m4.1.1.2.cmml" xref="alg1.l26.m4.1.1.2"><csymbol cd="ambiguous" id="alg1.l26.m4.1.1.2.1.cmml" xref="alg1.l26.m4.1.1.2">superscript</csymbol><ci id="alg1.l26.m4.1.1.2.2a.cmml" xref="alg1.l26.m4.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="alg1.l26.m4.1.1.2.2.cmml" mathsize="90%" xref="alg1.l26.m4.1.1.2.2">h</mtext></ci><ci id="alg1.l26.m4.1.1.2.3.cmml" xref="alg1.l26.m4.1.1.2.3">ğ‘™</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.m4.1c">\nabla\textbf{h}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l26.m4.1d">âˆ‡ h start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l26.8" style="font-size:90%;"> of </span><math alttext="V_{i}" class="ltx_Math" display="inline" id="alg1.l26.m5.1"><semantics id="alg1.l26.m5.1a"><msub id="alg1.l26.m5.1.1" xref="alg1.l26.m5.1.1.cmml"><mi id="alg1.l26.m5.1.1.2" mathsize="90%" xref="alg1.l26.m5.1.1.2.cmml">V</mi><mi id="alg1.l26.m5.1.1.3" mathsize="90%" xref="alg1.l26.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l26.m5.1b"><apply id="alg1.l26.m5.1.1.cmml" xref="alg1.l26.m5.1.1"><csymbol cd="ambiguous" id="alg1.l26.m5.1.1.1.cmml" xref="alg1.l26.m5.1.1">subscript</csymbol><ci id="alg1.l26.m5.1.1.2.cmml" xref="alg1.l26.m5.1.1.2">ğ‘‰</ci><ci id="alg1.l26.m5.1.1.3.cmml" xref="alg1.l26.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l26.m5.1c">V_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l26.m5.1d">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l26.9" style="font-size:90%;">)
Â Â Â Â </span>
</div>
<div class="ltx_listingline" id="alg1.l27">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l27.1.1.1" style="font-size:80%;">27:</span></span><span class="ltx_text ltx_font_bold" id="alg1.l27.2" style="font-size:90%;">for</span><span class="ltx_text" id="alg1.l27.3" style="font-size:90%;">Â layer </span><math alttext="l" class="ltx_Math" display="inline" id="alg1.l27.m1.1"><semantics id="alg1.l27.m1.1a"><mi id="alg1.l27.m1.1.1" mathsize="90%" xref="alg1.l27.m1.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="alg1.l27.m1.1b"><ci id="alg1.l27.m1.1.1.cmml" xref="alg1.l27.m1.1.1">ğ‘™</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l27.m1.1c">l</annotation><annotation encoding="application/x-llamapun" id="alg1.l27.m1.1d">italic_l</annotation></semantics></math><span class="ltx_text" id="alg1.l27.4" style="font-size:90%;"> = </span><math alttext="0" class="ltx_Math" display="inline" id="alg1.l27.m2.1"><semantics id="alg1.l27.m2.1a"><mn id="alg1.l27.m2.1.1" mathsize="90%" xref="alg1.l27.m2.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="alg1.l27.m2.1b"><cn id="alg1.l27.m2.1.1.cmml" type="integer" xref="alg1.l27.m2.1.1">0</cn></annotation-xml></semantics></math><span class="ltx_text" id="alg1.l27.5" style="font-size:90%;"> to </span><math alttext="L-1" class="ltx_Math" display="inline" id="alg1.l27.m3.1"><semantics id="alg1.l27.m3.1a"><mrow id="alg1.l27.m3.1.1" xref="alg1.l27.m3.1.1.cmml"><mi id="alg1.l27.m3.1.1.2" mathsize="90%" xref="alg1.l27.m3.1.1.2.cmml">L</mi><mo id="alg1.l27.m3.1.1.1" mathsize="90%" xref="alg1.l27.m3.1.1.1.cmml">âˆ’</mo><mn id="alg1.l27.m3.1.1.3" mathsize="90%" xref="alg1.l27.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l27.m3.1b"><apply id="alg1.l27.m3.1.1.cmml" xref="alg1.l27.m3.1.1"><minus id="alg1.l27.m3.1.1.1.cmml" xref="alg1.l27.m3.1.1.1"></minus><ci id="alg1.l27.m3.1.1.2.cmml" xref="alg1.l27.m3.1.1.2">ğ¿</ci><cn id="alg1.l27.m3.1.1.3.cmml" type="integer" xref="alg1.l27.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l27.m3.1c">L-1</annotation><annotation encoding="application/x-llamapun" id="alg1.l27.m3.1d">italic_L - 1</annotation></semantics></math><span class="ltx_text" id="alg1.l27.6" style="font-size:90%;">Â </span><span class="ltx_text ltx_font_bold" id="alg1.l27.7" style="font-size:90%;">do</span><span class="ltx_text" id="alg1.l27.8" style="font-size:90%;">
</span>
</div>
<div class="ltx_listingline" id="alg1.l28">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l28.1.1.1" style="font-size:80%;">28:</span></span><span class="ltx_text" id="alg1.l28.2" style="font-size:90%;">Â Â Â Â </span><span class="ltx_text ltx_font_typewriter" id="alg1.l28.3" style="font-size:90%;">sync_and_update</span><span class="ltx_text" id="alg1.l28.4" style="font-size:90%;"> (</span><math alttext="\textbf{W}^{l}" class="ltx_Math" display="inline" id="alg1.l28.m1.1"><semantics id="alg1.l28.m1.1a"><msup id="alg1.l28.m1.1.1" xref="alg1.l28.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="alg1.l28.m1.1.1.2" mathsize="90%" xref="alg1.l28.m1.1.1.2a.cmml">W</mtext><mi id="alg1.l28.m1.1.1.3" mathsize="90%" xref="alg1.l28.m1.1.1.3.cmml">l</mi></msup><annotation-xml encoding="MathML-Content" id="alg1.l28.m1.1b"><apply id="alg1.l28.m1.1.1.cmml" xref="alg1.l28.m1.1.1"><csymbol cd="ambiguous" id="alg1.l28.m1.1.1.1.cmml" xref="alg1.l28.m1.1.1">superscript</csymbol><ci id="alg1.l28.m1.1.1.2a.cmml" xref="alg1.l28.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="alg1.l28.m1.1.1.2.cmml" mathsize="90%" xref="alg1.l28.m1.1.1.2">W</mtext></ci><ci id="alg1.l28.m1.1.1.3.cmml" xref="alg1.l28.m1.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l28.m1.1c">\textbf{W}^{l}</annotation><annotation encoding="application/x-llamapun" id="alg1.l28.m1.1d">W start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="alg1.l28.5" style="font-size:90%;">) </span><span class="ltx_text" id="alg1.l28.6" style="font-size:90%;color:#808080;">//parameter update</span><span class="ltx_text" id="alg1.l28.7" style="font-size:90%;">
</span>
</div>
</div>
</figure>
<div class="ltx_para" id="S4.SS2.SSS2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">Based on chunk-based task scheduling, we can further overlap the communication and computation processes of each chunk. Our plan involves overlapping each <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.p1.1.1">split</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.p1.1.2">gather</span> operation with the adjacent graph aggregation operation without disrupting the original layer-wise synchronization. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.F9" title="Figure 9 â€£ 4.1.2. Decoupled GNN Tensor Parallelism â€£ 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">9</span></a> (b), the full graph computation process and two collective communication operations need to be executed serially to ensure layer-wise synchronization. Benefiting from chunk-based task scheduling, we can further partition the two collective communication operations into chunk-level communication tasks to overlap with computation tasks. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.F9" title="Figure 9 â€£ 4.1.2. Decoupled GNN Tensor Parallelism â€£ 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">9</span></a> (c), the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.p1.1.3">split</span> operation pre-splits the embeddings of src vertices for each chunk, while the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.p1.1.4">gather</span> operation collects the embedding slices of dst vertices for each chunk. This chunk-level communication task requires further design to avoid redundant communication. Firstly, for each chunk, we evenly distribute its vertex-related communication tasks across all workers to ensure communication load balancing. However, due to duplicate src vertex sets within chunks, this may result in redundant communication operations for some vertices. Therefore, when assigning communication tasks for each chunk, NeutronTP checks whether the vertices within the current chunk have already been communicated in previous chunks. As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S4.F9" title="Figure 9 â€£ 4.1.2. Decoupled GNN Tensor Parallelism â€£ 4.1. Generalized Decoupled Training Method â€£ 4. The NeutronTP â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">9</span></a> (d), upon detecting that the vertices have been communicated, NeutronTP directly reuses the previous communication results. After traversing each chunk and determining the vertex-related communication tasks assigned to each worker, we aggregate them into a non-redundant vertex set. Each worker executes the relevant communication tasks and NN computation tasks based on its local vertex set.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Overall Execution Flow in NeutronTP</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.15">Algorithm 1 outlines the overall execution flow. To begin with, NeutronTP employs a chunk-based task scheduling strategy to partition the graph topology into a series of chunks <math alttext="G_{j}" class="ltx_Math" display="inline" id="S4.SS3.p1.1.m1.1"><semantics id="S4.SS3.p1.1.m1.1a"><msub id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mi id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">G</mi><mi id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">ğº</ci><ci id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">G_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.1.m1.1d">italic_G start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>, each containing a set of disjoint vertex sets <math alttext="V_{j}" class="ltx_Math" display="inline" id="S4.SS3.p1.2.m2.1"><semantics id="S4.SS3.p1.2.m2.1a"><msub id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mi id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">V</mi><mi id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">ğ‘‰</ci><ci id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">V_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.2.m2.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> and their in-neighbor sets <math alttext="N_{j}" class="ltx_Math" display="inline" id="S4.SS3.p1.3.m3.1"><semantics id="S4.SS3.p1.3.m3.1a"><msub id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mi id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">N</mi><mi id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">ğ‘</ci><ci id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.3.m3.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="j" class="ltx_Math" display="inline" id="S4.SS3.p1.4.m4.1"><semantics id="S4.SS3.p1.4.m4.1a"><mi id="S4.SS3.p1.4.m4.1.1" xref="S4.SS3.p1.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.4.m4.1b"><ci id="S4.SS3.p1.4.m4.1.1.cmml" xref="S4.SS3.p1.4.m4.1.1">ğ‘—</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.4.m4.1c">j</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.4.m4.1d">italic_j</annotation></semantics></math> is the chunk id (line 1).
Subsequently, NeutronTP evenly distributes the vertex-related tasks within each chunk across all workers. After deduplication, each worker obtains its local vertex work queue <math alttext="V_{i}" class="ltx_Math" display="inline" id="S4.SS3.p1.5.m5.1"><semantics id="S4.SS3.p1.5.m5.1a"><msub id="S4.SS3.p1.5.m5.1.1" xref="S4.SS3.p1.5.m5.1.1.cmml"><mi id="S4.SS3.p1.5.m5.1.1.2" xref="S4.SS3.p1.5.m5.1.1.2.cmml">V</mi><mi id="S4.SS3.p1.5.m5.1.1.3" xref="S4.SS3.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.5.m5.1b"><apply id="S4.SS3.p1.5.m5.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.5.m5.1.1.1.cmml" xref="S4.SS3.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS3.p1.5.m5.1.1.2.cmml" xref="S4.SS3.p1.5.m5.1.1.2">ğ‘‰</ci><ci id="S4.SS3.p1.5.m5.1.1.3.cmml" xref="S4.SS3.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.5.m5.1c">V_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.5.m5.1d">italic_V start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, where <math alttext="i" class="ltx_Math" display="inline" id="S4.SS3.p1.6.m6.1"><semantics id="S4.SS3.p1.6.m6.1a"><mi id="S4.SS3.p1.6.m6.1.1" xref="S4.SS3.p1.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.6.m6.1b"><ci id="S4.SS3.p1.6.m6.1.1.cmml" xref="S4.SS3.p1.6.m6.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.6.m6.1d">italic_i</annotation></semantics></math> is the worker id, utilized for subsequent execution of NN computations and communication operations (line 2).
During the forward pass, each worker first completes <math alttext="L" class="ltx_Math" display="inline" id="S4.SS3.p1.7.m7.1"><semantics id="S4.SS3.p1.7.m7.1a"><mi id="S4.SS3.p1.7.m7.1.1" xref="S4.SS3.p1.7.m7.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.7.m7.1b"><ci id="S4.SS3.p1.7.m7.1.1.cmml" xref="S4.SS3.p1.7.m7.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.7.m7.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.7.m7.1d">italic_L</annotation></semantics></math> rounds of NN operations to obtain local vertex embeddings (line 5). Next, all workers schedule chunks in the same order and begin by splitting the embeddings of their in-neighbor sets, i.e., <math alttext="\textbf{h}^{L}" class="ltx_Math" display="inline" id="S4.SS3.p1.8.m8.1"><semantics id="S4.SS3.p1.8.m8.1a"><msup id="S4.SS3.p1.8.m8.1.1" xref="S4.SS3.p1.8.m8.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.8.m8.1.1.2" xref="S4.SS3.p1.8.m8.1.1.2a.cmml">h</mtext><mi id="S4.SS3.p1.8.m8.1.1.3" xref="S4.SS3.p1.8.m8.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.8.m8.1b"><apply id="S4.SS3.p1.8.m8.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.8.m8.1.1.1.cmml" xref="S4.SS3.p1.8.m8.1.1">superscript</csymbol><ci id="S4.SS3.p1.8.m8.1.1.2a.cmml" xref="S4.SS3.p1.8.m8.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.8.m8.1.1.2.cmml" xref="S4.SS3.p1.8.m8.1.1.2">h</mtext></ci><ci id="S4.SS3.p1.8.m8.1.1.3.cmml" xref="S4.SS3.p1.8.m8.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.8.m8.1c">\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.8.m8.1d">h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> of <math alttext="N_{j}" class="ltx_Math" display="inline" id="S4.SS3.p1.9.m9.1"><semantics id="S4.SS3.p1.9.m9.1a"><msub id="S4.SS3.p1.9.m9.1.1" xref="S4.SS3.p1.9.m9.1.1.cmml"><mi id="S4.SS3.p1.9.m9.1.1.2" xref="S4.SS3.p1.9.m9.1.1.2.cmml">N</mi><mi id="S4.SS3.p1.9.m9.1.1.3" xref="S4.SS3.p1.9.m9.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.9.m9.1b"><apply id="S4.SS3.p1.9.m9.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.9.m9.1.1.1.cmml" xref="S4.SS3.p1.9.m9.1.1">subscript</csymbol><ci id="S4.SS3.p1.9.m9.1.1.2.cmml" xref="S4.SS3.p1.9.m9.1.1.2">ğ‘</ci><ci id="S4.SS3.p1.9.m9.1.1.3.cmml" xref="S4.SS3.p1.9.m9.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.9.m9.1c">N_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.9.m9.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> (Line 9).
Upon completion of the splitting phase, each worker initiates graph aggregation operations using its local embedding slices, i.e., <math alttext="\textbf{h\_cut}_{i}^{l}" class="ltx_Math" display="inline" id="S4.SS3.p1.10.m10.1"><semantics id="S4.SS3.p1.10.m10.1a"><msubsup id="S4.SS3.p1.10.m10.1.1" xref="S4.SS3.p1.10.m10.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.10.m10.1.1.2.2" xref="S4.SS3.p1.10.m10.1.1.2.2a.cmml">h_cut</mtext><mi id="S4.SS3.p1.10.m10.1.1.2.3" xref="S4.SS3.p1.10.m10.1.1.2.3.cmml">i</mi><mi id="S4.SS3.p1.10.m10.1.1.3" xref="S4.SS3.p1.10.m10.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.10.m10.1b"><apply id="S4.SS3.p1.10.m10.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.1.cmml" xref="S4.SS3.p1.10.m10.1.1">superscript</csymbol><apply id="S4.SS3.p1.10.m10.1.1.2.cmml" xref="S4.SS3.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.10.m10.1.1.2.1.cmml" xref="S4.SS3.p1.10.m10.1.1">subscript</csymbol><ci id="S4.SS3.p1.10.m10.1.1.2.2a.cmml" xref="S4.SS3.p1.10.m10.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.10.m10.1.1.2.2.cmml" xref="S4.SS3.p1.10.m10.1.1.2.2">h_cut</mtext></ci><ci id="S4.SS3.p1.10.m10.1.1.2.3.cmml" xref="S4.SS3.p1.10.m10.1.1.2.3">ğ‘–</ci></apply><ci id="S4.SS3.p1.10.m10.1.1.3.cmml" xref="S4.SS3.p1.10.m10.1.1.3">ğ‘™</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.10.m10.1c">\textbf{h\_cut}_{i}^{l}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.10.m10.1d">h_cut start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT</annotation></semantics></math> of <math alttext="{N_{j}}" class="ltx_Math" display="inline" id="S4.SS3.p1.11.m11.1"><semantics id="S4.SS3.p1.11.m11.1a"><msub id="S4.SS3.p1.11.m11.1.1" xref="S4.SS3.p1.11.m11.1.1.cmml"><mi id="S4.SS3.p1.11.m11.1.1.2" xref="S4.SS3.p1.11.m11.1.1.2.cmml">N</mi><mi id="S4.SS3.p1.11.m11.1.1.3" xref="S4.SS3.p1.11.m11.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.11.m11.1b"><apply id="S4.SS3.p1.11.m11.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.11.m11.1.1.1.cmml" xref="S4.SS3.p1.11.m11.1.1">subscript</csymbol><ci id="S4.SS3.p1.11.m11.1.1.2.cmml" xref="S4.SS3.p1.11.m11.1.1.2">ğ‘</ci><ci id="S4.SS3.p1.11.m11.1.1.3.cmml" xref="S4.SS3.p1.11.m11.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.11.m11.1c">{N_{j}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.11.m11.1d">italic_N start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> (Line 10).
Following <math alttext="L" class="ltx_Math" display="inline" id="S4.SS3.p1.12.m12.1"><semantics id="S4.SS3.p1.12.m12.1a"><mi id="S4.SS3.p1.12.m12.1.1" xref="S4.SS3.p1.12.m12.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.12.m12.1b"><ci id="S4.SS3.p1.12.m12.1.1.cmml" xref="S4.SS3.p1.12.m12.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.12.m12.1c">L</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.12.m12.1d">italic_L</annotation></semantics></math> rounds of graph aggregation within the chunk, all workers gather the complete embeddings of destination vertices in each chunk, i.e., <math alttext="\textbf{h}^{L}" class="ltx_Math" display="inline" id="S4.SS3.p1.13.m13.1"><semantics id="S4.SS3.p1.13.m13.1a"><msup id="S4.SS3.p1.13.m13.1.1" xref="S4.SS3.p1.13.m13.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.13.m13.1.1.2" xref="S4.SS3.p1.13.m13.1.1.2a.cmml">h</mtext><mi id="S4.SS3.p1.13.m13.1.1.3" xref="S4.SS3.p1.13.m13.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.13.m13.1b"><apply id="S4.SS3.p1.13.m13.1.1.cmml" xref="S4.SS3.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.13.m13.1.1.1.cmml" xref="S4.SS3.p1.13.m13.1.1">superscript</csymbol><ci id="S4.SS3.p1.13.m13.1.1.2a.cmml" xref="S4.SS3.p1.13.m13.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.13.m13.1.1.2.cmml" xref="S4.SS3.p1.13.m13.1.1.2">h</mtext></ci><ci id="S4.SS3.p1.13.m13.1.1.3.cmml" xref="S4.SS3.p1.13.m13.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.13.m13.1c">\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.13.m13.1d">h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> of <math alttext="V_{j}" class="ltx_Math" display="inline" id="S4.SS3.p1.14.m14.1"><semantics id="S4.SS3.p1.14.m14.1a"><msub id="S4.SS3.p1.14.m14.1.1" xref="S4.SS3.p1.14.m14.1.1.cmml"><mi id="S4.SS3.p1.14.m14.1.1.2" xref="S4.SS3.p1.14.m14.1.1.2.cmml">V</mi><mi id="S4.SS3.p1.14.m14.1.1.3" xref="S4.SS3.p1.14.m14.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.14.m14.1b"><apply id="S4.SS3.p1.14.m14.1.1.cmml" xref="S4.SS3.p1.14.m14.1.1"><csymbol cd="ambiguous" id="S4.SS3.p1.14.m14.1.1.1.cmml" xref="S4.SS3.p1.14.m14.1.1">subscript</csymbol><ci id="S4.SS3.p1.14.m14.1.1.2.cmml" xref="S4.SS3.p1.14.m14.1.1.2">ğ‘‰</ci><ci id="S4.SS3.p1.14.m14.1.1.3.cmml" xref="S4.SS3.p1.14.m14.1.1.3">ğ‘—</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.14.m14.1c">V_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.14.m14.1d">italic_V start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> (Line 12).
Upon completion of all chunk computations and communication tasks, each worker initiates downstream tasks and computes gradients <math alttext="\nabla\textbf{h}^{L}" class="ltx_Math" display="inline" id="S4.SS3.p1.15.m15.1"><semantics id="S4.SS3.p1.15.m15.1a"><mrow id="S4.SS3.p1.15.m15.1.1" xref="S4.SS3.p1.15.m15.1.1.cmml"><mo id="S4.SS3.p1.15.m15.1.1.1" rspace="0.167em" xref="S4.SS3.p1.15.m15.1.1.1.cmml">âˆ‡</mo><msup id="S4.SS3.p1.15.m15.1.1.2" xref="S4.SS3.p1.15.m15.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.15.m15.1.1.2.2" xref="S4.SS3.p1.15.m15.1.1.2.2a.cmml">h</mtext><mi id="S4.SS3.p1.15.m15.1.1.2.3" xref="S4.SS3.p1.15.m15.1.1.2.3.cmml">L</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.15.m15.1b"><apply id="S4.SS3.p1.15.m15.1.1.cmml" xref="S4.SS3.p1.15.m15.1.1"><ci id="S4.SS3.p1.15.m15.1.1.1.cmml" xref="S4.SS3.p1.15.m15.1.1.1">âˆ‡</ci><apply id="S4.SS3.p1.15.m15.1.1.2.cmml" xref="S4.SS3.p1.15.m15.1.1.2"><csymbol cd="ambiguous" id="S4.SS3.p1.15.m15.1.1.2.1.cmml" xref="S4.SS3.p1.15.m15.1.1.2">superscript</csymbol><ci id="S4.SS3.p1.15.m15.1.1.2.2a.cmml" xref="S4.SS3.p1.15.m15.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S4.SS3.p1.15.m15.1.1.2.2.cmml" xref="S4.SS3.p1.15.m15.1.1.2.2">h</mtext></ci><ci id="S4.SS3.p1.15.m15.1.1.2.3.cmml" xref="S4.SS3.p1.15.m15.1.1.2.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.15.m15.1c">\nabla\textbf{h}^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.p1.15.m15.1d">âˆ‡ h start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> (lines 13-14).
The backward pass is the reverse process of the forward pass, requiring embedding <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.15.1">split</span> and <span class="ltx_text ltx_font_typewriter" id="S4.SS3.p1.15.2">gather</span> operations before and after the graph aggregation operation, respectively.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Evaluation</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Experimental Setup</h3>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">Environments. </span> Our experiments are conducted on the Aliyun ECS cluster with 16 GPU nodes. Each node (ecs.gn6i-c16g1.4xlarge instance) is equipped with 16 vCPUs, 186GB DRAM, and 1 NVIDIA Tesla T4 GPU, running Ubuntu 18.04 LTS OS. The network bandwidth is 15 Gbps/s. Libraries CUDA 11.1, OpenMPI-3.0.2, PyTorch v1.5 backend, and cuDNN 7.0 are used in both clusters.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">Datasets and GNN algorithms. </span>
Table <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.T1" title="Table 1 â€£ 5.1. Experimental Setup â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">1</span></a> lists six graph datasets that we used in our evaluation, including three popular GNN datasets: Reddit <cite class="ltx_cite ltx_citemacro_citep">(Hamilton etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib13" title="">2017</a>)</cite>, Ogbn-products <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib16" title="">2020</a>)</cite>, and Ogbn-paper <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib16" title="">2020</a>)</cite>, and one graph dataset Friendster <cite class="ltx_cite ltx_citemacro_citep">(Leskovec and Sosic, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib21" title="">2016</a>)</cite>. Ogbn-mag <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib16" title="">2020</a>)</cite> and Mag-lsc <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib15" title="">2021</a>)</cite> are two heterogeneous graphs that we use to evaluate the heterogeneous GNN training. For graphs without ground-truth properties (Friendster), we use randomly generated features, labels, training (65%), test (10%), and validation (25%) set division.
We use two popular GNN models with different computation patterns, GCN <cite class="ltx_cite ltx_citemacro_citep">(Kipf and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib19" title="">2017</a>)</cite> and GAT <cite class="ltx_cite ltx_citemacro_citep">(Velickovic etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib38" title="">2018</a>)</cite>. All of them are in a 2-layer structure. The vertex feature dimensions, hidden layer dimensions, and the number of labels of datasets are listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.T1" title="Table 1 â€£ 5.1. Experimental Setup â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">Competitor systems. </span>
In our performance evaluation, we compare NeutronTP with two kinds of GNN training systems, i.e., mini-batch system and full-graph system.
For the mini-batch system, we compare NeutronTP with DistDGL <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>, a representative deep learning library for graphs. DistDGL relies on data sampling to reduce computation cost <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>, which is set to execute a (25, 10) neighborhood sampling for the training. In such a configuration, DistDGL picks a maximum of 10 neighbors for the first hop of a vertex, and then a maximum of 25 neighbors for each of those 10.
For the full-graph system, we compare NeutronTP with NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite> and Sancus <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>)</cite>. Neutronstar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite> designs hybrid vertex dependency management for a more balanced use of communication and computational resources. Sancus <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>)</cite> reuses historical embedding for cross-worker vertices to reduce communication.</p>
</div>
<figure class="ltx_table" id="S5.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span>Dataset description.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S5.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.2.1" style="font-size:80%;">Dataset</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.3.1" style="font-size:80%;">â€”Vâ€”</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.4.1" style="font-size:80%;">â€”Eâ€”</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.5.1" style="font-size:80%;">ftr. dim</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.1.1" style="font-size:80%;">#<math alttext="\mathbb{L}" class="ltx_Math" display="inline" id="S5.T1.1.1.1.1.m1.1"><semantics id="S5.T1.1.1.1.1.m1.1a"><mi id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml">ğ•ƒ</mi><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><ci id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">ğ•ƒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">\mathbb{L}</annotation><annotation encoding="application/x-llamapun" id="S5.T1.1.1.1.1.m1.1d">blackboard_L</annotation></semantics></math></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T1.1.1.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S5.T1.1.1.6.1" style="font-size:80%;">hid. dim</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T1.1.2.1.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.2.1.1.1" style="font-size:80%;">Reddit (RDT)</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.2.1.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.2.1.2.1" style="font-size:80%;">0.23M</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S5.T1.1.2.1.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.2.1.3.1" style="font-size:80%;">114M</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.2.1.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.2.1.4.1" style="font-size:80%;">602</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.2.1.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.2.1.5.1" style="font-size:80%;">41</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.1.2.1.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.2.1.6.1" style="font-size:80%;">256</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.3.2">
<td class="ltx_td ltx_align_left" id="S5.T1.1.3.2.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.3.2.1.1" style="font-size:80%;">Ogbn-products (OPT)</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.3.2.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.3.2.2.1" style="font-size:80%;">2.45M</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.3.2.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.3.2.3.1" style="font-size:80%;">61.68M</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.3.2.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.3.2.4.1" style="font-size:80%;">100</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.3.2.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.3.2.5.1" style="font-size:80%;">47</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.3.2.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.3.2.6.1" style="font-size:80%;">64</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.4.3">
<td class="ltx_td ltx_align_left" id="S5.T1.1.4.3.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.4.3.1.1" style="font-size:80%;">Ogbn-paper (OPR)</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.4.3.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.4.3.2.1" style="font-size:80%;">111.1M</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.4.3.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.4.3.3.1" style="font-size:80%;">1.616B</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.3.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.4.3.4.1" style="font-size:80%;">128</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.3.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.4.3.5.1" style="font-size:80%;">172</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.4.3.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.4.3.6.1" style="font-size:80%;">128</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.5.4">
<td class="ltx_td ltx_align_left" id="S5.T1.1.5.4.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.5.4.1.1" style="font-size:80%;">Friendster (FS)</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.5.4.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.5.4.2.1" style="font-size:80%;">65.6M</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.5.4.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.5.4.3.1" style="font-size:80%;">2.5B</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.5.4.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.5.4.4.1" style="font-size:80%;">256</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.5.4.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.5.4.5.1" style="font-size:80%;">64</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.5.4.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.5.4.6.1" style="font-size:80%;">128</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.6.5">
<td class="ltx_td ltx_align_left" id="S5.T1.1.6.5.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.6.5.1.1" style="font-size:80%;color:#000000;">Ogbn-mag (MAG)</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.6.5.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.6.5.2.1" style="font-size:80%;color:#000000;">1.9M</span></td>
<td class="ltx_td ltx_align_right" id="S5.T1.1.6.5.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.6.5.3.1" style="font-size:80%;color:#000000;">21M</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.6.5.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.6.5.4.1" style="font-size:80%;color:#000000;">128</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.6.5.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.6.5.5.1" style="font-size:80%;color:#000000;">349</span></td>
<td class="ltx_td ltx_align_center" id="S5.T1.1.6.5.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.6.5.6.1" style="font-size:80%;color:#000000;">64</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T1.1.7.6.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.7.6.1.1" style="font-size:80%;color:#000000;">Mag-lsc (LSC)</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T1.1.7.6.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.7.6.2.1" style="font-size:80%;color:#000000;">244.2M</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T1.1.7.6.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.7.6.3.1" style="font-size:80%;color:#000000;">1.7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.7.6.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.7.6.4.1" style="font-size:80%;color:#000000;">768</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.7.6.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.7.6.5.1" style="font-size:80%;color:#000000;">153</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.1.7.6.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S5.T1.1.7.6.6.1" style="font-size:80%;color:#000000;">256</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Overall Comparison</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We conduct a comprehensive performance comparison with NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite>, DistDGL <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>, and Sancus <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>)</cite> on a 16-node cluster. We record the computation time, communication time, and the per epoch runtime.
â€maxâ€ indicates the longest computation and communication time among all workers, which typically determines the actual runtime of distributed training. Similarly, â€minâ€ indicates the shortest computation time and communication time among all workers. For systems employing pipelining techniques to overlap computation and communication (i.e., NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite> and NeutronTP), the sum of the longest computation and communication time exceeds the total runtime. By meticulously logging these times, we gain insights into the workload of distributed training. The experimental results are summarized in Table <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.T2" title="Table 2 â€£ 5.2. Overall Comparison â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.3"><span class="ltx_text ltx_font_bold" id="S5.SS2.p2.3.1">Comparison with mini-batch system. </span>
Compared to DistDGL <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>, NeutronTP exhibits superior performance across most datasets, achieving up to 6.23<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mo id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><times id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">Ã—</annotation></semantics></math> speedup.
The METIS partitioning used by DistDGL may result in certain workers having more vertices, leading to more frequent access by other workers. As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.T2" title="Table 2 â€£ 5.2. Overall Comparison â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">2</span></a>, DistDGL exhibits an imbalance in both computation and communication times among different workers, with disparities reaching up to 1.38<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mo id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><times id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">Ã—</annotation></semantics></math> and 2.2<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mo id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><times id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">Ã—</annotation></semantics></math>, respectively, thereby causing resource wastage in the less loaded workers. NeutronTP mitigates these issues by adopting tensor parallelism, achieving more balanced workloads while avoiding redundant computations and communications. On the Ogbn-paper dataset, DistDGL demonstrates a better performance as it trains only on 1.1% of the total vertices, resulting in reduced computational load compared to NeutronTP.</p>
</div>
<figure class="ltx_table" id="S5.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Comparison with different systems a 16-node ECS cluster. â€maxâ€ and â€minâ€ indicate the longest and shortest computation or communication times among workers, respectively. â€totalâ€ indicates the per-epoch runtime. </figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.1" style="width:433.6pt;height:954.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(73.7pt,-162.3pt) scale(1.51509126918054,1.51509126918054) ;">
<table class="ltx_tabular ltx_align_middle" id="S5.T2.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.1.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.1" rowspan="3"><span class="ltx_text" id="S5.T2.1.1.1.1.1.1" style="font-size:80%;">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.2" rowspan="3"><span class="ltx_text" id="S5.T2.1.1.1.1.2.1" style="font-size:80%;">Dataset</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.1.1.3" rowspan="3"><span class="ltx_text" id="S5.T2.1.1.1.1.3.1" style="font-size:80%;">System</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S5.T2.1.1.1.1.4"><span class="ltx_text" id="S5.T2.1.1.1.1.4.1" style="font-size:80%;">Runtime (s)</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.1.1.2.2.1"><span class="ltx_text" id="S5.T2.1.1.2.2.1.1" style="font-size:80%;">Computation</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S5.T2.1.1.2.2.2"><span class="ltx_text" id="S5.T2.1.1.2.2.2.1" style="font-size:80%;">Communication</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.2.2.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.2.2.3.1" style="font-size:80%;">total</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.3.1"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.3.1.1" style="font-size:80%;">max</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.3.2"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.3.2.1" style="font-size:80%;">min</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.3.3"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.3.3.1" style="font-size:80%;">max</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.3.3.4"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.3.3.4.1" style="font-size:80%;">min</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.4.4.1" rowspan="16"><span class="ltx_text" id="S5.T2.1.1.4.4.1.1" style="font-size:80%;">GCN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.4.4.2" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.4.4.2.1" style="font-size:80%;">RDT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.4.4.3"><span class="ltx_text" id="S5.T2.1.1.4.4.3.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.4.4.4"><span class="ltx_text" id="S5.T2.1.1.4.4.4.1" style="font-size:80%;">0.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.4.4.5"><span class="ltx_text" id="S5.T2.1.1.4.4.5.1" style="font-size:80%;">0.11</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.4.4.6"><span class="ltx_text" id="S5.T2.1.1.4.4.6.1" style="font-size:80%;">2.12</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.4.4.7"><span class="ltx_text" id="S5.T2.1.1.4.4.7.1" style="font-size:80%;">1.38</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.4.4.8"><span class="ltx_text" id="S5.T2.1.1.4.4.8.1" style="font-size:80%;">2.27</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.5.5.1"><span class="ltx_text" id="S5.T2.1.1.5.5.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.5.2"><span class="ltx_text" id="S5.T2.1.1.5.5.2.1" style="font-size:80%;">0.86</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.5.3"><span class="ltx_text" id="S5.T2.1.1.5.5.3.1" style="font-size:80%;">0.77</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.5.4"><span class="ltx_text" id="S5.T2.1.1.5.5.4.1" style="font-size:80%;">1.17</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.5.5.5"><span class="ltx_text" id="S5.T2.1.1.5.5.5.1" style="font-size:80%;">0.87</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.5.5.6"><span class="ltx_text" id="S5.T2.1.1.5.5.6.1" style="font-size:80%;">1.92</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.6.6.1"><span class="ltx_text" id="S5.T2.1.1.6.6.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.6.2"><span class="ltx_text" id="S5.T2.1.1.6.6.2.1" style="font-size:80%;">0.35</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.6.3"><span class="ltx_text" id="S5.T2.1.1.6.6.3.1" style="font-size:80%;">0.31</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.6.4"><span class="ltx_text" id="S5.T2.1.1.6.6.4.1" style="font-size:80%;">0.82</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.6.6.5"><span class="ltx_text" id="S5.T2.1.1.6.6.5.1" style="font-size:80%;">0.71</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.6.6.6"><span class="ltx_text" id="S5.T2.1.1.6.6.6.1" style="font-size:80%;">1.17</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.7.7">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.7.7.1"><span class="ltx_text" id="S5.T2.1.1.7.7.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.7.7.2"><span class="ltx_text" id="S5.T2.1.1.7.7.2.1" style="font-size:80%;">0.39</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.7.7.3"><span class="ltx_text" id="S5.T2.1.1.7.7.3.1" style="font-size:80%;">0.38</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.7.7.4"><span class="ltx_text" id="S5.T2.1.1.7.7.4.1" style="font-size:80%;">0.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.7.7.5"><span class="ltx_text" id="S5.T2.1.1.7.7.5.1" style="font-size:80%;">0.18</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.7.7.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.7.7.6.1" style="font-size:80%;">0.40</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.8.8">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.8.8.1" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.8.8.1.1" style="font-size:80%;">OPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.8.8.2"><span class="ltx_text" id="S5.T2.1.1.8.8.2.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.8.8.3"><span class="ltx_text" id="S5.T2.1.1.8.8.3.1" style="font-size:80%;">0.26</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.8.8.4"><span class="ltx_text" id="S5.T2.1.1.8.8.4.1" style="font-size:80%;">0.16</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.8.8.5"><span class="ltx_text" id="S5.T2.1.1.8.8.5.1" style="font-size:80%;">2.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.8.8.6"><span class="ltx_text" id="S5.T2.1.1.8.8.6.1" style="font-size:80%;">1.28</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.8.8.7"><span class="ltx_text" id="S5.T2.1.1.8.8.7.1" style="font-size:80%;">3.18</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.9.9.1"><span class="ltx_text" id="S5.T2.1.1.9.9.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.9.2"><span class="ltx_text" id="S5.T2.1.1.9.9.2.1" style="font-size:80%;">2.71</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.9.3"><span class="ltx_text" id="S5.T2.1.1.9.9.3.1" style="font-size:80%;">1.42</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.9.4"><span class="ltx_text" id="S5.T2.1.1.9.9.4.1" style="font-size:80%;">2.89</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.9.9.5"><span class="ltx_text" id="S5.T2.1.1.9.9.5.1" style="font-size:80%;">1.78</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.9.9.6"><span class="ltx_text" id="S5.T2.1.1.9.9.6.1" style="font-size:80%;">4.45</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.10.10">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.10.10.1"><span class="ltx_text" id="S5.T2.1.1.10.10.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.10.2"><span class="ltx_text" id="S5.T2.1.1.10.10.2.1" style="font-size:80%;">0.86</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.10.3"><span class="ltx_text" id="S5.T2.1.1.10.10.3.1" style="font-size:80%;">0.36</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.10.4"><span class="ltx_text" id="S5.T2.1.1.10.10.4.1" style="font-size:80%;">1.59</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.10.10.5"><span class="ltx_text" id="S5.T2.1.1.10.10.5.1" style="font-size:80%;">1.22</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.10.10.6"><span class="ltx_text" id="S5.T2.1.1.10.10.6.1" style="font-size:80%;">2.45</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.11.11">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.11.11.1"><span class="ltx_text" id="S5.T2.1.1.11.11.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.11.11.2"><span class="ltx_text" id="S5.T2.1.1.11.11.2.1" style="font-size:80%;">0.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.11.11.3"><span class="ltx_text" id="S5.T2.1.1.11.11.3.1" style="font-size:80%;">0.44</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.11.11.4"><span class="ltx_text" id="S5.T2.1.1.11.11.4.1" style="font-size:80%;">0.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.11.11.5"><span class="ltx_text" id="S5.T2.1.1.11.11.5.1" style="font-size:80%;">0.22</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.11.11.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.11.11.6.1" style="font-size:80%;">0.50</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.12.12">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.12.12.1" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.12.12.1.1" style="font-size:80%;">OPR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.12.12.2"><span class="ltx_text" id="S5.T2.1.1.12.12.2.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.12.12.3"><span class="ltx_text" id="S5.T2.1.1.12.12.3.1" style="font-size:80%;">5.35</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.12.12.4"><span class="ltx_text" id="S5.T2.1.1.12.12.4.1" style="font-size:80%;">4.19</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.12.12.5"><span class="ltx_text" id="S5.T2.1.1.12.12.5.1" style="font-size:80%;">20.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.12.12.6"><span class="ltx_text" id="S5.T2.1.1.12.12.6.1" style="font-size:80%;">11.21</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.12.12.7"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.12.12.7.1" style="font-size:80%;">25.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.13.13">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.13.13.1"><span class="ltx_text" id="S5.T2.1.1.13.13.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.13.13.2"><span class="ltx_text" id="S5.T2.1.1.13.13.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.13.13.3"><span class="ltx_text" id="S5.T2.1.1.13.13.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.13.13.4"><span class="ltx_text" id="S5.T2.1.1.13.13.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.13.13.5"><span class="ltx_text" id="S5.T2.1.1.13.13.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.13.13.6"><span class="ltx_text" id="S5.T2.1.1.13.13.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.14.14">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.14.14.1"><span class="ltx_text" id="S5.T2.1.1.14.14.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.14.14.2"><span class="ltx_text" id="S5.T2.1.1.14.14.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.14.14.3"><span class="ltx_text" id="S5.T2.1.1.14.14.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.14.14.4"><span class="ltx_text" id="S5.T2.1.1.14.14.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.14.14.5"><span class="ltx_text" id="S5.T2.1.1.14.14.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.14.14.6"><span class="ltx_text" id="S5.T2.1.1.14.14.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.15.15">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.15.15.1"><span class="ltx_text" id="S5.T2.1.1.15.15.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.15.15.2"><span class="ltx_text" id="S5.T2.1.1.15.15.2.1" style="font-size:80%;">95.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.15.15.3"><span class="ltx_text" id="S5.T2.1.1.15.15.3.1" style="font-size:80%;">95.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.15.15.4"><span class="ltx_text" id="S5.T2.1.1.15.15.4.1" style="font-size:80%;">53.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.15.15.5"><span class="ltx_text" id="S5.T2.1.1.15.15.5.1" style="font-size:80%;">49.4</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.15.15.6"><span class="ltx_text" id="S5.T2.1.1.15.15.6.1" style="font-size:80%;">134.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.16.16">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.16.16.1" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.16.16.1.1" style="font-size:80%;">FS</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.16.16.2"><span class="ltx_text" id="S5.T2.1.1.16.16.2.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.16.16.3"><span class="ltx_text" id="S5.T2.1.1.16.16.3.1" style="font-size:80%;">136.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.16.16.4"><span class="ltx_text" id="S5.T2.1.1.16.16.4.1" style="font-size:80%;">118.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.16.16.5"><span class="ltx_text" id="S5.T2.1.1.16.16.5.1" style="font-size:80%;">323.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.16.16.6"><span class="ltx_text" id="S5.T2.1.1.16.16.6.1" style="font-size:80%;">197.5</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.16.16.7"><span class="ltx_text" id="S5.T2.1.1.16.16.7.1" style="font-size:80%;">459.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.17.17">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.17.17.1"><span class="ltx_text" id="S5.T2.1.1.17.17.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.17.17.2"><span class="ltx_text" id="S5.T2.1.1.17.17.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.17.17.3"><span class="ltx_text" id="S5.T2.1.1.17.17.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.17.17.4"><span class="ltx_text" id="S5.T2.1.1.17.17.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.17.17.5"><span class="ltx_text" id="S5.T2.1.1.17.17.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.17.17.6"><span class="ltx_text" id="S5.T2.1.1.17.17.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.18.18">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.18.18.1"><span class="ltx_text" id="S5.T2.1.1.18.18.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.18.18.2"><span class="ltx_text" id="S5.T2.1.1.18.18.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.18.18.3"><span class="ltx_text" id="S5.T2.1.1.18.18.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.18.18.4"><span class="ltx_text" id="S5.T2.1.1.18.18.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.18.18.5"><span class="ltx_text" id="S5.T2.1.1.18.18.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.18.18.6"><span class="ltx_text" id="S5.T2.1.1.18.18.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.19.19">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.19.19.1"><span class="ltx_text" id="S5.T2.1.1.19.19.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.19.19.2"><span class="ltx_text" id="S5.T2.1.1.19.19.2.1" style="font-size:80%;">74.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.19.19.3"><span class="ltx_text" id="S5.T2.1.1.19.19.3.1" style="font-size:80%;">73.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.19.19.4"><span class="ltx_text" id="S5.T2.1.1.19.19.4.1" style="font-size:80%;">32.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.19.19.5"><span class="ltx_text" id="S5.T2.1.1.19.19.5.1" style="font-size:80%;">29.4</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.19.19.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.19.19.6.1" style="font-size:80%;">90.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.20.20">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S5.T2.1.1.20.20.1" rowspan="16"><span class="ltx_text" id="S5.T2.1.1.20.20.1.1" style="font-size:80%;">GAT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.20.20.2" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.20.20.2.1" style="font-size:80%;">RDT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.20.20.3"><span class="ltx_text" id="S5.T2.1.1.20.20.3.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.20.20.4"><span class="ltx_text" id="S5.T2.1.1.20.20.4.1" style="font-size:80%;">0.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.20.20.5"><span class="ltx_text" id="S5.T2.1.1.20.20.5.1" style="font-size:80%;">0.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.20.20.6"><span class="ltx_text" id="S5.T2.1.1.20.20.6.1" style="font-size:80%;">2.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.20.20.7"><span class="ltx_text" id="S5.T2.1.1.20.20.7.1" style="font-size:80%;">1.49</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.20.20.8"><span class="ltx_text" id="S5.T2.1.1.20.20.8.1" style="font-size:80%;">2.92</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.21.21">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.21.21.1"><span class="ltx_text" id="S5.T2.1.1.21.21.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.21.21.2"><span class="ltx_text" id="S5.T2.1.1.21.21.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.21.21.3"><span class="ltx_text" id="S5.T2.1.1.21.21.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.21.21.4"><span class="ltx_text" id="S5.T2.1.1.21.21.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.21.21.5"><span class="ltx_text" id="S5.T2.1.1.21.21.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.21.21.6"><span class="ltx_text" id="S5.T2.1.1.21.21.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.22.22">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.22.22.1"><span class="ltx_text" id="S5.T2.1.1.22.22.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.22.22.2"><span class="ltx_text" id="S5.T2.1.1.22.22.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.22.22.3"><span class="ltx_text" id="S5.T2.1.1.22.22.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.22.22.4"><span class="ltx_text" id="S5.T2.1.1.22.22.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.22.22.5"><span class="ltx_text" id="S5.T2.1.1.22.22.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.22.22.6"><span class="ltx_text" id="S5.T2.1.1.22.22.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.23.23">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.23.23.1"><span class="ltx_text" id="S5.T2.1.1.23.23.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.23.23.2"><span class="ltx_text" id="S5.T2.1.1.23.23.2.1" style="font-size:80%;">0.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.23.23.3"><span class="ltx_text" id="S5.T2.1.1.23.23.3.1" style="font-size:80%;">0.88</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.23.23.4"><span class="ltx_text" id="S5.T2.1.1.23.23.4.1" style="font-size:80%;">0.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.23.23.5"><span class="ltx_text" id="S5.T2.1.1.23.23.5.1" style="font-size:80%;">0.42</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.23.23.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.23.23.6.1" style="font-size:80%;">1.29</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.24.24">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.24.24.1" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.24.24.1.1" style="font-size:80%;">OPT</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.24.24.2"><span class="ltx_text" id="S5.T2.1.1.24.24.2.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.24.24.3"><span class="ltx_text" id="S5.T2.1.1.24.24.3.1" style="font-size:80%;">1.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.24.24.4"><span class="ltx_text" id="S5.T2.1.1.24.24.4.1" style="font-size:80%;">0.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.24.24.5"><span class="ltx_text" id="S5.T2.1.1.24.24.5.1" style="font-size:80%;">2.76</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.24.24.6"><span class="ltx_text" id="S5.T2.1.1.24.24.6.1" style="font-size:80%;">1.29</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.24.24.7"><span class="ltx_text" id="S5.T2.1.1.24.24.7.1" style="font-size:80%;">3.93</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.25.25">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.25.25.1"><span class="ltx_text" id="S5.T2.1.1.25.25.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.25.25.2"><span class="ltx_text" id="S5.T2.1.1.25.25.2.1" style="font-size:80%;">8.72</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.25.25.3"><span class="ltx_text" id="S5.T2.1.1.25.25.3.1" style="font-size:80%;">5.98</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.25.25.4"><span class="ltx_text" id="S5.T2.1.1.25.25.4.1" style="font-size:80%;">15.9</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.25.25.5"><span class="ltx_text" id="S5.T2.1.1.25.25.5.1" style="font-size:80%;">8.29</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.25.25.6"><span class="ltx_text" id="S5.T2.1.1.25.25.6.1" style="font-size:80%;">22.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.26.26">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.26.26.1"><span class="ltx_text" id="S5.T2.1.1.26.26.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.26.26.2"><span class="ltx_text" id="S5.T2.1.1.26.26.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.26.26.3"><span class="ltx_text" id="S5.T2.1.1.26.26.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.26.26.4"><span class="ltx_text" id="S5.T2.1.1.26.26.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.26.26.5"><span class="ltx_text" id="S5.T2.1.1.26.26.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.26.26.6"><span class="ltx_text" id="S5.T2.1.1.26.26.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.27.27">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.27.27.1"><span class="ltx_text" id="S5.T2.1.1.27.27.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.27.27.2"><span class="ltx_text" id="S5.T2.1.1.27.27.2.1" style="font-size:80%;">2.17</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.27.27.3"><span class="ltx_text" id="S5.T2.1.1.27.27.3.1" style="font-size:80%;">1.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.27.27.4"><span class="ltx_text" id="S5.T2.1.1.27.27.4.1" style="font-size:80%;">1.06</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.27.27.5"><span class="ltx_text" id="S5.T2.1.1.27.27.5.1" style="font-size:80%;">0.95</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.27.27.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.27.27.6.1" style="font-size:80%;">3.03</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.28.28">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.28.28.1" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.28.28.1.1" style="font-size:80%;">OPR</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.28.28.2"><span class="ltx_text" id="S5.T2.1.1.28.28.2.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.28.28.3"><span class="ltx_text" id="S5.T2.1.1.28.28.3.1" style="font-size:80%;">8.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.28.28.4"><span class="ltx_text" id="S5.T2.1.1.28.28.4.1" style="font-size:80%;">6.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.28.28.5"><span class="ltx_text" id="S5.T2.1.1.28.28.5.1" style="font-size:80%;">21.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.28.28.6"><span class="ltx_text" id="S5.T2.1.1.28.28.6.1" style="font-size:80%;">11.7</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.28.28.7"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.28.28.7.1" style="font-size:80%;">29.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.29.29">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.29.29.1"><span class="ltx_text" id="S5.T2.1.1.29.29.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.29.29.2"><span class="ltx_text" id="S5.T2.1.1.29.29.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.29.29.3"><span class="ltx_text" id="S5.T2.1.1.29.29.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.29.29.4"><span class="ltx_text" id="S5.T2.1.1.29.29.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.29.29.5"><span class="ltx_text" id="S5.T2.1.1.29.29.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.29.29.6"><span class="ltx_text" id="S5.T2.1.1.29.29.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.30.30">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.30.30.1"><span class="ltx_text" id="S5.T2.1.1.30.30.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.30.30.2"><span class="ltx_text" id="S5.T2.1.1.30.30.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.30.30.3"><span class="ltx_text" id="S5.T2.1.1.30.30.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.30.30.4"><span class="ltx_text" id="S5.T2.1.1.30.30.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.30.30.5"><span class="ltx_text" id="S5.T2.1.1.30.30.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.30.30.6"><span class="ltx_text" id="S5.T2.1.1.30.30.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.31.31">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S5.T2.1.1.31.31.1"><span class="ltx_text" id="S5.T2.1.1.31.31.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.31.31.2"><span class="ltx_text" id="S5.T2.1.1.31.31.2.1" style="font-size:80%;">154.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.31.31.3"><span class="ltx_text" id="S5.T2.1.1.31.31.3.1" style="font-size:80%;">136.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.31.31.4"><span class="ltx_text" id="S5.T2.1.1.31.31.4.1" style="font-size:80%;">98.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.1.1.31.31.5"><span class="ltx_text" id="S5.T2.1.1.31.31.5.1" style="font-size:80%;">84.7</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T2.1.1.31.31.6"><span class="ltx_text" id="S5.T2.1.1.31.31.6.1" style="font-size:80%;">235.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.32.32">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt" id="S5.T2.1.1.32.32.1" rowspan="4"><span class="ltx_text" id="S5.T2.1.1.32.32.1.1" style="font-size:80%;">FS</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S5.T2.1.1.32.32.2"><span class="ltx_text" id="S5.T2.1.1.32.32.2.1" style="font-size:80%;">DistDGL</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.32.32.3"><span class="ltx_text" id="S5.T2.1.1.32.32.3.1" style="font-size:80%;">157.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.32.32.4"><span class="ltx_text" id="S5.T2.1.1.32.32.4.1" style="font-size:80%;">110.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.32.32.5"><span class="ltx_text" id="S5.T2.1.1.32.32.5.1" style="font-size:80%;">419.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.1.1.32.32.6"><span class="ltx_text" id="S5.T2.1.1.32.32.6.1" style="font-size:80%;">283.7</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T2.1.1.32.32.7"><span class="ltx_text" id="S5.T2.1.1.32.32.7.1" style="font-size:80%;">577.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.33.33">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.33.33.1"><span class="ltx_text" id="S5.T2.1.1.33.33.1.1" style="font-size:80%;">NeutronStar</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.33.33.2"><span class="ltx_text" id="S5.T2.1.1.33.33.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.33.33.3"><span class="ltx_text" id="S5.T2.1.1.33.33.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.33.33.4"><span class="ltx_text" id="S5.T2.1.1.33.33.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.33.33.5"><span class="ltx_text" id="S5.T2.1.1.33.33.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.33.33.6"><span class="ltx_text" id="S5.T2.1.1.33.33.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.34.34">
<td class="ltx_td ltx_align_center ltx_border_r" id="S5.T2.1.1.34.34.1"><span class="ltx_text" id="S5.T2.1.1.34.34.1.1" style="font-size:80%;">Sancus</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.34.34.2"><span class="ltx_text" id="S5.T2.1.1.34.34.2.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.34.34.3"><span class="ltx_text" id="S5.T2.1.1.34.34.3.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.34.34.4"><span class="ltx_text" id="S5.T2.1.1.34.34.4.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_center" id="S5.T2.1.1.34.34.5"><span class="ltx_text" id="S5.T2.1.1.34.34.5.1" style="font-size:80%;">-</span></td>
<td class="ltx_td ltx_align_left" id="S5.T2.1.1.34.34.6"><span class="ltx_text" id="S5.T2.1.1.34.34.6.1" style="font-size:80%;">OOM</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.1.1.35.35">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S5.T2.1.1.35.35.1"><span class="ltx_text" id="S5.T2.1.1.35.35.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.35.35.2"><span class="ltx_text" id="S5.T2.1.1.35.35.2.1" style="font-size:80%;">115.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.35.35.3"><span class="ltx_text" id="S5.T2.1.1.35.35.3.1" style="font-size:80%;">92.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.35.35.4"><span class="ltx_text" id="S5.T2.1.1.35.35.4.1" style="font-size:80%;">72.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T2.1.1.35.35.5"><span class="ltx_text" id="S5.T2.1.1.35.35.5.1" style="font-size:80%;">61.4</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S5.T2.1.1.35.35.6"><span class="ltx_text ltx_font_bold" id="S5.T2.1.1.35.35.6.1" style="font-size:80%;">167.9</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.6"><span class="ltx_text ltx_font_bold" id="S5.SS2.p3.6.1">Comparison with full-graph system. </span>
Compared to NeutronStar <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>)</cite> and Sancus <cite class="ltx_cite ltx_citemacro_citep">(Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>)</cite>, NeutronTP demonstrates superior performance across all datasets, achieving speedups of up to 8.72<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.1.m1.1"><semantics id="S5.SS2.p3.1.m1.1a"><mo id="S5.SS2.p3.1.m1.1.1" xref="S5.SS2.p3.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.1.m1.1b"><times id="S5.SS2.p3.1.m1.1.1.cmml" xref="S5.SS2.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.1.m1.1d">Ã—</annotation></semantics></math> and 4.81<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.2.m2.1"><semantics id="S5.SS2.p3.2.m2.1a"><mo id="S5.SS2.p3.2.m2.1.1" xref="S5.SS2.p3.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.2.m2.1b"><times id="S5.SS2.p3.2.m2.1.1.cmml" xref="S5.SS2.p3.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.2.m2.1d">Ã—</annotation></semantics></math>, respectively. They are both constrained by imbalanced workloads and communication overhead resulting from extensive cross-worker vertex dependencies.
The computation and communication time gap between different workers in NeutronStar can reach up to 1.91<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.3.m3.1"><semantics id="S5.SS2.p3.3.m3.1a"><mo id="S5.SS2.p3.3.m3.1.1" xref="S5.SS2.p3.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.3.m3.1b"><times id="S5.SS2.p3.3.m3.1.1.cmml" xref="S5.SS2.p3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.3.m3.1d">Ã—</annotation></semantics></math> and 1.62<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.4.m4.1"><semantics id="S5.SS2.p3.4.m4.1a"><mo id="S5.SS2.p3.4.m4.1.1" xref="S5.SS2.p3.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.4.m4.1b"><times id="S5.SS2.p3.4.m4.1.1.cmml" xref="S5.SS2.p3.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.4.m4.1d">Ã—</annotation></semantics></math>, respectively. For Sancus, these gaps can reach up to 2.38<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.5.m5.1"><semantics id="S5.SS2.p3.5.m5.1a"><mo id="S5.SS2.p3.5.m5.1.1" xref="S5.SS2.p3.5.m5.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.5.m5.1b"><times id="S5.SS2.p3.5.m5.1.1.cmml" xref="S5.SS2.p3.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.5.m5.1d">Ã—</annotation></semantics></math> and 1.18<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS2.p3.6.m6.1"><semantics id="S5.SS2.p3.6.m6.1a"><mo id="S5.SS2.p3.6.m6.1.1" xref="S5.SS2.p3.6.m6.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS2.p3.6.m6.1b"><times id="S5.SS2.p3.6.m6.1.1.cmml" xref="S5.SS2.p3.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p3.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p3.6.m6.1d">Ã—</annotation></semantics></math>, respectively.
NeutronStar exhibits long communication times due to its chunk-based partitioning strategy, which has more cross-worker vertex dependencies, as described in Section 2.2.
Sancus reduces communication overhead by reusing historical embeddings. However, when updating historical embeddings, Sancus sequentially triggers each worker to broadcast embeddings, sending all local embeddings to all workers, regardless of whether other partitions contain these vertices. This not only leads to prolonged waiting times for workers but also results in considerable redundant communication. Both NeutronStar and Sancus encounter out-of-memory errors when dealing with large-scale graphs and complex model due to their lack of intra-worker task scheduling strategies.
The advantages of NeutronTP stem from two main factors: (1) Tensor parallelism training achieves a more balanced computation and communication load, while the decoupled GNN training approach significantly reduces communication overhead. (2) The chunk-based task scheduling strategy partitions local graph data into multiple chunks smaller than GPU memory and loads them sequentially, overlapping computation and communication while avoiding out-of-memory errors.</p>
</div>
<figure class="ltx_figure" id="S5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="291" id="S5.F10.g1" src="x10.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10. </span>The computation/communication load of each partition in different systems. â€TPâ€ indicates NeutronTP with naive GNN tensor parallelism and â€DTPâ€ indicates NeutronTP with decoupled GNN tensor parallelism.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Computation and Communication Analysis</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">We evaluate the computational and communication loads of different systems to illustrate the load-balanced advantages of NeutronTP. Experiments are performed on the Reddit dataset using DistDGL, NeutronStar (NTS), Sancus, NeutronTP with naive GNN tensor parallelism (TP), and NeutronTP with decoupled GNN tensor parallelism (DTP). We train a 2-layer GCN on a 4-node cluster and record the workload for each worker as well as the overall workload. The communication load was measured based on the amount of data transferred, while the computational load was determined by the number of edges involved in the computation. Since NeutronTP utilizes feature slices during computation, whereas other systems use complete features, we scale the edge computation of NeutronTP accordingly. Experimental results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F10" title="Figure 10 â€£ 5.2. Overall Comparison â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">Regarding computational load, NeutronTP achieves complete load balancing by partitioning vertex data, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F10" title="Figure 10 â€£ 5.2. Overall Comparison â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">10</span></a> (a). Regarding total computation, NeutronTP is comparable to other full-graph systems but surpasses the DistDGL. Although DistDGL reduces the computation through sampling, the sampling process incurs significant overhead and leads to decreased efficiency as the model layer increases (see details in Section 5.5).
As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F10" title="Figure 10 â€£ 5.2. Overall Comparison â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">10</span></a> (b), regarding communication load, NeutronTP ensures load balance by assigning each worker an equal number of vertices for embedding <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p2.1.1">gather</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p2.1.2">split</span>. However, naive tensor parallelism requires embedding <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p2.1.3">gather</span> and <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p2.1.4">split</span> operations at each layer, leading to frequent communication. Benefiting from the decoupled tensor parallelism training approach, NeutronTP reduces the overall communication frequency while converting the communication entities into lighter-weight vertex embeddings, significantly reducing communication volume by up to 7.23 <math alttext="\times" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><mo id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><times id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS3.p2.1.m1.1d">Ã—</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Performance Gain Analysis of NeutronTP</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.10">We analyze the performance gain of GNN tensor parallelism (TP), decoupled training method (DT), chunk-based task scheduling (CS), and inter-chunk pipelining (IP) on the GCN model with four datasets.
To ensure a fair comparison, we start with a data parallelism baseline based on the NeutronTP codebase and gradually integrate the four optimization methods. The data parallelism baseline employs a chunk-based approach for graph partitioning.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F11" title="Figure 11 â€£ 5.4. Performance Gain Analysis of NeutronTP â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">11</span></a> shows the normalized speedups.
Compared to the baseline, the baseline+CS addresses the memory requirements of large-scale data by further partitioning chunks within each worker.
Compared to the baseline+CS, TP achieves speedups ranging from 1.92<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><mo id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><times id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.1.m1.1d">Ã—</annotation></semantics></math> to 2.45<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.2.m2.1"><semantics id="S5.SS4.p1.2.m2.1a"><mo id="S5.SS4.p1.2.m2.1.1" xref="S5.SS4.p1.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.2.m2.1b"><times id="S5.SS4.p1.2.m2.1.1.cmml" xref="S5.SS4.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.2.m2.1d">Ã—</annotation></semantics></math> by implementing a more balanced workload. On the Friendster dataset, TP achieves the highest speedup, attributed to its inherent power-law distribution as a social network graph. The chunk-based partitioning strategy exacerbates severe workload imbalances in such graphs. Compared to the baseline+CS+TP, DT achieves speedups ranging from 2.56<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.3.m3.1"><semantics id="S5.SS4.p1.3.m3.1a"><mo id="S5.SS4.p1.3.m3.1.1" xref="S5.SS4.p1.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.3.m3.1b"><times id="S5.SS4.p1.3.m3.1.1.cmml" xref="S5.SS4.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.3.m3.1d">Ã—</annotation></semantics></math> to 4.47<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.4.m4.1"><semantics id="S5.SS4.p1.4.m4.1a"><mo id="S5.SS4.p1.4.m4.1.1" xref="S5.SS4.p1.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.4.m4.1b"><times id="S5.SS4.p1.4.m4.1.1.cmml" xref="S5.SS4.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.4.m4.1d">Ã—</annotation></semantics></math> by significantly reducing communication overhead. DT achieves a 4.47<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.5.m5.1"><semantics id="S5.SS4.p1.5.m5.1a"><mo id="S5.SS4.p1.5.m5.1.1" xref="S5.SS4.p1.5.m5.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.5.m5.1b"><times id="S5.SS4.p1.5.m5.1.1.cmml" xref="S5.SS4.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.5.m5.1d">Ã—</annotation></semantics></math> speedup on the Reddit dataset, whereas on the Ogbn-paper dataset, the speedup is only 2.21<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.6.m6.1"><semantics id="S5.SS4.p1.6.m6.1a"><mo id="S5.SS4.p1.6.m6.1.1" xref="S5.SS4.p1.6.m6.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.6.m6.1b"><times id="S5.SS4.p1.6.m6.1.1.cmml" xref="S5.SS4.p1.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.6.m6.1d">Ã—</annotation></semantics></math>. This discrepancy is due to the embedding dimension in Reddit being significantly lower than the raw features, facilitating a reduction in communication volume through the early computation of NN operations.
Lastly, IP provides speedups ranging from 1.1<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.7.m7.1"><semantics id="S5.SS4.p1.7.m7.1a"><mo id="S5.SS4.p1.7.m7.1.1" xref="S5.SS4.p1.7.m7.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.7.m7.1b"><times id="S5.SS4.p1.7.m7.1.1.cmml" xref="S5.SS4.p1.7.m7.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.7.m7.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.7.m7.1d">Ã—</annotation></semantics></math> to 1.5<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.8.m8.1"><semantics id="S5.SS4.p1.8.m8.1a"><mo id="S5.SS4.p1.8.m8.1.1" xref="S5.SS4.p1.8.m8.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.8.m8.1b"><times id="S5.SS4.p1.8.m8.1.1.cmml" xref="S5.SS4.p1.8.m8.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.8.m8.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.8.m8.1d">Ã—</annotation></semantics></math> by overlapping computation and communication. IP achieves an average speedup of 1.47<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.9.m9.1"><semantics id="S5.SS4.p1.9.m9.1a"><mo id="S5.SS4.p1.9.m9.1.1" xref="S5.SS4.p1.9.m9.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.9.m9.1b"><times id="S5.SS4.p1.9.m9.1.1.cmml" xref="S5.SS4.p1.9.m9.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.9.m9.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.9.m9.1d">Ã—</annotation></semantics></math> on the Reddit and Product datasets, while on the two larger datasets, the speedup averages only 1.11<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS4.p1.10.m10.1"><semantics id="S5.SS4.p1.10.m10.1a"><mo id="S5.SS4.p1.10.m10.1.1" xref="S5.SS4.p1.10.m10.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.10.m10.1b"><times id="S5.SS4.p1.10.m10.1.1.cmml" xref="S5.SS4.p1.10.m10.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.10.m10.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS4.p1.10.m10.1d">Ã—</annotation></semantics></math>. This is because large datasets require more chunks partitioned, leading to more frequent CPU-GPU communication.</p>
</div>
<figure class="ltx_figure" id="S5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="151" id="S5.F11.g1" src="x11.png" width="436"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11. </span>Performance gain analysis. â€CSâ€ indicates the chunk-based task scheduling, â€TPâ€ indicates the GNN tensor parallelism training, â€DTâ€ indicates the decoupled training method, and â€IPâ€ indicates the inter-chunk pipelining.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5. </span>Scalability Analysis</h3>
<div class="ltx_para ltx_noindent" id="S5.SS5.p1">
<p class="ltx_p" id="S5.SS5.p1.5"><span class="ltx_text ltx_font_bold" id="S5.SS5.p1.5.1">Performance with varying cluster sizes. </span>
In this experiment, we compare NeutronTP with baselines when training GCN with different cluster sizes over two datasets.
The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F12" title="Figure 12 â€£ 5.5. Scalability Analysis â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">12</span></a>. Across different cluster sizes, NeutronTP consistently outperforms the baselines. Specifically, as the cluster size increases from 2 to 16, NeutronTP achieves an average speedup of 6.33<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p1.1.m1.1"><semantics id="S5.SS5.p1.1.m1.1a"><mo id="S5.SS5.p1.1.m1.1.1" xref="S5.SS5.p1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.1.m1.1b"><times id="S5.SS5.p1.1.m1.1.1.cmml" xref="S5.SS5.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.1.m1.1d">Ã—</annotation></semantics></math>, 5.97<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p1.2.m2.1"><semantics id="S5.SS5.p1.2.m2.1a"><mo id="S5.SS5.p1.2.m2.1.1" xref="S5.SS5.p1.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.2.m2.1b"><times id="S5.SS5.p1.2.m2.1.1.cmml" xref="S5.SS5.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.2.m2.1d">Ã—</annotation></semantics></math>, and 2.69<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p1.3.m3.1"><semantics id="S5.SS5.p1.3.m3.1a"><mo id="S5.SS5.p1.3.m3.1.1" xref="S5.SS5.p1.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.3.m3.1b"><times id="S5.SS5.p1.3.m3.1.1.cmml" xref="S5.SS5.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.3.m3.1d">Ã—</annotation></semantics></math> compared to DistDGL, NeutronStar, and Sancus, respectively. We observe that the execution time of NeutronTP, DistDGL, and NeutronStar decreases with an increase in the number of nodes. However, Sancus demonstrates poor scalability. That may be due to its communication implementation, where each worker needs to fetch the entire partition data from remote workers, even if only a small portion of the data is required. In contrast, NeutronTP adopts tensor parallelism to eliminate vertex dependencies and employs a decoupled training approach to reduce communication overhead, achieving nearly linear speedup. Specifically, as the number of nodes in the cluster increases from 2 to 16, NeutronTP achieves an average speedup of 6.33<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p1.4.m4.1"><semantics id="S5.SS5.p1.4.m4.1a"><mo id="S5.SS5.p1.4.m4.1.1" xref="S5.SS5.p1.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.4.m4.1b"><times id="S5.SS5.p1.4.m4.1.1.cmml" xref="S5.SS5.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.4.m4.1d">Ã—</annotation></semantics></math> and 4.97<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p1.5.m5.1"><semantics id="S5.SS5.p1.5.m5.1a"><mo id="S5.SS5.p1.5.m5.1.1" xref="S5.SS5.p1.5.m5.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p1.5.m5.1b"><times id="S5.SS5.p1.5.m5.1.1.cmml" xref="S5.SS5.p1.5.m5.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p1.5.m5.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p1.5.m5.1d">Ã—</annotation></semantics></math> on Reddit and Ogbn-products.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS5.p2">
<p class="ltx_p" id="S5.SS5.p2.4"><span class="ltx_text ltx_font_bold" id="S5.SS5.p2.4.1">Performance with varying model layers. </span>
In this experiment, we compare NeutronTP with baselines when training GCN with different model layers over two datasets in a 16-node cluster. For the 2, 3, and 4-layer models, the DGL sampling strategies were set to (25,10), (25,15,10), and (25,20,15,10) respectively. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F13" title="Figure 13 â€£ 5.5. Scalability Analysis â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">13</span></a>. We observe that the performance advantage of NeutronTP over other baselines gradually increased with the model depths. For the 2-layer model, NeutronTP achieves an average speedup of 5.99<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p2.1.m1.1"><semantics id="S5.SS5.p2.1.m1.1a"><mo id="S5.SS5.p2.1.m1.1.1" xref="S5.SS5.p2.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.1.m1.1b"><times id="S5.SS5.p2.1.m1.1.1.cmml" xref="S5.SS5.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.1.m1.1d">Ã—</annotation></semantics></math>. For the 3-layer and 4-layer models, the speedups were 8.65<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p2.2.m2.1"><semantics id="S5.SS5.p2.2.m2.1a"><mo id="S5.SS5.p2.2.m2.1.1" xref="S5.SS5.p2.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.2.m2.1b"><times id="S5.SS5.p2.2.m2.1.1.cmml" xref="S5.SS5.p2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.2.m2.1d">Ã—</annotation></semantics></math> and 11.13<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p2.3.m3.1"><semantics id="S5.SS5.p2.3.m3.1a"><mo id="S5.SS5.p2.3.m3.1.1" xref="S5.SS5.p2.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.3.m3.1b"><times id="S5.SS5.p2.3.m3.1.1.cmml" xref="S5.SS5.p2.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.3.m3.1d">Ã—</annotation></semantics></math> respectively.
<span class="ltx_text" id="S5.SS5.p2.4.2" style="color:#000000;">This is because NeutronTPâ€™s tensor parallelism can effectively eliminate the cross-worker vertex dependencies among layers in GNN data parallel training, thereby removing substantial communication overhead.</span>
DistDGL experiences the most severe efficiency degradation because of the neighbor explosion problem <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>)</cite>, where the computation and memory requirements for mini-batch GNN training increase exponentially with the number of layers.
NeutronTP outperforms DistDGL by up to 26.64<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p2.4.m4.1"><semantics id="S5.SS5.p2.4.m4.1a"><mo id="S5.SS5.p2.4.m4.1.1" xref="S5.SS5.p2.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p2.4.m4.1b"><times id="S5.SS5.p2.4.m4.1.1.cmml" xref="S5.SS5.p2.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p2.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p2.4.m4.1d">Ã—</annotation></semantics></math> in the 4-layer model on the Ogbn-products dataset. This is because the average degree of Ogbn-products is much smaller than that of Reddit, making the graph topology sparser and causing a faster increase in the sampled subgraph size.</p>
</div>
<figure class="ltx_figure" id="S5.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="300" id="S5.F12.g1" src="x12.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12. </span>Per-epoch runtime of different systems with different cluster sizes.</figcaption>
</figure>
<figure class="ltx_figure" id="S5.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="297" id="S5.F13.g1" src="x13.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13. </span>Per-epoch runtime of different systems with different model layers.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S5.SS5.p3">
<p class="ltx_p" id="S5.SS5.p3.4"><span class="ltx_text ltx_font_bold" id="S5.SS5.p3.4.5" style="color:#000000;">Performance with varying feature dimensions.<span class="ltx_text" id="S5.SS5.p3.4.5.1" style="color:#000000;"> </span></span> <span class="ltx_text" id="S5.SS5.p3.4.4" style="color:#000000;">In this experiment, we compare NeutronTP with baselines when training GCN with different input feature dimensions over two datasets in a 16-node cluster. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F14" title="Figure 14 â€£ 5.5. Scalability Analysis â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">14</span></a>. We observe that the performance advantage of NeutronTP over other baselines gradually increased with the feature dimensions. For the 128-dimensional dataset, NeutronTP achieves an average speedup of 5,87<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p3.1.1.m1.1"><semantics id="S5.SS5.p3.1.1.m1.1a"><mo id="S5.SS5.p3.1.1.m1.1.1" mathcolor="#000000" xref="S5.SS5.p3.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.1.1.m1.1b"><times id="S5.SS5.p3.1.1.m1.1.1.cmml" xref="S5.SS5.p3.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.1.1.m1.1d">Ã—</annotation></semantics></math>. For the 256-dimensional, 512-dimensional, and 1024-dimensional datasets, the speedups are 7.28<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p3.2.2.m2.1"><semantics id="S5.SS5.p3.2.2.m2.1a"><mo id="S5.SS5.p3.2.2.m2.1.1" mathcolor="#000000" xref="S5.SS5.p3.2.2.m2.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.2.2.m2.1b"><times id="S5.SS5.p3.2.2.m2.1.1.cmml" xref="S5.SS5.p3.2.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.2.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.2.2.m2.1d">Ã—</annotation></semantics></math>, 8.14<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p3.3.3.m3.1"><semantics id="S5.SS5.p3.3.3.m3.1a"><mo id="S5.SS5.p3.3.3.m3.1.1" mathcolor="#000000" xref="S5.SS5.p3.3.3.m3.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.3.3.m3.1b"><times id="S5.SS5.p3.3.3.m3.1.1.cmml" xref="S5.SS5.p3.3.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.3.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.3.3.m3.1d">Ã—</annotation></semantics></math>, and 12.74<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS5.p3.4.4.m4.1"><semantics id="S5.SS5.p3.4.4.m4.1a"><mo id="S5.SS5.p3.4.4.m4.1.1" mathcolor="#000000" xref="S5.SS5.p3.4.4.m4.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS5.p3.4.4.m4.1b"><times id="S5.SS5.p3.4.4.m4.1.1.cmml" xref="S5.SS5.p3.4.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS5.p3.4.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS5.p3.4.4.m4.1d">Ã—</annotation></semantics></math> respectively. When feature dimensions increase, GNN data parallelism suffers from significant communication overhead, particularly during the communication of raw features in the first layer. NeutronTP employs decoupled GNN tensor parallelism, which only gathers and splits vertex embeddings. Compared to GNN data parallelism, it reduces communication frequency and transforms features into lower-dimensional embeddings before communication.</span></p>
</div>
<figure class="ltx_figure" id="S5.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="313" id="S5.F14.g1" src="x14.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14. </span><span class="ltx_text" id="S5.F14.2.1" style="color:#000000;">Per-epoch runtime of different systems with different feature dimensions.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S5.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="238" id="S5.F15.g1" src="x15.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15. </span>GPU utilization comparison. The average GPU utilizations are 62.85%, 19.91%, 33.97%, and 37.67% for NeutronTP, DistDGL, NeutronStar, and Sancus, respectively.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6. </span>GPU Utilization</h3>
<div class="ltx_para" id="S5.SS6.p1">
<p class="ltx_p" id="S5.SS6.p1.1">We evaluate the GPU utilization during the training of GCN on Reddit for NeutronTP and baselines in a 16-node cluster. Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F15" title="Figure 15 â€£ 5.5. Scalability Analysis â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">15</span></a> shows the results in a 20-second time window. The GPU utilization is recorded every 100 milliseconds and averaged in a 1-second interval. NeutronTP exhibits higher GPU utilization (62.85% on average) compared to DistDGL (19.91% on average), Sancus (37.67% on average), and NeutronStar (33.97% on average), with consistently higher peak GPU utilization for most of the time.
DistDGL shows relatively low GPU utilization due to the sampling step involving a large amount of random access, which can be the bottleneck to limit GPU utilization. Additionally, baselines based on GNN data parallelism suffer from GPU idle time due to unbalanced workloads, resulting in decreased overall GPU utilization. NeutronTP experiences minimal GPU idle time, attributed to balanced workloads and a pipeline design between chunks, maximizing the overlap of communication and computation.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7. </span>Accuracy Comparisons</h3>
<div class="ltx_para" id="S5.SS7.p1">
<p class="ltx_p" id="S5.SS7.p1.1"><span class="ltx_text" id="S5.SS7.p1.1.1" style="color:#000000;">The changes in the execution process introduced by the decoupled training method may impact model performance. We plot the epoch-to-accuracy curve on different systems for a GCN model over two datasets. The results are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S5.F16" title="Figure 16 â€£ 5.7. Accuracy Comparisons â€£ 5. Evaluation â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">16</span></a>. After 100 epochs, the test accuracy reaches a stable state, NeutronTP and other baselines almost achieve the same test accuracy. However, NeutronTP converges slightly slower compared to the traditional GNN training method.</span>
Sancus exhibits the slowest increase in accuracy over epochs due to its use of historical embeddings. Additionally, it is worth noting that while many works <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Md etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib26" title="">2021</a>)</cite> have demonstrated that sampling strategies can lead to lower accuracy, we find that DistDGL performs close to full-graph training accuracy on commonly used datasets. We attribute this to the well-tuned parameters of DistDGL. <span class="ltx_text" id="S5.SS7.p1.1.2" style="color:#000000;">Both mini-batch and full-graph training methods have their advantages. In summary, NeutronTP exhibits advantages when training deep GNNs or when the input graph includes a large proportion of training vertices. However, when the training set and the number of model layers are small, DistDGL still holds certain advantages.</span></p>
</div>
<figure class="ltx_figure" id="S5.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="242" id="S5.F16.g1" src="x16.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16. </span>Epoch-to-accuracy.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S5.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.8. </span><span class="ltx_text" id="S5.SS8.1.1" style="color:#000000;">Extension to heterogeneous graphs</span>
</h3>
<div class="ltx_para" id="S5.SS8.p1">
<p class="ltx_p" id="S5.SS8.p1.1"><span class="ltx_text" id="S5.SS8.p1.1.1" style="color:#000000;">NeutronTP can be naturally extended to heterogeneous graphs. We compare NeutronTP with DistDGLv2 <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib56" title="">2022b</a>)</cite> using two heterogeneous graphs <cite class="ltx_cite ltx_citemacro_citep">(Hu etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib15" title="">2021</a>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib16" title="">2020</a>)</cite> and the R-GCN algorithm <cite class="ltx_cite ltx_citemacro_citep">(Schlichtkrull etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib32" title="">2018</a>)</cite> in a 16-node cluster. DistDGLv2 extends DistDGL to support heterogeneous GNN training. R-GCN are designed to handle heterogeneous graphs, which consist of multiple types of edges. On the Ogbn-mag dataset, NeutronTP achieves a 6.15<math alttext="\times" class="ltx_Math" display="inline" id="S5.SS8.p1.1.1.m1.1"><semantics id="S5.SS8.p1.1.1.m1.1a"><mo id="S5.SS8.p1.1.1.m1.1.1" mathcolor="#000000" xref="S5.SS8.p1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.SS8.p1.1.1.m1.1b"><times id="S5.SS8.p1.1.1.m1.1.1.cmml" xref="S5.SS8.p1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.SS8.p1.1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS8.p1.1.1.m1.1d">Ã—</annotation></semantics></math> speedup. On the Mag-lsc dataset, DistDGLv2 exhibits better performance as it trains on only 0.4% of the total vertices, reducing the computational load compared to NeutronTP. This is similar to the Ogbn-paper dataset, which includes only 1.1% training vertices, leading to significant differences in overall computation between full-graph and mini-batch training. </span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.9. </span><span class="ltx_text" id="S5.SS9.1.1" style="color:#000000;">Training cost breakdown</span>
</h3>
<div class="ltx_para" id="S5.SS9.p1">
<p class="ltx_p" id="S5.SS9.p1.1"><span class="ltx_text" id="S5.SS9.p1.1.1" style="color:#000000;">We evaluate the training costs of different stages for both node classification and link prediction tasks using the GCN algorithm with the Reddit dataset. The results are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#S6.T4" title="Table 4 â€£ 6. Related work â€£ NeutronTP: Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism"><span class="ltx_text ltx_ref_tag">4</span></a>. We can observe that GNN computation is the primary cost, accounting for an average of 94% of the time in node classification and 79% in link prediction. By optimizing the GNN computation process, NeutronTP reduces end-to-end training time by 65% to 80% compared to NeutronStar. Therefore, the practical downstream tasks that benefit most from NeutronTP are those where GNN computation is a significant part of the overall training cost.</span></p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Related work</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.p1.1.1">Full-graph GNN training. </span> A set of GNN systems <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib25" title="">2019</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib44" title="">2022</a>; Cai etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib6" title="">2021</a>; Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>; Peng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib30" title="">2022</a>; Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib40" title="">2022b</a>; Tripathy etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib37" title="">2020</a>; Fey and Lenssen, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib11" title="">2019</a>)</cite> adopt full-graph GNN training to guarantee high accuracy. NeuGraph <cite class="ltx_cite ltx_citemacro_citep">(Ma etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib25" title="">2019</a>)</cite> defines a new, flexible SAGA-NN model to express GNNs.
CAGNET <cite class="ltx_cite ltx_citemacro_citep">(Tripathy etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib37" title="">2020</a>)</cite> proposes 1.5D, 2D, and 3D graph partitioning to optimize the data distribution among GPUs.
ROC <cite class="ltx_cite ltx_citemacro_citep">(Jia etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib17" title="">2020</a>)</cite> optimizes graph partitioning with online learning while managing memory with dynamic programming.
DGCL <cite class="ltx_cite ltx_citemacro_citep">(Cai etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib6" title="">2021</a>)</cite> designs a communication planning algorithm that avoids conflict on various links.
PipeGCN <cite class="ltx_cite ltx_citemacro_citep">(Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib40" title="">2022b</a>)</cite> reduces communication for boundary vertices by utilizing historical embeddings and effectively overlaps computation across different partitions.
G3 <cite class="ltx_cite ltx_citemacro_citep">(Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>)</cite> propose GNN hybrid parallelism to scale out GNN training with carefully scheduled peer-to-peer intermediate data sharing. Hongtu <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib43" title="">2023</a>)</cite> designs a recomputation-cache-hybrid intermediate data management to significantly reduce the GPU memory requirement.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Load balancing study in distributed GNN training. </span>
Many survey papers <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib22" title="">2023</a>; Shao etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib33" title="">2022</a>; Besta and Hoefler, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib3" title="">2024</a>)</cite> highlight workload imbalance as a primary challenge in distributed GNN training.
Experimental studies <cite class="ltx_cite ltx_citemacro_citep">(Yuan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib51" title="">2023</a>; Merkel etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib27" title="">2023</a>)</cite> have empirically demonstrated the prevalence of load imbalance.
Many GNN systems attempt to address this issue by exploring graph partitioning strategies <cite class="ltx_cite ltx_citemacro_citep">(Kaler etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib18" title="">2023</a>; Tripathy etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib37" title="">2020</a>; Lin etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib23" title="">2020</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib54" title="">2022a</a>; Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>; Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib55" title="">2020</a>)</cite>.
SALIENT++ <cite class="ltx_cite ltx_citemacro_citep">(Kaler etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib18" title="">2023</a>)</cite> extends the METIS partitioning approach with additional constraints to balance workloads while minimizing edge-cuts.
PaGraph <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib23" title="">2020</a>)</cite> and ByteGNN <cite class="ltx_cite ltx_citemacro_citep">(Zheng etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib54" title="">2022a</a>)</cite> employ streaming partitioning methods, selecting the optimal partition for each vertex individually. G3 <cite class="ltx_cite ltx_citemacro_citep">(Wan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib41" title="">2023</a>)</cite> adopts an iterative partitioning approach, continuously exchanging vertices between different partitions.
Given the complexity of real-world graph data, these methods often approximate load balance and may experience diminishing effectiveness with increasing graph power-law characteristics <cite class="ltx_cite ltx_citemacro_citep">(Yuan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib51" title="">2023</a>; Merkel etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib27" title="">2023</a>)</cite>. Furthermore, the memory and computation overhead of these methods is considerable, especially for METIS and streaming partitioning, which may even surpass the training itself <cite class="ltx_cite ltx_citemacro_citep">(Yuan etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib51" title="">2023</a>; Du etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib7" title="">2023</a>; Gandhi and Iyer, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib12" title="">2021</a>)</cite>.
Therefore, we believe that partitioning features instead of graph data for GNN tensor parallelism is a promising distributed training approach.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Vertical feature partitioning. </span>
Some recent studies <cite class="ltx_cite ltx_citemacro_citep">(Gandhi and Iyer, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib12" title="">2021</a>; Du etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib7" title="">2023</a>)</cite> explore vertical feature partitioning in distributed GNN training.
P3 <cite class="ltx_cite ltx_citemacro_citep">(Gandhi and Iyer, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib12" title="">2021</a>)</cite> utilizes feature slices to complete the first graph aggregation operation, reducing feature fetching overhead. Du et al. <cite class="ltx_cite ltx_citemacro_citep">(Du etÂ al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2412.20379v1#bib.bib7" title="">2023</a>)</cite> propose skipping feature fetching in some iterations, leveraging only partial feature dimensions for local training to achieve a trade-off between convergence error and feature communication time.</p>
</div>
<figure class="ltx_table" id="S6.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3. </span><span class="ltx_text" id="S6.T3.2.1" style="color:#000000;">Comparison with DistDGLv2 on two heterogeneous graphs.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S6.T3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S6.T3.3.1.1.1" rowspan="2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T3.3.1.1.1.1" style="font-size:80%;">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="2" id="S6.T3.3.1.1.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.1.1.2.1" style="font-size:80%;">Runtime of R-GCN (s)</span></th>
</tr>
<tr class="ltx_tr" id="S6.T3.3.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T3.3.2.2.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.2.2.1.1" style="font-size:80%;">Ogbn-mag</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T3.3.2.2.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.2.2.2.1" style="font-size:80%;">Mag-lsc</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.3.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T3.3.3.1.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.3.1.1.1" style="font-size:80%;">DistDGLv2</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.3.1.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.3.1.2.1" style="font-size:80%;">36.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.3.1.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T3.3.3.1.3.1" style="font-size:80%;">56.9</span></td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T3.3.4.2.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.4.2.1.1" style="font-size:80%;">NeutronTP</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.4.2.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T3.3.4.2.2.1" style="font-size:80%;">5.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.4.2.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T3.3.4.2.3.1" style="font-size:80%;">695.2</span></td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="S6.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4. </span><span class="ltx_text" id="S6.T4.2.1" style="color:#000000;">The runtime breakdown (in seconds) with different tasks. (NC: node classification, LP: link prediction)</span></figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T4.3" style="width:195.1pt;height:66.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-60.0pt,20.6pt) scale(0.619320620391559,0.619320620391559) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T4.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T4.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S6.T4.3.1.1.1.1" rowspan="2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.1.1.1.1" style="font-size:80%;">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.1.1.2" rowspan="2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.1.1.2.1" style="font-size:80%;">System</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.1.1.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.1.1.3.1" style="font-size:80%;">Negative</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.1.1.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.1.1.4.1" style="font-size:80%;">GNN</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.1.1.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.1.1.5.1" style="font-size:80%;">Classification</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.1.1.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.1.1.6.1" style="font-size:80%;">Loss</span></th>
<td class="ltx_td ltx_border_t" id="S6.T4.3.1.1.1.7" style="padding-top:0.8pt;padding-bottom:0.8pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.2.2">
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.2.2.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.2.2.1.1" style="font-size:80%;">Sampling</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.2.2.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.2.2.2.1" style="font-size:80%;">Computation</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.2.2.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.2.2.3.1" style="font-size:80%;">Computation</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.2.2.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.2.2.4.1" style="font-size:80%;">Calculation</span></td>
<td class="ltx_td" id="S6.T4.3.1.2.2.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="S6.T4.3.1.3.3.1" rowspan="2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.3.3.1.1" style="font-size:80%;">NC</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.3.3.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.3.3.2.1" style="font-size:80%;">NeutronStar</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.3.3.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.3.3.3.1" style="font-size:80%;">-/-</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.3.3.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.3.3.4.1" style="font-size:80%;">1.88/97%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.3.3.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.3.3.5.1" style="font-size:80%;">0.03/2%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.3.3.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.3.3.6.1" style="font-size:80%;">0.01/1%</span></th>
<td class="ltx_td ltx_border_t" id="S6.T4.3.1.3.3.7" style="padding-top:0.8pt;padding-bottom:0.8pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.4.4">
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.4.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.4.4.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.4.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.4.4.2.1" style="font-size:80%;">-/-</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.4.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.4.4.3.1" style="font-size:80%;">0.36/90%</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.4.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.4.4.4.1" style="font-size:80%;">0.03/7%</span></td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.4.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.4.4.5.1" style="font-size:80%;">0.01/3%</span></td>
<td class="ltx_td" id="S6.T4.3.1.4.4.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_bb ltx_border_t" id="S6.T4.3.1.5.5.1" rowspan="2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.5.5.1.1" style="font-size:80%;">LP</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.5.5.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.5.5.2.1" style="font-size:80%;">NeutronStar</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.5.5.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.5.5.3.1" style="font-size:80%;">0.07/3%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.5.5.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.5.5.4.1" style="font-size:80%;">2.12/90%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.5.5.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.5.5.5.1" style="font-size:80%;">0.11/5%</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S6.T4.3.1.5.5.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.5.5.6.1" style="font-size:80%;">0.04/2%</span></th>
<td class="ltx_td ltx_border_t" id="S6.T4.3.1.5.5.7" style="padding-top:0.8pt;padding-bottom:0.8pt;"></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.6.6.1" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.6.6.1.1" style="font-size:80%;">NeutronTP</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.6.6.2" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.6.6.2.1" style="font-size:80%;">0.07/9%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.6.6.3" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text ltx_font_bold" id="S6.T4.3.1.6.6.3.1" style="font-size:80%;">0.53/67%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.6.6.4" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.6.6.4.1" style="font-size:80%;">0.15/19%</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.6.6.5" style="padding-top:0.8pt;padding-bottom:0.8pt;"><span class="ltx_text" id="S6.T4.3.1.6.6.5.1" style="font-size:80%;">0.04/5%</span></td>
<td class="ltx_td ltx_border_bb" id="S6.T4.3.1.6.6.6" style="padding-top:0.8pt;padding-bottom:0.8pt;"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We present NeutronTP, a load-balanced and efficient distributed full-graph GNN training system. NeutronTP leverages GNN tensor parallelism for distributed training, which partitions feature rather than graph structures. Compared to GNN data parallelism, NeutronTP eliminates cross-worker vertex dependencies and achieves a balanced workload. To address the unique challenges of GNN tensor parallelism, NeutronTP employs a generalized decoupled training approach to significantly reduce communication overhead and a memory-efficient task scheduling strategy to reduce memory consumption while overlapping computation and communication. Extensive experiments demonstrate that our approach accelerates distributed GNN training significantly compared to GNN data parallelism while achieving comparable model accuracy.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work is supported by the National Natural Science Foundation of China (U2241212, 62072082, 62202088, 62072083, and 62372097), the 111 Project (B16009), and the Distinguished Youth Foundation of Liaoning Province (2024021148-JH3/501). Yanfeng Zhang and Qiange Wang are the corresponding authors.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baker and Patil (1998)</span>
<span class="ltx_bibblock">
MarkÂ R. Baker and RajendraÂ B. Patil. 1998.

</span>
<span class="ltx_bibblock">Universal Approximation Theorem for Interval Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Reliab. Comput.</em> 4, 3 (1998), 235â€“239.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Besta and Hoefler (2024)</span>
<span class="ltx_bibblock">
Maciej Besta and Torsten Hoefler. 2024.

</span>
<span class="ltx_bibblock">Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IEEE Trans. Pattern Anal. Mach. Intell.</em> 46, 5 (2024), 2584â€“2606.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bian etÂ al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhengda Bian, Qifan Xu, Boxiang Wang, and Yang You. 2021.

</span>
<span class="ltx_bibblock">Maximizing Parallelism in Distributed Training for Huge Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">CoRR</em> abs/2105.14450 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bojchevski etÂ al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Aleksandar Bojchevski, Johannes Klicpera, Bryan Perozzi, Amol Kapoor, Martin Blais, Benedek RÃ³zemberczki, Michal Lukasik, and Stephan GÃ¼nnemann. 2020.

</span>
<span class="ltx_bibblock">Scaling Graph Neural Networks with Approximate PageRank. In <em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">KDD â€™20: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020</em>. ACM, 2464â€“2473.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai etÂ al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Zhenkun Cai, Xiao Yan, Yidi Wu, Kaihao Ma, James Cheng, and Fan Yu. 2021.

</span>
<span class="ltx_bibblock">DGCL: an efficient communication library for distributed GNN training. In <em class="ltx_emph ltx_font_italic" id="bib.bib6.3.1">Sixteenth European Conference on Computer Systems, EuroSys â€™21, Online Event, United Kingdom</em>. ACM, 130â€“144.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du etÂ al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Bingqian Du, Jun Liu, Ziyue Luo, Chuan Wu, Qiankun Zhang, and Hai Jin. 2023.

</span>
<span class="ltx_bibblock">Expediting Distributed GNN Training with Feature-only Partition and Optimized Communication Planning. In <em class="ltx_emph ltx_font_italic" id="bib.bib7.3.1">IEEE INFOCOM 2024 - IEEE Conference on Computer Communications</em>. IEEE, 1â€“10.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwivedi and Bresson (2020)</span>
<span class="ltx_bibblock">
VijayÂ Prakash Dwivedi and Xavier Bresson. 2020.

</span>
<span class="ltx_bibblock">A Generalization of Transformer Networks to Graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">CoRR</em> abs/2012.09699 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Facebook. (2021)</span>
<span class="ltx_bibblock">
Facebook. 2021.

</span>
<span class="ltx_bibblock">Gloo.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">https://github.com/facebookincubator/gloo.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan etÂ al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Wenqi Fan, Yao Ma, Qing Li, Yuan He, YihongÂ Eric Zhao, Jiliang Tang, and Dawei Yin. 2019.

</span>
<span class="ltx_bibblock">Graph Neural Networks for Social Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019</em>. ACM, 417â€“426.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fey and Lenssen (2019)</span>
<span class="ltx_bibblock">
Matthias Fey and JanÂ Eric Lenssen. 2019.

</span>
<span class="ltx_bibblock">Fast Graph Representation Learning with PyTorch Geometric.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">CoRR</em> abs/1903.02428 (2019).

</span>
<span class="ltx_bibblock">arXiv:1903.02428

<a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1903.02428" title="">http://arxiv.org/abs/1903.02428</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gandhi and Iyer (2021)</span>
<span class="ltx_bibblock">
Swapnil Gandhi and AnandÂ Padmanabha Iyer. 2021.

</span>
<span class="ltx_bibblock">P3: Distributed Deep Graph Learning at Scale. In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">15th USENIX Symposium on Operating Systems Design and Implementation, OSDI 2021, July 14-16, 2021</em>. USENIX Association, 551â€“568.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hamilton etÂ al<span class="ltx_text" id="bib.bib13.2.2.1">.</span> (2017)</span>
<span class="ltx_bibblock">
WilliamÂ L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017.

</span>
<span class="ltx_bibblock">Inductive Representation Learning on Large Graphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib13.3.1">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, NeurIPSâ€™17 Long Beach, CA, USA</em>. 1024â€“1034.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yong-Dong Zhang, and Meng Wang. 2020.

</span>
<span class="ltx_bibblock">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020</em>. ACM, 639â€“648.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, and Jure Leskovec. 2021.

</span>
<span class="ltx_bibblock">OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al<span class="ltx_text" id="bib.bib16.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. 2020.

</span>
<span class="ltx_bibblock">Open Graph Benchmark: Datasets for Machine Learning on Graphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.3.1">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPSâ€™20, December 6-12</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia etÂ al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhihao Jia, Sina Lin, Mingyu Gao, Matei Zaharia, and Alex Aiken. 2020.

</span>
<span class="ltx_bibblock">Improving the Accuracy, Scalability, and Performance of Graph Neural Networks with Roc. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of Machine Learning and Systems 2020, MLSysâ€™20, Austin, TX, USA</em>. mlsys.org.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaler etÂ al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Tim Kaler, Alexandros-Stavros Iliopoulos, Philip Murzynowski, TaoÂ B. Schardl, CharlesÂ E. Leiserson, and Jie Chen. 2023.

</span>
<span class="ltx_bibblock">Communication-Efficient Graph Neural Networks with Probabilistic Neighborhood Expansion Analysis and Caching.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">CoRR</em> abs/2305.03152 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kipf and Welling (2017)</span>
<span class="ltx_bibblock">
ThomasÂ N. Kipf and Max Welling. 2017.

</span>
<span class="ltx_bibblock">Semi-Supervised Classification with Graph Convolutional Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">5th International Conference on Learning Representations, ICLRâ€™17, Toulon, France, Conference Track Proceedings</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klicpera etÂ al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Johannes Klicpera, Aleksandar Bojchevski, and Stephan GÃ¼nnemann. 2019.

</span>
<span class="ltx_bibblock">Predict then Propagate: Graph Neural Networks meet Personalized PageRank. In <em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leskovec and Sosic (2016)</span>
<span class="ltx_bibblock">
Jure Leskovec and Rok Sosic. 2016.

</span>
<span class="ltx_bibblock">SNAP: A General Purpose Network Analysis and Graph Mining Library.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">CoRR</em> abs/1606.07550 (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Haiyang Lin, Mingyu Yan, Xiaochun Ye, Dongrui Fan, Shirui Pan, Wenguang Chen, and Yuan Xie. 2023.

</span>
<span class="ltx_bibblock">A Comprehensive Survey on Distributed Training of Graph Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">Proc. IEEE</em> 111, 12 (2023), 1572â€“1606.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhiqi Lin, Cheng Li, Youshan Miao, Yunxin Liu, and Yinlong Xu. 2020.

</span>
<span class="ltx_bibblock">PaGraph: Scaling GNN training on large graphs via computation-aware caching. In <em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">ACM Symposium on Cloud Computing, SoCCâ€™20, Virtual Event, USA</em>. 401â€“415.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Meng Liu, Hongyang Gao, and Shuiwang Ji. 2020.

</span>
<span class="ltx_bibblock">Towards Deeper Graph Neural Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.1">KDD â€™20: The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, CA, USA, August 23-27, 2020</em>. ACM, 338â€“348.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma etÂ al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Lingxiao Ma, Zhi Yang, Youshan Miao, Jilong Xue, Ming Wu, Lidong Zhou, and Yafei Dai. 2019.

</span>
<span class="ltx_bibblock">NeuGraph: Parallel Deep Neural Network Computation on Large Graphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">2019 USENIX Annual Technical Conference, ATCâ€™19, Renton, WA, USA</em>. USENIX Association, 443â€“458.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Md etÂ al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Vasimuddin Md, Sanchit Misra, Guixiang Ma, Ramanarayan Mohanty, Evangelos Georganas, Alexander Heinecke, DhirajÂ D. Kalamkar, NesreenÂ K. Ahmed, and Sasikanth Avancha. 2021.

</span>
<span class="ltx_bibblock">DistGNN: scalable distributed training for large-scale graph neural networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">International Conference for High Performance Computing, Networking, Storage and Analysis, SCâ€™21, St. Louis, Missouri, USA</em>. ACM, 76.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Merkel etÂ al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Nikolai Merkel, Daniel Stoll, Ruben Mayer, and Hans-Arno Jacobsen. 2023.

</span>
<span class="ltx_bibblock">An Experimental Comparison of Partitioning Strategies for Distributed Graph Neural Network Training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">CoRR</em> abs/2308.15602 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishijima (2021)</span>
<span class="ltx_bibblock">
Takato Nishijima. 2021.

</span>
<span class="ltx_bibblock">Universal Approximation Theorem for Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">CoRR</em> abs/2102.10993 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">NVIDIA. (2021)</span>
<span class="ltx_bibblock">
NVIDIA. 2021.

</span>
<span class="ltx_bibblock">Collective Communication Library (NCCL).

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">https://developer.nvidia.com/nccl.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng etÂ al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Jingshu Peng, Zhao Chen, Yingxia Shao, Yanyan Shen, Lei Chen, and Jiannong Cao. 2022.

</span>
<span class="ltx_bibblock">SANCUS: Staleness-Aware Communication-Avoiding Full-Graph Decentralized Training in Large-Scale Graph Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proc. VLDB Endow.</em> 15, 9 (2022), 1937â€“1950.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rossi etÂ al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Emanuele Rossi, Fabrizio Frasca, Ben Chamberlain, Davide Eynard, MichaelÂ M. Bronstein, and Federico Monti. 2020.

</span>
<span class="ltx_bibblock">SIGN: Scalable Inception Graph Neural Networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">CoRR</em> abs/2004.11198 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schlichtkrull etÂ al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
MichaelÂ Sejr Schlichtkrull, ThomasÂ N. Kipf, Peter Bloem, Rianne vanÂ den Berg, Ivan Titov, and Max Welling. 2018.

</span>
<span class="ltx_bibblock">Modeling Relational Data with Graph Convolutional Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">The Semantic Web - 15th International Conference, ESWC 2018, Heraklion, Crete, Greece, June 3-7, 2018, Proceedings</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao etÂ al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yingxia Shao, Hongzheng Li, Xizhi Gu, Hongbo Yin, Yawen Li, Xupeng Miao, Wentao Zhang, Bin Cui, and Lei Chen. 2022.

</span>
<span class="ltx_bibblock">Distributed Graph Neural Network Training: A Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">CoRR</em> abs/2211.00216 (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoeybi etÂ al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019.

</span>
<span class="ltx_bibblock">Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">CoRR</em> abs/1909.08053 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Spinelli etÂ al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Indro Spinelli, Simone Scardapane, and Aurelio Uncini. 2021.

</span>
<span class="ltx_bibblock">Adaptive Propagation Graph Convolutional Network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.3.1">IEEE Trans. Neural Networks Learn. Syst.</em> 32, 10 (2021), 4755â€“4760.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang etÂ al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Shanshan Tang, Bo Li, and Haijun Yu. 2019.

</span>
<span class="ltx_bibblock">ChebNet: Efficient and Stable Constructions of Deep Neural Networks with Rectified Power Units using Chebyshev Approximations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">CoRR</em> abs/1911.05467 (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tripathy etÂ al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Alok Tripathy, KatherineÂ A. Yelick, and Aydin BuluÃ§. 2020.

</span>
<span class="ltx_bibblock">Reducing communication in graph neural network training. In <em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2020, Virtual Event / Atlanta, Georgia, USA, November 9-19, 2020</em>. IEEE/ACM, 70.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Velickovic etÂ al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro LiÃ², and Yoshua Bengio. 2018.

</span>
<span class="ltx_bibblock">Graph Attention Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">6th International Conference on Learning Representations, ICLRâ€™18, Vancouver, BC, Canada, Conference Track Proceedings</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan etÂ al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Cheng Wan, Youjie Li, Ang Li, NamÂ Sung Kim, and Yingyan Lin. 2022a.

</span>
<span class="ltx_bibblock">BNS-GCN: Efficient Full-Graph Training of Graph Convolutional Networks with Partition-Parallelism and Random Boundary Node Sampling. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.3.1">Proceedings of Machine Learning and Systems 2022, MLSys 2022, Santa Clara, CA, USA, August 29 - September 1, 2022</em>. mlsys.org.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan etÂ al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Cheng Wan, Youjie Li, CameronÂ R. Wolfe, Anastasios Kyrillidis, NamÂ Sung Kim, and Yingyan Lin. 2022b.

</span>
<span class="ltx_bibblock">PipeGCN: Efficient Full-Graph Training of Graph Convolutional Networks with Pipelined Feature Communication. In <em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wan etÂ al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xinchen Wan, Kaiqiang Xu, Xudong Liao, Yilun Jin, Kai Chen, and Xin Jin. 2023.

</span>
<span class="ltx_bibblock">Scalable and Efficient Full-Graph GNN Training for Large Graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.3.1">Proc. ACM Manag. Data</em> 1, 2 (2023), 143:1â€“143:23.

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3589288" title="">https://doi.org/10.1145/3589288</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Boxiang Wang, Qifan Xu, Zhengda Bian, and Yang You. 2021.

</span>
<span class="ltx_bibblock">2.5-dimensional distributed model training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">CoRR</em> abs/2105.14500 (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Qiange Wang, Yao Chen, Weng-Fai Wong, and Bingsheng He. 2023.

</span>
<span class="ltx_bibblock">HongTu: Scalable Full-Graph GNN Training on Multiple GPUs (via communication-optimized CPU data offloading).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">CoRR</em> abs/2311.14898 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Qiange Wang, Yanfeng Zhang, Hao Wang, Chaoyi Chen, Xiaodong Zhang, and Ge Yu. 2022.

</span>
<span class="ltx_bibblock">NeutronStar: Distributed GNN Training with Hybrid Dependency Management. In <em class="ltx_emph ltx_font_italic" id="bib.bib44.3.1">International Conference on Management of Data, Philadelphia, SIGMODâ€™22, PA, USA</em>. ACM, 1301â€“1315.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weisstein (2003)</span>
<span class="ltx_bibblock">
EricÂ W Weisstein. 2003.

</span>
<span class="ltx_bibblock">Gershgorin circle theorem.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">https://mathworld. wolfram. com/</em> (2003).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Felix Wu, Amauri H.Â Souza Jr., Tianyi Zhang, Christopher Fifty, Tao Yu, and KilianÂ Q. Weinberger. 2019.

</span>
<span class="ltx_bibblock">Simplifying Graph Convolutional Networks. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA</em> <em class="ltx_emph ltx_font_italic" id="bib.bib46.4.2">(Proceedings of Machine Learning Research)</em>, Vol.Â 97. PMLR, 6861â€“6871.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019.

</span>
<span class="ltx_bibblock">How Powerful are Graph Neural Networks?. In <em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">7th International Conference on Learning Representations, ICLRâ€™2019, New Orleans, LA, USA, May 6-9, 2019</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu and You (2023)</span>
<span class="ltx_bibblock">
Qifan Xu and Yang You. 2023.

</span>
<span class="ltx_bibblock">An Efficient 2D Method for Training Super-Large Deep Learning Models. In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">IEEE International Parallel and Distributed Processing Symposium, IPDPS 2023, St. Petersburg, FL, USA, May 15-19, 2023</em>. IEEE, 222â€“232.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao etÂ al<span class="ltx_text" id="bib.bib49.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Liang Yao, Chengsheng Mao, and Yuan Luo. 2019.

</span>
<span class="ltx_bibblock">Graph Convolutional Networks for Text Classification. In <em class="ltx_emph ltx_font_italic" id="bib.bib49.3.1">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019</em>. AAAI Press, 7370â€“7377.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ying etÂ al<span class="ltx_text" id="bib.bib50.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, WilliamÂ L. Hamilton, and Jure Leskovec. 2018.

</span>
<span class="ltx_bibblock">Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib50.3.1">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining, KDDâ€™18, London, UK</em>. ACM, 974â€“983.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan etÂ al<span class="ltx_text" id="bib.bib51.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hao Yuan, Yajiong Liu, Yanfeng Zhang, Xin Ai, Qiange Wang, Chaoyi Chen, Yu Gu, and Ge Yu. 2023.

</span>
<span class="ltx_bibblock">Comprehensive Evaluation of GNN Training Systems: A Data Management Perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.3.1">CoRR</em> abs/2311.13279 (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span class="ltx_text" id="bib.bib52.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Dalong Zhang, Xin Huang, Ziqi Liu, Jun Zhou, Zhiyang Hu, Xianzheng Song, Zhibang Ge, Lin Wang, Zhiqiang Zhang, and Yuan Qi. 2020.

</span>
<span class="ltx_bibblock">AGL: A Scalable System for Industrial-purpose Graph Machine Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.3.1">Proc. VLDB Endow.</em> 13, 12 (2020), 3125â€“3137.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span class="ltx_text" id="bib.bib53.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Wentao Zhang, Ziqi Yin, Zeang Sheng, Yang Li, Wen Ouyang, Xiaosen Li, Yangyu Tao, Zhi Yang, and Bin Cui. 2022.

</span>
<span class="ltx_bibblock">Graph Attention Multi-Layer Perceptron. In <em class="ltx_emph ltx_font_italic" id="bib.bib53.3.1">KDD â€™22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022</em>. ACM, 4560â€“4570.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al<span class="ltx_text" id="bib.bib54.2.2.1">.</span> (2022a)</span>
<span class="ltx_bibblock">
Chenguang Zheng, Hongzhi Chen, Yuxuan Cheng, Zhezheng Song, Yifan Wu, Changji Li, James Cheng, Hao Yang, and Shuai Zhang. 2022a.

</span>
<span class="ltx_bibblock">ByteGNN: Efficient Graph Neural Network Training at Large Scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.3.1">Proc. VLDB Endow.</em> 15, 6 (2022), 1228â€“1242.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al<span class="ltx_text" id="bib.bib55.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Da Zheng, Chao Ma, Minjie Wang, Jinjing Zhou, Qidong Su, Xiang Song, Quan Gan, Zheng Zhang, and George Karypis. 2020.

</span>
<span class="ltx_bibblock">DistDGL: Distributed Graph Neural Network Training for Billion-Scale Graphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib55.3.1">10th IEEE/ACM Workshop on Irregular Applications: Architectures and Algorithms, IA3 2020, Atlanta, GA, USA, November 11, 2020</em>. IEEE, 36â€“44.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al<span class="ltx_text" id="bib.bib56.2.2.1">.</span> (2022b)</span>
<span class="ltx_bibblock">
Da Zheng, Xiang Song, Chengru Yang, Dominique LaSalle, and George Karypis. 2022b.

</span>
<span class="ltx_bibblock">Distributed Hybrid CPU and GPU training for Graph Neural Networks on Billion-Scale Heterogeneous Graphs. In <em class="ltx_emph ltx_font_italic" id="bib.bib56.3.1">KDD â€™22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022</em>. ACM, 4582â€“4591.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng etÂ al<span class="ltx_text" id="bib.bib57.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yanping Zheng, Zhewei Wei, and Jiajun Liu. 2023.

</span>
<span class="ltx_bibblock">Decoupled Graph Neural Networks for Large Dynamic Graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.3.1">Proc. VLDB Endow.</em> 16, 9 (2023), 2239â€“2247.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al<span class="ltx_text" id="bib.bib58.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, and Maosong Sun. 2020.

</span>
<span class="ltx_bibblock">Graph neural networks: A review of methods and applications.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.3.1">AI Open</em> 1 (2020), 57â€“81.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al<span class="ltx_text" id="bib.bib59.2.2.1">.</span> (2019)</span>
<span class="ltx_bibblock">
Rong Zhu, Kun Zhao, Hongxia Yang, Wei Lin, Chang Zhou, Baole Ai, Yong Li, and Jingren Zhou. 2019.

</span>
<span class="ltx_bibblock">AliGraph: A Comprehensive Graph Neural Network Platform.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.3.1">Proc. VLDB Endow.</em> 12, 12 (2019), 2094â€“2105.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Dec 27 06:32:31 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
