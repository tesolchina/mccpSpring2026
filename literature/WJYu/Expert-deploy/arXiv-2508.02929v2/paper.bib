
@article{bommasani_opportunities_2021,
	title = {On the opportunities and risks of foundation models},
	journal = {arXiv preprint arXiv:2108.07258},
	author = {Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and {others}},
	year = {2021},
}

@inproceedings{liang_external_2025,
	title = {External large foundation model: {How} to efficiently serve trillions of parameters for online ads recommendation},
	booktitle = {Companion {Proceedings} of the {ACM} on {Web} {Conference} 2025},
	author = {Liang, Mingfu and Liu, Xi and Jin, Rong and Liu, Boyang and Suo, Qiuling and Zhou, Qinghai and Zhou, Song and Chen, Laming and Zheng, Hua and Li, Zhiyuan and {others}},
	year = {2025},
	pages = {344--353},
}

@inproceedings{zhang_scaling_2024,
	title = {Scaling {User} {Modeling}: {Large}-scale {Online} {User} {Representations} for {Ads} {Personalization} in {Meta}},
	booktitle = {Companion {Proceedings} of the {ACM} {Web} {Conference} 2024},
	author = {Zhang, Wei and Li, Dai and Liang, Chen and Zhou, Fang and Zhang, Zhongke and Wang, Xuewei and Li, Ru and Zhou, Yi and Huang, Yaning and Liang, Dong and {others}},
	year = {2024},
	pages = {47--55},
}

@inproceedings{rasul_lag-llama_2023,
	title = {Lag-llama: {Towards} foundation models for time series forecasting},
	booktitle = {R0-{FoMo}: {Robustness} of {Few}-shot and {Zero}-shot {Learning} in {Large} {Foundation} {Models}},
	author = {Rasul, Kashif and Ashok, Arjun and Williams, Andrew Robert and Khorasani, Arian and Adamopoulos, George and Bhagwatkar, Rishika and Biloš, Marin and Ghonia, Hena and Hassen, Nadhir and Schneider, Anderson and {others}},
	year = {2023},
}

@article{brown_language_2020,
	title = {Language models are few-shot learners},
	volume = {33},
	journal = {Advances in neural information processing systems},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and {others}},
	year = {2020},
	pages = {1877--1901},
}

@inproceedings{devlin_bert_2019,
	title = {Bert: {Pre}-training of deep bidirectional transformers for language understanding},
	booktitle = {Proceedings of the 2019 conference of the {North} {American} chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	year = {2019},
	pages = {4171--4186},
}

@inproceedings{radford_learning_2021,
	title = {Learning transferable visual models from natural language supervision},
	booktitle = {International conference on machine learning},
	publisher = {PmLR},
	author = {Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and {others}},
	year = {2021},
	pages = {8748--8763},
}

@inproceedings{kirillov_segment_2023,
	title = {Segment anything},
	booktitle = {Proceedings of the {IEEE}/{CVF} international conference on computer vision},
	author = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and {others}},
	year = {2023},
	pages = {4015--4026},
}

@inproceedings{liang_foundation_2024,
	title = {Foundation models for time series analysis: {A} tutorial and survey},
	booktitle = {Proceedings of the 30th {ACM} {SIGKDD} conference on knowledge discovery and data mining},
	author = {Liang, Yuxuan and Wen, Haomin and Nie, Yuqi and Jiang, Yushan and Jin, Ming and Song, Dongjin and Pan, Shirui and Wen, Qingsong},
	year = {2024},
	pages = {6555--6565},
}

@article{zhai_actions_2024,
	title = {Actions speak louder than words: {Trillion}-parameter sequential transducers for generative recommendations},
	journal = {arXiv preprint arXiv:2402.17152},
	author = {Zhai, Jiaqi and Liao, Lucy and Liu, Xing and Wang, Yueming and Li, Rui and Cao, Xuan and Gao, Leon and Gong, Zhaojie and Gu, Fangda and He, Michael and {others}},
	year = {2024},
}

@article{hertel_efficient_2024,
	title = {Efficient user history modeling with amortized inference for deep learning recommendation models},
	journal = {arXiv preprint arXiv:2412.06924},
	author = {Hertel, Lars and Daftary, Neil and Borisyuk, Fedor and Gupta, Aman and Mazumder, Rahul},
	year = {2024},
}

@article{chai_longer_2025,
	title = {{LONGER}: {Scaling} {Up} {Long} {Sequence} {Modeling} in {Industrial} {Recommenders}},
	journal = {arXiv preprint arXiv:2505.04421},
	author = {Chai, Zheng and Ren, Qin and Xiao, Xijun and Yang, Huizhi and Han, Bo and Zhang, Sijun and Chen, Di and Lu, Hui and Zhao, Wenlin and Yu, Lele and {others}},
	year = {2025},
}

@article{huang_towards_2025,
	title = {Towards {Large}-scale {Generative} {Ranking}},
	journal = {arXiv preprint arXiv:2505.04180},
	author = {Huang, Yanhua and Chen, Yuqi and Cao, Xiong and Yang, Rui and Qi, Mingliang and Zhu, Yinghao and Han, Qingchang and Liu, Yaowei and Liu, Zhaoyu and Yao, Xuefeng and {others}},
	year = {2025},
}

@article{wang_scaling_2025,
	title = {Scaling {Transformers} for {Discriminative} {Recommendation} via {Generative} {Pretraining}},
	journal = {arXiv preprint arXiv:2506.03699},
	author = {Wang, Chunqi and Wu, Bingchao and Chen, Zheng and Shen, Lei and Wang, Bing and Zeng, Xiaoyi},
	year = {2025},
}

@article{pfeiffer_modular_2023,
	title = {Modular {Deep} {Learning}},
	issn = {2835-8856},
	url = {https://openreview.net/forum?id=z9EkXfvxta},
	journal = {Transactions on Machine Learning Research},
	author = {Pfeiffer, Jonas and Ruder, Sebastian and Vulić, Ivan and Ponti, Edoardo},
	year = {2023},
}

@article{hu_lora_2022,
	title = {Lora: {Low}-rank adaptation of large language models.},
	volume = {1},
	number = {2},
	journal = {ICLR},
	author = {Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and {others}},
	year = {2022},
	pages = {3},
}

@article{raffel_exploring_2020,
	title = {Exploring the limits of transfer learning with a unified text-to-text transformer},
	volume = {21},
	number = {140},
	journal = {Journal of machine learning research},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	year = {2020},
	pages = {1--67},
}

@article{hinton_distilling_2015,
	title = {Distilling the knowledge in a neural network},
	journal = {arXiv preprint arXiv:1503.02531},
	author = {Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	year = {2015},
}

@inproceedings{busbridge_distillation_2025,
	title = {Distillation {Scaling} {Laws}},
	url = {https://openreview.net/forum?id=1nEBAkpfb9},
	booktitle = {Forty-second {International} {Conference} on {Machine} {Learning}},
	author = {Busbridge, Dan and Shidani, Amitis and Weers, Floris and Ramapuram, Jason and Littwin, Etai and Webb, Russell},
	year = {2025},
}

@article{luo_empirical_2023,
	title = {An empirical study of catastrophic forgetting in large language models during continual fine-tuning},
	journal = {arXiv preprint arXiv:2308.08747},
	author = {Luo, Yun and Yang, Zhen and Meng, Fandong and Li, Yafu and Zhou, Jie and Zhang, Yue},
	year = {2023},
}

@inproceedings{kumar_fine-tuning_2022,
	title = {Fine-{Tuning} can {Distort} {Pretrained} {Features} and {Underperform} {Out}-of-{Distribution}},
	url = {https://openreview.net/forum?id=UYneFzXSJWh},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Kumar, Ananya and Raghunathan, Aditi and Jones, Robbie Matthew and Ma, Tengyu and Liang, Percy},
	year = {2022},
}

@inproceedings{he2014practical,
  title={Practical lessons from predicting clicks on ads at facebook},
  author={He, Xinran and Pan, Junfeng and Jin, Ou and Xu, Tianbing and Liu, Bo and Xu, Tao and Shi, Yanxin and Atallah, Antoine and Herbrich, Ralf and Bowers, Stuart and others},
  booktitle={Proceedings of the eighth international workshop on data mining for online advertising},
  pages={1--9},
  year={2014}
}

@inproceedings{sum,
author = {Zhang, Wei and Li, Dai and Liang, Chen and Zhou, Fang and Zhang, Zhongke and Wang, Xuewei and Li, Ru and Zhou, Yi and Huang, Yaning and Liang, Dong and Wang, Kai and Wang, Zhangyuan and Chen, Zhengxing and Wu, Fenggang and Chen, Minghai and Li, Huayu and Wu, Yunnan and Shu, Zhan and Yuan, Mindi and Reddy, Sri},
title = {Scaling User Modeling: Large-scale Online User Representations for Ads Personalization in Meta},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3648301},
doi = {10.1145/3589335.3648301},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {47–55},
numpages = {9},
keywords = {online advertising, personalization, user representation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{rebuffi_learning_2017,
	title = {Learning multiple visual domains with residual adapters},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/e7b24b112a44fdd9ee93bdf998c6ca0e-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
	editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
	year = {2017},
}

@inproceedings{pfeiffer_mad-x_2020,
	address = {Online},
	title = {{MAD}-{X}: {An} {Adapter}-{Based} {Framework} for {Multi}-{Task} {Cross}-{Lingual} {Transfer}},
	url = {https://aclanthology.org/2020.emnlp-main.617/},
	doi = {10.18653/v1/2020.emnlp-main.617},
	abstract = {The main goal behind state-of-the-art pre-trained multilingual models such as multilingual BERT and XLM-R is enabling and bootstrapping NLP applications in low-resource languages through zero-shot or few-shot cross-lingual transfer. However, due to limited model capacity, their transfer performance is the weakest exactly on such low-resource languages and languages unseen during pre-training. We propose MAD-X, an adapter-based framework that enables high portability and parameter-efficient transfer to arbitrary tasks and languages by learning modular language and task representations. In addition, we introduce a novel invertible adapter architecture and a strong baseline method for adapting a pre-trained multilingual model to a new language. MAD-X outperforms the state of the art in cross lingual transfer across a representative set of typologically diverse languages on named entity recognition and causal commonsense reasoning, and achieves competitive results on question answering. Our code and adapters are available at AdapterHub.ml.},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Pfeiffer, Jonas and Vulić, Ivan and Gurevych, Iryna and Ruder, Sebastian},
	editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
	month = nov,
	year = {2020},
	pages = {7654--7673},
}

@inproceedings{cheng_wide_2016,
	title = {Wide \& deep learning for recommender systems},
	booktitle = {Proceedings of the 1st workshop on deep learning for recommender systems},
	author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and {others}},
	year = {2016},
	pages = {7--10},
}

@inproceedings{el2022twhin,
  title={Twhin: Embedding the twitter heterogeneous information network for personalized recommendation},
  author={El-Kishky, Ahmed and Markovich, Thomas and Park, Serim and Verma, Chetan and Kim, Baekjin and Eskander, Ramy and Malkov, Yury and Portman, Frank and Samaniego, Sof{\'\i}a and Xiao, Ying and others},
  booktitle={Proceedings of the 28th ACM SIGKDD conference on knowledge discovery and data mining},
  pages={2842--2850},
  year={2022}
}

@inproceedings{pinsage,
author = {Ying, Rex and He, Ruining and Chen, Kaifeng and Eksombatchai, Pong and Hamilton, William L. and Leskovec, Jure},
title = {Graph Convolutional Neural Networks for Web-Scale Recommender Systems},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219890},
doi = {10.1145/3219819.3219890},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {974–983},
numpages = {10},
keywords = {recommender systems, scalability, deep learning, graph convolutional networks},
location = {London, United Kingdom},
series = {KDD '18}
}

@inproceedings{itemsage,
author = {Baltescu, Paul and Chen, Haoyu and Pancha, Nikil and Zhai, Andrew and Leskovec, Jure and Rosenberg, Charles},
title = {ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539170},
doi = {10.1145/3534678.3539170},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2703–2711},
numpages = {9},
keywords = {multi-task learning, multi-modal learning, representation learning, recommender systems},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{tencent,
author = {Zhang, Junqi and Bai, Bing and Lin, Ye and Liang, Jian and Bai, Kun and Wang, Fei},
title = {General-Purpose User Embeddings Based on Mobile App Usage},
year = {2020},
isbn = {9781450379984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3394486.3403334},
doi = {10.1145/3394486.3403334},
booktitle = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {2831–2840},
numpages = {10},
keywords = {embeddings, autoencoder, app usage, user modeling, transformer},
location = {Virtual Event, CA, USA},
series = {KDD '20}
}

@inproceedings{ali,
author = {Pi, Qi and Bian, Weijie and Zhou, Guorui and Zhu, Xiaoqiang and Gai, Kun},
title = {Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330666},
doi = {10.1145/3292500.3330666},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {2671–2679},
numpages = {9},
keywords = {user behavior modeling, click-through rate prediction},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@misc{dv365,
      title={DV365: Extremely Long User History Modeling at Instagram}, 
      author={Wenhan Lyu and Devashish Tyagi and Yihang Yang and Ziwei Li and Ajay Somani and Karthikeyan Shanmugasundaram and Nikola Andrejevic and Ferdi Adeputra and Curtis Zeng and Arun K. Singh and Maxime Ransan and Sagar Jain},
      year={2025},
      eprint={2506.00450},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2506.00450}, 
}

@inproceedings{chang2023twin,
  title={TWIN: TWo-stage interest network for lifelong user behavior modeling in CTR prediction at kuaishou},
  author={Chang, Jianxin and Zhang, Chenbin and Fu, Zhiyi and Zang, Xiaoxue and Guan, Lin and Lu, Jing and Hui, Yiqun and Leng, Dewei and Niu, Yanan and Song, Yang and others},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={3785--3794},
  year={2023}
}

@inproceedings{twinv2, series={CIKM ’24},
   title={TWIN V2: Scaling Ultra-Long User Behavior Sequence Modeling for Enhanced CTR Prediction at Kuaishou},
   url={http://dx.doi.org/10.1145/3627673.3680030},
   DOI={10.1145/3627673.3680030},
   booktitle={Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
   publisher={ACM},
   author={Si, Zihua and Guan, Lin and Sun, Zhongxiang and Zang, Xiaoxue and Lu, Jing and Hui, Yiqun and Cao, Xingchao and Yang, Zeyu and Zheng, Yichen and Leng, Dewei and Zheng, Kai and Zhang, Chenbin and Niu, Yanan and Song, Yang and Gai, Kun},
   year={2024},
   month=oct, pages={4890–4897},
   collection={CIKM ’24} }


@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}
@article{zhang2024wukong,
  title={Wukong: Towards a scaling law for large-scale recommendation},
  author={Zhang, Buyun and Luo, Liang and Chen, Yuxin and Nie, Jade and Liu, Xi and Guo, Daifeng and Zhao, Yanli and Li, Shen and Hao, Yuchen and Yao, Yantao and others},
  journal={arXiv preprint arXiv:2403.02545},
  year={2024}
}
@article{han2025mtgr,
  title={MTGR: Industrial-Scale Generative Recommendation Framework in Meituan},
  author={Han, Ruidong and Yin, Bin and Chen, Shangyu and Jiang, He and Jiang, Fei and Li, Xiang and Ma, Chi and Huang, Mincong and Li, Xiaoguang and Jing, Chunzhen and others},
  journal={arXiv preprint arXiv:2505.18654},
  year={2025}
}

@article{chen2025pinfm,
  title={PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform},
  author={Chen, Xiangyi and Rajesh, Kousik and Lawhon, Matthew and Wang, Zelun and Li, Hanyu and Li, Haomiao and Joshi, Saurabh Vishwas and Eksombatchai, Pong and Yang, Jaewon and Hsu, Yi-Ping and others},
  journal={arXiv preprint arXiv:2507.12704},
  year={2025}
}

@inproceedings{kd_google_transfer_ratio,
author = {Khani, Nikhil and Wei, Li and Nath, Aniruddh and Andrews, Shawn and Yang, Shuo and Liu, Yang and Abbo, Pendo and Kula, Maciej and Kahn, Jarrod and Zhao, Zhe and Hong, Lichan and Chi, Ed},
title = {Bridging the Gap: Unpacking the Hidden Challenges in Knowledge Distillation for Online Ranking Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688055},
doi = {10.1145/3640457.3688055},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {758–761},
numpages = {4},
keywords = {Knowledge Distillation, Learning to Rank, Multitask Learning, Recommender Systems},
location = {Bari, Italy},
series = {RecSys '24}
}
@article{gou2021knowledge,
  title={Knowledge distillation: A survey},
  author={Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
  journal={International journal of computer vision},
  volume={129},
  number={6},
  pages={1789--1819},
  year={2021},
  publisher={Springer}
}

@book{casella_statistical_2001,
	address = {CA, USA},
	edition = {2nd ed.},
	title = {Statistical {Inference}},
	publisher = {Duxbury Press},
	author = {Casella, George and Berger, Roger L.},
	year = {2001},
}
