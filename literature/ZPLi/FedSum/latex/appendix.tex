\label{Appendix}
    
\section{Experimental Setup Details}
    \paragraph{Computing infrastructure}
    All experiments were performed using PyTorch 2.1.0 with NVIDIA GeForce RTX 3090 24GB GPU. The ROUGE scores are calculated by a third-party Python library called rouge, using version 1.0.1.
    
    \paragraph{Description of datasets}
        To have an impartial result, we experiment on four widely used benchmark datasets, Reddit, CNN/DailyMail, WikiHow, and PubMed.
        Table \ref{tb:dataset} presents an overview of these datasets.
        Specifically,
        % Reddit
        The Reddit dataset contains 120K posts of informal stories from the online discussion forum Reddit, more specifically the TIFU sub-reddit from 2013-Jan to 2018-Mar.
        We use the TIFU-long subset (using TLDR as summaries) in this work.
        % CNN/DM
        The CNN/DailyMail dataset consists of news articles and their human-written abstracts collected from CNN and Daily Mail websites. 
        Both publishers supplement their articles with bullet point summaries, which are considered as ground truth summaries.
        % WikiHow
        The WikiHow dataset is a comprehensive collection of instructional articles obtained from the WikiHow website. 
        The articles are not written by professional journalists but by ordinary individuals, detailing the steps required to perform a specific task. 
        % PubMed
        The PubMed dataset is a well-known dataset for long documents that focus on biomedical research. 
        The dataset includes large scientific articles and abstracts that have been labeled by humans. \\
        
        
        \begin{table*}[htbp]
        % 放附录
            \centering
            \begin{tabular}{ccccc}
            \hline
            Dataset & Domain & \# Docs (train/val/test) & Doc./Sum. Avg. Length & \# Ext\\
            \hline
            Reddit & Social Media &(41,675/645/645) & 482.2/28.0 & 2\\
            CNN/DM & News &(287,227/13,368/11,490) & 679.3/48.3 & 3\\
            WikiHow & Knowledge instruction &(157,252/5,599/5,577) & 502.6/45.6  &  4\\
            PubMed & Medicine &(83,233/4,946/5,025) & 3,049.0/202.4 & 6\\
            \hline
            \end{tabular}
            
            \caption{Comparison of summarization datasets in different domains: the size of dataset, the average length of source and target. \# Ext denotes the number of sentences that should be extracted from source data.}
            \label{tb:dataset}
        \end{table*}


    \paragraph{Baselines}
        In this paper, we adopt the following state-of-the-art algorithms as our baselines, which are designed for the problems of heterogeneity and data scarcity:
    \begin{itemize}
        \item Separate: To observe the effect of server aggregation, we also adopt the separate training setting, where each client updates their model by only local training.
        
        \item FedAvg \cite{mcmahan2017communication}: the original FL algorithm which does not consider performance degeneration in data scarcity.
        
        
        \item FedProx \cite{FedProx}: the representative FL algorithm for tackling the statistical heterogeneous problem by solving an optimization object with regularization constrain. 
        We compare the performance of FedProx to verify the effectiveness of FedSum in tackling heterogeneous problems.  
        
        \item Scaffold \cite{SCAFFOLD}: the FL algorithm for the statistical heterogeneous problem by constructing regularization term with aggregated variate.
        We set Scaffold in our comparative group to observe the impact of statistical heterogeneity.

        % 消除由于数据异质性导致的目标不一致性
        \item FedNova \cite{FedNova}: the FL algorithm that introduces a normalizing weight to eliminate the objective inconsistency. We compare FedNova to verify our effectiveness in dealing with data heterogeneity issues.

        \item FedProto \cite{FedProto}: the typical FL algorithm that introduces the concept of prototype learning. We analyze FedProto to evaluate the effectiveness of our approach in introducing prototypes and learning knowledge from multi-source.

        \item FedDC \cite{FedDC}: the FL algorithm that interleaving model aggregation and permutation steps. We included FedDC in our comparative group to demonstrate the effectiveness of our approach in data scarcity scenarios.


        To better observe the difference between centralized and federated paradigms, we also simulate centralized and separated methods.
        The centralized can access all training samples, and the separated takes the average of performance over FL clients, which perform supervised training as shown in Fig.\ref{fig:ExtSum}.
        \begin{figure}[phtb]
            \centering
            \includegraphics[width=0.45\columnwidth]{latex/fig/ExtSum.png}
            \caption{The standard training process of ExtSum task.}
            \label{fig:ExtSum}
        \end{figure}
    \end{itemize}
        
    \noindent {\bf Measurement.}
    To measure the quality of the output summary, we apply the commonly used overlap metric ROUGE \cite{lin-2004-rouge}. ROUGE evaluates the quality of exacted summaries by comparing the overlap between the reference and generated text at word level. In this paper, we report the ROUGE-N and ROUGE-L for a more comprehensive evaluation. ROUGE-N evaluates the quality through n-gram overlap, while ROUGE-L focuses on the longest common subsequence. To further capture lexical similarity, we report the ROUGE-Recall and ROUGE-F1 of ROUGE-1, ROUGE-2 and ROUGE-L.
    \begin{itemize}    
        \item ROUGE-Recall measures the proportion of matching n-grams in the generated text to those in the reference text. It focuses on evaluating whether the exacted summaries cover the significant information in the reference text. The formula is shown below:
        % \begin{equation}
        %     ROUGE\text{-}R = \frac{\sum_{s \in S}\sum_{gram_n \in s} \min(Count(gram_n, s), Count(gram_n, C))}{\sum_{s \in S}\sum_{gram_n \in s} Count(gram_n, s)}
        % \end{equation}
        \begin{equation}
            \text{ROUGE-Recall}=\frac{|\text{n-gram}_{\text{match}}|}{|\text{n-gram}_{\text{ref}}|}
            \label{eq: ROUGE-R}
        \end{equation}
        where $|\text{n-gram}_{\text{match}}|$ means the frequency of co-occurring n-grams between generated and reference text, $|\text{n-gram}_{\text{ref}}|$ means the number of total \text{n-grams} in the reference text.
        \item ROUGE-F1 combines ROUGE-Recall and ROUGE-Precision, comprehensively considers both coverage and accuracy of the generated text, as shown below:
        \begin{equation}
            \text{ROUGE-F1}=2\times\frac{\text{ROUGE-Recall}\times\text{ROUGE-Precision}}{\text{ROUGE-Recall}+\text{ROUGE-Precision}}
        \end{equation}
        where ROUGE-Precision is formulated as:
        \begin{equation}
            \text{ROUGE-Precision}=\frac{|\text{n-gram}_{\text{match}}|}{|\text{n-gram}_{\text{gen}}|}
        \end{equation}
        the meaning of $|\text{n-gram}_{\text{match}}|$ and $|\text{n-gram}_{\text{gen}}|$ is similar to Equation~\ref{eq: ROUGE-R}.
        
    \end{itemize}
    

    \noindent {\bf Hyperparameters.}
    We follow the hyperparameter setting proposed in several works \cite{sun-etal-2019-utilizing, Cohan_2019, zhong-etal-2020-extractive,liu2021simcls,lin2022fednlp}.
    We set communication round $T$ as 5, local epoch $E$ as 2, client number $K$ as 20, active ratio $\alpha$ as 0.2, and local batch size $B$ as 32.
    The hyperparameter of regularization term $\mu$ in FedProx \cite{FedProx} and Scaffold \cite{SCAFFOLD} are tuned in \{0.01, 0.1, 0.5, 1, 2\}, and we set $\mu=1$ according to the optimal result.
    Specifically, we set $\lambda$ as $0.5$. 
    If need to increase the attention to leading bias, then $\lambda$ can be smaller, and vice versa.
    The dropout rate of Bernoulli perturbation $\gamma$ is 0.3.
    Besides, we study the effect of different learning rates on performance.
    The results are presented in the following content and we set $\eta$ as 5e-3 for all methods according to the result.
    
\newpage

\section{Additional Numerical Experiments}
    \paragraph{Result Summary}
        To observe the effects of federated learning, we introduced a centralized setting, where all data is centralized storage, and a single global model is trained on a central server. In this setting, we temporarily set aside data privacy concerns and focus on performance evaluation. As shown in Table~\ref{Table: Centralized Method}, the global model trained by the central server faces a risk of overfitting with the number of epochs increases, leading to a decline in performance. We can observe that when the number of epochs increases from 20 to 30, the Mean ROUGE-R-1 score for CNNDM decreases 5.63.
        \begin{table*}[htbp]
  \centering
  \resizebox{1\textwidth}{!}{   
  \begin{tabular}{|c|cc|cc|cc|}
\hline
\textbf{Centralized} &
  \multicolumn{2}{c|}{\textbf{Epoch=10}} &
  \multicolumn{2}{c|}{\textbf{Epoch=20}} &
  \multicolumn{2}{c|}{\textbf{Epoch=30}} \\ \hline
\textbf{CNNDM} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} \\ \hline
R-F(1/2/L) &
  \multicolumn{1}{c|}{33.92/12.79/26.77} &
  25.74/15.02/21.13 &
  \multicolumn{1}{c|}{33.94/12.56/26.52} &
  10.32/7.57/8.17 &
  \multicolumn{1}{c|}{29.4/8.86/22.54} &
  0.05/0.05/0.05 \\ \hline
R-R(1/2/L) &
  \multicolumn{1}{c|}{41.74/16.59/33.04} &
  54.04/30.39/42.68 &
  \multicolumn{1}{c|}{41.37/16.05/32.44} &
  18.61/13.67/14.56 &
  \multicolumn{1}{c|}{35.74/11.27/27.51} &
  0.13/0.09/0.11 \\ \hline
\textbf{PubMed} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} \\ \hline
R-F(1/2/L) &
  \multicolumn{1}{c|}{33.35/12.91/30.11} &
  0.0/0.0/0.0 &
  \multicolumn{1}{c|}{31.16/10.85/27.99} &
  0.01/0.01/0.01 &
  \multicolumn{1}{c|}{31.67/11.28/28.46} &
  0.84/0.87/0.82 \\ \hline
R-R(1/2/L) &
  \multicolumn{1}{c|}{35.29/13.43/31.84} &
  0.0/0.0/0.0 &
  \multicolumn{1}{c|}{32.86/11.2/29.48} &
  0.01/0.02/0.01 &
  \multicolumn{1}{c|}{33.41/11.65/29.99} &
  1.08/1.06/1.04 \\ \hline
\textbf{WikiHow} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} \\ \hline
R-F(1/2/L) &
  \multicolumn{1}{c|}{23.09/5.24/21.44} &
  0.39/0.11/0.35 &
  \multicolumn{1}{c|}{23.03/5.16/21.37} &
  0.03/0.01/0.03 &
  \multicolumn{1}{c|}{22.8/5.09/21.17} &
  0.32/0.07/0.28 \\ \hline
R-R(1/2/L) &
  \multicolumn{1}{c|}{34.2/8.62/31.9} &
  0.68/0.29/0.6 &
  \multicolumn{1}{c|}{33.87/8.44/31.59} &
  0.04/0.01/0.04 &
  \multicolumn{1}{c|}{33.56/8.29/31.32} &
  0.38/0.15/0.33 \\ \hline
\textbf{Reddit} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} &
  \multicolumn{1}{c|}{\textbf{Mean}} &
  \textbf{Var.} \\ \hline
R-F(1/2/L) &
  \multicolumn{1}{c|}{17.9/3.2/15.16} &
  0.0/0.0/0.0 &
  \multicolumn{1}{c|}{17.9/3.21/15.18} &
  0.0/0.0/0.01 &
  \multicolumn{1}{c|}{17.97/3.24/15.22} &
  0.02/0.0/0.02 \\ \hline
R-R(1/2/L) &
  \multicolumn{1}{c|}{41.68/9.12/35.92} &
  0.02/0.0/0.02 &
  \multicolumn{1}{c|}{41.72/9.18/35.99} &
  0.03/0.02/0.06 &
  \multicolumn{1}{c|}{41.91/9.26/36.1} &
  0.2/0.06/0.17 \\ \hline
\end{tabular}
  }
  \caption{Experimental results with centralized setting on four datasets. The mean and variance of three optimal results for each method are presented.}
  \label{Table: Centralized Method}
\end{table*}
        

    
        To evaluate the performance of each algorithm on four different datasets, we construct several sets of experiments with different levels of heterogeneity.           
        Since the performance fluctuation caused by various random sampling in FL is inevitable, we report the mean and variance of the ROUGE-Recall scores about different algorithms over 3 repeated to avoid the unfair comparison caused by random factors in practice and hyperparameter settings.
        Specifically, for a fair comparison, we pick the most optimal performance (with better ROUGE-1 values) from testing records in each communication round for each algorithm.
        As shown in experimental results (see Table \ref{Table: CNNDM full result summary}-\ref{Table: Reddit full result summary}), FedSum outperforms other baseline methods in most cases and shows a satisfactory level of ROUGE-Recall in most cases, under different heterogeneity scenarios. 
        These results support the effectiveness of our proposed method.

        
        \begin{table*}[htpb]
            \centering
            \resizebox{1\textwidth}{!}{   
            \begin{tabular}{|c|c|cc|cc|cc|cc|cc|}
            \hline
            \textbf{CNNDM} &
              \multirow{2}{*}{\textbf{Method}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.5$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=8$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=+\infty$}} \\ \cline{1-1} \cline{3-12} 
            \textbf{Metric} &
               &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} \\ \hline
            \multirow{8}{*}{\textbf{R-F(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{32.21/11.52/25.38} &
              0.88/0.74/0.87 &
              \multicolumn{1}{c|}{33.38/12.33/26.47} &
              1.03/0.98/1.16 &
              \multicolumn{1}{c|}{31.88/11.21/25.07} &
              1.06/0.89/1.02 &
              \multicolumn{1}{c|}{30.72/10.17/23.85} &
              2.13/1.72/1.98 &
              \multicolumn{1}{c|}{31.59/10.87/24.72} &
              0.45/0.37/0.43 \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{34.11/12.87/27.17} &
              0.88/0.62/0.84 &
              \multicolumn{1}{c|}{33.08/12.22/26.19} &
              2.27/1.8/2.22 &
              \multicolumn{1}{c|}{33.39/12.39/26.48} &
              0.53/0.42/0.48 &
              \multicolumn{1}{c|}{34.08/13.04/27.26} &
              0.18/0.13/0.18 &
              \multicolumn{1}{c|}{\textbf{33.3/12.32/26.44}} &
              1.22/1.0/1.24 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{35.32/13.85/28.44} &
              0.55/0.47/0.59 &
              \multicolumn{1}{c|}{31.27/10.37/24.34} &
              2.28/2.05/2.27 &
              \multicolumn{1}{c|}{33.77/12.56/26.85} &
              1.48/1.26/1.52 &
              \multicolumn{1}{c|}{34.25/13.05/27.34} &
              0.35/0.21/0.31 &
              \multicolumn{1}{c|}{30.71/10.3/23.9} &
              2.2/1.71/2.0 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{30.96/10.33/24.13} &
              1.14/0.66/0.89 &
              \multicolumn{1}{c|}{32.29/11.57/25.43} &
              1.01/0.81/1.01 &
              \multicolumn{1}{c|}{32.02/11.37/25.25} &
              2.15/1.67/2.07 &
              \multicolumn{1}{c|}{33.58/12.65/26.79} &
              0.45/0.34/0.45 &
              \multicolumn{1}{c|}{32.97/12.06/26.1} &
              1.17/0.86/1.11 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{32.91/11.87/25.98} &
              2.43/2.13/2.39 &
              \multicolumn{1}{c|}{31.05/10.32/24.18} &
              1.96/1.74/1.92 &
              \multicolumn{1}{c|}{34.13/12.98/27.17} &
              0.22/0.22/0.2 &
              \multicolumn{1}{c|}{\textbf{36.01/14.38/29.05}} &
              0.32/0.24/0.33 &
              \multicolumn{1}{c|}{33.1/12.14/26.21} &
              1.52/1.3/1.6 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{33.39/12.47/26.48} &
              0.57/0.45/0.49 &
              \multicolumn{1}{c|}{31.53/10.44/24.44} &
              1.5/1.26/1.39 &
              \multicolumn{1}{c|}{32.91/12.07/26.01} &
              0.13/0.13/0.13 &
              \multicolumn{1}{c|}{33.48/12.53/26.57} &
              \textbf{0.11/0.09/0.09} &
              \multicolumn{1}{c|}{33.36/12.42/26.45} &
              \textbf{0.03/0.02/0.03} \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{31.04/10.54/24.18} &
              \textbf{0.09/0.07/0.08} &
              \multicolumn{1}{c|}{31.09/10.57/24.21} &
              \textbf{0.1/0.1/0.1} &
              \multicolumn{1}{c|}{30.96/10.45/24.09} &
              \textbf{0.13/0.11/0.14} &
              \multicolumn{1}{c|}{31.08/10.58/24.24} &
              0.07/0.04/0.07 &
              \multicolumn{1}{c|}{31.23/10.68/24.35} &
              0.11/0.08/0.11 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{35.71/14.18/28.69}} &
              0.65/0.5/0.5 &
              \multicolumn{1}{c|}{\textbf{33.8/12.65/26.89}} &
              1.44/1.07/1.38 &
              \multicolumn{1}{c|}{\textbf{35.33/13.86/28.4}} &
              0.38/0.18/0.3 &
              \multicolumn{1}{c|}{35.13/13.56/28.13} &
              0.57/0.53/0.6 &
              \multicolumn{1}{c|}{32.73/11.59/25.77} &
              2.0/1.82/2.04 \\ \hline
            \multirow{8}{*}{\textbf{R-R(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{39.7/14.8/31.35} &
              1.36/1.06/1.29 &
              \multicolumn{1}{c|}{41.56/16.05/33.02} &
              1.63/1.41/1.71 &
              \multicolumn{1}{c|}{39.34/14.43/31.0} &
              1.57/1.26/1.46 &
              \multicolumn{1}{c|}{37.53/12.99/29.23} &
              3.14/2.4/2.84 &
              \multicolumn{1}{c|}{38.77/13.92/30.41} &
              0.57/0.47/0.52 \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{42.8/16.92/34.15} &
              1.42/0.99/1.3 &
              \multicolumn{1}{c|}{40.81/15.75/32.39} &
              3.41/2.56/3.21 &
              \multicolumn{1}{c|}{41.62/16.15/33.07} &
              0.76/0.6/0.67 &
              \multicolumn{1}{c|}{42.66/17.07/34.17} &
              0.27/0.19/0.25 &
              \multicolumn{1}{c|}{\textbf{41.46/16.05/32.99}} &
              1.9/1.47/1.83 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{44.64/18.38/35.99} &
              0.84/0.69/0.84 &
              \multicolumn{1}{c|}{38.36/13.33/29.96} &
              3.47/2.9/3.3 &
              \multicolumn{1}{c|}{42.3/16.5/33.7} &
              2.35/1.87/2.27 &
              \multicolumn{1}{c|}{42.95/17.13/34.35} &
              0.62/0.34/0.5 &
              \multicolumn{1}{c|}{37.26/13.0/29.09} &
              3.24/2.4/2.88 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{37.76/13.13/29.5} &
              1.56/0.93/1.23 &
              \multicolumn{1}{c|}{39.76/14.85/31.4} &
              1.69/1.22/1.59 &
              \multicolumn{1}{c|}{39.47/14.64/31.21} &
              3.42/2.46/3.13 &
              \multicolumn{1}{c|}{41.93/16.5/33.51} &
              0.72/0.52/0.69 &
              \multicolumn{1}{c|}{40.96/15.65/32.49} &
              1.89/1.33/1.72 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{40.82/15.43/32.29} &
              3.6/2.99/3.4 &
              \multicolumn{1}{c|}{38.17/13.3/29.82} &
              2.83/2.37/2.67 &
              \multicolumn{1}{c|}{42.61/16.94/33.99} &
              0.16/0.23/0.15 &
              \multicolumn{1}{c|}{\textbf{45.63/19.17/36.86}} &
              0.59/0.42/0.57 &
              \multicolumn{1}{c|}{40.98/15.71/32.52} &
              2.53/1.96/2.47 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{41.23/16.07/32.77} &
              0.68/0.58/0.6 &
              \multicolumn{1}{c|}{38.48/13.34/29.92} &
              2.05/1.71/1.86 &
              \multicolumn{1}{c|}{40.57/15.53/32.13} &
              \textbf{0.2/0.18/0.2} &
              \multicolumn{1}{c|}{41.41/16.19/32.93} &
              \textbf{0.12/0.11/0.1} &
              \multicolumn{1}{c|}{41.2/16.03/32.74} &
              \textbf{0.05/0.03/0.04} \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{37.72/13.34/29.47} &
              \textbf{0.13/0.1/0.12} &
              \multicolumn{1}{c|}{37.8/13.38/29.53} &
              \textbf{0.15/0.14/0.15} &
              \multicolumn{1}{c|}{37.62/13.22/29.37} &
              0.22/0.17/0.22 &
              \multicolumn{1}{c|}{37.84/13.42/29.59} &
              0.13/0.08/0.13 &
              \multicolumn{1}{c|}{38.01/13.53/29.72} &
              0.18/0.13/0.17 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{44.98/18.74/36.2}} &
              0.74/0.61/0.56 &
              \multicolumn{1}{c|}{\textbf{42.3/16.59/33.71}} &
              2.34/1.66/2.14 &
              \multicolumn{1}{c|}{\textbf{44.68/18.4/35.96}} &
              0.76/0.4/0.61 &
              \multicolumn{1}{c|}{44.42/18.01/35.62} &
              0.96/0.78/0.93 &
              \multicolumn{1}{c|}{40.49/15.02/31.96} &
              3.23/2.66/3.08 \\ \hline
            \end{tabular}
            }
            \caption{Experimental results with different heterogeneous settings on CNNDM.
            The mean and variance of three optimal results for each method are presented.
            }
            \label{Table: CNNDM full result summary}
            \end{table*}

        \begin{table*}[htpb]
            \centering
            \resizebox{1\textwidth}{!}{   
            \begin{tabular}{|c|c|cc|cc|cc|cc|cc|}
            \hline
            \textbf{PubMed} &
              \multirow{2}{*}{\textbf{Method}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.5$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=8$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=+\infty$}} \\ \cline{1-1} \cline{3-12} 
            \textbf{Metric} &
               &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} \\ \hline
            \multirow{8}{*}{\textbf{R-F(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{31.01/10.76/27.8} &
              0.26/0.31/0.27 &
              \multicolumn{1}{c|}{30.67/10.28/27.45} &
              0.04/0.07/0.04 &
              \multicolumn{1}{c|}{30.67/10.38/27.47} &
              0.04/0.04/0.04 &
              \multicolumn{1}{c|}{31.25/10.91/28.04} &
              0.07/0.07/0.06 &
              \multicolumn{1}{c|}{31.16/10.9/27.96} &
              0.28/0.25/0.27 \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{31.1/10.81/27.9} &
              0.15/0.13/0.13 &
              \multicolumn{1}{c|}{31.18/10.92/27.97} &
              0.17/0.16/0.16 &
              \multicolumn{1}{c|}{31.22/10.96/28.01} &
              0.21/0.2/0.19 &
              \multicolumn{1}{c|}{31.1/10.81/27.87} &
              0.21/0.19/0.19 &
              \multicolumn{1}{c|}{30.95/10.68/27.75} &
              0.18/0.16/0.17 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{31.29/11.0/28.07} &
              0.09/0.09/0.08 &
              \multicolumn{1}{c|}{31.0/10.77/27.81} &
              0.13/0.11/0.12 &
              \multicolumn{1}{c|}{31.13/10.87/27.94} &
              0.16/0.13/0.16 &
              \multicolumn{1}{c|}{31.18/10.9/27.98} &
              0.05/0.03/0.05 &
              \multicolumn{1}{c|}{31.0/10.74/27.8} &
              0.23/0.22/0.22 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{31.08/10.79/27.87} &
              0.07/0.09/0.08 &
              \multicolumn{1}{c|}{30.91/10.64/27.71} &
              0.13/0.15/0.13 &
              \multicolumn{1}{c|}{31.04/10.76/27.83} &
              0.21/0.19/0.21 &
              \multicolumn{1}{c|}{30.92/10.63/27.72} &
              0.27/0.27/0.27 &
              \multicolumn{1}{c|}{30.99/10.75/27.79} &
              0.24/0.23/0.24 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{31.43/11.13/28.22} &
              0.0/0.01/0.0 &
              \multicolumn{1}{c|}{31.26/11.02/28.06} &
              0.18/0.16/0.18 &
              \multicolumn{1}{c|}{31.2/10.96/28.01} &
              0.23/0.19/0.22 &
              \multicolumn{1}{c|}{\textbf{31.4/11.1/28.19}} &
              0.04/0.06/0.05 &
              \multicolumn{1}{c|}{31.29/11.06/28.09} &
              0.09/0.02/0.07 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{30.76/10.51/27.55} &
              0.01/0.01/0.01 &
              \multicolumn{1}{c|}{30.95/10.62/27.74} &
              0.26/0.34/0.27 &
              \multicolumn{1}{c|}{30.8/10.51/27.59} &
              \textbf{0.02/0.0/0.02} &
              \multicolumn{1}{c|}{30.77/10.55/27.58} &
              \textbf{0.01/0.01/0.02} &
              \multicolumn{1}{c|}{30.78/10.55/27.59} &
              \textbf{0.01/0.01/0.01} \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{30.72/10.41/27.51} &
              \textbf{0.02/0.02/0.02} &
              \multicolumn{1}{c|}{30.73/10.42/27.53} &
              \textbf{0.03/0.05/0.02} &
              \multicolumn{1}{c|}{30.7/10.39/27.5} &
              0.02/0.02/0.01 &
              \multicolumn{1}{c|}{30.73/10.42/27.53} &
              0.03/0.02/0.02 &
              \multicolumn{1}{c|}{30.74/10.44/27.54} &
              0.06/0.06/0.06 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{31.48/11.2/28.26}} &
              0.02/0.02/0.03 &
              \multicolumn{1}{c|}{\textbf{31.53/11.25/28.32}} &
              0.4/0.33/0.37 &
              \multicolumn{1}{c|}{\textbf{31.42/11.14/28.22}} &
              0.38/0.31/0.37 &
              \multicolumn{1}{c|}{31.23/10.98/28.04} &
              0.02/0.06/0.04 &
              \multicolumn{1}{c|}{\textbf{31.12/10.85/27.91}} &
              0.33/0.3/0.32 \\ \hline
            \multirow{8}{*}{\textbf{R-R(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{32.73/11.13/29.32} &
              0.32/0.36/0.33 &
              \multicolumn{1}{c|}{32.33/10.58/28.89} &
              0.03/0.08/0.05 &
              \multicolumn{1}{c|}{32.39/10.73/28.98} &
              0.05/0.04/0.05 &
              \multicolumn{1}{c|}{32.94/11.24/29.53} &
              0.07/0.08/0.07 &
              \multicolumn{1}{c|}{32.89/11.25/29.48} &
              0.28/0.24/0.27 \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{32.85/11.18/29.44} &
              0.14/0.12/0.13 &
              \multicolumn{1}{c|}{32.96/11.32/29.54} &
              0.17/0.15/0.16 &
              \multicolumn{1}{c|}{33.0/11.36/29.58} &
              0.23/0.21/0.21 &
              \multicolumn{1}{c|}{32.87/11.21/29.44} &
              0.21/0.19/0.2 &
              \multicolumn{1}{c|}{32.72/11.08/29.31} &
              0.19/0.16/0.18 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{33.05/11.38/29.63} &
              0.09/0.09/0.08 &
              \multicolumn{1}{c|}{32.78/11.19/29.39} &
              0.13/0.12/0.12 &
              \multicolumn{1}{c|}{32.88/11.26/29.49} &
              0.13/0.09/0.11 &
              \multicolumn{1}{c|}{32.93/11.28/29.52} &
              0.03/0.02/0.04 &
              \multicolumn{1}{c|}{32.76/11.12/29.36} &
              0.26/0.24/0.25 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{32.83/11.19/29.42} &
              0.08/0.1/0.09 &
              \multicolumn{1}{c|}{32.7/11.06/29.28} &
              0.16/0.18/0.16 &
              \multicolumn{1}{c|}{32.8/11.14/29.38} &
              0.21/0.19/0.21 &
              \multicolumn{1}{c|}{32.67/11.0/29.26} &
              0.28/0.26/0.28 &
              \multicolumn{1}{c|}{32.76/11.14/29.34} &
              0.25/0.25/0.25 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{33.2/11.52/29.77} &
              0.02/0.02/0.02 &
              \multicolumn{1}{c|}{33.02/11.43/29.63} &
              0.17/0.15/0.16 &
              \multicolumn{1}{c|}{32.99/11.37/29.58} &
              0.23/0.18/0.21 &
              \multicolumn{1}{c|}{\textbf{33.15/11.47/29.73}} &
              0.04/0.06/0.04 &
              \multicolumn{1}{c|}{33.1/11.49/29.69} &
              0.08/0.04/0.06 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{32.43/10.86/29.01} &
              0.01/0.02/0.02 &
              \multicolumn{1}{c|}{32.6/10.92/29.18} &
              0.33/0.4/0.34 &
              \multicolumn{1}{c|}{32.48/10.88/29.07} &
              \textbf{0.02/0.01/0.02} &
              \multicolumn{1}{c|}{32.44/10.89/29.03} &
              \textbf{0.02/0.01/0.02} &
              \multicolumn{1}{c|}{32.46/10.91/29.05} &
              \textbf{0.02/0.01/0.02} \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{32.41/10.75/28.99} &
              \textbf{0.02/0.02/0.02} &
              \multicolumn{1}{c|}{32.42/10.75/29.0} &
              \textbf{0.04/0.06/0.05} &
              \multicolumn{1}{c|}{32.39/10.73/28.97} &
              0.02/0.02/0.02 &
              \multicolumn{1}{c|}{32.42/10.75/29.0} &
              0.02/0.02/0.03 &
              \multicolumn{1}{c|}{32.43/10.77/29.02} &
              0.06/0.07/0.06 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{33.3/11.62/29.86}} &
              0.03/0.03/0.02 &
              \multicolumn{1}{c|}{\textbf{33.32/11.67/29.9}} &
              0.39/0.33/0.36 &
              \multicolumn{1}{c|}{\textbf{33.18/11.53/29.78}} &
              0.39/0.3/0.39 &
              \multicolumn{1}{c|}{33.01/11.38/29.61} &
              0.05/0.07/0.06 &
              \multicolumn{1}{c|}{\textbf{32.76/11.12/29.45}} &
              0.28/0.23/0.33 \\ \hline
            \end{tabular}
            }
            \caption{Experimental results with different heterogeneous settings on PubMed.
            The mean and variance of three optimal results for each method are presented.
            }
            \label{Table: PubMed full result summary}
            \end{table*}

        \begin{table*}[htpb]
            \centering
            \resizebox{1\textwidth}{!}{   
            \begin{tabular}{|c|c|cc|cc|cc|cc|cc|}
            \hline
            \textbf{WikiHow} &
              \multirow{2}{*}{\textbf{Method}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.5$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=8$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=+\infty$}} \\ \cline{1-1} \cline{3-12} 
            \textbf{Metric} &
               &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} \\ \hline
            \multirow{8}{*}{\textbf{R-F(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{22.41/4.85/20.79} &
              0.06/0.03/0.05 &
              \multicolumn{1}{c|}{22.15/4.74/20.55} &
              0.07/0.02/0.05 &
              \multicolumn{1}{c|}{22.2/4.76/20.61} &
              0.1/0.02/0.1 &
              \multicolumn{1}{c|}{22.39/4.88/20.74} &
              0.25/0.15/0.22 &
              \multicolumn{1}{c|}{22.2/4.75/20.59} &
              0.14/0.05/0.14 \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{22.21/4.77/20.61} &
              0.14/0.05/0.13 &
              \multicolumn{1}{c|}{22.38/4.85/20.76} &
              0.1/0.03/0.08 &
              \multicolumn{1}{c|}{22.24/4.8/20.64} &
              0.02/0.02/0.02 &
              \multicolumn{1}{c|}{22.25/4.79/20.66} &
              0.11/0.03/0.1 &
              \multicolumn{1}{c|}{22.36/4.82/20.75} &
              0.07/0.03/0.06 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{22.29/4.81/20.69} &
              0.17/0.07/0.15 &
              \multicolumn{1}{c|}{22.12/4.75/20.53} &
              0.05/0.03/0.05 &
              \multicolumn{1}{c|}{22.24/4.78/20.64} &
              0.11/0.06/0.1 &
              \multicolumn{1}{c|}{22.21/4.77/20.6} &
              0.16/0.06/0.15 &
              \multicolumn{1}{c|}{22.28/4.8/20.67} &
              0.18/0.07/0.16 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{22.02/4.7/20.44} &
              0.03/0.01/0.03 &
              \multicolumn{1}{c|}{22.09/4.73/20.49} &
              0.06/0.03/0.06 &
              \multicolumn{1}{c|}{22.17/4.76/20.58} &
              0.06/0.02/0.06 &
              \multicolumn{1}{c|}{22.18/4.77/20.59} &
              0.01/0.0/0.01 &
              \multicolumn{1}{c|}{22.37/4.82/20.76} &
              0.09/0.02/0.08 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{22.14/4.75/20.54} &
              0.13/0.08/0.12 &
              \multicolumn{1}{c|}{22.35/4.84/20.73} &
              0.35/0.16/0.32 &
              \multicolumn{1}{c|}{22.11/4.74/20.52} &
              0.04/0.03/0.03 &
              \multicolumn{1}{c|}{22.31/4.83/20.7} &
              0.1/0.04/0.09 &
              \multicolumn{1}{c|}{22.42/4.83/20.8} &
              0.04/0.01/0.03 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{22.11/4.73/20.55} &
              0.05/0.03/0.05 &
              \multicolumn{1}{c|}{22.09/4.72/20.51} &
              0.05/0.0/0.05 &
              \multicolumn{1}{c|}{22.02/4.71/20.44} &
              0.01/0.0/0.01 &
              \multicolumn{1}{c|}{22.01/4.69/20.42} &
              \textbf{0.01/0.0/0.01} &
              \multicolumn{1}{c|}{22.05/4.71/20.48} &
              \textbf{0.01/0.0/0.01} \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{22.16/4.73/20.6} &
              \textbf{0.01/0.0/0.01} &
              \multicolumn{1}{c|}{22.17/4.74/20.61} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{22.21/4.75/20.64} &
              \textbf{0.01/0.0/0.01} &
              \multicolumn{1}{c|}{22.21/4.77/20.64} &
              0.03/0.02/0.02 &
              \multicolumn{1}{c|}{22.2/4.75/20.63} &
              0.0/0.01/0.01 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{22.32/4.83/20.7}} &
              0.14/0.05/0.12 &
              \multicolumn{1}{c|}{\textbf{22.38/4.85/20.75}} &
              0.2/0.08/0.18 &
              \multicolumn{1}{c|}{\textbf{22.44/4.88/20.82}} &
              0.14/0.06/0.14 &
              \multicolumn{1}{c|}{\textbf{22.45/4.87/20.81}} &
              0.25/0.1/0.21 &
              \multicolumn{1}{c|}{\textbf{22.2/4.78/20.64}} &
              0.06/0.03/0.07 \\ \hline
            \multirow{8}{*}{\textbf{R-R(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{33.22/7.97/30.96} &
              0.08/0.05/0.06 &
              \multicolumn{1}{c|}{32.73/7.75/30.53} &
              0.2/0.06/0.16 &
              \multicolumn{1}{c|}{33.06/7.84/30.83} &
              0.01/0.01/0.0 &
              \multicolumn{1}{c|}{33.52/8.13/31.21} &
              0.53/0.3/0.48 &
              \multicolumn{1}{c|}{32.99/7.8/30.75} &
              0.09/0.05/0.09 \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{33.03/7.88/30.79} &
              0.06/0.02/0.05 &
              \multicolumn{1}{c|}{33.23/7.97/30.98} &
              0.22/0.07/0.18 &
              \multicolumn{1}{c|}{32.99/7.9/30.77} &
              0.04/0.03/0.04 &
              \multicolumn{1}{c|}{33.0/7.86/30.79} &
              0.1/0.02/0.07 &
              \multicolumn{1}{c|}{33.07/7.88/30.84} &
              0.04/0.02/0.03 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{33.14/7.95/30.9} &
              0.14/0.07/0.13 &
              \multicolumn{1}{c|}{32.89/7.84/30.67} &
              0.11/0.05/0.09 &
              \multicolumn{1}{c|}{32.98/7.84/30.76} &
              0.12/0.09/0.12 &
              \multicolumn{1}{c|}{32.98/7.86/30.75} &
              0.17/0.06/0.15 &
              \multicolumn{1}{c|}{33.08/7.91/30.85} &
              0.18/0.08/0.15 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{32.78/7.77/30.58} &
              0.02/0.01/0.02 &
              \multicolumn{1}{c|}{32.9/7.83/30.67} &
              0.06/0.04/0.05 &
              \multicolumn{1}{c|}{32.92/7.84/30.7} &
              0.06/0.01/0.06 &
              \multicolumn{1}{c|}{32.99/7.88/30.77} &
              0.06/0.02/0.05 &
              \multicolumn{1}{c|}{33.1/7.9/30.87} &
              0.1/0.03/0.09 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{32.72/7.76/30.52} &
              0.18/0.1/0.16 &
              \multicolumn{1}{c|}{33.3/8.03/31.03} &
              0.47/0.25/0.42 &
              \multicolumn{1}{c|}{32.98/7.87/30.76} &
              0.04/0.02/0.03 &
              \multicolumn{1}{c|}{33.22/7.99/30.97} &
              0.18/0.07/0.16 &
              \multicolumn{1}{c|}{33.2/7.92/30.94} &
              0.1/0.03/0.08 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{32.58/7.69/30.43} &
              0.01/0.03/0.02 &
              \multicolumn{1}{c|}{32.8/7.76/30.59} &
              0.02/0.02/0.03 &
              \multicolumn{1}{c|}{32.8/7.8/30.57} &
              0.06/0.03/0.06 &
              \multicolumn{1}{c|}{32.58/7.7/30.38} &
              \textbf{0.01/0.01/0.01} &
              \multicolumn{1}{c|}{32.53/7.7/30.36} &
              \textbf{0.0/0.0/0.01} \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{32.68/7.71/30.53} &
              \textbf{0.01/0.0/0.01} &
              \multicolumn{1}{c|}{32.69/7.72/30.55} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{32.77/7.75/30.61} &
              \textbf{0.04/0.02/0.03} &
              \multicolumn{1}{c|}{32.76/7.75/30.6} &
              0.03/0.02/0.02 &
              \multicolumn{1}{c|}{32.77/7.75/30.61} &
              0.06/0.03/0.04 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{33.18/7.97/30.93}} &
              0.2/0.07/0.16 &
              \multicolumn{1}{c|}{\textbf{33.35/8.02/31.06}} &
              0.3/0.13/0.26 &
              \multicolumn{1}{c|}{\textbf{33.37/8.06/31.09}} &
              0.17/0.07/0.16 &
              \multicolumn{1}{c|}{\textbf{33.46/8.07/31.16}} &
              0.34/0.17/0.3 &
              \multicolumn{1}{c|}{\textbf{33.11/7.91/30.86}} &
              0.03/0.02/0.03 \\ \hline
            \end{tabular}
            }
            \caption{Experimental results with different heterogeneous settings on WikiHow.
            The mean and variance of three optimal results for each method are presented.
            }
            \label{Table: WikiHow full result summary}
            \end{table*}

        \begin{table*}[htpb]
            \centering
            \resizebox{1\textwidth}{!}{   
            \begin{tabular}{|c|c|cc|cc|cc|cc|cc|}
            \hline
            \textbf{Reddit} &
              \multirow{2}{*}{\textbf{Method}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=0.5$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=1$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=8$}} &
              \multicolumn{2}{c|}{\textbf{$Dir=+\infty$}} \\ \cline{1-1} \cline{3-12} 
            \textbf{Metric} &
               &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} &
              \multicolumn{1}{c|}{\textbf{Mean}} &
              \textbf{Var.} \\ \hline
            \multirow{8}{*}{\textbf{R-F(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{17.88/3.17/15.1} &
              0.02/0.01/0.02 &
              \multicolumn{1}{c|}{17.86/3.17/15.1} &
              0.01/0.0/0.01 &
              \multicolumn{1}{c|}{17.87/3.17/15.11} &
              0.03/0.0/0.02 &
              \multicolumn{1}{c|}{17.83/3.14/15.06} &
              0.0/0.01/0.0 &
              \multicolumn{1}{c|}{17.84/3.18/15.09} &
              \textbf{0.0/0.0/0.0} \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{17.87/3.19/15.11} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.86/3.18/15.1} &
              0.01/0.0/0.0 &
              \multicolumn{1}{c|}{17.92/3.21/15.14} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.89/3.19/15.14} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.86/3.18/15.1} &
              0.01/0.0/0.0 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{17.86/3.19/15.08} &
              0.01/0.0/0.0 &
              \multicolumn{1}{c|}{17.86/3.18/15.11} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.87/3.18/15.11} &
              0.0/0.01/0.01 &
              \multicolumn{1}{c|}{17.89/3.19/15.12} &
              0.01/0.01/0.01 &
              \multicolumn{1}{c|}{17.88/3.19/15.12} &
              0.0/0.01/0.0 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{17.86/3.17/15.09} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.84/3.18/15.08} &
              0.01/0.0/0.01 &
              \multicolumn{1}{c|}{17.9/3.2/15.13} &
              0.0/0.0/0.01 &
              \multicolumn{1}{c|}{17.87/3.19/15.11} &
              0.0/0.0/0.01 &
              \multicolumn{1}{c|}{17.86/3.19/15.1} &
              \textbf{0.0/0.0/0.0} \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{17.91/3.2/15.15} &
              0.01/0.0/0.03 &
              \multicolumn{1}{c|}{17.89/3.19/15.13} &
              0.02/0.01/0.01 &
              \multicolumn{1}{c|}{17.95/3.21/15.22} &
              0.02/0.01/0.02 &
              \multicolumn{1}{c|}{17.92/3.21/15.18} &
              0.05/0.03/0.08 &
              \multicolumn{1}{c|}{17.91/3.19/15.13} &
              0.02/0.0/0.04 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{17.86/3.17/15.13} &
              0.01/0.01/0.0 &
              \multicolumn{1}{c|}{17.9/3.19/15.17} &
              0.0/0.01/0.01 &
              \multicolumn{1}{c|}{17.89/3.19/15.14} &
              0.02/0.01/0.03 &
              \multicolumn{1}{c|}{17.85/3.17/15.13} &
              0.01/0.0/0.01 &
              \multicolumn{1}{c|}{17.87/3.17/15.14} &
              0.0/0.0/0.01 \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{17.84/3.17/15.09} &
              0.01/0.0/0.01 &
              \multicolumn{1}{c|}{17.91/3.2/15.19} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.91/3.2/15.19} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.91/3.2/15.17} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{17.88/3.19/15.12} &
              0.01/0.01/0.0 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{17.95/3.21/15.17}} &
              0.01/0.01/0.02 &
              \multicolumn{1}{c|}{\textbf{17.96/3.21/15.2}} &
              0.05/0.02/0.07 &
              \multicolumn{1}{c|}{\textbf{17.96/3.22/15.22}} &
              0.04/0.01/0.02 &
              \multicolumn{1}{c|}{\textbf{17.91/3.2/15.19}} &
              0.0/0.0/0.02 &
              \multicolumn{1}{c|}{\textbf{17.91/3.19/15.15}} &
              0.02/0.01/0.02 \\ \hline
            \multirow{8}{*}{\textbf{R-R(1/2/L)}} &
              Separate &
              \multicolumn{1}{c|}{41.57/9.02/35.73} &
              0.05/0.03/0.04 &
              \multicolumn{1}{c|}{41.53/9.02/35.7} &
              0.0/0.01/0.0 &
              \multicolumn{1}{c|}{41.59/9.05/35.78} &
              0.06/0.02/0.06 &
              \multicolumn{1}{c|}{41.42/8.97/35.58} &
              0.0/0.01/0.0 &
              \multicolumn{1}{c|}{41.52/9.07/35.76} &
              \textbf{0.0/0.0/0.0} \\ \cline{2-12} 
             &
              FedAvg &
              \multicolumn{1}{c|}{41.66/9.1/35.81} &
              0.05/0.0/0.03 &
              \multicolumn{1}{c|}{41.56/9.06/35.73} &
              0.03/0.01/0.03 &
              \multicolumn{1}{c|}{41.73/9.12/35.89} &
              0.0/0.01/0.02 &
              \multicolumn{1}{c|}{41.63/9.12/35.84} &
              0.02/0.02/0.0 &
              \multicolumn{1}{c|}{41.63/9.1/35.82} &
              0.01/0.02/0.03 \\ \cline{2-12} 
             &
              FedProx &
              \multicolumn{1}{c|}{41.59/9.09/35.71} &
              \textbf{0.0/0.01/0.0} &
              \multicolumn{1}{c|}{41.62/9.06/35.79} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{41.62/9.09/35.8} &
              0.03/0.0/0.0 &
              \multicolumn{1}{c|}{41.64/9.1/35.78} &
              0.01/0.0/0.02 &
              \multicolumn{1}{c|}{41.62/9.1/35.81} &
              0.04/0.04/0.03 \\ \cline{2-12} 
             &
              Scaffold &
              \multicolumn{1}{c|}{41.58/9.07/35.74} &
              0.0/0.02/0.01 &
              \multicolumn{1}{c|}{41.6/9.07/35.75} &
              0.02/0.02/0.02 &
              \multicolumn{1}{c|}{41.64/9.12/35.79} &
              0.03/0.02/0.06 &
              \multicolumn{1}{c|}{41.59/9.09/35.78} &
              0.0/0.0/0.05 &
              \multicolumn{1}{c|}{41.63/9.1/35.8} &
              0.01/0.02/0.0 \\ \cline{2-12} 
             &
              FedDC &
              \multicolumn{1}{c|}{41.77/9.13/35.94} &
              0.11/0.04/0.15 &
              \multicolumn{1}{c|}{41.69/9.07/35.85} &
              0.01/0.01/0.0 &
              \multicolumn{1}{c|}{41.76/9.13/36.04} &
              0.08/0.04/0.07 &
              \multicolumn{1}{c|}{41.76/9.16/35.99} &
              0.1/0.08/0.19 &
              \multicolumn{1}{c|}{41.76/9.14/35.94} &
              0.08/0.02/0.12 \\ \cline{2-12} 
             &
              FedNova &
              \multicolumn{1}{c|}{41.56/9.03/35.81} &
              0.01/0.02/0.03 &
              \multicolumn{1}{c|}{41.65/9.07/35.91} &
              0.04/0.04/0.05 &
              \multicolumn{1}{c|}{41.66/9.08/35.86} &
              0.1/0.06/0.12 &
              \multicolumn{1}{c|}{41.49/9.03/35.76} &
              0.04/0.0/0.03 &
              \multicolumn{1}{c|}{41.54/8.99/35.8} &
              0.01/0.02/0.02 \\ \cline{2-12} 
             &
              FedProto &
              \multicolumn{1}{c|}{41.66/9.07/35.83} &
              \textbf{0.0/0.0/0.01} &
              \multicolumn{1}{c|}{41.75/9.13/36.01} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{41.75/9.13/36.01} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{41.75/9.13/36.01} &
              \textbf{0.0/0.0/0.0} &
              \multicolumn{1}{c|}{41.56/9.09/35.77} &
              0.08/0.01/0.11 \\ \cline{2-12} 
             &
              \textbf{FedSum} &
              \multicolumn{1}{c|}{\textbf{41.78/9.13/35.92}} &
              0.04/0.0/0.02 &
              \multicolumn{1}{c|}{\textbf{41.87/9.18/36.06}} &
              0.03/0.05/0.09 &
              \multicolumn{1}{c|}{\textbf{41.76/9.17/36.04}} &
              0.01/0.03/0.04 &
              \multicolumn{1}{c|}{\textbf{41.76/9.13/35.99}} &
              0.02/0.0/0.03 &
              \multicolumn{1}{c|}{\textbf{41.79/9.12/35.91}} &
              0.04/0.02/0.04 \\ \hline
            \end{tabular}
            }
            \caption{Experimental results with different heterogeneous settings on Reddit.
            The mean and variance of three optimal results for each method are presented.
            }
            \label{Table: Reddit full result summary}
            \end{table*}
    \newpage{}
    \paragraph{Learning rate turning.}
        We trained FedAvg with different training rates in CNNDM and WikiHow datasets.
        Every time the FL server communicates with the clients, we perform the performance test and record it.
        We run every experiment 3 times in order to reduce variance.
        The experimental results are shown in Table \ref{tb:cnndm_learning_rate} and Table \ref{tb:wikihow_learning_rate}. 
        According to the result, FedAvg can achieve better performance under the training rate of 5e-3. Therefore, we set $\eta$ as 5e-3 for all experiments.
        
        \begin{table*}[htpb]
            \centering
            \resizebox{1\textwidth}{!}{   
            \begin{tabular}{|c|c|c|c|c|c|c|}
            
                \hline
                \multicolumn{1}{|l|}{\textbf{FedAvg}} & \textbf{$Dir=0.1$} & \textbf{$T = 1$}  & \textbf{$T = 2$}  & \textbf{$T = 3$}  & \textbf{$T = 4$}  & \textbf{$T = 5$}  \\ \hline
                \multirow{2}{*}{5e-2}          & R-F(1/2/l)     & 28.88/8.35/22.02 &28.88/8.35/22.02  & 28.88/8.35/22.02  &28.88/8.35/22.02  & 28.88/8.35/22.02  \\ \cline{2-7} 
                                                      & R-R(1/2/l)     & 35.11/10.62/26.88 & 35.11/10.62/26.88 & 35.11/10.62/26.88 & 35.11/10.62/26.88 & 35.11/10.62/26.88 \\ \hline
                \multirow{2}{*}{\textbf{5e-3}} &
                  \textbf{R-F(1/2/l)} &
                  \textbf{33.58/12.66/26.81} &
                  \textbf{33.95/12.92/27.17} &
                  \textbf{34.19/13.13/27.39} &
                  \textbf{32.45/11.11/25.30} &
                  \textbf{34.13/12.50/26.89} \\ \cline{2-7} 
                 &
                  \textbf{R-R(1/2/l)} &
                  \textbf{41.92/16.50/33.52} &
                  \textbf{42.53/16.92/34.09} &
                  \textbf{42.86/17.21/34.39} &
                  \textbf{39.93/14.34/31.22} &
                  \textbf{42.69/16.46/33.72} \\ \hline
                \multirow{2}{*}{5e-4}          & R-F(1/2/l)     & 32.83/12.02/25.90 & 32.88/12.06/25.95 & 33.01/12.17/26.09 & 33.09/12.22/26.16 & 33.17/12.31/26.26 \\ \cline{2-7} 
                                                      & R-R(1/2/l)     & 40.41/15.44/31.97 & 40.49/15.49/32.04 & 40.69/15.65/32.23 & 40.81/15.74/32.33 & 40.90/15.86/32.46 \\ \hline
                \multirow{2}{*}{5e-5}          & R-F(1/2/l)     & 32.10/11.41/25.18 & 32.13/11.44/25.23 & 32.16/11.48/25.27 & 32.17/11.49/25.28 & 32.19/11.50/25.29 \\ \cline{2-7} 
                                                      & R-R(1/2/l)     & 39.28/14.55/30.91 & 39.33/14.60/30.98 & 39.39/14.65/31.04 & 39.41/14.67/31.05 & 39.43/14.69/31.07 \\ \hline
                \multirow{2}{*}{5e-6}          & R-F(1/2/l)     & 31.53/10.94/24.62 & 31.62/11.00/24.69 & 31.64/11.02/24.72 & 31.68/11.06/24.76 & 31.71/11.09/24.80 \\ \cline{2-7} 
                                                      & R-R(1/2/l)     & 38.39/13.87/30.06 & 38.53/13.96/30.16 & 38.56/13.99/30.22 & 38.61/14.03/30.27 & 38.66/14.07/30.32 \\ \hline
            \end{tabular}
            }
            \caption{Performance comparison of FedAvg trained with different learning rate $\eta$=\{5e-2, 5e-3, 5e-4, 5e-5, 5e-6\} in CNNDM. R-F and R-R stand for the ROUGE-F1 metric and ROUGE-Recall metric, respectively.
            }
            \label{tb:cnndm_learning_rate}
        \end{table*}

        \begin{table*}[htpb]
            \centering
            \resizebox{1\textwidth}{!}{   
            \begin{tabular}{|c|c|c|c|c|c|c|}
            \hline
            \multicolumn{1}{|l|}{\textbf{FedAvg}} &
              $Dir=0.1$ &
              $T = 1$ &
              $T = 2$ &
              $T = 3$ &
              $T = 4$ &
              $T = 5$ \\ \hline
            \multirow{2}{*}{5e-2} &
              R-F(1/2/l) &
              22.25/4.78/20.64 &
              22.28/4.80/20.68 &
              22.28/4.80/20.68 &
              22.28/4.80/20.68 &
              22.28/4.80/20.68 \\ \cline{2-7} 
             &
              R-R(1/2/l) &
              32.93/7.83/30.69 &
              32.97/7.85/30.73 &
              32.97/7.85/30.73 &
              32.97/7.85/30.73 &
              32.97/7.85/30.73 \\ \hline
            \multirow{2}{*}{\textbf{5e-3}} &
              \textbf{R-F(1/2/l)} &
              \textbf{22.36/4.80/20.75} &
              \textbf{22.29/4.79/20.68} &
              \textbf{22.26/4.78/20.66} &
              \textbf{22.27/4.78/20.68} &
              \textbf{22.25/4.77/20.65} \\ \cline{2-7} 
             &
              \textbf{R-R(1/2/l)} &
              \textbf{33.06/7.86/30.83} &
              \textbf{32.97/7.83/30.74} &
              \textbf{32.88/7.82/30.68} &
              \textbf{32.90/7.82/30.69} &
              \textbf{32.88/7.81/30.67} \\ \hline
            \multirow{2}{*}{5e-4} &
              R-F(1/2/l) &
              21.97/4.68/20.41 &
              21.99/4.68/20.42 &
              21.98/4.68/20.42 &
              21.99/4.68/20.43 &
              21.99/4.69/20.43 \\ \cline{2-7} 
             &
              R-R(1/2/l) &
              32.50/7.66/30.35 &
              32.51/7.66/30.35 &
              32.47/7.65/30.31 &
              32.49/7.66/30.34 &
              32.46/7.65/30.32 \\ \hline
            \multirow{2}{*}{5e-5} &
              R-F(1/2/l) &
              22.18/4.73/20.61 &
              22.15/4.73/20.58 &
              22.09/4.71/20.53 &
              22.03/4.69/20.47 &
              22.02/4.69/20.47 \\ \cline{2-7} 
             &
              R-R(1/2/l) &
              32.64/7.69/30.50 &
              32.60/7.68/30.45 &
              32.57/7.67/30.42 &
              32.51/7.65/30.36 &
              32.54/7.67/30.39 \\ \hline
            \multirow{2}{*}{5e-6} &
              R-F(1/2/l) &
              22.20/4.74/20.64 &
              22.19/4.74/20.63 &
              22.19/4.74/20.62 &
              22.19/4.74/20.62 &
              22.18/4.73/20.62 \\ \cline{2-7} 
             &
              R-R(1/2/l) &
              32.66/7.70/30.53 &
              32.67/7.70/30.52 &
              32.66/7.69/30.51 &
              32.66/7.70/30.51 &
              32.64/7.69/30.49 \\ \hline
          \end{tabular}
          }
          \caption{Performance comparison of FedAvg trained with different learning rate $\eta$=\{5e-2, 5e-3, 5e-4, 5e-5, 5e-6\} in WikiHow. R-F and R-R stand for the ROUGE-F1 metric and ROUGE-Recall metric, respectively.}
          \label{tb:wikihow_learning_rate}   
        \end{table*}


    
    \paragraph{Hyperparameter $\gamma$ turning.}
    $\gamma$ controls the dropout rate of Bernoulli perturbation, which helps to avoid catastrophic forgetting and protect privacy. We adjust $\gamma$ and experiment in heterogeneity scenarios on CNNDM, PubMed, and WikiHow datasets. We observe that $\gamma$ has the most obvious effect on the CNNDM dataset. As showns in Fig.~\ref{fig:gamma_all_dataset}, when $\gamma$ increases from $0.1$ to $0.3$, the perturbations of the uploaded classification on modules become stronger, and ROUGE scores go better. When $\gamma$ over $0.3$, the perturbations are too strong and cause degeneration.

    \begin{figure}[!htb]
            \centering
            \includegraphics[width=0.45\columnwidth]{latex/fig/hyperparameter_γ_all_dataset.png}
            \includegraphics[width=0.45\columnwidth]{latex/fig/hyperparameter_γ_CNNDM.png}

            \caption{ROUGE scores of FedSum with different $\gamma$ in CNNDM, PubMed and WikiHow.}
            \label{fig:gamma_all_dataset}
        \end{figure}

    % \begin{figure}[htpb]
    %         \centering
    %         \includegraphics[width=0.45\columnwidth]{latex/fig/hyperparameter_γ_CNNDM.png}
    %         \caption{Comprehensive ROUGE scores of FedSum in CNNDM dataset.}
    %         \label{fig:gamma_CNNDM}
    %     \end{figure}
    

\newpage

\section{Detail of Data Partition Algorithm}

% Center the algorithm using center environment
\begin{center}
\begin{algorithm}[!htb]
    \caption{Data Partition.}
    \begin{algorithmic}[1]
    \REQUIRE $LD$, $LM$, $m$, $\lambda$, $\bar\epsilon^{(t-1)}$, $\bar Q^{(t-1)}$, $D_{(i,N)}$, $D_{(i,P)}$
    
    \textcolor[rgb]{0.25, 0.5, 0.75}{\textit{\# Sentences' Masked loss matrix}}
    \STATE $MM = LD \odot LM$
    
    \textcolor[rgb]{0.25, 0.5, 0.75}{\textit{\# Local significance: Avg. of masked loss over batch}}
    \STATE $\epsilon_{(i,j)}^{(e,t)} = \sum_b^B\sum_c^m\frac{MM[b][c]}{B}$
    \textcolor[rgb]{0.25, 0.5, 0.75}{\textit{\# Iteratively find the local bias level $Q_{(i,j)}^{(e,t)}$}}
    
    \STATE \textbf{for} $Q_{(i,j)}^{(e,t)} = 1$ \textbf{to} $m$ \textbf{do}
    \textcolor[rgb]{0.25, 0.5, 0.75}{\textit{\quad \# $m$ is the max index of the sentence in $\mathcal B_j$}}
    
    \STATE \quad $\sigma = \sum_{b=1}^{B}\sum_{c=1}^{Q_{(i,j)}^{(e,t)}} \frac{LD[b][c]}{B}$
    
    \STATE \quad \textbf{if} $\sigma \geq \Big\lceil \lambda \cdot \sum_{b=1}^{B}\sum_{c=1}^{m} \frac{LD[b][c]}{B} \Big\rceil$ \textbf{then}
    \STATE \qquad \textbf{break}
    \STATE \quad \textbf{end if}
    \STATE \textbf{end for}
    
    \textcolor[rgb]{0.25, 0.5, 0.75}{\textit{\# Comparison between local and global levels}}
    \STATE \textbf{if} $(Q_{(i,j)}^{(e,t)} < \bar Q^{(t-1)})$ \& $(\epsilon_{(i,j)}^{(e,t)} < \bar\epsilon^{(t-1)})$ \textbf{then}
    \STATE \quad $D_{(i,N)} := D_{(i,N)} \cup \mathcal B_j$ \textcolor[rgb]{0.25, 0.75, 0.25}{\textit{~\# belongs to normal subset}}
    \STATE \textbf{else}
    \STATE \quad $D_{(i,P)} := D_{(i,P)} \cup \mathcal B_j$ \textcolor[rgb]{0.75, 0.25, 0.25}{\textit{~\# belongs to the prime subset}}
    \STATE \textbf{end if}
    \RETURN $Q_{(i,j)}^{(e,t)}$, $\epsilon_{(i,j)}^{(e,t)}$, $D_{(i,N)}$, $D_{(i,P)}$
    \end{algorithmic}
\end{algorithm}
\end{center}

