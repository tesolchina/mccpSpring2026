<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Task Achievement Analysis: Model Papers Comparison</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 20px;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
            padding: 40px;
        }
        
        header {
            text-align: center;
            margin-bottom: 50px;
            padding-bottom: 30px;
            border-bottom: 3px solid #4a90e2;
        }
        
        h1 {
            color: #2c3e50;
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: #7f8c8d;
            font-size: 1.2em;
            font-weight: 300;
        }
        
        .paper-info {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 30px;
            margin-bottom: 40px;
        }
        
        .paper-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        .paper-card.kvflow {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        }
        
        .paper-card h2 {
            font-size: 1.5em;
            margin-bottom: 15px;
            border-bottom: 2px solid rgba(255,255,255,0.3);
            padding-bottom: 10px;
        }
        
        .paper-card p {
            margin: 8px 0;
            opacity: 0.95;
        }
        
        .aspect-section {
            margin: 50px 0;
            padding: 30px;
            background: #f8f9fa;
            border-radius: 8px;
            border-left: 5px solid #4a90e2;
        }
        
        .aspect-section h2 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            display: flex;
            align-items: center;
        }
        
        .aspect-number {
            background: #4a90e2;
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: bold;
            margin-right: 15px;
        }
        
        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 25px;
            margin-top: 25px;
        }
        
        .paper-analysis {
            background: white;
            padding: 25px;
            border-radius: 8px;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
            border-top: 4px solid #4a90e2;
        }
        
        .paper-analysis.kvflow {
            border-top-color: #f5576c;
        }
        
        .paper-analysis h3 {
            color: #2c3e50;
            font-size: 1.3em;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #e0e0e0;
        }
        
        .excerpt {
            background: #fff9e6;
            border-left: 4px solid #ffc107;
            padding: 15px;
            margin: 15px 0;
            border-radius: 4px;
            font-style: italic;
            position: relative;
        }
        
        .excerpt::before {
            content: '"';
            font-size: 3em;
            color: #ffc107;
            position: absolute;
            top: -10px;
            left: 10px;
            opacity: 0.3;
        }
        
        .analysis-points {
            margin-top: 20px;
        }
        
        .analysis-points ul {
            list-style: none;
            padding-left: 0;
        }
        
        .analysis-points li {
            padding: 12px;
            margin: 8px 0;
            background: white;
            border-left: 4px solid #4a90e2;
            border-radius: 4px;
            transition: transform 0.2s;
        }
        
        .analysis-points li:hover {
            transform: translateX(5px);
            box-shadow: 0 3px 8px rgba(0,0,0,0.1);
        }
        
        .analysis-points li strong {
            color: #4a90e2;
            display: block;
            margin-bottom: 5px;
        }
        
        .actionable-insights {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 8px;
            margin-top: 30px;
        }
        
        .actionable-insights h3 {
            font-size: 1.5em;
            margin-bottom: 20px;
            border-bottom: 2px solid rgba(255,255,255,0.3);
            padding-bottom: 10px;
        }
        
        .insight-item {
            background: rgba(255,255,255,0.1);
            padding: 15px;
            margin: 10px 0;
            border-radius: 5px;
            border-left: 4px solid white;
        }
        
        .insight-item strong {
            display: block;
            margin-bottom: 8px;
            font-size: 1.1em;
        }
        
        .comparison-table {
            width: 100%;
            margin-top: 25px;
            border-collapse: collapse;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }
        
        .comparison-table th {
            background: #4a90e2;
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: 600;
        }
        
        .comparison-table td {
            padding: 15px;
            border-bottom: 1px solid #e0e0e0;
        }
        
        .comparison-table tr:hover {
            background: #f8f9fa;
        }
        
        .comparison-table tr:last-child td {
            border-bottom: none;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: 600;
        }
        
        .tag {
            display: inline-block;
            background: #4a90e2;
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.85em;
            margin: 2px;
        }
        
        .tag.kvflow {
            background: #f5576c;
        }
        
        footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 30px;
            border-top: 2px solid #e0e0e0;
            color: #7f8c8d;
        }
        
        @media (max-width: 968px) {
            .comparison-grid {
                grid-template-columns: 1fr;
            }
            
            .paper-info {
                grid-template-columns: 1fr;
            }
        }
        
        .scroll-top {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background: #4a90e2;
            color: white;
            width: 50px;
            height: 50px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
            transition: transform 0.3s;
        }
        
        .scroll-top:hover {
            transform: scale(1.1);
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Task Achievement Analysis</h1>
            <p class="subtitle">Comparative Analysis of Model Papers: Aspect 1 & 2</p>
            <p class="subtitle" style="font-size: 1em; margin-top: 10px;">Focus: Research Background, Centrality Statements, and Gap Identification</p>
        </header>
        
        <div class="paper-info">
            <div class="paper-card">
                <h2>Paper 1: NeutronTP</h2>
                <p><strong>Title:</strong> Load-Balanced Distributed Full-Graph GNN Training with Tensor Parallelism</p>
                <p><strong>Authors:</strong> Ai et al. (2024)</p>
                <p><strong>Venue:</strong> PVLDB 2025</p>
                <p><strong>Field:</strong> Distributed Systems, Parallel Computing</p>
            </div>
            
            <div class="paper-card kvflow">
                <h2>Paper 2: KVFlow</h2>
                <p><strong>Title:</strong> Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows</p>
                <p><strong>Authors:</strong> Pan et al. (2025)</p>
                <p><strong>Venue:</strong> arXiv</p>
                <p><strong>Field:</strong> LLM Serving Systems, Multi-Agent Systems</p>
            </div>
        </div>
        
        <!-- Aspect 1: Research Background and Centrality Statements -->
        <div class="aspect-section">
            <h2>
                <span class="aspect-number">1</span>
                Research Background and Centrality Statements
            </h2>
            
            <div class="comparison-grid">
                <div class="paper-analysis">
                    <h3>NeutronTP: Establishing Territory</h3>
                    
                    <div class="excerpt">
                        "Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness in machine learning tasks (Wu et al., 2019; Yao et al., 2019; Ying et al., 2018; Fan et al., 2019). Graph-structured data serves as the input for GNNs, where each vertex is associated with a high-dimensional feature vector. The expressive power of GNNs stems from their ability to learn from relationships between data samples, whereas traditional DNNs are trained on individual samples (Zhou et al., 2020)."
                    </div>
                    
                    <div class="excerpt">
                        "Recently, full-graph GNN training, which involves training on the entire graph, has emerged as a promising GNN training method for its effectiveness brought by full-neighbor aggregation semantics and full-batch gradient descent (Jia et al., 2020; Wang et al., 2022; Md et al., 2021; Wang et al., 2023; Wan et al., 2023). Given the massive scale of graphs generated from applications, large-scale parallel and distributed computing becomes imperative for handling GNNs effectively (Lin et al., 2023; Shao et al., 2022; Yuan et al., 2023)."
                    </div>
                    
                    <div class="analysis-points">
                        <ul>
                            <li>
                                <strong>Opening Strategy:</strong> Begins with broad claim about GNN effectiveness, supported by multiple citations. Uses evaluative language: "remarkable effectiveness," "promising," "emerged."
                            </li>
                            <li>
                                <strong>Centrality Features:</strong>
                                <ul style="list-style: disc; padding-left: 20px; margin-top: 8px;">
                                    <li>Present perfect tense: "have demonstrated," "has emerged"</li>
                                    <li>Evaluative adjectives: "remarkable," "promising," "imperative"</li>
                                    <li>Progression from general (GNNs) to specific (full-graph training)</li>
                                </ul>
                            </li>
                            <li>
                                <strong>Citation Pattern:</strong> Multiple citations per sentence, showing comprehensive literature awareness. Uses information-prominent approach with parenthetical citations.
                            </li>
                            <li>
                                <strong>Transition Strategy:</strong> Moves from general GNN effectiveness → specific training method (full-graph) → need for distributed computing, creating logical progression.
                            </li>
                        </ul>
                    </div>
                </div>
                
                <div class="paper-analysis kvflow">
                    <h3>KVFlow: Establishing Territory</h3>
                    
                    <div class="excerpt">
                        "LLM-based agentic workflows coordinate multiple specialized agents, each defined by a fixed prompt and responsible for a specific subtask, to solve complex problems in a modular and interpretable way (yao2023react; shinn2023reflexion; hong2023metagpt; li2023camel; wang2024peer)."
                    </div>
                    
                    <div class="excerpt">
                        "To alleviate this overhead, existing agentic frameworks and applications (hong2023metagpt; wu2023autogen; zhuge2024gptswarm; zhang2024aflow; pan2024very; he2025cognify) rely on LLM serving systems (vllm; sglang; trtllm) equipped with system-level optimizations. A prevalent technique is prefix caching (sglang; vllm_prefix_cache), which reuses the key-value (KV) tensors produced by self-attention layers for static prompt tokens across decoding steps and requests."
                    </div>
                    
                    <div class="analysis-points">
                        <ul>
                            <li>
                                <strong>Opening Strategy:</strong> Begins with definition and characterization of agentic workflows, immediately establishing the research domain. Uses descriptive language: "modular and interpretable way."
                            </li>
                            <li>
                                <strong>Centrality Features:</strong>
                                <ul style="list-style: disc; padding-left: 20px; margin-top: 8px;">
                                    <li>Present tense for current state: "coordinate," "rely on"</li>
                                    <li>Technical terminology: "agentic workflows," "prefix caching," "KV tensors"</li>
                                    <li>Progression: paradigm definition → optimization need → specific technique</li>
                                </ul>
                            </li>
                            <li>
                                <strong>Citation Pattern:</strong> Multiple citations grouped by theme (frameworks, systems, techniques). Uses author-date citation style with lowercase keys.
                            </li>
                            <li>
                                <strong>Transition Strategy:</strong> Defines paradigm → identifies overhead problem → introduces optimization technique (prefix caching), showing clear problem-solution connection.
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="actionable-insights">
                <h3>Actionable Insights: Aspect 1</h3>
                
                <div class="insight-item">
                    <strong>1. Opening Sentence Patterns</strong>
                    <p>Both papers use different but effective opening strategies. <span class="highlight">NeutronTP</span> starts with a broad effectiveness claim, while <span class="highlight">KVFlow</span> begins with a definition. Choose based on whether your field expects immediate problem statement or domain definition.</p>
                </div>
                
                <div class="insight-item">
                    <strong>2. Centrality Statement Language</strong>
                    <p>Use evaluative language strategically: "remarkable," "promising," "emerged," "prevalent." Combine present perfect tense ("have demonstrated") with present tense ("becomes imperative") to show both historical development and current importance.</p>
                </div>
                
                <div class="insight-item">
                    <strong>3. Citation Density</strong>
                    <p>Both papers cite multiple sources per sentence in Move 1, demonstrating comprehensive field knowledge. Aim for 3-5 citations when establishing general territory, showing you've surveyed the field.</p>
                </div>
                
                <div class="insight-item">
                    <strong>4. Logical Progression</strong>
                    <p>Follow a clear progression: General domain → Specific approach/method → Current challenges/needs. This creates a funnel effect that guides readers from broad context to your specific contribution.</p>
                </div>
                
                <div class="insight-item">
                    <strong>5. Technical Terminology Balance</strong>
                    <p>Introduce domain-specific terms naturally within context. Both papers define concepts through usage rather than explicit definitions, assuming expert audience knowledge.</p>
                </div>
            </div>
        </div>
        
        <!-- Aspect 2: Research Gap Identification and Delineation -->
        <div class="aspect-section">
            <h2>
                <span class="aspect-number">2</span>
                Research Gap Identification and Delineation
            </h2>
            
            <div class="comparison-grid">
                <div class="paper-analysis">
                    <h3>NeutronTP: Identifying the Niche</h3>
                    
                    <div class="excerpt">
                        "Despite that partitioning graph data enables distributed GNN systems to handle large-scale data, it also constitutes a primary constraint on the performance of GNN data parallelism. Firstly, as illustrated in Figure 2 (a), the irregular nature of graph data makes it challenging to ensure load balance when partitioning the workload. Many survey papers (Lin et al., 2023; Shao et al., 2022; Yuan et al., 2023) highlight workload imbalance as a primary challenge, both in mini-batch and full-graph training. Secondly, the edges among data samples (i.e., vertices) lead to complex cross-worker vertex dependencies since graph aggregation may require neighbor data located on remote workers (Jia et al., 2020; Wang et al., 2022)."
                    </div>
                    
                    <div class="excerpt">
                        "Existing systems adopt methods such as cross-worker neighbor replication (Zhu et al., 2019; Zheng et al., 2020; Zhang et al., 2020; Gandhi and Iyer, 2021) and neighbor communication (Jia et al., 2020; Peng et al., 2022; Wan et al., 2023, 2022a; Md et al., 2021) to manage vertex dependencies. As a result, the efficiency of GNN data parallelism is constrained by redundant computations and substantial communication overhead (Wang et al., 2022; Wan et al., 2023; Jia et al., 2020)."
                    </div>
                    
                    <div class="analysis-points">
                        <ul>
                            <li>
                                <strong>Gap-Signaling Language:</strong> Uses "Despite that" to acknowledge benefits while introducing limitations. "constitutes a primary constraint" clearly identifies the problem.
                            </li>
                            <li>
                                <strong>Systematic Enumeration:</strong> Uses "Firstly" and "Secondly" to clearly delineate multiple aspects of the gap, making the problem comprehensive and researchable.
                            </li>
                            <li>
                                <strong>Evidence Support:</strong> References survey papers and multiple studies to show the gap is recognized in the field, not just the authors' observation.
                            </li>
                            <li>
                                <strong>Technical Specificity:</strong> Identifies specific technical problems (load imbalance, cross-worker dependencies) rather than vague limitations.
                            </li>
                            <li>
                                <strong>Consequence Articulation:</strong> Clearly states the impact: "constrained by redundant computations and substantial communication overhead."
                            </li>
                        </ul>
                    </div>
                </div>
                
                <div class="paper-analysis kvflow">
                    <h3>KVFlow: Identifying the Niche</h3>
                    
                    <div class="excerpt">
                        "However, prefix caching alone is insufficient in the presence of limited GPU memory. Existing systems typically adopt a Least Recently Used (LRU) policy to evict KV caches that have not been accessed recently. We observe that this strategy can lead to suboptimal performance in agentic workflows."
                    </div>
                    
                    <div class="excerpt">
                        "For instance, as illustrated in Figure 1, consider a workflow (wang2024peer) where four agents are organized into a sequential execution pipeline that is invoked iteratively. During the execution of the Executor agent shown in the figure, the LRU policy identifies the Expresser's KV cache as the eviction candidate since it has not been accessed recently. This results in a cache miss when the workflow proceeds to the Expresser agent, despite its imminent reuse. Such eviction behavior introduces unnecessary recomputation and degrades the overall efficiency of agentic execution."
                    </div>
                    
                    <div class="analysis-points">
                        <ul>
                            <li>
                                <strong>Gap-Signaling Language:</strong> Uses "However" for clear opposition. "insufficient" and "suboptimal" indicate limitations without being overly negative.
                            </li>
                            <li>
                                <strong>Concrete Example:</strong> Provides a specific scenario (Figure 1) to illustrate the gap, making abstract problems tangible and understandable.
                            </li>
                            <li>
                                <strong>Observation Language:</strong> Uses "We observe that" to present the gap as an empirical finding, adding credibility.
                            </li>
                            <li>
                                <strong>Problem Mechanism:</strong> Explains HOW the gap occurs (LRU evicts before reuse), not just THAT it exists, showing deep understanding.
                            </li>
                            <li>
                                <strong>Consequence Articulation:</strong> Links gap to specific negative outcomes: "cache miss," "unnecessary recomputation," "degrades efficiency."
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
            
            <div class="actionable-insights">
                <h3>Actionable Insights: Aspect 2</h3>
                
                <div class="insight-item">
                    <strong>1. Transition from Move 1 to Move 2</strong>
                    <p>Use clear oppositional markers: <span class="highlight">"Despite that," "However," "Nevertheless"</span>. Acknowledge what existing approaches achieve before introducing limitations to show balanced evaluation.</p>
                </div>
                
                <div class="insight-item">
                    <strong>2. Gap Delineation Strategies</strong>
                    <p>Two effective approaches: (1) <span class="highlight">Systematic enumeration</span> (NeutronTP: "Firstly... Secondly") for multiple related gaps, (2) <span class="highlight">Concrete example</span> (KVFlow: Figure 1 scenario) for complex gaps. Choose based on gap complexity.</p>
                </div>
                
                <div class="insight-item">
                    <strong>3. Evidence for Gap Legitimacy</strong>
                    <p>Support gap claims with: (1) References to survey papers or multiple studies showing field recognition, (2) Empirical observations ("We observe that"), (3) Specific technical mechanisms explaining why the gap exists.</p>
                </div>
                
                <div class="insight-item">
                    <strong>4. Technical Specificity</strong>
                    <p>Make gaps researchable by identifying: (1) <span class="highlight">Specific technical problems</span> (load imbalance, cache eviction), (2) <span class="highlight">Root causes</span> (irregular graph structure, LRU policy limitations), (3) <span class="highlight">Consequences</span> (communication overhead, recomputation).</p>
                </div>
                
                <div class="insight-item">
                    <strong>5. Language for Gap Articulation</strong>
                    <p>Use precise language: "constitutes a primary constraint," "leads to suboptimal performance," "fails to anticipate." Avoid vague terms like "not good" or "has problems." Be specific about what doesn't work and why.</p>
                </div>
            </div>
            
            <table class="comparison-table">
                <thead>
                    <tr>
                        <th>Feature</th>
                        <th>NeutronTP Strategy</th>
                        <th>KVFlow Strategy</th>
                        <th>When to Use</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Gap Presentation</strong></td>
                        <td>Systematic enumeration (Firstly, Secondly)</td>
                        <td>Concrete example with scenario</td>
                        <td>Enumeration: Multiple related gaps. Example: Complex gap needing illustration</td>
                    </tr>
                    <tr>
                        <td><strong>Opposition Marker</strong></td>
                        <td>"Despite that" (acknowledges benefits)</td>
                        <td>"However" (direct contrast)</td>
                        <td>"Despite": Want to show balanced view. "However": Clear problem focus</td>
                    </tr>
                    <tr>
                        <td><strong>Evidence Type</strong></td>
                        <td>Survey papers + multiple studies</td>
                        <td>Empirical observation + concrete scenario</td>
                        <td>Surveys: Well-established field. Observation: Novel problem identification</td>
                    </tr>
                    <tr>
                        <td><strong>Technical Detail</strong></td>
                        <td>High (load balance, dependencies, communication)</td>
                        <td>Medium (LRU policy, cache eviction)</td>
                        <td>Match detail level to audience expertise and paper type</td>
                    </tr>
                    <tr>
                        <td><strong>Consequence Link</strong></td>
                        <td>Direct: "constrained by overhead"</td>
                        <td>Narrative: "results in cache miss... degrades efficiency"</td>
                        <td>Direct: Technical audience. Narrative: Broader audience or complex systems</td>
                    </tr>
                </tbody>
            </table>
        </div>
        
        <!-- Cross-Paper Patterns -->
        <div class="aspect-section">
            <h2>
                <span class="aspect-number">★</span>
                Cross-Paper Patterns and Scalability Notes
            </h2>
            
            <div class="actionable-insights">
                <h3>Common Patterns Across Both Papers</h3>
                
                <div class="insight-item">
                    <strong>Pattern 1: Three-Paragraph Introduction Structure</strong>
                    <p>Both papers follow: (1) Establish territory with centrality statements, (2) Identify niche with gap articulation, (3) Occupy niche with solution preview. This structure is scalable to 30+ papers analysis.</p>
                </div>
                
                <div class="insight-item">
                    <strong>Pattern 2: Citation Density Gradient</strong>
                    <p>High citation density in Move 1 (3-5 citations), moderate in Move 2 (2-3 citations), lower in Move 3 (1-2 citations). This pattern supports credibility while maintaining readability.</p>
                </div>
                
                <div class="insight-item">
                    <strong>Pattern 3: Technical Terminology Introduction</strong>
                    <p>Both papers introduce domain terms naturally through context rather than explicit definitions, assuming expert audience. This is common in systems/engineering papers.</p>
                </div>
                
                <div class="insight-item">
                    <strong>Pattern 4: Quantitative Claims in Introduction</strong>
                    <p>Both papers include performance metrics (speedup numbers) in Move 3, providing concrete evidence of contribution significance. This is effective for systems papers.</p>
                </div>
                
                <div class="insight-item">
                    <strong>Pattern 5: Visual Support for Gap Illustration</strong>
                    <p>Both papers reference figures (Figure 2, Figure 1) to illustrate gaps, making abstract problems concrete. This is a scalable pattern for complex technical gaps.</p>
                </div>
            </div>
            
            <div style="background: #e8f4f8; padding: 25px; border-radius: 8px; margin-top: 25px;">
                <h3 style="color: #2c3e50; margin-bottom: 15px;">Scalability Framework for 30-Paper Analysis</h3>
                <p style="color: #555; line-height: 1.8;">
                    This analysis framework can be scaled to 30 papers by: (1) <strong>Automated extraction</strong> of Move 1-3 paragraphs from introductions, (2) <strong>Pattern classification</strong> using the strategies identified here (enumeration vs. example, "Despite" vs. "However"), (3) <strong>Citation analysis</strong> to identify common sources and citation patterns, (4) <strong>Language feature tagging</strong> (evaluative adjectives, gap-signaling phrases), (5) <strong>Comparative clustering</strong> to group papers by similar strategies. The HTML structure supports dynamic filtering and comparison across multiple papers.
                </p>
            </div>
        </div>
        
        <footer>
            <p>Analysis Framework: Task Achievement Aspects 1 & 2 | Based on analyzeModelPaperPlan.md</p>
            <p style="margin-top: 10px; font-size: 0.9em;">Papers Analyzed: NeutronTP (2412.20379) | KVFlow (2507.07400)</p>
        </footer>
    </div>
    
    <div class="scroll-top" onclick="window.scrollTo({top: 0, behavior: 'smooth'})">
        ↑
    </div>
    
    <script>
        // Smooth scroll behavior
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                document.querySelector(this.getAttribute('href')).scrollIntoView({
                    behavior: 'smooth'
                });
            });
        });
        
        // Show/hide scroll to top button
        window.addEventListener('scroll', function() {
            const scrollTop = document.querySelector('.scroll-top');
            if (window.pageYOffset > 300) {
                scrollTop.style.display = 'flex';
            } else {
                scrollTop.style.display = 'none';
            }
        });
    </script>
</body>
</html>
