# Specialised vocabulary (50 items)

1. **Term**: multimodal model
   - Sentence: "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs."
   - Why it’s good: It is a standard research term that signals the model handles multiple input modalities.
   - Future use: Use when describing systems that process text plus images, audio, or other modalities.

2. **Term**: professional and academic benchmarks
   - Sentence: "While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers."
   - Why it’s good: It precisely refers to standardized evaluations used in research and reporting.
   - Future use: Use in results sections to frame performance against established tests.

3. **Term**: simulated bar exam
   - Sentence: "While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers."
   - Why it’s good: It names a concrete, high-stakes evaluation, making claims more interpretable.
   - Future use: Use when citing legal-domain evaluation or professional certification proxies.

4. **Term**: Transformer-based model
   - Sentence: "GPT-4 is a Transformer-based model pre-trained to predict the next token in a document."
   - Why it’s good: It locates the approach within a specific, widely recognized architecture family.
   - Future use: Use in method descriptions to quickly situate model type.

5. **Term**: next token
   - Sentence: "GPT-4 is a Transformer-based model pre-trained to predict the next token in a document."
   - Why it’s good: It refers to the core objective in language modeling, a precise technical concept.
   - Future use: Use when explaining training objectives or generative behavior.

6. **Term**: post-training alignment process
   - Sentence: "The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior."
   - Why it’s good: It captures a distinct stage in modern model development with a clear purpose.
   - Future use: Use in discussions of safety, alignment, or fine-tuning pipelines.

7. **Term**: factuality
   - Sentence: "The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior."
   - Why it’s good: It denotes a specific evaluation dimension for model outputs.
   - Future use: Use when reporting accuracy or truthfulness metrics for generated text.

8. **Term**: adherence to desired behavior
   - Sentence: "The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior."
   - Why it’s good: It expresses alignment outcomes in a measurable, professional tone.
   - Future use: Use when describing safety constraints or policy-compliant outputs.

9. **Term**: optimization methods
   - Sentence: "A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales."
   - Why it’s good: It connects technical procedures to scalability and reliability.
   - Future use: Use when detailing training strategies or system engineering choices.

10. **Term**: predictably across a wide range of scales
    - Sentence: "A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales."
    - Why it’s good: It conveys robust scaling behavior, a key research objective.
    - Future use: Use to justify extrapolations from smaller to larger models.

11. **Term**: compute
    - Sentence: "This allowed us to accurately predict some aspects of GPT-4’s performance based on models trained with no more than 1/1,000th the compute of GPT-4."
    - Why it’s good: It is a standard term for training resources with quantifiable meaning.
    - Future use: Use in scaling analyses or efficiency comparisons.

12. **Term**: chain-of-thought prompting
    - Sentence: "We use chain-of-thought prompting [ 11 ] when evaluating."
    - Why it’s good: It names a specific prompting technique widely cited in LLM literature.
    - Future use: Use when describing evaluation protocols or reasoning elicitation.

13. **Term**: transfer learning
    - Sentence: "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP)."
    - Why it’s good: It defines a core paradigm in modern NLP research.
    - Future use: Use in introductions or related work to situate methodology.

14. **Term**: pre-trained
    - Sentence: "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP)."
    - Why it’s good: It signals prior training on large corpora, a key technical detail.
    - Future use: Use when contrasting base models with task-specific variants.

15. **Term**: fine-tuned
    - Sentence: "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP)."
    - Why it’s good: It conveys task adaptation with a precise technical verb.
    - Future use: Use when describing task-specific adaptation steps.

16. **Term**: downstream task
    - Sentence: "Ideally, this pre-training causes the model to develop general-purpose abilities and knowledge that can then be transferred to downstream tasks."
    - Why it’s good: It distinguishes target applications from pre-training objectives.
    - Future use: Use in methods and evaluation sections to define target tasks.

17. **Term**: general-purpose abilities
    - Sentence: "Ideally, this pre-training causes the model to develop general-purpose abilities and knowledge that can then be transferred to downstream tasks."
    - Why it’s good: It summarizes a key motivation for pre-training in academic style.
    - Future use: Use when motivating transfer learning benefits.

18. **Term**: encoder-decoder architecture
    - Sentence: "The original Transformer consisted of an encoder-decoder architecture and was intended for sequence-to-sequence (Sutskever et al., 2014 ; Kalchbrenner et al., 2014 ) tasks."
    - Why it’s good: It names a canonical model structure with clear technical meaning.
    - Future use: Use when describing model topology in a methods section.

19. **Term**: sequence of tokens
    - Sentence: "First, an input sequence of tokens is mapped to a sequence of embeddings, which is then passed into the encoder."
    - Why it’s good: It uses standard NLP terminology for input representation.
    - Future use: Use when explaining preprocessing or model input pipelines.

20. **Term**: temperature-scaled mixing
    - Sentence: "Temperature-scaled mixing An alternative way of mitigating the huge disparity between data set sizes is to adjust the “temperature” of the mixing rates."
    - Why it’s good: It is a precise collocation describing data balancing in training.
    - Future use: Use in data preparation or curriculum learning discussions.

21. **Term**: Colossal Clean Crawled Corpus
    - Sentence: "By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more."
    - Why it’s good: It names a specific dataset, which adds credibility and reproducibility.
    - Future use: Use when citing data sources or pre-training corpora.

22. **Term**: state-of-the-art results
    - Sentence: "By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more."
    - Why it’s good: It is a standard evaluation claim in research writing.
    - Future use: Use when reporting best-known performance on benchmarks.

23. **Term**: zero-shot learning
    - Sentence: "( 2019 ) evaluate the zero-shot learning capabilities of language models by feeding some input to the model as a prefix and then autoregressively sampling an output."
    - Why it’s good: It labels a specific evaluation setting with no labeled examples.
    - Future use: Use to describe performance without task-specific training.

24. **Term**: autoregressively sampling
    - Sentence: "( 2019 ) evaluate the zero-shot learning capabilities of language models by feeding some input to the model as a prefix and then autoregressively sampling an output."
    - Why it’s good: It precisely describes the generation procedure in LLMs.
    - Future use: Use when detailing inference or decoding steps.

25. **Term**: embeddings
    - Sentence: "First, an input sequence of tokens is mapped to a sequence of embeddings, which is then passed into the encoder."
    - Why it’s good: It specifies a core representation used inside neural architectures.
    - Future use: Use when explaining feature representation or model inputs.

26. **Term**: attention layers
    - Sentence: "These equivalences are approximate—there are some extra parameters in the decoder due to the encoder-decoder attention and there are also some computational costs in the attention layers that are quadratic in the sequence lengths."
    - Why it’s good: It references a core component with specific computational implications.
    - Future use: Use when analyzing complexity or architecture trade-offs.

27. **Term**: adversarial
    - Sentence: "Omitting results on the WNLI validation set is standard practice (Devlin et al., 2018 ) due to the fact that it is “adversarial” with respect to the training set, i.e."
    - Why it’s good: It highlights adversarial behavior in datasets, a specialized evaluation concern.
    - Future use: Use when discussing robustness or dataset bias.

28. **Term**: calibration
    - Sentence: "Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit “breakthrough” behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting."
    - Why it’s good: It names a precise evaluation dimension in probabilistic predictions.
    - Future use: Use when reporting reliability of model confidence.

29. **Term**: sparsity
    - Sentence: "Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit “breakthrough” behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting."
    - Why it’s good: It captures a known architectural property linked to efficiency and performance.
    - Future use: Use when describing model design choices like sparse activations or routing.

30. **Term**: zero- and few-shot evaluation setting
    - Sentence: "By focusing on such tasks in the zero- and few-shot evaluation setting, it becomes possible to provide meaningful scores for even those tasks with a very small number of examples."
    - Why it’s good: It clearly labels an evaluation protocol used in LLM research.
    - Future use: Use when framing experiments with limited supervision.

31. **Term**: in-context
    - Sentence: "A clear example of this sort of task is modified_arithmetic, which involves applying a mathematical operator, defined in-context to certain inputs."
    - Why it’s good: It describes a key mechanism of LLM behavior without gradient updates.
    - Future use: Use in analyses of prompting or in-context learning.

32. **Term**: robustness
    - Sentence: "Using pre-training can improve model robustness and uncertainty."
    - Why it’s good: It refers to a standard criterion for reliable model behavior.
    - Future use: Use in claims about stability across noise or distribution shifts.

33. **Term**: uncertainty estimates
    - Sentence: "In this section, we quantify how well calibrated model uncertainty estimates are on BIG-bench, and how this calibration changes with model scale."
    - Why it’s good: It is precise language for probabilistic reliability analysis.
    - Future use: Use when discussing confidence or risk-aware prediction.

34. **Term**: BIG-bench
    - Sentence: "To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench)."
    - Why it’s good: It names a specific benchmark suite, adding specificity to evaluation claims.
    - Future use: Use when referencing evaluation datasets or benchmark results.

35. **Term**: generalizations
    - Sentence: "These tasks present a context where the completion is ambiguous given the available evidence, or where the model is asked to make generalizations about broad classes."
    - Why it’s good: It conveys a theoretical goal of learning beyond memorization.
    - Future use: Use in analysis sections to describe model reasoning scope.

36. **Term**: instruction tuning
    - Sentence: "Multitask prompted finetuning (also referred to as instruction tuning) involves finetuning a pretrained language model on a training mixture composed of a large set of different tasks specified through natural language prompts."
    - Why it’s good: It defines a specific and widely adopted fine-tuning regime.
    - Future use: Use when describing multi-task training and alignment methods.

37. **Term**: training mixture
    - Sentence: "Multitask prompted finetuning (also referred to as instruction tuning) involves finetuning a pretrained language model on a training mixture composed of a large set of different tasks specified through natural language prompts."
    - Why it’s good: It concisely describes how tasks are combined in training.
    - Future use: Use when describing data composition in multitask learning.

38. **Term**: natural language prompts
    - Sentence: "Multitask prompted finetuning (also referred to as instruction tuning) involves finetuning a pretrained language model on a training mixture composed of a large set of different tasks specified through natural language prompts."
    - Why it’s good: It captures a key interface between tasks and models in LLM research.
    - Future use: Use when specifying task formats or datasets.

39. **Term**: pretrained language models
    - Sentence: "Pretrained language models have become a cornerstone of modern natural language processing (NLP) pipelines because they often produce better performance from smaller quantities of labeled data."
    - Why it’s good: It states a widely accepted motivation for using large models.
    - Future use: Use in introductions or background sections.

40. **Term**: data curation
    - Sentence: "This abstractive approach to data curation leads to corpora that are difficult to meaningfully document and govern after the fact, as the provenance and authorship of individual items is usually lost in the process."
    - Why it’s good: It signals a specialized methodological concern in dataset construction.
    - Future use: Use when describing data collection or governance limitations.

41. **Term**: ethical considerations
    - Sentence: "Ethical Considerations within BigScience In order to acknowledge and start addressing social limitations of LLM development within BigScience, the workshop relied on a collaboratively designed Ethical Charter 3 3 3 bigscience.huggingface.co/blog/bigscience-ethical-charter and original research on applicable regulations in jurisdictions outside of the US 4 4 4 bigscience.huggingface.co/blog/legal-playbook-for-natural-language-processing-researchers to guide its choices throughout the project."
    - Why it’s good: It frames research practice within a formal ethical governance context.
    - Future use: Use in broader impact or ethics sections.

42. **Term**: social limitations
    - Sentence: "Social Limitations of LLM Development While the continued increase in the size of large language models has resulted in improvements across a wide range of tasks, it has also exacerbated issues with their development and use (Bender et al., 2021 ) ."
    - Why it’s good: It expresses a nuanced caution in academic tone.
    - Future use: Use when discussing limitations or societal impacts.

43. **Term**: language safety
    - Sentence: "Second, as this work builds on top of large language models, language safety is a key consideration warranting further study before our approach could be used in practice."
    - Why it’s good: It highlights safety as a formal research constraint.
    - Future use: Use in risk or deployment considerations.

44. **Term**: preference uncertainty
    - Sentence: "The main challenge is to balance continued question asking to reduce preference uncertainty and provide recommendations using the least number of conversation turns."
    - Why it’s good: It denotes uncertainty in user preference modeling with technical precision.
    - Future use: Use in dialogue systems or recommendation contexts.

45. **Term**: conversation turns
    - Sentence: "The main challenge is to balance continued question asking to reduce preference uncertainty and provide recommendations using the least number of conversation turns."
    - Why it’s good: It is standard terminology in conversational AI evaluation.
    - Future use: Use when discussing efficiency or user burden in dialog.

46. **Term**: limitations
    - Sentence: "Finally, we provide a detailed analysis of cases where the models show their limitations."
    - Why it’s good: It is a formal and expected framing in research reporting.
    - Future use: Use to structure limitation sections in papers.

47. **Term**: hallucinations
    - Sentence: "Nevertheless, during experimentation, we did not observe concerning language nor hallucinations."
    - Why it’s good: It uses a widely recognized term for false or unsupported outputs.
    - Future use: Use in safety or evaluation reporting.

48. **Term**: streamlining workflows
    - Sentence: "Particularly, GUI-based tools can improve productivity by streamlining workflows and automating repetitive tasks."
    - Why it’s good: It expresses process optimization in a professional, technical style.
    - Future use: Use in system design or tooling discussions.

49. **Term**: malicious attacks
    - Sentence: "Overall, incorporating tools into the workflow of foundation models can improve the robustness of the system and reduce the risk of malicious attacks."
    - Why it’s good: It connects security risk with system-level design choices.
    - Future use: Use in security or threat modeling sections.

50. **Term**: name tokens
    - Sentence: "We argue that learning is considerably stalled when these circuits are under development, as errors are not properly backpropagated from attribute value tokens to name tokens, explaining the existence of the plateau."
    - Why it’s good: It is a precise phrase from mechanistic interpretability work.
    - Future use: Use when describing token-level representations or circuit analysis.
