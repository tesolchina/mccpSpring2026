<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>How do language models learn facts? Dynamics, curricula and hallucinations</title>
<!--Generated on Thu Jul 24 12:00:16 2025 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2503.21676v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_document ltx_ref_self">
<span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">How do language models learn facts? Dynamics, curricula and hallucinations</span></span>
<ol class="ltx_toclist ltx_toclist_document">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1" title="In How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>An experimental setup to track knowledge over the course of learning</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS1" title="In 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Knowledge, and how it differs from memory</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS2" title="In 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Synthetic biographies as a framework for studying knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS3" title="In 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Measuring knowledge at scale</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS4" title="In 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Language models are trained following standard recipes</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2" title="In How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>How language models acquire knowledge during learning</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS1" title="In 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>The three phases underlying knowledge acquisition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS2" title="In 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>The attention-based circuits supporting recall are created during the loss plateau</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3" title="In How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data distributional properties drive knowledge acquisition</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.SS1" title="In 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>The trade-off underlying imbalances in the data distribution</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.SS2" title="In 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Data schedulers increase the final amount of acquired knowledge</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="In How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Hallucinations hinder the integration of new knowledge post-training</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.SS1" title="In 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Models start hallucinating as soon as they acquire knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.SS2" title="In 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>A large portion of the pre-training knowledge is erased during early fine-tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S5" title="In How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S5.SS0.SSS0.Px1" title="In 5 Discussion ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title">On the learning dynamics of language models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S5.SS0.SSS0.Px2" title="In 5 Discussion ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title">On the learning dynamics of neural networks more broadly.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S5.SS0.SSS0.Px3" title="In 5 Discussion ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title">On the role of non-uniformity and connections to developmental psychology.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#Sx1.SS0.SSS0.Px1" title="In Limitations ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title">Scale and architecture.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#Sx1.SS0.SSS0.Px2" title="In Limitations ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title">Data.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_part">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#Pt1" title="In How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">Appendix </span></span></a>
<ol class="ltx_toclist ltx_toclist_part">
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A1" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A1.SS1" title="In Appendix A Related work ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Associative memories and factual knowledge of neural networks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A1.SS2" title="In Appendix A Related work ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Learning dynamics of neural networks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Experimental setup</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.SS1" title="In Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Rationale behind our design choices</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.SS2" title="In Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Details about the biography generation process</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.SS3" title="In Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.3 </span>Architecture, optimization and metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional analysis of the learning dynamics (Section¬†<span class="ltx_text ltx_ref_tag">2.1</span>)</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.SS1" title="In Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>The three phases are robust to sensible hyperparameter choices</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Details of the mechanistic study and additional analyses (Section¬†<span class="ltx_text ltx_ref_tag">2.2</span>)</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS1" title="In Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.1 </span>Implementation of the attention patching experiment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS2" title="In Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D.2 </span>Details of the attention pattern analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional analysis for the impact of data distribution properties (Section¬†<span class="ltx_text ltx_ref_tag">3</span>)</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.SS1" title="In Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Learning curves for different data distributions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.SS2" title="In Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Extensive comparison of the performance of different data distributions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Details of the fine-tuning analysis and additional experiments (Section¬†<span class="ltx_text ltx_ref_tag">4</span>)</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS1" title="In Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.1 </span>Experimental details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS2" title="In Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.2 </span>Hallucinations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS3" title="In Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.3 </span>Additional analysis for fine-tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS4" title="In Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.4 </span>Reproducing fine-tuning behavior on a toy associative memory problem</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS5" title="In Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.5 </span>Experiments with regular changes in training distribution</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7" title="In Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Hyperparameter configurations</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.SS1" title="In Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.1 </span>Default configuration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.SS2" title="In Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.2 </span>Hyperparameters for Section¬†<span class="ltx_text ltx_ref_tag">2.1</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.SS3" title="In Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.3 </span>Hyperparameters for Section¬†<span class="ltx_text ltx_ref_tag">2.2</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.SS4" title="In Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.4 </span>Hyperparameters for Section¬†<span class="ltx_text ltx_ref_tag">3</span></span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.SS5" title="In Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.5 </span>Hyperparameters for Section¬†<span class="ltx_text ltx_ref_tag">4</span></span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\pdftrailerid</span>
<p class="ltx_p" id="p1.2">redacted







<span class="ltx_ERROR undefined" id="p1.2.1">\correspondingauthor</span>nzucchet@ethz.ch and sohamde@google.com
<span class="ltx_ERROR undefined" id="p1.2.2">\reportnumber</span>001 









</p>
</div>
<h1 class="ltx_title ltx_title_document">How do language models learn facts? Dynamics, curricula and hallucinations
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Nicolas Zucchet
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">ETH Z√ºrich
</span>
<span class="ltx_contact ltx_role_affiliation">Work done at Google DeepMind
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">J√∂rg Bornschein
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google DeepMind
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Stephanie Chan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google DeepMind
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Andrew Lampinen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google DeepMind
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Razvan Pascanu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google DeepMind
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Soham De
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google DeepMind
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood.
This work investigates the learning dynamics of language models on a synthetic factual recall task, uncovering three key findings: First, language models learn in three phases, exhibiting a performance plateau before acquiring precise factual knowledge.
Mechanistically, this plateau coincides with the formation of attention-based circuits that support recall.
Second, the training data distribution significantly impacts learning dynamics, as imbalanced distributions lead to shorter plateaus.
Finally, hallucinations emerge simultaneously with knowledge, and integrating new knowledge into the model through fine-tuning is challenging, as it quickly corrupts its existing parametric memories.
Our results emphasize the importance of data distribution in knowledge acquisition and suggest novel data scheduling strategies to accelerate neural network training.</p>
</div>
<div class="ltx_para ltx_noindent" id="p2">
<span class="ltx_ERROR undefined" id="p2.1" lang="en">\doparttoc</span><span class="ltx_ERROR undefined" id="p2.2" lang="en">\faketableofcontents</span>
</div>
<div class="ltx_para ltx_noindent" id="p3">
<p class="ltx_p" id="p3.1"><span class="ltx_text" id="p3.1.1" lang="en">Large language models offer a powerful and intuitive interface to access the vast amounts of knowledge on which they were trained. The learning process acts as a lossy compression algorithm turning training data into neural network parameters, thereby implicitly determining what information is preserved within the final model. The extent and nature of this information loss depend on numerous factors, including architecture, training objective, and data distribution, dependencies that remain poorly understood. Deciphering the mechanisms underlying knowledge compression is increasingly important as these models are becoming our main gateway to human knowledge. Our work addresses this challenge by systematically investigating how language models acquire factual knowledge.</span></p>
</div>
<div class="ltx_para ltx_noindent" id="p4">
<p class="ltx_p" id="p4.1"><span class="ltx_text" id="p4.1.1" lang="en">Inspired by a long history of work in neuroscience focusing on associative recall to study <cite class="ltx_cite ltx_citemacro_citep">(Pavlov, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib41" title="">1927</a>)</cite> and model <cite class="ltx_cite ltx_citemacro_citep">(Hopfield, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib23" title="">1982</a>)</cite> intelligence, we focus on a synthetic factual recall task to study in depth the learning dynamics of language models. Our contributions are:</span></p>
<ul class="ltx_itemize" id="S0.I1" lang="en">
<li class="ltx_item" id="S0.I1.ix1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Äì</span>
<div class="ltx_para" id="S0.I1.ix1.p1">
<p class="ltx_p" id="S0.I1.ix1.p1.1">We adapt the synthetic task of <cite class="ltx_cite ltx_citemacro_citet">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, which generates artificial biographies for testing factual recall, to make it suitable for studying the formation of associative memories (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1" title="1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S0.I1.ix2" style="list-style-type:none;padding-top:2.0pt;">
<span class="ltx_tag ltx_tag_item">‚Äì</span>
<div class="ltx_para" id="S0.I1.ix2.p1">
<p class="ltx_p" id="S0.I1.ix2.p1.1">We find that language models learn in multiple phases on this task. They first learn overall distribution statistics, then their performance plateaus, and, finally, they acquire individual-specific knowledge (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS1" title="2.1 The three phases underlying knowledge acquisition ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.1</span></a>). Leveraging a novel attention patching technique, we demonstrate that attention-based recall circuits develop during this plateau (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS2" title="2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.2</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S0.I1.ix3" style="list-style-type:none;padding-top:2.0pt;">
<span class="ltx_tag ltx_tag_item">‚Äì</span>
<div class="ltx_para" id="S0.I1.ix3.p1">
<p class="ltx_p" id="S0.I1.ix3.p1.1">We analyze the impact of data distribution properties on these dynamics, revealing that imbalanced distributions accelerate the transition through the intermediate plateau phase (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3" title="3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a>) but lead to overfitting. We further demonstrate that data scheduling strategies can exploit this accelerated transition while mitigating overfitting, providing a rare example in which data curricula benefit (self-)supervised learning.</p>
</div>
</li>
<li class="ltx_item" id="S0.I1.ix4" style="list-style-type:none;padding-top:2.0pt;">
<span class="ltx_tag ltx_tag_item">‚Äì</span>
<div class="ltx_para ltx_noindent" id="S0.I1.ix4.p1">
<p class="ltx_p" id="S0.I1.ix4.p1.1">We highlight the ineffectiveness of fine-tuning to incorporate new knowledge in the model (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>). This stems from two related factors: First, models hallucinate (overconfident predictions on unseen individuals) as soon as they acquire individual-specific knowledge.
Second, associative memories stored in feed-forward layers are rapidly corrupted when training on new individuals.</p>
</div>
</li>
</ul>
</div>
<section class="ltx_section" id="S1" lang="en">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>An experimental setup to track knowledge over the course of learning</h3>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">This study investigates the learning dynamics underlying factual recall and knowledge acquisition in language models. This presents two main methodological challenges: First, we need to isolate the model‚Äôs knowledge from other abilities. Second, we want to evaluate the models over the course of learning, which requires computationally efficient measurement techniques. Following <cite class="ltx_cite ltx_citemacro_citet">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, we train language models on synthetic biographies that feature key properties of datasets used to train large language models. By carefully designing these synthetic biographies, we can attribute the model‚Äôs ability to predict specific tokens solely to its acquired knowledge and efficiently measure its knowledge through its performance on these tokens. In this section, we first define knowledge and contrast it with memory, then describe our synthetic dataset and introduce the metrics we use to track knowledge during training, and finally, describe training details.</p>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Knowledge, and how it differs from memory</h4>
<div class="ltx_para ltx_noindent" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">For our analysis, we define knowledge to be the information a model has internally stored about its training data, abstracted from the specific form in which it was encountered. It is important to distinguish it from memorization. While knowledge involves accessing and applying information flexibly across different contexts, memorization is tied to particular training instances. In this view, knowledge can be understood as a form of memorization in a latent semantic space.
For instance, knowing that Paris is France‚Äôs capital represents knowledge, while remembering the exact sentence ‚ÄòParis is the capital of France‚Äô would constitute memorization. From a practical perspective, this distinction carries significant implications. Memorization can be problematic due to potential data leakage <cite class="ltx_cite ltx_citemacro_citep">(e.g., Nasr et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib34" title="">2023</a>)</cite>, while knowledge is a more desirable property that enables models to ground their outputs in factual reality, making their responses both accurate and generalizable.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Synthetic biographies as a framework for studying knowledge</h4>
<div class="ltx_para ltx_noindent" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">An important methodological challenge in our study is to isolate knowledge from other model capabilities. To address this, we adapt the synthetic biography dataset of <cite class="ltx_cite ltx_citemacro_citet">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, which offers several appealing properties. First, all facts in the dataset are atomic, meaning no fact can be derived from others, thus allowing us to disambiguate knowledge recall from other abilities like reasoning. Second, it is fully synthetic, which allows for precise control of the data distributional properties, while employing natural language with realistic statistics. For example, sufficient textual variation is crucial for enabling genuine knowledge acquisition rather than mere memorization <cite class="ltx_cite ltx_citemacro_citep">(Allen-Zhu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, cf. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.F1" title="Figure A ‚Ä£ B.1 Rationale behind our design choices ‚Ä£ Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">A</span></a> in the appendix. Third, and most importantly, previous work has established that relatively small language models trained on this dataset <cite class="ltx_cite ltx_citemacro_citep">(Allen-Zhu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite> store and use knowledge in a similar way to large language models <cite class="ltx_cite ltx_citemacro_citep">(Geva et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib17" title="">2021</a>; Meng et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib31" title="">2022</a>; Geva et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>; Nanda et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="205" id="S1.F1.g1" src="x1.png" width="653"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1">Data generation process underlying the synthetic biography dataset we train on.</span> We measure the knowledge stored within these models through the loss they achieve when predicting the attribute tokens, highlighted in blue. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1" title="1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1</span></a> for more details.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S1.SS2.p2">
<p class="ltx_p" id="S1.SS2.p2.1">We summarize the data generation process in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.F1" title="Figure 1 ‚Ä£ 1.2 Synthetic biographies as a framework for studying knowledge ‚Ä£ 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1</span></a>. The dataset contains a population of <math alttext="N" class="ltx_Math" display="inline" id="S1.SS2.p2.1.m1.1"><semantics id="S1.SS2.p2.1.m1.1a"><mi id="S1.SS2.p2.1.m1.1.1" xref="S1.SS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S1.SS2.p2.1.m1.1b"><ci id="S1.SS2.p2.1.m1.1.1.cmml" xref="S1.SS2.p2.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.SS2.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S1.SS2.p2.1.m1.1d">italic_N</annotation></semantics></math> randomly sampled individuals, each with a unique name and six attributes: birthdate, birthplace, university, major, company, and location. To generate a biography, we first sample an individual from the population. For each attribute, we then sample a template from a finite pool, fill it with the individual‚Äôs information, and concatenate the resulting sentences in random order to form a complete biography.
It should be noted that to make the dataset suitable for our study, our template generation and manipulation differ from the original setup. We detail these modifications in the next section and provide additional details in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2" title="Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span>Measuring knowledge at scale</h4>
<div class="ltx_para ltx_noindent" id="S1.SS3.p1">
<p class="ltx_p" id="S1.SS3.p1.1">Measuring knowledge in language models typically relies on factual question-answering tasks <cite class="ltx_cite ltx_citemacro_citep">(Lin et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib26" title="">2021</a>)</cite>. However, this approach is computationally intractable in our setup, as it requires repeatedly fine-tuning models to handle question-answer prompt formats throughout the training process. Our framework offers a simple solution to this challenge: by consistently placing information about the individual and attribute type before the attribute value, we transform each attribute value prediction into a factual recall task. This lets us quantify knowledge via the model‚Äôs loss and accuracy on predicting attribute value tokens. We denote them as <span class="ltx_text ltx_font_italic" id="S1.SS3.p1.1.1">attribute loss</span> and <span class="ltx_text ltx_font_italic" id="S1.SS3.p1.1.2">attribute accuracy</span>. Formal definitions are provided in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2" title="Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">B</span></a>. The attribute accuracy metric is arguably more intuitive, as it serves as a proxy for the accuracy with which the model, once fine-tuned, would correctly answer recall questions. However, we focus most of our analysis on the attribute loss due to its greater interpretive power and as it generally exhibits more consistent progression across various scales <cite class="ltx_cite ltx_citemacro_citep">(Schaeffer et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib46" title="">2024</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.SS3.p2">
<p class="ltx_p" id="S1.SS3.p2.1">Two important considerations remain to be solved: how to distinguish knowledge from memorization, and what is a meaningful baseline for the attribute loss. To address the first point, we evaluate models on unseen biographies of previously encountered individuals.
We do so by randomly splitting the template pool into training and evaluation templates for each individual, with this split varying across individuals.
This ensures that models are evaluated on entirely new biography formulations, thereby ruling out the possibility that strong performance stems from memorization. For the second point, we introduce a theoretical baseline corresponding to the best possible performance achievable by a model with no individual-specific knowledge. Such a model would only know the overall distribution of attribute values, and its loss would be equal to the entropy of the attribute value distribution. We refer to this value as the <span class="ltx_text ltx_font_italic" id="S1.SS3.p2.1.1">no knowledge</span> baseline. Any model performing better than this baseline must necessarily have acquired some knowledge about specific individuals in the training distribution.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.4 </span>Language models are trained following standard recipes</h4>
<div class="ltx_para ltx_noindent" id="S1.SS4.p1">
<p class="ltx_p" id="S1.SS4.p1.1">While we use synthetic data in our experiments, we keep the architecture and the training protocol as close as possible to standard practices. By default, we train an 8-layer decoder-only Transformer (<math alttext="44" class="ltx_Math" display="inline" id="S1.SS4.p1.1.m1.1"><semantics id="S1.SS4.p1.1.m1.1a"><mn id="S1.SS4.p1.1.m1.1.1" xref="S1.SS4.p1.1.m1.1.1.cmml">44</mn><annotation-xml encoding="MathML-Content" id="S1.SS4.p1.1.m1.1b"><cn id="S1.SS4.p1.1.m1.1.1.cmml" type="integer" xref="S1.SS4.p1.1.m1.1.1">44</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.SS4.p1.1.m1.1c">44</annotation><annotation encoding="application/x-llamapun" id="S1.SS4.p1.1.m1.1d">44</annotation></semantics></math>M non-embedding parameters) with the same structure as in <cite class="ltx_cite ltx_citemacro_citet">Hoffmann et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib22" title="">2022</a>)</cite> using the AdamW optimizer <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov and Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib27" title="">2019</a>)</cite> and a cosine learning rate schedule without warm-up. We tune the learning rate in all our experiments. Additional details are provided in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2" title="Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2" lang="en">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>How language models acquire knowledge during learning</h3>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our findings reveal that language models initially learn generic statistics before acquiring individual-specific knowledge. When individuals appear less frequently, such as when the population size grows, performance can plateau for extended periods between these two phases.
Mechanistically, we attribute this plateau to the development of attention-based circuits that enable the recall of knowledge stored within the network‚Äôs parameters and modulate the learning speed of the rest of the model.</p>
</div>
<figure class="ltx_figure" id="S2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S2.F2.g1" src="x2.png" width="640"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S2.F2.5.1">Knowledge acquisition occurs in three phases.</span> (left) In a very short first phase, the model learns generic attribute value statistics. In the second phase, performance plateaus at a level achievable by an ideal model lacking individual-specific knowledge (this corresponds to the <span class="ltx_text ltx_font_italic" id="S2.F2.6.2">no knowledge</span> baseline defined in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS3" title="1.3 Measuring knowledge at scale ‚Ä£ 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1.3</span></a> and a near-zero knowledge accuracy). This plateau‚Äôs duration is nearly proportional to the number of individuals (right). Finally, the model learns associations between subjects and attributes: knowledge emerges as the model is trained longer (middle). Results are averaged over 5 seeds (<math alttext="\pm" class="ltx_Math" display="inline" id="S2.F2.2.m1.1"><semantics id="S2.F2.2.m1.1b"><mo id="S2.F2.2.m1.1.1" xref="S2.F2.2.m1.1.1.cmml">¬±</mo><annotation-xml encoding="MathML-Content" id="S2.F2.2.m1.1c"><csymbol cd="latexml" id="S2.F2.2.m1.1.1.cmml" xref="S2.F2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.F2.2.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.F2.2.m1.1e">¬±</annotation></semantics></math> std). See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS1" title="2.1 The three phases underlying knowledge acquisition ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.1</span></a> for details.</figcaption>
</figure>
<section class="ltx_subsection" id="S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>The three phases underlying knowledge acquisition</h4>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">The temporal evolution of the attribute loss (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a>) exhibits a consistent three-phase pattern:</p>
<ol class="ltx_enumerate" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Initial language understanding.</span> Early on during learning, the network learns the overall attribute value distribution. At the end of this phase, it performs like an optimal model without individual-specific knowledge, matching the no knowledge baseline.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Performance plateaus at the edge of knowledge acquisition.</span> The model‚Äôs performance then plateaus at the no knowledge baseline. This could be both explained from an optimization argument ‚Äì the network parameters are at a saddle point of the loss landscape ‚Äì or from a statistical argument ‚Äì the model needs to observe multiple biographies from the same individual to discern that attribute values are specific to each individual. The plateau length grows almost linearly with the number of individuals (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a>, right panel), supporting the statistical hypothesis.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Knowledge emergence.</span> The model finally enters a knowledge acquisition phase, in which it progressively learns associations between individuals and their attributes. Its knowledge accuracy progressively leaves the near-zero regime in this phase: knowledge emerges.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The pattern described above is robust across a range of hyperparameter configurations. Specifically, qualitative results remain consistent when varying learning rate, weight decay, batch size, number of individuals, model size, and even the type of sequence mixing block (attention-based vs. recurrent), cf. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>. This is consistent with the findings of <cite class="ltx_cite ltx_citemacro_cite">Nichani et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib36" title="">2024</a>)</cite>, who observed a similar pattern in a theoretically tractable version of the task learned by a linear attention layer. These findings suggest that the data structure, particularly the high individual-to-attribute ratio, plays a critical role in driving this multi-phase learning behavior. <cite class="ltx_cite ltx_citemacro_cite">Gu et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib19" title="">2025</a>)</cite> found a similar behavior in a setup closely related to ours, and that, below some critical model size, the model does not learn any individual-specific information at all despite extensive training. We additionally discuss connections to existing work studying Transformer learning dynamics through the lens of <math alttext="N" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mi id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><ci id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_N</annotation></semantics></math>-grams in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A1" title="Appendix A Related work ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>The attention-based circuits supporting recall are created during the loss plateau</h4>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Although knowledge retrieval performance remains constant during the plateau phase, we observe the development of attention-based circuits supporting individual-specific attribute recall. We argue that learning is considerably stalled when these circuits are under development, as errors are not properly backpropagated from attribute value tokens to name tokens, explaining the existence of the plateau. The following evidence supports this claim.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Previous work has analyzed how Transformer-based language models solve factual recall tasks similar to the one we are interested in this study. It can be summarized as follows (cf. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F5" title="Figure E ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">E</span></a> for a visual summary). The first attention layers aggregate name tokens together to form a representation of the individual‚Äôs name at the position of the last name token. This representation serves as a query for subsequent layers, particularly the multi-layer perceptrons, which effectively act as a key-value database <cite class="ltx_cite ltx_citemacro_citep">(Geva et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib17" title="">2021</a>; Meng et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib31" title="">2022</a>)</cite>. Individual-specific knowledge thus typically appears within the final name token‚Äôs residual stream <cite class="ltx_cite ltx_citemacro_citep">(Nanda et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>; Allen-Zhu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>; Geva et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>)</cite>. The final attention layer then selects the relevant information conditioned on the attribute type and makes it available for predicting attribute value tokens when needed <cite class="ltx_cite ltx_citemacro_citep">(Geva et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>; Nanda et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>)</cite>. With this last circuit established, attribute value prediction errors directly backpropagate to relevant tokens, here the name tokens. However, without it, errors are spread across irrelevant tokens, hindering learning efficiency. We therefore hypothesize that the plateau phase corresponds to the formation of these attention-based recall circuits, with learning speed directly linked to their development stage.</p>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="164" id="S2.F3.g1" src="x3.png" width="653"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S2.F3.2.1">The attention-based circuits supporting recall are created during the loss plateau.</span> (left) We design an attention patching experiment, in which we take a snapshot of a reference model at some time during its training, and use its attention patterns as a replacement for the ones of a modified model throughout its training. (middle) The more trained the reference model is, the better its attention patterns are for the modified model, and these changes mainly happen during the plateau. The very beginning of learning is an exception to this trend. This correlates with the fact that, at this time during training, the name tokens (compared to the rest of the text, which contains information about the attribute type) receive reduced attention when the first attribute value token is predicted (cf. right panel). See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS2" title="2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.2</span></a> for more details.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.2">A consequence of that hypothesis is that a model with learned attention patterns should learn faster than one with pre-learning patterns. To test this, we design the following <em class="ltx_emph ltx_font_italic" id="S2.SS2.p3.2.1">attention patching</em> experiment (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a>, left). We first train a reference model and save reference checkpoints from it at various stages of training. We then restart training a model from scratch, but replace the model‚Äôs attention patterns<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We call attention patterns the softmax of the attention logits.</span></span></span> with those produced from one of the reference checkpoints. This means that all the token-to-token interactions are specified by the reference model and that the modified model only learns token-wise feedforward transformations. We expect the quality of the attention patterns, measured by how easy it is to learn the task with them, provided by the reference model to progressively improve as they are taken closer to the plateau end. This is what we observe empirically (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a>, middle), and the plateau disappears when providing the model with learned attention patterns (i.e. post-plateau patterns). Interestingly, the attention patterns acquired early during learning (e.g., at steps <math alttext="500" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mn id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><cn id="S2.SS2.p3.1.m1.1.1.cmml" type="integer" xref="S2.SS2.p3.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">500</annotation></semantics></math> and <math alttext="1" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m2.1"><semantics id="S2.SS2.p3.2.m2.1a"><mn id="S2.SS2.p3.2.m2.1.1" xref="S2.SS2.p3.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m2.1b"><cn id="S2.SS2.p3.2.m2.1.1.cmml" type="integer" xref="S2.SS2.p3.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m2.1d">1</annotation></semantics></math>k) are significantly worse than the pre-learning ones, likely due to initial focus on predicting the attribute value distribution conditioned on the attribute type only. This attention on attribute type tokens rather than on name tokens slows down learning, as per our argument from the last paragraph.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">So far, our results show the formation of an attention-based circuit during the plateau phase, though not necessarily the specific extraction circuit we hypothesized. To investigate this further, we examine the evolution of the network‚Äôs attention patterns during training for signatures of such a circuit. Specifically, we analyze the attention paid to name tokens (relative to general text tokens containing attribute type information) when predicting the first attribute value token, the primary position testing factual recall. We observe this attention increasing throughout the plateau, after being significantly lower during the initial phase where predictions align with the generic attribute value distribution (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a>, right panel). This offers an intuitive explanation for the qualitative differences in attention patterns observed in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> (middle). A similar analysis for the name tokens grouping circuit, characterized by high attention to name tokens from the last name token in the first layer, reveals its emergence within a few hundred steps. This may be specific to our setup, in which such a circuit is useful to better predict which template comes next. Details of this analysis are provided in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS2" title="D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D.2</span></a>. Together with our attention patching results, this result suggests that the attention-based extraction circuit responsible for recall develops during the plateau phase, consistent with the findings of <cite class="ltx_cite ltx_citemacro_cite">Ou et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib38" title="">2025</a>)</cite>. Note that our results do not rule out that other qualitative changes may occur during this phase, and they do not provide any mechanistic insights regarding how models acquire individual-specific knowledge.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3" lang="en">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data distributional properties drive knowledge acquisition</h3>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">While each individual appears with equal frequency in the preceding analysis, real-world data can be significantly less balanced. This section investigates the impact of such imbalances on the learning dynamics. We find that plateau length scales with the frequency of the most prevalent individuals (minimized in highly imbalanced distributions), whereas knowledge acquisition speed primarily depends on the frequency of the least prevalent ones (maximized in uniform distributions). This observation has two implications we confirm empirically: First, the training distribution that maximizes the final knowledge stored within the model becomes more imbalanced as the amount of knowledge within the data increases, or the network is trained for a shorter amount of time.
Second, dynamically adjusting the data distribution during training allows for simultaneous minimization of plateau length and maximization of knowledge acquisition speed.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="170" id="S3.F4.g1" src="x4.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S3.F4.8.1">Data distributional properties can speed up knowledge acquisition.</span> (left) The length of the plateau significantly decreases when some individuals appear more frequently (up to some extent) than other, which is here achieved by increasing <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.F4.4.m1.1"><semantics id="S3.F4.4.m1.1b"><mi id="S3.F4.4.m1.1.1" xref="S3.F4.4.m1.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.F4.4.m1.1c"><ci id="S3.F4.4.m1.1.1.cmml" xref="S3.F4.4.m1.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.4.m1.1d">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.F4.4.m1.1e">italic_Œ±</annotation></semantics></math>. (middle) As a result, it is beneficial to train the model on more imbalanced distributions (higher <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.F4.5.m2.1"><semantics id="S3.F4.5.m2.1b"><mi id="S3.F4.5.m2.1.1" xref="S3.F4.5.m2.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.F4.5.m2.1c"><ci id="S3.F4.5.m2.1.1.cmml" xref="S3.F4.5.m2.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.5.m2.1d">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.F4.5.m2.1e">italic_Œ±</annotation></semantics></math> values), particularly as the number of training steps decreases or as the total number of individuals increases. This panel reports the <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.F4.6.m3.1"><semantics id="S3.F4.6.m3.1b"><mi id="S3.F4.6.m3.1.1" xref="S3.F4.6.m3.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.F4.6.m3.1c"><ci id="S3.F4.6.m3.1.1.cmml" xref="S3.F4.6.m3.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F4.6.m3.1d">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.F4.6.m3.1e">italic_Œ±</annotation></semantics></math> value that minimizes the final attribute loss for each number of steps and individuals. (right) Such a strategy, improves the final amount of knowledge contained in the network (purple vs. grey line). Dynamically adapting the data distribution yields even larger benefits (blue line). See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3" title="3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> for more detail.</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>The trade-off underlying imbalances in the data distribution</h4>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Building on the analysis presented in the preceding section, we can already develop an intuition of how data distribution impact the plateau and knowledge acquisition phases.
Assuming that the circuits that the network creates during the plateau transfer to other individuals, reducing the number of individuals should minimize time spent in this phase, as shown in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a> (right). Naturally, this assumption will break when an excessively small number of individuals is over-represented, as the model will likely overfit. As a consequence, imbalanced distributions with a small group of over represented individuals should generally shorten the plateau duration.
However, this does not hold for the knowledge acquisition phase. Each individual contributes equally to the total amount of knowledge the model has, so the attribute loss on the entire population will asymptotically behave like the one on the group which is learned slowly, that is, the least frequent one. For that reason, a uniform distribution should be optimal for knowledge acquisition.
As a consequence, there is a trade-off: imbalanced distributions speed up the plateau and slow down knowledge acquisition, whereas the reverse holds for more uniform distributions. The distribution that optimizes the final amount of knowledge stored within the network weights should therefore become increasingly more imbalanced as the plateau takes a larger portion of training time, i.e., when the number of training steps decreases or when the number of individuals increases.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.10">To empirically test this intuition, we modify the individual occurrence probability to follow an inverse power law with exponent <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mi id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><ci id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_Œ±</annotation></semantics></math>. This exponent controls the balance of the distribution: <math alttext="\alpha=0" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">Œ±</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><eq id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></eq><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">ùõº</ci><cn id="S3.SS1.p2.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\alpha=0</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_Œ± = 0</annotation></semantics></math> recovers the uniform distribution whereas <math alttext="\alpha=1" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><mrow id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">Œ±</mi><mo id="S3.SS1.p2.3.m3.1.1.1" xref="S3.SS1.p2.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><eq id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1.1"></eq><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">ùõº</ci><cn id="S3.SS1.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\alpha=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">italic_Œ± = 1</annotation></semantics></math> corresponds to the highly imbalanced Zipf law. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a> (left) reports how the number of training steps needed to escape the plateau evolves with different numbers of individuals and <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.4.m4.1"><semantics id="S3.SS1.p2.4.m4.1a"><mi id="S3.SS1.p2.4.m4.1.1" xref="S3.SS1.p2.4.m4.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.4.m4.1b"><ci id="S3.SS1.p2.4.m4.1.1.cmml" xref="S3.SS1.p2.4.m4.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.4.m4.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.4.m4.1d">italic_Œ±</annotation></semantics></math> values, when the total training budget is fixed to <math alttext="16" class="ltx_Math" display="inline" id="S3.SS1.p2.5.m5.1"><semantics id="S3.SS1.p2.5.m5.1a"><mn id="S3.SS1.p2.5.m5.1.1" xref="S3.SS1.p2.5.m5.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.5.m5.1b"><cn id="S3.SS1.p2.5.m5.1.1.cmml" type="integer" xref="S3.SS1.p2.5.m5.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.5.m5.1c">16</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.5.m5.1d">16</annotation></semantics></math>k steps. As expected, increasing <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.6.m6.1"><semantics id="S3.SS1.p2.6.m6.1a"><mi id="S3.SS1.p2.6.m6.1.1" xref="S3.SS1.p2.6.m6.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.6.m6.1b"><ci id="S3.SS1.p2.6.m6.1.1.cmml" xref="S3.SS1.p2.6.m6.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.6.m6.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.6.m6.1d">italic_Œ±</annotation></semantics></math> reduces the plateau length. However, excessive increases are detrimental, likely due to overfitting. We find that the optimal <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.7.m7.1"><semantics id="S3.SS1.p2.7.m7.1a"><mi id="S3.SS1.p2.7.m7.1.1" xref="S3.SS1.p2.7.m7.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.7.m7.1b"><ci id="S3.SS1.p2.7.m7.1.1.cmml" xref="S3.SS1.p2.7.m7.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.7.m7.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.7.m7.1d">italic_Œ±</annotation></semantics></math> minimizing plateau length lies between <math alttext="0.6" class="ltx_Math" display="inline" id="S3.SS1.p2.8.m8.1"><semantics id="S3.SS1.p2.8.m8.1a"><mn id="S3.SS1.p2.8.m8.1.1" xref="S3.SS1.p2.8.m8.1.1.cmml">0.6</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.8.m8.1b"><cn id="S3.SS1.p2.8.m8.1.1.cmml" type="float" xref="S3.SS1.p2.8.m8.1.1">0.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.8.m8.1c">0.6</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.8.m8.1d">0.6</annotation></semantics></math> and <math alttext="0.8" class="ltx_Math" display="inline" id="S3.SS1.p2.9.m9.1"><semantics id="S3.SS1.p2.9.m9.1a"><mn id="S3.SS1.p2.9.m9.1.1" xref="S3.SS1.p2.9.m9.1.1.cmml">0.8</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.9.m9.1b"><cn id="S3.SS1.p2.9.m9.1.1.cmml" type="float" xref="S3.SS1.p2.9.m9.1.1">0.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.9.m9.1c">0.8</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.9.m9.1d">0.8</annotation></semantics></math>, irrespective of the population size, while the plateau length itself increases with the total number of individuals. We expect this improvement to be particularly significant when the plateau consumes a large portion of training ‚Äì i.e., with large population sizes or limited training budgets. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a> (middle) confirms this: the <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS1.p2.10.m10.1"><semantics id="S3.SS1.p2.10.m10.1a"><mi id="S3.SS1.p2.10.m10.1.1" xref="S3.SS1.p2.10.m10.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.10.m10.1b"><ci id="S3.SS1.p2.10.m10.1.1.cmml" xref="S3.SS1.p2.10.m10.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.10.m10.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.10.m10.1d">italic_Œ±</annotation></semantics></math> minimizing final attribute loss follows the anticipated trend. Overall, the properties of the data distribution significantly impact final knowledge retrieval performance, as demonstrated in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a> (right), especially when individuals appear infrequently, as is likely the case during the pre-training of large-scale models.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">We are aware of three related findings. First, <cite class="ltx_cite ltx_citemacro_cite">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite> demonstrated the benefits of ‚Äúcelebrities‚Äù in a similar setup to ours. Our analysis provides a partial explanation for this phenomenon. While we find that celebrities offer comparable benefits to our inverse power law distribution (cf. Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5" title="Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">E</span></a>), their effect may be amplified in their setup due to their use of a single biography for non-celebrities, whereas we never repeat biographies. Second, <cite class="ltx_cite ltx_citemacro_cite">Charton and Kempe (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib11" title="">2024</a>)</cite> showed that repetition benefits Transformer training on arithmetic tasks. Their learning curves exhibit numerous plateaus, and sample-level repetition reduces time spent on these plateaus. Our analysis may generalize to this task, suggesting a broader principle underlying our findings. Finally, <cite class="ltx_cite ltx_citemacro_cite">Park et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib40" title="">2024</a>)</cite> trained Transformers on a synthetic mixture of Markov chains and found that low task diversity shortens plateau length, albeit leading to solutions that do not generalize as well out-of-distribution.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data schedulers increase the final amount of acquired knowledge</h4>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">The previous section revealed a trade-off in choosing a data distribution, depending on the learning phase we wish to optimize. That analysis assumed a fixed distribution throughout training. However, we can envision data distribution schedulers that dynamically adapt the distribution to the current learning phase. We confirm that this strategy can yield substantial improvements.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">We implement a ‚Äúwarm-up‚Äù strategy: the model initially trains on a subset of individuals for a fixed number of steps, and on all individuals afterwards. Starting with a subset of individuals should shorten the plateau, while the subsequent uniform distribution maximizes knowledge acquisition once the recall circuits are well established. Indeed, we observe significant gains, particularly when the number of individuals is large and the model starts acquiring knowledge (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>, right), which is a practically relevant regime. Experimental details and additional analysis are available in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5" title="Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">While our experiments used a fixed warm-up duration, it could be dynamically adjusted based on observed plateau termination. This training strategy shares goals with curriculum learning <cite class="ltx_cite ltx_citemacro_citep">(Bengio et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib7" title="">2009</a>)</cite>, but differs in that data complexity remains constant. Although preliminary and task-specific, this promising result suggests a novel strategy for accelerating training in neural networks that exhibit similar loss plateaus on learned sub-tasks. Further investigation is needed to better understand the precise conditions under which data repetition can effectively reduce time spent on performance plateaus during training.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Hallucinations hinder the integration of new knowledge post-training</h3>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">This final section examines the challenge of expanding language models‚Äô parametric knowledge through post-training procedures like fine-tuning. We find that certain types of hallucinations (overconfident predictions on unseen individuals) emerge simultaneously with knowledge about individuals within the training distribution and can be detected at the population level. These hallucinations significantly impact learning dynamics on new data, requiring numerous training steps to overcome miscalibration, during which pre-existing knowledge is significantly degraded, a phenomenon reminiscent of catastrophic forgetting <cite class="ltx_cite ltx_citemacro_cite">McCloskey and Cohen (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib29" title="">1989</a>)</cite>. Adding replay of existing knowledge to the fine-tuning data mix only partially mitigates this issue. Overall, our findings offer an explanation for the infrequent use of fine-tuning <cite class="ltx_cite ltx_citemacro_citep">(Ovadia et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib39" title="">2023</a>; Jain et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib24" title="">2024</a>)</cite> for incorporating new knowledge in the model‚Äôs parameters.</p>
</div>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="172" id="S4.F5.g1" src="x5.png" width="655"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S4.F5.2.1">Hallucinations hinder the integration of new knowledge post-training.</span> (left) Hallucinations (overconfidence in inaccurate predictions) appear concurrently with the knowledge acquisition, hindering subsequent adaptation to new knowledge. (middle) Fine-tuning on new individuals causes a rapid drop in performance on individuals learned during pre-training, with new knowledge acquisition being a slower process. (right) Incorporating replay of pre-training data partially mitigates the final performance drop, but not the initial decline. Grey dots in the middle and right panels indicate performance at the beginning of fine-tuning. The pre-training (resp. fine-tuning) losses are attribute losses measured on pre-training (resp. fine-tuning) individuals. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a> for details.</figcaption>
</figure>
<section class="ltx_subsection" id="S4.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Models start hallucinating as soon as they acquire knowledge</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Before investigating fine-tuning per se, we first analyze the evolution of the model‚Äôs performance on unseen individuals over the course of (pre-)training, focusing on whether it predicts attribute values following the relation-based distribution, i.e., whether it matches the no-knowledge baseline. We find that the model hallucinates, confidently predicting incorrect attribute values (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a>, left), but with lower overall confidence compared to predictions for individuals seen during training (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F13" title="Figure M ‚Ä£ F.2 Hallucinations ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">M</span></a>). Furthermore, hallucinations emerge simultaneously with knowledge acquisition about the training individuals, suggesting they may be a counterpart to accurate predictions in current language models.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>A large portion of the pre-training knowledge is erased during early fine-tuning</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Given this uncalibrated starting point, fine-tuning on new individuals is expected to be challenging. We observe a rapid collapse in performance on pre-training data during the initial stages of fine-tuning (first few hundred steps), with very little corresponding acquisition of new knowledge (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a>, middle). A larger number of fine-tuning individuals intensifies this effect. Extended fine-tuning eventually changes this trend, and the model starts learning about new individuals. Incorporating replay data about pre-training individuals in the fine-tuning set partially mitigates the initial collapse and facilitates the restoration of corrupted knowledge (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a>, right). Finally, we do not observe such degradation when fine-tuning on subsets of the pre-training data (see the corresponding analysis in Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS3" title="F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.3</span></a>). These results are consistent with the findings of <cite class="ltx_cite ltx_citemacro_citet">Gekhman et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib16" title="">2024</a>)</cite>, who found that fine-tuning on new knowledge is slow and leads to hallucinations. We complement our analysis of fine-tuning dynamics with one in which the training distribution changes regularly (Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS5" title="F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.5</span></a>). These experiments confirm the findings reported here, as well as highlight that it becomes easier to learn new individuals as training progresses.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">We now turn to explaining this behavior. The first hypothesis we consider is related to attention patterns. Indeed, introducing new individuals may disrupt attention patterns, requiring time to restore recall ability, while keeping parametric knowledge relatively untouched, and further training may restore them. We analyze the network‚Äôs attention patterns, in both our fine-tuning (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F15" title="Figure O ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">O</span></a>) and switching distribution (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F24" title="Figure X ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">X</span></a>) setups, and find them to be remarkably stable, therefore mostly ruling out this hypothesis. Our second hypothesis is that introducing novel individuals creates additional key-value pairs that corrupt existing ones when being learned. To test this hypothesis, we train a one hidden layer multi-layer perceptron on a toy associative recall task (Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS4" title="F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.4</span></a>). With such a model, which has no attention layers at all, we are able to reproduce the main qualitative findings of the experiments above, suggesting that changes in the feed-forward associative memories of the model we consider are the main factor explaining the model‚Äôs behavior. Getting a finer understanding of these dynamics constitutes an interesting future research direction. For example, investigating how introducing independent knowledge topics affects this early catastrophic forgetting could provide some practically relevant insights.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5" lang="en">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h3>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">On the learning dynamics of language models.</h5>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">This work reveals the existence of phase transitions, the formation of induction heads being the canonical example <cite class="ltx_cite ltx_citemacro_citep">(Olsson et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib37" title="">2022</a>; Garg et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib15" title="">2022</a>; Reddy, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib44" title="">2024</a>)</cite>, in tasks as simple as factual recall.
While the results presented above were obtained on an isolated task, we speculate that even with natural text and its multi-task nature, task-specific learning dynamics retain the same abrupt transitions and plateaus appear when the formation of a new circuit is the main bottleneck for solving a specific task.
We found the time spent in the transition phase to depend more on the data distribution than the model size. Emergent abilities <cite class="ltx_cite ltx_citemacro_citep">(Wei et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib50" title="">2022</a>)</cite> can thus result from increased training time as models are scaled.
On the data distribution side, our results have two consequences: First, they suggest the benefits of using synthetic data early in pre-training, since data used before the end of the plateau is not retained in the final model. Second, data schedulers, potentially even adaptive ones that reduce diversity when performance plateaus on a task, appear to be a promising direction to improve learning speed.
Finally, our identification of changes in feedforward associative memories leading to rapid performance drops during early fine-tuning provides a simple explanation for the practically-observed ineffectiveness of fine-tuning for new knowledge (e.g., <cite class="ltx_cite ltx_citemacro_cite">Ovadia et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib39" title="">2023</a>); Jain et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib24" title="">2024</a>)</cite>).</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">On the learning dynamics of neural networks more broadly.</h5>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">This analysis reveals that, in a simple but relevant setting, attention-based recall circuits emerge before the formation of associative memories in feedforward layers. We hypothesize that this occurs as established circuits amplify the correlation between the inputs and backpropagated errors received by feedforward layers. Prior to circuit formation, task learning remains possible (e.g., by artificially increasing name token values), but progress is slow, performance plateaus, and generalization likely suffers. Phenomena like grokking <cite class="ltx_cite ltx_citemacro_citep">(Power et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib43" title="">2022</a>; Nanda et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib32" title="">2023a</a>)</cite> may indicate that learning dynamics initially find this shortcut, before abandoning it due to regularization. The proposed credit-assignment argument for plateau formation generalizes to other architectures, as evidenced by ablations in which attention is replaced with recurrence (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>). Decoupling the token-mixing role of attention from other computations, as advocated by <cite class="ltx_cite ltx_citemacro_cite">Elhage et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib14" title="">2021</a>)</cite> for mechanistic understanding of trained Transformers, also proves powerful for analyzing learning dynamics. This perspective offers a promising avenue for future investigations into neural network learning dynamics.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">On the role of non-uniformity and connections to developmental psychology.</h5>
<div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1">A key finding of this work is the precise analysis of how imbalances in the training distribution enable faster escape from performance plateaus. While not explicitly connected to the formation of attention patterns, similar phenomena have been observed in diverse settings <cite class="ltx_cite ltx_citemacro_citep">(Charton and Kempe, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib11" title="">2024</a>; Park et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib40" title="">2024</a>)</cite>, though sometimes at the cost of limited generalization. Our data scheduling results, by adapting the data to the network‚Äôs current learning phase, offer a promising path towards accelerated learning without sacrificing generalization. Intriguingly, these strategies mirror the implicit curriculum experienced by developing infants <cite class="ltx_cite ltx_citemacro_citep">(Smith et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib48" title="">2018</a>)</cite>, arising from factors like limited mobility or frequent exposure to familiar faces, and similar strategies have proven successful in reinforcement learning <cite class="ltx_cite ltx_citemacro_citep">(Baranes and Oudeyer, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib6" title="">2013</a>; Stooke et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib49" title="">2021</a>)</cite>. As argued earlier in the discussion, repetition strengthens the signal-to-noise ratio in correlations between events (tokens in our case), facilitating faster identification of key relationships and accelerating learning. Crucially, however, (progressive) diversification remains essential for optimal generalization in later stages of learning. Our findings could therefore serve as a building block for a statistical theory of development.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx1" lang="en">
<h3 class="ltx_title ltx_title_section">Limitations</h3>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">In our study, we train relatively small language models on a synthetic factual recall task to investigate knowledge acquisition dynamics. While this approach enables precise experimental control and mechanistic insights, it presents several important limitations.</p>
</div>
<section class="ltx_paragraph" id="Sx1.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Scale and architecture.</h5>
<div class="ltx_para ltx_noindent" id="Sx1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="Sx1.SS0.SSS0.Px1.p1.1">The <math alttext="44" class="ltx_Math" display="inline" id="Sx1.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="Sx1.SS0.SSS0.Px1.p1.1.m1.1a"><mn id="Sx1.SS0.SSS0.Px1.p1.1.m1.1.1" xref="Sx1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">44</mn><annotation-xml encoding="MathML-Content" id="Sx1.SS0.SSS0.Px1.p1.1.m1.1b"><cn id="Sx1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="Sx1.SS0.SSS0.Px1.p1.1.m1.1.1">44</cn></annotation-xml><annotation encoding="application/x-tex" id="Sx1.SS0.SSS0.Px1.p1.1.m1.1c">44</annotation><annotation encoding="application/x-llamapun" id="Sx1.SS0.SSS0.Px1.p1.1.m1.1d">44</annotation></semantics></math>M parameter models we train are substantially smaller than the billion-parameter models used in practice. The learning dynamics we observe may manifest differently at larger scales or with different architectural choices. However, our ablations across model sizes, architectures (including recurrent variants), and hyperparameters suggest the core phenomena are robust to these variations.</p>
</div>
</section>
<section class="ltx_paragraph" id="Sx1.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Data.</h5>
<div class="ltx_para ltx_noindent" id="Sx1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="Sx1.SS0.SSS0.Px2.p1.1">The synthetic factual recall task, while designed to capture essential properties of knowledge acquisition, only represents one specific type of knowledge language models acquire during pretraining. Different types of knowledge could interact in sophisticated ways that are not modeled in our task. This may create extra redundancy that language models could leverage to accelerate learning. Nevertheless, our fine-tuning results already align with practically observed inefficiencies of fine-tuning for integrating new knowledge, suggesting some degree of transferability.</p>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="Sx1.SS0.SSS0.Px2.p2.1">Despite these limitations, we believe our work provides a necessary foundation for understanding knowledge acquisition in neural language models. The mechanistic insights we derive offer concrete hypotheses that future work can validate in more realistic scenarios. We hope these findings will guide the design of more effective training strategies and data scheduling approaches for large-scale language models.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Sx2" lang="en">
<h3 class="ltx_title ltx_title_section">Acknowledgements</h3>
<div class="ltx_para ltx_noindent" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">The authors thank Nino Scherrer, Katja Filippova, Carter Blum, Jay McClelland and Arslan Chaudhry for insightful discussions.</p>
</div>
<div class="ltx_para" id="Sx2.p2">
<span class="ltx_ERROR undefined" id="Sx2.p2.1">\nobibliography</span>
<p class="ltx_p" id="Sx2.p2.2">*</p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h3 class="ltx_title ltx_title_bibliography">References</h3>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allen-Zhu and Li (2023)</span>
<span class="ltx_bibblock">
Z.¬†Allen-Zhu and Y.¬†Li.

</span>
<span class="ltx_bibblock">Physics of language models: Part 3.1, knowledge storage and
extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2309.14316</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allen-Zhu and Li (2024)</span>
<span class="ltx_bibblock">
Z.¬†Allen-Zhu and Y.¬†Li.

</span>
<span class="ltx_bibblock">Physics of language models: Part 3.3, knowledge capacity scaling
laws.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2404.05405</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amari (1972)</span>
<span class="ltx_bibblock">
S.-I. Amari.

</span>
<span class="ltx_bibblock">Learning patterns and pattern sequences by self-organizing nets of
threshold elements.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">IEEE Transactions on Computers</em>, C-21(11), 1972.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arora et¬†al. (2024)</span>
<span class="ltx_bibblock">
S.¬†Arora, S.¬†Eyuboglu, A.¬†Timalsina, I.¬†Johnson, M.¬†Poli, J.¬†Zou, A.¬†Rudra, and
C.¬†R√©.

</span>
<span class="ltx_bibblock">Zoology: Measuring and improving recall in efficient language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">International conference on learning representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baldi and Hornik (1995)</span>
<span class="ltx_bibblock">
P.¬†F. Baldi and K.¬†Hornik.

</span>
<span class="ltx_bibblock">Learning in linear neural networks: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE Transactions on neural networks</em>, 6(4), 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baranes and Oudeyer (2013)</span>
<span class="ltx_bibblock">
A.¬†Baranes and P.-Y. Oudeyer.

</span>
<span class="ltx_bibblock">Active learning of inverse models with intrinsically motivated goal
exploration in robots.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Robotics and autonomous systems</em>, 61(1), 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bengio et¬†al. (2009)</span>
<span class="ltx_bibblock">
Y.¬†Bengio, J.¬†Louradour, R.¬†Collobert, and J.¬†Weston.

</span>
<span class="ltx_bibblock">Curriculum learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">International conference on machine learning</em>, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et¬†al. (2020)</span>
<span class="ltx_bibblock">
T.¬†Brown, B.¬†Mann, N.¬†Ryder, M.¬†Subbiah, J.¬†D. Kaplan, P.¬†Dhariwal,
A.¬†Neelakantan, P.¬†Shyam, G.¬†Sastry, A.¬†Askell, et¬†al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Advances in neural information processing systems</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chan et¬†al. (2022)</span>
<span class="ltx_bibblock">
S.¬†Chan, A.¬†Santoro, A.¬†Lampinen, J.¬†Wang, A.¬†Singh, P.¬†Richemond,
J.¬†McClelland, and F.¬†Hill.

</span>
<span class="ltx_bibblock">Data distributional properties drive emergent in-context learning in
transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Advances in neural information processing systems</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et¬†al. (2024)</span>
<span class="ltx_bibblock">
H.¬†Chang, J.¬†Park, S.¬†Ye, S.¬†Yang, Y.¬†Seo, D.-S. Chang, and M.¬†Seo.

</span>
<span class="ltx_bibblock">How do large language models acquire factual knowledge during
pretraining?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in neural information processing systems</em>,
volume¬†37, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Charton and Kempe (2024)</span>
<span class="ltx_bibblock">
F.¬†Charton and J.¬†Kempe.

</span>
<span class="ltx_bibblock">Emergent properties with repeated examples.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2410.07041</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De et¬†al. (2024)</span>
<span class="ltx_bibblock">
S.¬†De, S.¬†L. Smith, A.¬†Fernando, A.¬†Botev, G.¬†Cristian-Muraru, A.¬†Gu,
R.¬†Haroun, L.¬†Berrada, Y.¬†Chen, S.¬†Srinivasan, et¬†al.

</span>
<span class="ltx_bibblock">Griffin: Mixing gated linear recurrences with local attention for
efficient language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2402.19427</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et¬†al. (2018)</span>
<span class="ltx_bibblock">
J.¬†Devlin, M.-W. Change, K.¬†Lee, and K.¬†Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:1810.04805</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elhage et¬†al. (2021)</span>
<span class="ltx_bibblock">
N.¬†Elhage, N.¬†Nanda, C.¬†Olsson, T.¬†Henighan, N.¬†Joseph, B.¬†Mann, A.¬†Askell,
Y.¬†Bai, A.¬†Chen, T.¬†Conerly, et¬†al.

</span>
<span class="ltx_bibblock">A mathematical framework for transformer circuits.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Transformer circuits thread</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Garg et¬†al. (2022)</span>
<span class="ltx_bibblock">
S.¬†Garg, D.¬†Tsipras, P.¬†S. Liang, and G.¬†Valiant.

</span>
<span class="ltx_bibblock">What can transformers learn in-context? a case study of simple
function classes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Advances in neural information processing systems</em>, 35, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gekhman et¬†al. (2024)</span>
<span class="ltx_bibblock">
Z.¬†Gekhman, G.¬†Yona, R.¬†Aharoni, M.¬†Eyal, A.¬†Feder, R.¬†Reichart, and J.¬†Herzig.

</span>
<span class="ltx_bibblock">Does fine-tuning llms on new knowledge encourage hallucinations?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2405.05904</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et¬†al. (2021)</span>
<span class="ltx_bibblock">
M.¬†Geva, R.¬†Schuster, J.¬†Berant, and O.¬†Levy.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers are key-value memories.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Conference on empirical methods in natural language
processing</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et¬†al. (2023)</span>
<span class="ltx_bibblock">
M.¬†Geva, J.¬†Bastings, K.¬†Filippova, and A.¬†Globerson.

</span>
<span class="ltx_bibblock">Dissecting recall of factual associations in auto-regressive language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Conference on empirical methods in natural language
processing</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et¬†al. (2025)</span>
<span class="ltx_bibblock">
X.¬†Gu, K.¬†Lyu, J.¬†Li, and J.¬†Zhang.

</span>
<span class="ltx_bibblock">Data mixing can induce phase transitions in knowledge acquisition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2505.18091</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hebb (1949)</span>
<span class="ltx_bibblock">
D.¬†O. Hebb.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">The organization of behavior: A neuropsychological theory</em>.

</span>
<span class="ltx_bibblock">1949.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton (1986)</span>
<span class="ltx_bibblock">
G.¬†E. Hinton.

</span>
<span class="ltx_bibblock">Learning distributed representations of concepts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Proceedings of the eighth annual conference of the cognitive
science society</em>, volume¬†1, 1986.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et¬†al. (2022)</span>
<span class="ltx_bibblock">
J.¬†Hoffmann, S.¬†Borgeaud, A.¬†Mensch, E.¬†Buchatskaya, T.¬†Cai, E.¬†Rutherford,
D.¬†d.¬†L. Casas, L.¬†A. Hendricks, J.¬†Welbl, A.¬†Clark, et¬†al.

</span>
<span class="ltx_bibblock">Training compute-optimal large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2203.15556</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hopfield (1982)</span>
<span class="ltx_bibblock">
J.¬†J. Hopfield.

</span>
<span class="ltx_bibblock">Neural networks and physical systems with emergent collective
computational abilities.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the national academy of sciences</em>, 79(8), 1982.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et¬†al. (2024)</span>
<span class="ltx_bibblock">
A.¬†Jain, A.¬†Maleki, and N.¬†Saade.

</span>
<span class="ltx_bibblock">To fine-tune or not to fine-tune, 2024.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/blog/when-to-fine-tune-llms-vs-other-techniques" title="">https://ai.meta.com/blog/when-to-fine-tune-llms-vs-other-techniques</a>.

</span>
<span class="ltx_bibblock">Accessed: 14 February 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et¬†al. (2017)</span>
<span class="ltx_bibblock">
J.¬†Kirkpatrick, R.¬†Pascanu, N.¬†Rabinowitz, J.¬†Veness, G.¬†Desjardins, A.¬†A.
Rusu, K.¬†Milan, J.¬†Quan, T.¬†Ramalho, A.¬†Grabska-Barwinska, et¬†al.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the national academy of sciences</em>, 114(13), 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et¬†al. (2021)</span>
<span class="ltx_bibblock">
S.¬†Lin, J.¬†Hilton, and O.¬†Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2109.07958</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
I.¬†Loshchilov and F.¬†Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">International conference on learning representations</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McClelland (1995)</span>
<span class="ltx_bibblock">
J.¬†L. McClelland.

</span>
<span class="ltx_bibblock">A connectionist perspective on knowledge and development.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Developing cognitive competence: New approaches to process
modeling</em>. 1995.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen (1989)</span>
<span class="ltx_bibblock">
M.¬†McCloskey and N.¬†J. Cohen.

</span>
<span class="ltx_bibblock">Catastrophic interference in connectionist networks: the sequential
learning problem.

</span>
<span class="ltx_bibblock">volume¬†24. Psychology of learning and motivation, 1989.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McEliece et¬†al. (1987)</span>
<span class="ltx_bibblock">
R.¬†J. McEliece, E.¬†C. Posner, E.¬†R. Rodemich, and S.¬†S. Venkatesh.

</span>
<span class="ltx_bibblock">The capacity of the hopfield associative memory.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">IEEE transactions on Information Theory</em>, 33(4),
1987.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et¬†al. (2022)</span>
<span class="ltx_bibblock">
K.¬†Meng, D.¬†Bau, A.¬†Andonian, and Y.¬†Belinkov.

</span>
<span class="ltx_bibblock">Locating and editing factual associations in gpt.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Advances in neural information processing systems</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nanda et¬†al. (2023a)</span>
<span class="ltx_bibblock">
N.¬†Nanda, L.¬†Chan, T.¬†Lieberum, J.¬†Smith, and J.¬†Steinhardt.

</span>
<span class="ltx_bibblock">Progress measures for grokking via mechanistic interpretability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">International conference on learning representations</em>,
2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nanda et¬†al. (2023b)</span>
<span class="ltx_bibblock">
N.¬†Nanda, S.¬†Rajamanoharan, J.¬†Kram√°r, and R.¬†Shah.

</span>
<span class="ltx_bibblock">Fact finding: Attempting to reverse-engineer factual recall on the
neuron level.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">AI alignment forum, 2023</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et¬†al. (2023)</span>
<span class="ltx_bibblock">
M.¬†Nasr, N.¬†Carlini, J.¬†Hayase, M.¬†Jagielski, A.¬†F. Cooper, D.¬†Ippolito, C.¬†A.
Choquette-Choo, E.¬†Wallace, F.¬†Tram√®r, and K.¬†Lee.

</span>
<span class="ltx_bibblock">Scalable extraction of training data from (production) language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2311.17035</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen (2024)</span>
<span class="ltx_bibblock">
T.¬†Nguyen.

</span>
<span class="ltx_bibblock">Understanding transformers via n-gram statistics.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Advances in neural information processing systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichani et¬†al. (2024)</span>
<span class="ltx_bibblock">
E.¬†Nichani, J.¬†D. Lee, and A.¬†Bietti.

</span>
<span class="ltx_bibblock">Understanding factual recall in transformers via associative
memories.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2412.06538</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Olsson et¬†al. (2022)</span>
<span class="ltx_bibblock">
C.¬†Olsson, N.¬†Elhage, N.¬†Nanda, N.¬†Joseph, N.¬†DasSarma, T.¬†Henighan, B.¬†Mann,
A.¬†Askell, Y.¬†Bai, A.¬†Chen, et¬†al.

</span>
<span class="ltx_bibblock">In-context learning and induction heads.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Transformer circuits thread</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ou et¬†al. (2025)</span>
<span class="ltx_bibblock">
Y.¬†Ou, Y.¬†Yao, N.¬†Zhang, H.¬†Jin, J.¬†Sun, S.¬†Deng, Z.¬†Li, and H.¬†Chen.

</span>
<span class="ltx_bibblock">How do llms acquire new knowledge? a knowledge circuits perspective
on continual pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2502.11196</em>, 2025.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ovadia et¬†al. (2023)</span>
<span class="ltx_bibblock">
O.¬†Ovadia, M.¬†Brief, M.¬†Mishaeli, and O.¬†Elisha.

</span>
<span class="ltx_bibblock">Fine-tuning or retrieval? comparing knowledge injection in llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2312.05934</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et¬†al. (2024)</span>
<span class="ltx_bibblock">
C.¬†F. Park, E.¬†S. Lubana, I.¬†Pres, and H.¬†Tanaka.

</span>
<span class="ltx_bibblock">Competition dynamics shape algorithmic phases of in-context learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2412.01003</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pavlov (1927)</span>
<span class="ltx_bibblock">
P.¬†I. Pavlov.

</span>
<span class="ltx_bibblock">Conditioned reflexes: an investigation of the physiological activity
of the cerebral cortex.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Oxford university press</em>, 1927.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et¬†al. (2019)</span>
<span class="ltx_bibblock">
F.¬†Petroni, T.¬†Rocktaschel, P.¬†Lewis, A.¬†Bakhtin, Y.¬†Wu, A.¬†H. Miller, and
S.¬†Riedel.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Power et¬†al. (2022)</span>
<span class="ltx_bibblock">
A.¬†Power, Y.¬†Burda, H.¬†Edwards, I.¬†Babuschkin, and V.¬†Misra.

</span>
<span class="ltx_bibblock">Grokking: Generalization beyond overfitting on small algorithmic
datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2201.02177</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddy (2024)</span>
<span class="ltx_bibblock">
G.¬†Reddy.

</span>
<span class="ltx_bibblock">The mechanistic basis of data dependence and abrupt learning in an
in-context classification task.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">International conference on learning representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saxe et¬†al. (2014)</span>
<span class="ltx_bibblock">
A.¬†M. Saxe, J.¬†L. McClelland, and S.¬†Ganguli.

</span>
<span class="ltx_bibblock">Exact solutions to the nonlinear dynamics of learning in deep linear
neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">International conference on learning representations</em>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schaeffer et¬†al. (2024)</span>
<span class="ltx_bibblock">
R.¬†Schaeffer, B.¬†Miranda, and S.¬†Koyejo.

</span>
<span class="ltx_bibblock">Are emergent abilities of large language models a mirage?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Advances in neural information processing systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et¬†al. (2024)</span>
<span class="ltx_bibblock">
A.¬†Singh, S.¬†Chan, T.¬†Moskovitz, E.¬†Grant, A.¬†Saxe, and F.¬†Hill.

</span>
<span class="ltx_bibblock">The transient nature of emergent in-context learning in transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">Advances in neural information processing systems</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et¬†al. (2018)</span>
<span class="ltx_bibblock">
L.¬†B. Smith, S.¬†Jayaraman, E.¬†Clerkin, and C.¬†Yu.

</span>
<span class="ltx_bibblock">The developing infant creates a curriculum for statistical learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Trends in cognitive sciences</em>, 22(4), 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stooke et¬†al. (2021)</span>
<span class="ltx_bibblock">
A.¬†Stooke, A.¬†Mahajan, C.¬†Barros, C.¬†Deck, J.¬†Bauer, J.¬†Sygnowski, M.¬†Trebacz,
M.¬†Jaderberg, M.¬†Mathieu, et¬†al.

</span>
<span class="ltx_bibblock">Open-ended learning leads to generally capable agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2107.12808</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et¬†al. (2022)</span>
<span class="ltx_bibblock">
J.¬†Wei, Y.¬†Tay, R.¬†Bommasani, C.¬†Raffel, B.¬†Zoph, S.¬†Borgeaud, D.¬†Yogatama,
M.¬†Bosma, D.¬†Zhou, D.¬†Metzler, et¬†al.

</span>
<span class="ltx_bibblock">Emergent abilities of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Transactions on machine learning research</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et¬†al. (2023)</span>
<span class="ltx_bibblock">
Y.¬†Zhang, Y.¬†Li, L.¬†Cui, D.¬†Cai, L.¬†Liu, T.¬†Fu, X.¬†Huang, E.¬†Zhao, Y.¬†Zhang,
Y.¬†Chen, et¬†al.

</span>
<span class="ltx_bibblock">Siren‚Äôs song in the ai ocean: a survey on hallucination in large
language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2309.01219</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_part" id="Pt1" lang="en">
<h2 class="ltx_title ltx_title_part"><span class="ltx_tag ltx_tag_part"> Appendix </span></h2>
<div class="ltx_para ltx_noindent" id="Pt1.p1">
<span class="ltx_ERROR undefined" id="Pt1.p1.1">\parttoc</span>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Related work</h3>
<section class="ltx_subsection" id="A1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Associative memories and factual knowledge of neural networks</h4>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Associative memories have been extensively studied in neuroscience. The foundational experimental work on conditioning by <cite class="ltx_cite ltx_citemacro_cite">Pavlov (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib41" title="">1927</a>)</cite> sparked extensive theoretical research into the computational mechanism underlying associative memories. This led to breakthrough developments like Hebb‚Äôs rule <cite class="ltx_cite ltx_citemacro_citep">(Hebb, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib20" title="">1949</a>)</cite> and Hopfield networks <cite class="ltx_cite ltx_citemacro_citep">(Amari, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib3" title="">1972</a>; Hopfield, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib23" title="">1982</a>)</cite>, which later proved instrumental in the emergence of deep learning.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">In recent years, as language models have grown increasingly powerful, research has begun examining them through the lens of associative memories. Our work directly builds on this line of research. <cite class="ltx_cite ltx_citemacro_cite">Petroni et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib42" title="">2019</a>)</cite> first proposed that masked language models like BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib13" title="">2018</a>)</cite>, could encode relational knowledge within their weights. This analysis was subsequently extended to autoregressive Transformer-based language models: <cite class="ltx_cite ltx_citemacro_cite">Geva et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib17" title="">2021</a>)</cite> demonstrated that feed-forward layers act as associative key-value memories, <cite class="ltx_cite ltx_citemacro_cite">Meng et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib31" title="">2022</a>)</cite> showed how this stored knowledge could be located and edited, <cite class="ltx_cite ltx_citemacro_cite">Geva et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>); Nanda et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>)</cite> revealed the functional mechanisms underlying memory recall, and <cite class="ltx_cite ltx_citemacro_cite">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite> identified conditions under which these general mechanisms are developed. Beyond these mechanistic insights, associative memories have provided a framework for evaluating the knowledge capacity of language models. This includes empirical scaling laws <cite class="ltx_cite ltx_citemacro_citep">(Allen-Zhu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib2" title="">2024</a>)</cite> and theoretical analyses <cite class="ltx_cite ltx_citemacro_citep">(Nichani et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib36" title="">2024</a>)</cite> which follow from a long history of capacity analyses of Hopfield networks and related models <cite class="ltx_cite ltx_citemacro_citep">(e.g., McEliece et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib30" title="">1987</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p3">
<p class="ltx_p" id="A1.SS1.p3.1">While the above research primarily examines parametric memories stored in network weights, recent years have also seen growing interest in the in-context associative recall capabilities of sequential modeling networks. Notable examples include the induction head in Transformers <cite class="ltx_cite ltx_citemacro_cite">Olsson et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib37" title="">2022</a>)</cite> and comparative studies showing that the primary difference between attention-based and attention-free language models can be attributed to their different in-context associative recall capabilities <cite class="ltx_cite ltx_citemacro_citep">(Arora et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib4" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Learning dynamics of neural networks</h4>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">The study of neural network learning dynamics has deep roots in early connectionist research <cite class="ltx_cite ltx_citemacro_citep">(e.g., Hinton, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib21" title="">1986</a>; McClelland, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib28" title="">1995</a>; Baldi and Hornik, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib5" title="">1995</a>)</cite>. It has been particularly influential in the early days of deep learning. For example, the seminal work of <cite class="ltx_cite ltx_citemacro_cite">Saxe et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib45" title="">2014</a>)</cite> provided fundamental insights into the role of depth in neural network training.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p2">
<p class="ltx_p" id="A1.SS2.p2.1">The recent demonstration of in-context learning capabilities in large-scale models <cite class="ltx_cite ltx_citemacro_cite">Brown et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib8" title="">2020</a>)</cite> has sparked renewed interest in understanding the underlying dynamics. A significant contribution to this understanding came from <cite class="ltx_cite ltx_citemacro_cite">Olsson et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib37" title="">2022</a>)</cite>, who established a causal link between the development of induction heads and a phase transition that enables in-context learning. This mechanistic understanding has been complemented by research on the influence of training data distribution on learning trajectories and implemented algorithms. Notably, <cite class="ltx_cite ltx_citemacro_cite">Chan et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib9" title="">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Singh et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib47" title="">2024</a>)</cite> revealed how different data distributions guide networks through distinct algorithmic solutions, either facilitating in-context learning or not. The generality of these findings was later confirmed by <cite class="ltx_cite ltx_citemacro_cite">Park et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib40" title="">2024</a>)</cite>, who reproduced them using a simplified training distribution.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p3">
<p class="ltx_p" id="A1.SS2.p3.3">Parallel to these developments, <cite class="ltx_cite ltx_citemacro_cite">Nguyen (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib35" title="">2024</a>)</cite> showed that Transformer-based language models‚Äô predictions can be effectively approximated by <math alttext="N-" class="ltx_Math" display="inline" id="A1.SS2.p3.1.m1.1"><semantics id="A1.SS2.p3.1.m1.1a"><mrow id="A1.SS2.p3.1.m1.1.1" xref="A1.SS2.p3.1.m1.1.1.cmml"><mi id="A1.SS2.p3.1.m1.1.1.2" xref="A1.SS2.p3.1.m1.1.1.2.cmml">N</mi><mo id="A1.SS2.p3.1.m1.1.1.3" xref="A1.SS2.p3.1.m1.1.1.3.cmml">‚àí</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.1.m1.1b"><apply id="A1.SS2.p3.1.m1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1"><csymbol cd="latexml" id="A1.SS2.p3.1.m1.1.1.1.cmml" xref="A1.SS2.p3.1.m1.1.1">limit-from</csymbol><ci id="A1.SS2.p3.1.m1.1.1.2.cmml" xref="A1.SS2.p3.1.m1.1.1.2">ùëÅ</ci><minus id="A1.SS2.p3.1.m1.1.1.3.cmml" xref="A1.SS2.p3.1.m1.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.1.m1.1c">N-</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.1.m1.1d">italic_N -</annotation></semantics></math>gram statistics, with the optimal <math alttext="N" class="ltx_Math" display="inline" id="A1.SS2.p3.2.m2.1"><semantics id="A1.SS2.p3.2.m2.1a"><mi id="A1.SS2.p3.2.m2.1.1" xref="A1.SS2.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.2.m2.1b"><ci id="A1.SS2.p3.2.m2.1.1.cmml" xref="A1.SS2.p3.2.m2.1.1">ùëÅ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.2.m2.1d">italic_N</annotation></semantics></math> increasing throughout training. Our work observes similar dynamics during the transition from bigram to trigram predictions during the plateau phase. However, a key distinction lies in the level of abstraction: while <cite class="ltx_cite ltx_citemacro_cite">Nguyen (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib35" title="">2024</a>)</cite>‚Äôs <math alttext="N-" class="ltx_Math" display="inline" id="A1.SS2.p3.3.m3.1"><semantics id="A1.SS2.p3.3.m3.1a"><mrow id="A1.SS2.p3.3.m3.1.1" xref="A1.SS2.p3.3.m3.1.1.cmml"><mi id="A1.SS2.p3.3.m3.1.1.2" xref="A1.SS2.p3.3.m3.1.1.2.cmml">N</mi><mo id="A1.SS2.p3.3.m3.1.1.3" xref="A1.SS2.p3.3.m3.1.1.3.cmml">‚àí</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.p3.3.m3.1b"><apply id="A1.SS2.p3.3.m3.1.1.cmml" xref="A1.SS2.p3.3.m3.1.1"><csymbol cd="latexml" id="A1.SS2.p3.3.m3.1.1.1.cmml" xref="A1.SS2.p3.3.m3.1.1">limit-from</csymbol><ci id="A1.SS2.p3.3.m3.1.1.2.cmml" xref="A1.SS2.p3.3.m3.1.1.2">ùëÅ</ci><minus id="A1.SS2.p3.3.m3.1.1.3.cmml" xref="A1.SS2.p3.3.m3.1.1.3"></minus></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.p3.3.m3.1c">N-</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.p3.3.m3.1d">italic_N -</annotation></semantics></math>gram associations occur directly at the token level, our work observes these sequential dependencies at a higher level of abstraction.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS2.p4">
<p class="ltx_p" id="A1.SS2.p4.1">Finally, and most related to ours, is the study of factual knowledge acquisition in large language models from <cite class="ltx_cite ltx_citemacro_citet">Chang et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib10" title="">2024</a>)</cite>. Their key finding is that factual knowledge acquisition occurs through accumulating small probability increases when the model encounters the same knowledge, followed by gradual forgetting when not being exposed to it. These results are consistent with ours, although we find forgetting to be more pronounced, likely because of larger training distribution shifts. Additionally, while their findings were obtained by slightly altering the training distribution of a large language model, our work goes one step further by studying in depth the impact of training distributions on learning speed.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental setup</h3>
<section class="ltx_subsection" id="A2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Rationale behind our design choices</h4>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">Our goal is to identify a synthetic setting, as simple as possible, where a model exhibits knowledge of its training data (that is a flexible usage of it, cf. Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS1" title="1.1 Knowledge, and how it differs from memory ‚Ä£ 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1.1</span></a>, not mere memorization) using mechanisms similar to large language models. This allows precise control over the data distribution and increases the likelihood that our findings generalize to large language models.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1">We build upon the synthetic biography dataset and analysis of <cite class="ltx_cite ltx_citemacro_cite">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, as well as the mechanistic interpretability studies of <cite class="ltx_cite ltx_citemacro_cite">Geva et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Nanda et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>)</cite>. <cite class="ltx_cite ltx_citemacro_cite">Geva et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_cite">Nanda et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>)</cite> find that pretrained large language models encode individual-specific information in their residual stream as soon as the name of the individual is encountered. <cite class="ltx_cite ltx_citemacro_cite">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite> observe such a behavior when training models on biographies whose order is permuted every new occurrence, along with having multiple biographies for ‚Äúcelebrities‚Äù (see their Q-probing analysis). We hypothesize that textual variation within the biography distribution is key to achieve this behavior. Therefore, our setup ensures unique biographies by introducing 25 distinct templates per attribute type (see next section) and permuting their order. Importantly, biographies are resampled for each new sequence. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.F1" title="Figure A ‚Ä£ B.1 Rationale behind our design choices ‚Ä£ Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">A</span></a> demonstrates the critical importance of random ordering and the need for some textual diversity within individual biographies. While we have not ablated the total number of templates per attribute type, we believe that the overall textual diversity of the distribution is necessary for the learning of robust features. In our experiments, the individual‚Äôs name is repeated in every sentence to facilitate knowledge development, though we believe later occurrences could be replaced with pronouns without significantly affecting results, as <cite class="ltx_cite ltx_citemacro_citep">(Allen-Zhu and Li, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite> found the benefits of full name repetition primarily in the non-permuted and not so diverse regime.</p>
</div>
<figure class="ltx_figure" id="A2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="A2.F1.g1" src="x6.png" width="520"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure A: </span>(left) Training loss corresponding to the left and middle panels of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a>. (right) Ablation study demonstrating the importance of permuting the presentation order of attributes and the size of the template pool used for generating biographies. Random permutations are crucial, and some textual diversity is needed.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Details about the biography generation process</h4>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">Our data generation process largely follows <cite class="ltx_cite ltx_citemacro_cite">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, with a few important differences regarding how templates are generated and manipulated.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS2.p2">
<p class="ltx_p" id="A2.SS2.p2.1">Prior to training, we generate a population of individuals, each with a full name (first, middle, and last) and six attributes: birth place, birth date, university, major, company, and current location. These are generated as follows:</p>
<ul class="ltx_itemize" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i1.p1.1.1">Full name.</span> First and middle names are sampled from a list of 900, and last names from a list of 1,000, resulting in 810 million potential unique names. We ensure that each individual has a unique full name. These names are among the most commonly used worldwide.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i2.p1.1.1">Birth place and current location.</span> Sampled from a list of the 800 largest cities worldwide. Unlike <cite class="ltx_cite ltx_citemacro_cite">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, we do not correlate current location with the company.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i3.p1.1.1">University.</span> Sampled from the 200 largest universities worldwide.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I1.i4.p1">
<p class="ltx_p" id="A2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i4.p1.1.1">Major.</span> Sampled from a list of 100 majors.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I1.i5.p1">
<p class="ltx_p" id="A2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i5.p1.1.1">Company.</span> Sampled from the 500 companies with largest valuations.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para ltx_noindent" id="A2.I1.i6.p1">
<p class="ltx_p" id="A2.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I1.i6.p1.1.1">Birth date.</span> Year, month, and day are sampled independently (between 1900-2100, January-December, and 1-31, respectively). This allows unrealistic dates (e.g., February 31st), but should not significantly impact tokenization.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A2.SS2.p2.2">These values are chosen to reasonably approximate the token distribution a large language model might encounter during pre-training.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS2.p3">
<p class="ltx_p" id="A2.SS2.p3.3">For the sake of our analysis, the template generation requires extra care, as we want all the information needed to predict the attribute value and as we want to evaluate the model on sentences it has never seen. Such considerations were not needed in <cite class="ltx_cite ltx_citemacro_citet">Allen-Zhu and Li (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib1" title="">2023</a>)</cite>, so we had to adapt their setup. In our dataset, templates are generated prior to training with the assistance of a large language model, using the prompting scheme in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.F2" title="Figure B ‚Ä£ B.2 Details about the biography generation process ‚Ä£ Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">B</span></a>. This yields <math alttext="25" class="ltx_Math" display="inline" id="A2.SS2.p3.1.m1.1"><semantics id="A2.SS2.p3.1.m1.1a"><mn id="A2.SS2.p3.1.m1.1.1" xref="A2.SS2.p3.1.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.1.m1.1b"><cn id="A2.SS2.p3.1.m1.1.1.cmml" type="integer" xref="A2.SS2.p3.1.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.1.m1.1c">25</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p3.1.m1.1d">25</annotation></semantics></math> distinct templates per attribute type. As discussed in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS2" title="1.2 Synthetic biographies as a framework for studying knowledge ‚Ä£ 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1.2</span></a>, we (manually) ensure that the individual‚Äôs name and information identifying the attribute type precede the attribute value, allowing a model with perfect knowledge to achieve zero loss. For each individual, we pick <math alttext="20" class="ltx_Math" display="inline" id="A2.SS2.p3.2.m2.1"><semantics id="A2.SS2.p3.2.m2.1a"><mn id="A2.SS2.p3.2.m2.1.1" xref="A2.SS2.p3.2.m2.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.2.m2.1b"><cn id="A2.SS2.p3.2.m2.1.1.cmml" type="integer" xref="A2.SS2.p3.2.m2.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.2.m2.1c">20</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p3.2.m2.1d">20</annotation></semantics></math> templates for training and keep <math alttext="5" class="ltx_Math" display="inline" id="A2.SS2.p3.3.m3.1"><semantics id="A2.SS2.p3.3.m3.1a"><mn id="A2.SS2.p3.3.m3.1.1" xref="A2.SS2.p3.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.3.m3.1b"><cn id="A2.SS2.p3.3.m3.1.1.cmml" type="integer" xref="A2.SS2.p3.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.3.m3.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p3.3.m3.1d">5</annotation></semantics></math> for evaluation, ensuring the model encounters novel template-individual combinations during evaluation, thus measuring knowledge rather than memorization. Additionally, we introduce special tokens for tags (like name or birth date) in the templates and replace these tags by the desired content only after tokenization. This way, we can make sure that, after this manipulation, the tokens coming from names or attribute values directly appear in the token sequence (e.g. "1990." will be tokenized as "[1990][.]" and not "[1990.]" as it would usually be). Such a precaution facilitates analysis as we can be sure that each of the name or attribute value tokens only contain this information, and not some unrelated semantic information about the sentence.</p>
</div>
<figure class="ltx_figure" id="A2.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="205" id="A2.F2.g1" src="x7.png" width="653"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure B: </span>Illustration of the template creation process. At the end of it, we have <math alttext="25" class="ltx_Math" display="inline" id="A2.F2.2.m1.1"><semantics id="A2.F2.2.m1.1b"><mn id="A2.F2.2.m1.1.1" xref="A2.F2.2.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A2.F2.2.m1.1c"><cn id="A2.F2.2.m1.1.1.cmml" type="integer" xref="A2.F2.2.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.F2.2.m1.1d">25</annotation><annotation encoding="application/x-llamapun" id="A2.F2.2.m1.1e">25</annotation></semantics></math> different templates per attribute type.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A2.SS2.p4">
<p class="ltx_p" id="A2.SS2.p4.1">Biography generation, for both training and evaluation, is summarized in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.F1" title="Figure 1 ‚Ä£ 1.2 Synthetic biographies as a framework for studying knowledge ‚Ä£ 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1</span></a> and involves two steps:</p>
<ol class="ltx_enumerate" id="A2.I2">
<li class="ltx_item" id="A2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A2.I2.i1.p1">
<p class="ltx_p" id="A2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i1.p1.1.1">Individual sampling.</span> By default, we sample individuals uniformly at random from the population. This distribution is modified in some experiments (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.SS1" title="3.1 The trade-off underlying imbalances in the data distribution ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3.1</span></a>) and can be time-step dependent (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S1.SS1" title="1.1 Knowledge, and how it differs from memory ‚Ä£ 1 An experimental setup to track knowledge over the course of learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1.1</span></a> and Appendix¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS5" title="F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.5</span></a>). Here are the detail of these different distributions:</p>
<ul class="ltx_itemize" id="A2.I2.i1.I1">
<li class="ltx_item" id="A2.I2.i1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I2.i1.I1.i1.p1">
<p class="ltx_p" id="A2.I2.i1.I1.i1.p1.5"><span class="ltx_text ltx_font_bold" id="A2.I2.i1.I1.i1.p1.5.1">Inverse power law / Zipf distribution.</span> The <math alttext="i" class="ltx_Math" display="inline" id="A2.I2.i1.I1.i1.p1.1.m1.1"><semantics id="A2.I2.i1.I1.i1.p1.1.m1.1a"><mi id="A2.I2.i1.I1.i1.p1.1.m1.1.1" xref="A2.I2.i1.I1.i1.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A2.I2.i1.I1.i1.p1.1.m1.1b"><ci id="A2.I2.i1.I1.i1.p1.1.m1.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.1.m1.1.1">ùëñ</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.I1.i1.p1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i1.I1.i1.p1.1.m1.1d">italic_i</annotation></semantics></math>-th individual is sampled with probability proportional to <math alttext="i^{-\alpha}" class="ltx_Math" display="inline" id="A2.I2.i1.I1.i1.p1.2.m2.1"><semantics id="A2.I2.i1.I1.i1.p1.2.m2.1a"><msup id="A2.I2.i1.I1.i1.p1.2.m2.1.1" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.cmml"><mi id="A2.I2.i1.I1.i1.p1.2.m2.1.1.2" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.2.cmml">i</mi><mrow id="A2.I2.i1.I1.i1.p1.2.m2.1.1.3" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.cmml"><mo id="A2.I2.i1.I1.i1.p1.2.m2.1.1.3a" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.cmml">‚àí</mo><mi id="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.2" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.2.cmml">Œ±</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A2.I2.i1.I1.i1.p1.2.m2.1b"><apply id="A2.I2.i1.I1.i1.p1.2.m2.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.I2.i1.I1.i1.p1.2.m2.1.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1">superscript</csymbol><ci id="A2.I2.i1.I1.i1.p1.2.m2.1.1.2.cmml" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.2">ùëñ</ci><apply id="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.cmml" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.3"><minus id="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.1.cmml" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.3"></minus><ci id="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.2.cmml" xref="A2.I2.i1.I1.i1.p1.2.m2.1.1.3.2">ùõº</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.I1.i1.p1.2.m2.1c">i^{-\alpha}</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i1.I1.i1.p1.2.m2.1d">italic_i start_POSTSUPERSCRIPT - italic_Œ± end_POSTSUPERSCRIPT</annotation></semantics></math> with <math alttext="\alpha" class="ltx_Math" display="inline" id="A2.I2.i1.I1.i1.p1.3.m3.1"><semantics id="A2.I2.i1.I1.i1.p1.3.m3.1a"><mi id="A2.I2.i1.I1.i1.p1.3.m3.1.1" xref="A2.I2.i1.I1.i1.p1.3.m3.1.1.cmml">Œ±</mi><annotation-xml encoding="MathML-Content" id="A2.I2.i1.I1.i1.p1.3.m3.1b"><ci id="A2.I2.i1.I1.i1.p1.3.m3.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.3.m3.1.1">ùõº</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.I1.i1.p1.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i1.I1.i1.p1.3.m3.1d">italic_Œ±</annotation></semantics></math> an hyperparameter. Recall that we get the uniform distribution when <math alttext="\alpha=0" class="ltx_Math" display="inline" id="A2.I2.i1.I1.i1.p1.4.m4.1"><semantics id="A2.I2.i1.I1.i1.p1.4.m4.1a"><mrow id="A2.I2.i1.I1.i1.p1.4.m4.1.1" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.cmml"><mi id="A2.I2.i1.I1.i1.p1.4.m4.1.1.2" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.2.cmml">Œ±</mi><mo id="A2.I2.i1.I1.i1.p1.4.m4.1.1.1" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.1.cmml">=</mo><mn id="A2.I2.i1.I1.i1.p1.4.m4.1.1.3" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i1.I1.i1.p1.4.m4.1b"><apply id="A2.I2.i1.I1.i1.p1.4.m4.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1"><eq id="A2.I2.i1.I1.i1.p1.4.m4.1.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.1"></eq><ci id="A2.I2.i1.I1.i1.p1.4.m4.1.1.2.cmml" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.2">ùõº</ci><cn id="A2.I2.i1.I1.i1.p1.4.m4.1.1.3.cmml" type="integer" xref="A2.I2.i1.I1.i1.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.I1.i1.p1.4.m4.1c">\alpha=0</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i1.I1.i1.p1.4.m4.1d">italic_Œ± = 0</annotation></semantics></math> and, when <math alttext="\alpha=1" class="ltx_Math" display="inline" id="A2.I2.i1.I1.i1.p1.5.m5.1"><semantics id="A2.I2.i1.I1.i1.p1.5.m5.1a"><mrow id="A2.I2.i1.I1.i1.p1.5.m5.1.1" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.cmml"><mi id="A2.I2.i1.I1.i1.p1.5.m5.1.1.2" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.2.cmml">Œ±</mi><mo id="A2.I2.i1.I1.i1.p1.5.m5.1.1.1" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.1.cmml">=</mo><mn id="A2.I2.i1.I1.i1.p1.5.m5.1.1.3" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i1.I1.i1.p1.5.m5.1b"><apply id="A2.I2.i1.I1.i1.p1.5.m5.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1"><eq id="A2.I2.i1.I1.i1.p1.5.m5.1.1.1.cmml" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.1"></eq><ci id="A2.I2.i1.I1.i1.p1.5.m5.1.1.2.cmml" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.2">ùõº</ci><cn id="A2.I2.i1.I1.i1.p1.5.m5.1.1.3.cmml" type="integer" xref="A2.I2.i1.I1.i1.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.I1.i1.p1.5.m5.1c">\alpha=1</annotation><annotation encoding="application/x-llamapun" id="A2.I2.i1.I1.i1.p1.5.m5.1d">italic_Œ± = 1</annotation></semantics></math>, we get the Zipf distribution.</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I2.i1.I1.i2.p1">
<p class="ltx_p" id="A2.I2.i1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i1.I1.i2.p1.1.1">‚ÄúCelebrities‚Äù distribution.</span> A subset of the individuals of a size <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i2.p1.1.2">n_celebrities</span> is oversampled is sampled <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i2.p1.1.3">weight_celebrities</span> times more frequently larger than individuals outside the group. Here, <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i2.p1.1.4">n_celebrities</span> and <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i2.p1.1.5">weight_celebrities</span> are the two hyperparameters we vary.</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A2.I2.i1.I1.i3.p1">
<p class="ltx_p" id="A2.I2.i1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i1.I1.i3.p1.1.1">‚ÄúWarm-up‚Äù distribution.</span> Training begins on a subset of <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i3.p1.1.2">indiv_warmup</span> individuals for <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i3.p1.1.3">epochs_warmup</span> epochs. An epoch is here defined as the number of training steps required to see as many biographies as there are individuals in the entire population (number of individuals divided by batch size steps). Once the warm-up is over, we train on the full population. In both phases, individuals within the relevant group are uniformly sampled.</p>
</div>
</li>
<li class="ltx_item" id="A2.I2.i1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para ltx_noindent" id="A2.I2.i1.I1.i4.p1">
<p class="ltx_p" id="A2.I2.i1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i1.I1.i4.p1.1.1">Sequential distribution.</span> The population is divided into <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i4.p1.1.2">n_groups</span> groups and we go through these groups in increasing order <span class="ltx_text ltx_font_typewriter" id="A2.I2.i1.I1.i4.p1.1.3">n_repeats</span> times. Individuals within each group are uniformly sampled.</p>
</div>
</li>
</ul>
</div>
</li>
<li class="ltx_item" id="A2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="A2.I2.i2.p1">
<p class="ltx_p" id="A2.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.I2.i2.p1.1.1">Biography sampling.</span> For a given individual, we uniformly sample templates from the appropriate pool (training or evaluation) for each attribute. We then randomize the template order and concatenate them to form a single-sequence biography.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="A2.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Architecture, optimization and metrics</h4>
<div class="ltx_para ltx_noindent" id="A2.SS3.p1">
<p class="ltx_p" id="A2.SS3.p1.14">In almost all our experiments, we use the <math alttext="44" class="ltx_Math" display="inline" id="A2.SS3.p1.1.m1.1"><semantics id="A2.SS3.p1.1.m1.1a"><mn id="A2.SS3.p1.1.m1.1.1" xref="A2.SS3.p1.1.m1.1.1.cmml">44</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.1.m1.1b"><cn id="A2.SS3.p1.1.m1.1.1.cmml" type="integer" xref="A2.SS3.p1.1.m1.1.1">44</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.1.m1.1c">44</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.1.m1.1d">44</annotation></semantics></math>M-parameters Transformer architecture of <cite class="ltx_cite ltx_citemacro_cite">Hoffmann et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib22" title="">2022</a>)</cite>. It has <math alttext="8" class="ltx_Math" display="inline" id="A2.SS3.p1.2.m2.1"><semantics id="A2.SS3.p1.2.m2.1a"><mn id="A2.SS3.p1.2.m2.1.1" xref="A2.SS3.p1.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.2.m2.1b"><cn id="A2.SS3.p1.2.m2.1.1.cmml" type="integer" xref="A2.SS3.p1.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.2.m2.1c">8</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.2.m2.1d">8</annotation></semantics></math> layers, uses a residual stream of dimension <math alttext="512" class="ltx_Math" display="inline" id="A2.SS3.p1.3.m3.1"><semantics id="A2.SS3.p1.3.m3.1a"><mn id="A2.SS3.p1.3.m3.1.1" xref="A2.SS3.p1.3.m3.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.3.m3.1b"><cn id="A2.SS3.p1.3.m3.1.1.cmml" type="integer" xref="A2.SS3.p1.3.m3.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.3.m3.1c">512</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.3.m3.1d">512</annotation></semantics></math>, with one hidden layer multi-layer perceptrons with <math alttext="2048" class="ltx_Math" display="inline" id="A2.SS3.p1.4.m4.1"><semantics id="A2.SS3.p1.4.m4.1a"><mn id="A2.SS3.p1.4.m4.1.1" xref="A2.SS3.p1.4.m4.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.4.m4.1b"><cn id="A2.SS3.p1.4.m4.1.1.cmml" type="integer" xref="A2.SS3.p1.4.m4.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.4.m4.1c">2048</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.4.m4.1d">2048</annotation></semantics></math> hidden neurons. It has <math alttext="8" class="ltx_Math" display="inline" id="A2.SS3.p1.5.m5.1"><semantics id="A2.SS3.p1.5.m5.1a"><mn id="A2.SS3.p1.5.m5.1.1" xref="A2.SS3.p1.5.m5.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.5.m5.1b"><cn id="A2.SS3.p1.5.m5.1.1.cmml" type="integer" xref="A2.SS3.p1.5.m5.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.5.m5.1c">8</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.5.m5.1d">8</annotation></semantics></math> heads and each head has keys and values of dimension <math alttext="64" class="ltx_Math" display="inline" id="A2.SS3.p1.6.m6.1"><semantics id="A2.SS3.p1.6.m6.1a"><mn id="A2.SS3.p1.6.m6.1.1" xref="A2.SS3.p1.6.m6.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.6.m6.1b"><cn id="A2.SS3.p1.6.m6.1.1.cmml" type="integer" xref="A2.SS3.p1.6.m6.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.6.m6.1c">64</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.6.m6.1d">64</annotation></semantics></math>. The only deviation to this architecture is the model size ablation of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a> (lower right), in which we use a <math alttext="163" class="ltx_Math" display="inline" id="A2.SS3.p1.7.m7.1"><semantics id="A2.SS3.p1.7.m7.1a"><mn id="A2.SS3.p1.7.m7.1.1" xref="A2.SS3.p1.7.m7.1.1.cmml">163</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.7.m7.1b"><cn id="A2.SS3.p1.7.m7.1.1.cmml" type="integer" xref="A2.SS3.p1.7.m7.1.1">163</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.7.m7.1c">163</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.7.m7.1d">163</annotation></semantics></math>M-parameters (<math alttext="12" class="ltx_Math" display="inline" id="A2.SS3.p1.8.m8.1"><semantics id="A2.SS3.p1.8.m8.1a"><mn id="A2.SS3.p1.8.m8.1.1" xref="A2.SS3.p1.8.m8.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.8.m8.1b"><cn id="A2.SS3.p1.8.m8.1.1.cmml" type="integer" xref="A2.SS3.p1.8.m8.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.8.m8.1c">12</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.8.m8.1d">12</annotation></semantics></math> layers, <math alttext="16" class="ltx_Math" display="inline" id="A2.SS3.p1.9.m9.1"><semantics id="A2.SS3.p1.9.m9.1a"><mn id="A2.SS3.p1.9.m9.1.1" xref="A2.SS3.p1.9.m9.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.9.m9.1b"><cn id="A2.SS3.p1.9.m9.1.1.cmml" type="integer" xref="A2.SS3.p1.9.m9.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.9.m9.1c">16</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.9.m9.1d">16</annotation></semantics></math> heads, dimension <math alttext="896" class="ltx_Math" display="inline" id="A2.SS3.p1.10.m10.1"><semantics id="A2.SS3.p1.10.m10.1a"><mn id="A2.SS3.p1.10.m10.1.1" xref="A2.SS3.p1.10.m10.1.1.cmml">896</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.10.m10.1b"><cn id="A2.SS3.p1.10.m10.1.1.cmml" type="integer" xref="A2.SS3.p1.10.m10.1.1">896</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.10.m10.1c">896</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.10.m10.1d">896</annotation></semantics></math>) and a <math alttext="400" class="ltx_Math" display="inline" id="A2.SS3.p1.11.m11.1"><semantics id="A2.SS3.p1.11.m11.1a"><mn id="A2.SS3.p1.11.m11.1.1" xref="A2.SS3.p1.11.m11.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.11.m11.1b"><cn id="A2.SS3.p1.11.m11.1.1.cmml" type="integer" xref="A2.SS3.p1.11.m11.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.11.m11.1c">400</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.11.m11.1d">400</annotation></semantics></math>M-parameters (<math alttext="12" class="ltx_Math" display="inline" id="A2.SS3.p1.12.m12.1"><semantics id="A2.SS3.p1.12.m12.1a"><mn id="A2.SS3.p1.12.m12.1.1" xref="A2.SS3.p1.12.m12.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.12.m12.1b"><cn id="A2.SS3.p1.12.m12.1.1.cmml" type="integer" xref="A2.SS3.p1.12.m12.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.12.m12.1c">12</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.12.m12.1d">12</annotation></semantics></math> layers, <math alttext="12" class="ltx_Math" display="inline" id="A2.SS3.p1.13.m13.1"><semantics id="A2.SS3.p1.13.m13.1a"><mn id="A2.SS3.p1.13.m13.1.1" xref="A2.SS3.p1.13.m13.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.13.m13.1b"><cn id="A2.SS3.p1.13.m13.1.1.cmml" type="integer" xref="A2.SS3.p1.13.m13.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.13.m13.1c">12</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.13.m13.1d">12</annotation></semantics></math> heads, dimension <math alttext="1536" class="ltx_Math" display="inline" id="A2.SS3.p1.14.m14.1"><semantics id="A2.SS3.p1.14.m14.1a"><mn id="A2.SS3.p1.14.m14.1.1" xref="A2.SS3.p1.14.m14.1.1.cmml">1536</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.14.m14.1b"><cn id="A2.SS3.p1.14.m14.1.1.cmml" type="integer" xref="A2.SS3.p1.14.m14.1.1">1536</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.14.m14.1c">1536</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p1.14.m14.1d">1536</annotation></semantics></math>) architecture. The default hyperparameter configuration is detailed in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.T1" title="Table 1 ‚Ä£ G.1 Default configuration ‚Ä£ Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1</span></a>. For most experiments, we perform a sweep over different learning rates values, selecting the best performing one based on final training loss.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.p2">
<p class="ltx_p" id="A2.SS3.p2.1">The experiments in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a> use <math alttext="5" class="ltx_Math" display="inline" id="A2.SS3.p2.1.m1.1"><semantics id="A2.SS3.p2.1.m1.1a"><mn id="A2.SS3.p2.1.m1.1.1" xref="A2.SS3.p2.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p2.1.m1.1b"><cn id="A2.SS3.p2.1.m1.1.1.cmml" type="integer" xref="A2.SS3.p2.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p2.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p2.1.m1.1d">5</annotation></semantics></math> different seeds. However, given the low variance of the results, we preferred to use compute to explore more diverse hyperparameter configurations rather than performing our analysis on more seeds and ended up using a single seed for the rest of the experiments.</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS3.p3">
<p class="ltx_p" id="A2.SS3.p3.1">Throughout this study, we use two main metrics. The first one is the attribute loss, which is the sum of cross entropy losses measured on all attribute value tokens, which is then averaged by the number of attribute values in the sequence (always <math alttext="6" class="ltx_Math" display="inline" id="A2.SS3.p3.1.m1.1"><semantics id="A2.SS3.p3.1.m1.1a"><mn id="A2.SS3.p3.1.m1.1.1" xref="A2.SS3.p3.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A2.SS3.p3.1.m1.1b"><cn id="A2.SS3.p3.1.m1.1.1.cmml" type="integer" xref="A2.SS3.p3.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p3.1.m1.1c">6</annotation><annotation encoding="application/x-llamapun" id="A2.SS3.p3.1.m1.1d">6</annotation></semantics></math>) and by the batch size. Importantly, we don‚Äôt average by the number of tokens within each attribute value, so that the comparison to the no-knowledge baseline is easier. The second metric we use is the attribute accuracy, which is the accuracy the model gets when correctly predicting all consecutive attribute value tokens. For example, if the model always predicts correctly all attribute value tokens except the first one, it will get an accuracy of 0. This way, this metric is rather conservative, and that we are sure that for the model to be correct it has to get all the tokens requiring recall abilities (as opposed to completion abilities) right. The no-knowledge baseline is computed as the average entropy of all attribute values from all types, that is the average logarithm of the number of possible attribute values.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional analysis of the learning dynamics (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS1" title="2.1 The three phases underlying knowledge acquisition ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.1</span></a>)</h3>
<section class="ltx_subsection" id="A3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>The three phases are robust to sensible hyperparameter choices</h4>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">In Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>, we verify whether the three phases we identify are robust to sensible parameter changes. We find that they are robust to changes in learning rates, total number of individuals, weight decay values, batch size, model size and to changing the sequence mixing architecture to a recurrent one (we use the Hawk model for that <cite class="ltx_cite ltx_citemacro_citep">(De et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib12" title="">2024</a>)</cite>).</p>
</div>
<figure class="ltx_figure" id="A3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="330" id="A3.F3.g1" src="x8.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure C: </span>Different hyperparameter configurations lead to qualitatively similar learning dynamics.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Details of the mechanistic study and additional analyses (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS2" title="2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.2</span></a>)</h3>
<section class="ltx_subsection" id="A4.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.1 </span>Implementation of the attention patching experiment</h4>
<div class="ltx_para ltx_noindent" id="A4.SS1.p1">
<p class="ltx_p" id="A4.SS1.p1.1">Our attention patching experiment consists in training a reference model, then restarting training with the same initial parameters but providing the model with the attention patterns the reference model produced when seeing the same samples. Two hyperparameters control this: <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p1.1.1">reference_patching</span> (the number of training steps for which the reference model was trained) and <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p1.1.2">start_patching</span> (the step at which patching begins; before this, the modified model uses its own attention). There are two key configurations: when <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p1.1.3">start_patching</span> and <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p1.1.4">reference_patching</span> are equal, this effectively freezes the model‚Äôs attention at a given point; when <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p1.1.5">start_patching</span> is 0, patching occurs throughout training, as presented in the main text.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS1.p2">
<p class="ltx_p" id="A4.SS1.p2.1">We implement attention patching through a twin architecture. We initialize the modified model with the initial parameters and the reference model with the desired parameters. Both models process the input sequence layer-wise. At each layer, the reference model generates attention scores and output. The attention scores are sent to the corresponding layer in the modified model (and the output to the next layer), with gradients stopped on the attention scores to prevent training the reference model. The modified layer uses the provided attention pattern instead of its own if patching has begun. While generating all attention scores from the reference model beforehand is possible and potentially simpler code-wise, our layer-wise implementation is more memory-efficient, particularly for long sequences, and many layers and heads. That said, given that memory is not an issue in our experiments given the small size of the models, it would probably have been good enough. We always re-initialize the optimizer state to default values when starting patching. While we found some significant loss increase just after the beginning of patching with this strategy, we also found them to be smaller than without re-initializing them.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS1.p3">
<p class="ltx_p" id="A4.SS1.p3.1">The experimental setup that we have described here is richer than the one presented in the main text as we can now vary the beginning of patching. We provide the results of this more extensive analysis in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F4" title="Figure D ‚Ä£ D.1 Implementation of the attention patching experiment ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D</span></a> for completeness. Those results confirm our conclusions from the main text.</p>
</div>
<figure class="ltx_figure" id="A4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="A4.F4.g1" src="x9.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure D: </span>Extended analysis of the attention patching experiment. (right) Patching starts at the beginning of learning (<span class="ltx_text ltx_font_typewriter" id="A4.F4.4.1">start_patching</span> = 0). It is the same figure than Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> (middle). (middle) In this experiment, the attention pattern are frozen, that is <span class="ltx_text ltx_font_typewriter" id="A4.F4.5.2">start_patching</span> = <span class="ltx_text ltx_font_typewriter" id="A4.F4.6.3">reference_patching</span>. (right) Final attribute loss when independently varying the number of steps at which we start patching and the number of steps the reference model was traning.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A4.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">D.2 </span>Details of the attention pattern analysis</h4>
<figure class="ltx_figure" id="A4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="388" id="A4.F5.g1" src="x10.png" width="553"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure E: </span>High-level description of how Transformer-based language models solve associative recall tasks. Figure adapted from <cite class="ltx_cite ltx_citemacro_cite">Nanda et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib33" title="">2023b</a>)</cite>. This model motivates our fine-grained attention pattern analysis (described in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS2" title="D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D.2</span></a>) and is closely related, albeit slightly simplified, to the one of <cite class="ltx_cite ltx_citemacro_cite">Geva et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>)</cite>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS2.p1">
<p class="ltx_p" id="A4.SS2.p1.1">In our analysis, the model‚Äôs attention patterns during learning, we examine which tokens the network attends to when processing or predicting specific tokens. This approach is motivated by prior work (discussed in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS2" title="2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.2</span></a> and visualized in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F5" title="Figure E ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">E</span></a>) that identified specific attention-based circuits for factual recall tasks, each with distinct signatures observable through attention patterns. We focus on the following circuits and their signatures:</p>
<ul class="ltx_itemize" id="A4.I1">
<li class="ltx_item" id="A4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para" id="A4.I1.i1.p1">
<p class="ltx_p" id="A4.I1.i1.p1.3"><span class="ltx_text ltx_font_bold" id="A4.I1.i1.p1.3.2">Name tokens grouping circuit.</span> This circuit, present in the model‚Äôs first layer, groups the embeddings of name tokens to represent the individual‚Äôs full name. This occurs when processing the last name token, leading to high attention on other name tokens in the first layer. Focusing on the last name token is crucial to differentiate this mechanism from others like name completion. The <span class="ltx_text ltx_font_italic" id="A4.I1.i1.p1.1.1">name <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A4.I1.i1.p1.1.1.m1.1"><semantics id="A4.I1.i1.p1.1.1.m1.1a"><mo id="A4.I1.i1.p1.1.1.m1.1.1" stretchy="false" xref="A4.I1.i1.p1.1.1.m1.1.1.cmml">‚Üí</mo><annotation-xml encoding="MathML-Content" id="A4.I1.i1.p1.1.1.m1.1b"><ci id="A4.I1.i1.p1.1.1.m1.1.1.cmml" xref="A4.I1.i1.p1.1.1.m1.1.1">‚Üí</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i1.p1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i1.p1.1.1.m1.1d">‚Üí</annotation></semantics></math> name</span> line in the right panel of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> represents the average attention from the last name token to all other name tokens in the first layer, averaged over name occurrences (typically <math alttext="6" class="ltx_Math" display="inline" id="A4.I1.i1.p1.2.m1.1"><semantics id="A4.I1.i1.p1.2.m1.1a"><mn id="A4.I1.i1.p1.2.m1.1.1" xref="A4.I1.i1.p1.2.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A4.I1.i1.p1.2.m1.1b"><cn id="A4.I1.i1.p1.2.m1.1.1.cmml" type="integer" xref="A4.I1.i1.p1.2.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i1.p1.2.m1.1c">6</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i1.p1.2.m1.1d">6</annotation></semantics></math>, corresponding to the number of attributes), heads, and <math alttext="512" class="ltx_Math" display="inline" id="A4.I1.i1.p1.3.m2.1"><semantics id="A4.I1.i1.p1.3.m2.1a"><mn id="A4.I1.i1.p1.3.m2.1.1" xref="A4.I1.i1.p1.3.m2.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A4.I1.i1.p1.3.m2.1b"><cn id="A4.I1.i1.p1.3.m2.1.1.cmml" type="integer" xref="A4.I1.i1.p1.3.m2.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i1.p1.3.m2.1c">512</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i1.p1.3.m2.1d">512</annotation></semantics></math> input sequences. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F6" title="Figure F ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F</span></a> (left) shows this quantity for all layers.</p>
</div>
</li>
<li class="ltx_item" id="A4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">‚Ä¢</span>
<div class="ltx_para ltx_noindent" id="A4.I1.i2.p1">
<p class="ltx_p" id="A4.I1.i2.p1.2"><span class="ltx_text ltx_font_bold" id="A4.I1.i2.p1.2.3">Extraction circuit.</span> The final attention layer selects and relays relevant information based on the requested attribute type. We expect high attention to name tokens (but not text tokens) when predicting the first attribute value token, once this circuit is established. Again, focusing on the first token is crucial to isolate this from completion mechanisms. The <span class="ltx_text ltx_font_italic" id="A4.I1.i2.p1.1.1">attribute <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A4.I1.i2.p1.1.1.m1.1"><semantics id="A4.I1.i2.p1.1.1.m1.1a"><mo id="A4.I1.i2.p1.1.1.m1.1.1" stretchy="false" xref="A4.I1.i2.p1.1.1.m1.1.1.cmml">‚Üí</mo><annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.1.1.m1.1b"><ci id="A4.I1.i2.p1.1.1.m1.1.1.cmml" xref="A4.I1.i2.p1.1.1.m1.1.1">‚Üí</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i2.p1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i2.p1.1.1.m1.1d">‚Üí</annotation></semantics></math> text</span> and <span class="ltx_text ltx_font_italic" id="A4.I1.i2.p1.2.2">attribute <math alttext="\rightarrow" class="ltx_Math" display="inline" id="A4.I1.i2.p1.2.2.m1.1"><semantics id="A4.I1.i2.p1.2.2.m1.1a"><mo id="A4.I1.i2.p1.2.2.m1.1.1" stretchy="false" xref="A4.I1.i2.p1.2.2.m1.1.1.cmml">‚Üí</mo><annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.2.2.m1.1b"><ci id="A4.I1.i2.p1.2.2.m1.1.1.cmml" xref="A4.I1.i2.p1.2.2.m1.1.1">‚Üí</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i2.p1.2.2.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i2.p1.2.2.m1.1d">‚Üí</annotation></semantics></math> name</span> lines in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> are generated accordingly. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F6" title="Figure F ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F</span></a> (middle left and middle right) shows the layer-wise breakdown of these quantities.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="A4.SS2.p1.2">We do not include the attribute type propagation circuit highlighted in <cite class="ltx_cite ltx_citemacro_cite">Geva et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib18" title="">2023</a>)</cite> in this analysis to keep it simple. That said, the relatively high attention to text tokens in the first attention layers when predicting attribute values is consistent with that circuit.</p>
</div>
<figure class="ltx_figure" id="A4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="A4.F6.g1" src="x11.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure F: </span>Layer-wise analysis of the attention patterns of the model over the course of learning. (left) Attention given to the name tokens when seeing the last name tokens. (middle left) Attention given to the template tokens when predicting the first attribute value token. (middle right) Attention given to the name tokens when predicting the first attribute value token. (right) Sharpness of the attention probability distribution, defined as the entropy of the distribution divided by its mask value (<math alttext="\log t" class="ltx_Math" display="inline" id="A4.F6.3.m1.1"><semantics id="A4.F6.3.m1.1b"><mrow id="A4.F6.3.m1.1.1" xref="A4.F6.3.m1.1.1.cmml"><mi id="A4.F6.3.m1.1.1.1" xref="A4.F6.3.m1.1.1.1.cmml">log</mi><mo id="A4.F6.3.m1.1.1b" lspace="0.167em" xref="A4.F6.3.m1.1.1.cmml">‚Å°</mo><mi id="A4.F6.3.m1.1.1.2" xref="A4.F6.3.m1.1.1.2.cmml">t</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.F6.3.m1.1c"><apply id="A4.F6.3.m1.1.1.cmml" xref="A4.F6.3.m1.1.1"><log id="A4.F6.3.m1.1.1.1.cmml" xref="A4.F6.3.m1.1.1.1"></log><ci id="A4.F6.3.m1.1.1.2.cmml" xref="A4.F6.3.m1.1.1.2">ùë°</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.F6.3.m1.1d">\log t</annotation><annotation encoding="application/x-llamapun" id="A4.F6.3.m1.1e">roman_log italic_t</annotation></semantics></math> with <math alttext="t" class="ltx_Math" display="inline" id="A4.F6.4.m2.1"><semantics id="A4.F6.4.m2.1b"><mi id="A4.F6.4.m2.1.1" xref="A4.F6.4.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="A4.F6.4.m2.1c"><ci id="A4.F6.4.m2.1.1.cmml" xref="A4.F6.4.m2.1.1">ùë°</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.F6.4.m2.1d">t</annotation><annotation encoding="application/x-llamapun" id="A4.F6.4.m2.1e">italic_t</annotation></semantics></math> the index of the current token).</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A4.SS2.p2">
<p class="ltx_p" id="A4.SS2.p2.1">As a separate observation, Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F6" title="Figure F ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F</span></a> (right) reports the evolution of the sharpness of attention patterns in each layer, defined as the normalized entropy of the attention distribution (divided by the logarithm of the number of attendable tokens). Initially uniform, attention patterns become progressively sharper, with a slight increase in sharpness starting around the end of the plateau.</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.SS2.p3">
<p class="ltx_p" id="A4.SS2.p3.1">We conclude this section by discussing the limitations of this analysis. It ignores the impact of the values (e.g., attention patterns do not matter when values are equal to <math alttext="0" class="ltx_Math" display="inline" id="A4.SS2.p3.1.m1.1"><semantics id="A4.SS2.p3.1.m1.1a"><mn id="A4.SS2.p3.1.m1.1.1" xref="A4.SS2.p3.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A4.SS2.p3.1.m1.1b"><cn id="A4.SS2.p3.1.m1.1.1.cmml" type="integer" xref="A4.SS2.p3.1.m1.1.1">0</cn></annotation-xml></semantics></math>), is purely correlational, and relies on simplified mental models of the network‚Äôs internal workings. Nevertheless, it enables refining the conclusions drawn from our attention patching intervention.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A5">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional analysis for the impact of data distribution properties (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3" title="3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a>)</h3>
<section class="ltx_subsection" id="A5.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Learning curves for different data distributions</h4>
<div class="ltx_para ltx_noindent" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.2">We here provide some examples of learning curves when modifying the training distribution. We focus on the <math alttext="8" class="ltx_Math" display="inline" id="A5.SS1.p1.1.m1.1"><semantics id="A5.SS1.p1.1.m1.1a"><mn id="A5.SS1.p1.1.m1.1.1" xref="A5.SS1.p1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.1.m1.1b"><cn id="A5.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A5.SS1.p1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p1.1.m1.1d">8</annotation></semantics></math>k training steps, <math alttext="64" class="ltx_Math" display="inline" id="A5.SS1.p1.2.m2.1"><semantics id="A5.SS1.p1.2.m2.1a"><mn id="A5.SS1.p1.2.m2.1.1" xref="A5.SS1.p1.2.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.2.m2.1b"><cn id="A5.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A5.SS1.p1.2.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.2.m2.1c">64</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p1.2.m2.1d">64</annotation></semantics></math>k individuals regime as it is one in which we observe large differences between distributions.</p>
</div>
<figure class="ltx_figure" id="A5.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="180" id="A5.F7.g1" src="x12.png" width="200"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure G: </span>Learning curves for the inverse power law distribution, obtained for <math alttext="8" class="ltx_Math" display="inline" id="A5.F7.3.m1.1"><semantics id="A5.F7.3.m1.1b"><mn id="A5.F7.3.m1.1.1" xref="A5.F7.3.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.F7.3.m1.1c"><cn id="A5.F7.3.m1.1.1.cmml" type="integer" xref="A5.F7.3.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F7.3.m1.1d">8</annotation><annotation encoding="application/x-llamapun" id="A5.F7.3.m1.1e">8</annotation></semantics></math>k training steps and <math alttext="64" class="ltx_Math" display="inline" id="A5.F7.4.m2.1"><semantics id="A5.F7.4.m2.1b"><mn id="A5.F7.4.m2.1.1" xref="A5.F7.4.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A5.F7.4.m2.1c"><cn id="A5.F7.4.m2.1.1.cmml" type="integer" xref="A5.F7.4.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F7.4.m2.1d">64</annotation><annotation encoding="application/x-llamapun" id="A5.F7.4.m2.1e">64</annotation></semantics></math>k individuals.</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="A5.F8.g1" src="x13.png" width="440"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure H: </span>Learning curves for the celebrities distribution, obtained for <math alttext="8" class="ltx_Math" display="inline" id="A5.F8.5.m1.1"><semantics id="A5.F8.5.m1.1b"><mn id="A5.F8.5.m1.1.1" xref="A5.F8.5.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.F8.5.m1.1c"><cn id="A5.F8.5.m1.1.1.cmml" type="integer" xref="A5.F8.5.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F8.5.m1.1d">8</annotation><annotation encoding="application/x-llamapun" id="A5.F8.5.m1.1e">8</annotation></semantics></math>k training steps and <math alttext="64" class="ltx_Math" display="inline" id="A5.F8.6.m2.1"><semantics id="A5.F8.6.m2.1b"><mn id="A5.F8.6.m2.1.1" xref="A5.F8.6.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A5.F8.6.m2.1c"><cn id="A5.F8.6.m2.1.1.cmml" type="integer" xref="A5.F8.6.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F8.6.m2.1d">64</annotation><annotation encoding="application/x-llamapun" id="A5.F8.6.m2.1e">64</annotation></semantics></math>k individuals. In the left plot, the weight for celebrities is set to <math alttext="8" class="ltx_Math" display="inline" id="A5.F8.7.m3.1"><semantics id="A5.F8.7.m3.1b"><mn id="A5.F8.7.m3.1.1" xref="A5.F8.7.m3.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.F8.7.m3.1c"><cn id="A5.F8.7.m3.1.1.cmml" type="integer" xref="A5.F8.7.m3.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F8.7.m3.1d">8</annotation><annotation encoding="application/x-llamapun" id="A5.F8.7.m3.1e">8</annotation></semantics></math> and in the right plot the number of celebrities is set to <math alttext="4" class="ltx_Math" display="inline" id="A5.F8.8.m4.1"><semantics id="A5.F8.8.m4.1b"><mn id="A5.F8.8.m4.1.1" xref="A5.F8.8.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A5.F8.8.m4.1c"><cn id="A5.F8.8.m4.1.1.cmml" type="integer" xref="A5.F8.8.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F8.8.m4.1d">4</annotation><annotation encoding="application/x-llamapun" id="A5.F8.8.m4.1e">4</annotation></semantics></math>k.</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="180" id="A5.F9.g1" src="x14.png" width="420"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure I: </span>Learning curves for the warm-up distribution, obtained for <math alttext="8" class="ltx_Math" display="inline" id="A5.F9.5.m1.1"><semantics id="A5.F9.5.m1.1b"><mn id="A5.F9.5.m1.1.1" xref="A5.F9.5.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.F9.5.m1.1c"><cn id="A5.F9.5.m1.1.1.cmml" type="integer" xref="A5.F9.5.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F9.5.m1.1d">8</annotation><annotation encoding="application/x-llamapun" id="A5.F9.5.m1.1e">8</annotation></semantics></math>k training steps and <math alttext="64" class="ltx_Math" display="inline" id="A5.F9.6.m2.1"><semantics id="A5.F9.6.m2.1b"><mn id="A5.F9.6.m2.1.1" xref="A5.F9.6.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A5.F9.6.m2.1c"><cn id="A5.F9.6.m2.1.1.cmml" type="integer" xref="A5.F9.6.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F9.6.m2.1d">64</annotation><annotation encoding="application/x-llamapun" id="A5.F9.6.m2.1e">64</annotation></semantics></math>k individuals. In the left plot, the number of warm-up steps is set to <math alttext="1.5" class="ltx_Math" display="inline" id="A5.F9.7.m3.1"><semantics id="A5.F9.7.m3.1b"><mn id="A5.F9.7.m3.1.1" xref="A5.F9.7.m3.1.1.cmml">1.5</mn><annotation-xml encoding="MathML-Content" id="A5.F9.7.m3.1c"><cn id="A5.F9.7.m3.1.1.cmml" type="float" xref="A5.F9.7.m3.1.1">1.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F9.7.m3.1d">1.5</annotation><annotation encoding="application/x-llamapun" id="A5.F9.7.m3.1e">1.5</annotation></semantics></math>k and in the right plot the number of warm-up individuals is set to <math alttext="8" class="ltx_Math" display="inline" id="A5.F9.8.m4.1"><semantics id="A5.F9.8.m4.1b"><mn id="A5.F9.8.m4.1.1" xref="A5.F9.8.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.F9.8.m4.1c"><cn id="A5.F9.8.m4.1.1.cmml" type="integer" xref="A5.F9.8.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F9.8.m4.1d">8</annotation><annotation encoding="application/x-llamapun" id="A5.F9.8.m4.1e">8</annotation></semantics></math>k.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Extensive comparison of the performance of different data distributions</h4>
<div class="ltx_para ltx_noindent" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">In Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a>, we provide a detailed version of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a> (right). We vary the number of training steps and the number of individuals, and report both attribute accuracy and attribute loss. Additionally, we include the celebrities distribution in the comparison. The results stay qualitatively the same as what we reported in the main text.</p>
</div>
<figure class="ltx_figure" id="A5.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="190" id="A5.F10.g1" src="x15.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure J: </span>Extensive comparison of the final performance of the model when trained on different classes of data distribution. For each class, we pick the best data distribution hyperparameter specifying the class. (left and middle left) We vary the total number of individuals, (middle right and right) we vary the number of training steps.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A5.SS2.p2">
<p class="ltx_p" id="A5.SS2.p2.1">It should be noted that we have not tried to optimize the warm-up strategy more than through the hyperparameter grid search reported in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.SS4" title="G.4 Hyperparameters for Section 3 ‚Ä£ Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">G.4</span></a> as it is not the main focus of this paper, and it is possible that even better results could be achieved. For example, we only allow for changing distributions every epoch, with an epoch being defined as seeing all individuals in the training distribution. This implies that for a high number of individuals, tuning is rather coarse. Another potential improvement is to gradually increase the distribution size.</p>
</div>
<div class="ltx_para ltx_noindent" id="A5.SS2.p3">
<p class="ltx_p" id="A5.SS2.p3.7">In Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F11" title="Figure K ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">K</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F12" title="Figure L ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">L</span></a>, we plot the final performance of the model for different hyperparameter choices. In the low training step regime (<math alttext="8" class="ltx_Math" display="inline" id="A5.SS2.p3.1.m1.1"><semantics id="A5.SS2.p3.1.m1.1a"><mn id="A5.SS2.p3.1.m1.1.1" xref="A5.SS2.p3.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.1.m1.1b"><cn id="A5.SS2.p3.1.m1.1.1.cmml" type="integer" xref="A5.SS2.p3.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.1.m1.1d">8</annotation></semantics></math>k steps plot in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F11" title="Figure K ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">K</span></a>), we find the optimal hyperparameter choice to be within our grid search. However, in the large number of individuals scenario, it seems outside our range (cf. <math alttext="128" class="ltx_Math" display="inline" id="A5.SS2.p3.2.m2.1"><semantics id="A5.SS2.p3.2.m2.1a"><mn id="A5.SS2.p3.2.m2.1.1" xref="A5.SS2.p3.2.m2.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.2.m2.1b"><cn id="A5.SS2.p3.2.m2.1.1.cmml" type="integer" xref="A5.SS2.p3.2.m2.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.2.m2.1c">128</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.2.m2.1d">128</annotation></semantics></math>k individuals plot of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F12" title="Figure L ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">L</span></a>) and in particular suggests long warmup phase with a high number of individuals. This leads us to wonder whether the benefits we observe from the warming-up could be achieved by just training on less individuals. To that extent, we run an additional run with a uniform distribution on the individual, with a population size of <math alttext="83" class="ltx_Math" display="inline" id="A5.SS2.p3.3.m3.1"><semantics id="A5.SS2.p3.3.m3.1a"><mn id="A5.SS2.p3.3.m3.1.1" xref="A5.SS2.p3.3.m3.1.1.cmml">83</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.3.m3.1b"><cn id="A5.SS2.p3.3.m3.1.1.cmml" type="integer" xref="A5.SS2.p3.3.m3.1.1">83</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.3.m3.1c">83</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.3.m3.1d">83</annotation></semantics></math>k individuals. The model reaches an attribute accuracy of <math alttext="97.72" class="ltx_Math" display="inline" id="A5.SS2.p3.4.m4.1"><semantics id="A5.SS2.p3.4.m4.1a"><mn id="A5.SS2.p3.4.m4.1.1" xref="A5.SS2.p3.4.m4.1.1.cmml">97.72</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.4.m4.1b"><cn id="A5.SS2.p3.4.m4.1.1.cmml" type="float" xref="A5.SS2.p3.4.m4.1.1">97.72</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.4.m4.1c">97.72</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.4.m4.1d">97.72</annotation></semantics></math>%, which would become <math alttext="63.26" class="ltx_Math" display="inline" id="A5.SS2.p3.5.m5.1"><semantics id="A5.SS2.p3.5.m5.1a"><mn id="A5.SS2.p3.5.m5.1.1" xref="A5.SS2.p3.5.m5.1.1.cmml">63.26</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.5.m5.1b"><cn id="A5.SS2.p3.5.m5.1.1.cmml" type="float" xref="A5.SS2.p3.5.m5.1.1">63.26</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.5.m5.1c">63.26</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.5.m5.1d">63.26</annotation></semantics></math>% when evaluating on <math alttext="128" class="ltx_Math" display="inline" id="A5.SS2.p3.6.m6.1"><semantics id="A5.SS2.p3.6.m6.1a"><mn id="A5.SS2.p3.6.m6.1.1" xref="A5.SS2.p3.6.m6.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.6.m6.1b"><cn id="A5.SS2.p3.6.m6.1.1.cmml" type="integer" xref="A5.SS2.p3.6.m6.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.6.m6.1c">128</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.6.m6.1d">128</annotation></semantics></math>k individuals. On the other side, the model trained with warm-ups reaches <math alttext="94.92" class="ltx_Math" display="inline" id="A5.SS2.p3.7.m7.1"><semantics id="A5.SS2.p3.7.m7.1a"><mn id="A5.SS2.p3.7.m7.1.1" xref="A5.SS2.p3.7.m7.1.1.cmml">94.92</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.7.m7.1b"><cn id="A5.SS2.p3.7.m7.1.1.cmml" type="float" xref="A5.SS2.p3.7.m7.1.1">94.92</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.7.m7.1c">94.92</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.7.m7.1d">94.92</annotation></semantics></math>% accuracy. This refinement of our results strengthens our confidence in the benefits of warm-ups, particularly as we have not optimized the strategy beyond a relatively small hyperparameter grid search.</p>
</div>
<figure class="ltx_figure" id="A5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A5.F11.g1" src="x16.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure K: </span>Visualization of how final performance evolves as the hyperparameters of the warm-up distribution are changed. The total number of individuals is fixed to <math alttext="64" class="ltx_Math" display="inline" id="A5.F11.2.m1.1"><semantics id="A5.F11.2.m1.1b"><mn id="A5.F11.2.m1.1.1" xref="A5.F11.2.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A5.F11.2.m1.1c"><cn id="A5.F11.2.m1.1.1.cmml" type="integer" xref="A5.F11.2.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F11.2.m1.1d">64</annotation><annotation encoding="application/x-llamapun" id="A5.F11.2.m1.1e">64</annotation></semantics></math>k and these plots correspond to Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a> (middle right and right).</figcaption>
</figure>
<figure class="ltx_figure" id="A5.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="340" id="A5.F12.g1" src="x17.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure L: </span>Visualization of how final performance evolve as the hyperparameters of the warm-up distribution are changed. The total number of steps is fixed to <math alttext="16" class="ltx_Math" display="inline" id="A5.F12.2.m1.1"><semantics id="A5.F12.2.m1.1b"><mn id="A5.F12.2.m1.1.1" xref="A5.F12.2.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A5.F12.2.m1.1c"><cn id="A5.F12.2.m1.1.1.cmml" type="integer" xref="A5.F12.2.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.F12.2.m1.1d">16</annotation><annotation encoding="application/x-llamapun" id="A5.F12.2.m1.1e">16</annotation></semantics></math>k and these plots correspond to Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a> (left and middle left).</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Details of the fine-tuning analysis and additional experiments (Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>)</h3>
<section class="ltx_subsection" id="A6.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.1 </span>Experimental details</h4>
<div class="ltx_para ltx_noindent" id="A6.SS1.p1">
<p class="ltx_p" id="A6.SS1.p1.5">In our fine-tuning experiments, we generate <span class="ltx_text ltx_font_typewriter" id="A6.SS1.p1.5.1">n_individuals_finetune</span> new individuals and use their biographies for fine-tuning. By default, we use fine-tune a model trained for <math alttext="16" class="ltx_Math" display="inline" id="A6.SS1.p1.1.m1.1"><semantics id="A6.SS1.p1.1.m1.1a"><mn id="A6.SS1.p1.1.m1.1.1" xref="A6.SS1.p1.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.1.m1.1b"><cn id="A6.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A6.SS1.p1.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.1.m1.1d">16</annotation></semantics></math>k steps on <math alttext="64" class="ltx_Math" display="inline" id="A6.SS1.p1.2.m2.1"><semantics id="A6.SS1.p1.2.m2.1a"><mn id="A6.SS1.p1.2.m2.1.1" xref="A6.SS1.p1.2.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.2.m2.1b"><cn id="A6.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A6.SS1.p1.2.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.2.m2.1c">64</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.2.m2.1d">64</annotation></semantics></math>k individuals, with individuals sampled uniformly (i.e., the default parameters in Table¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A7.T1" title="Table 1 ‚Ä£ G.1 Default configuration ‚Ä£ Appendix G Hyperparameter configurations ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">1</span></a>). In the experiments with replay, we use sampling according to the ‚Äúcelebrities‚Äù distribution described in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.SS2" title="B.2 Details about the biography generation process ‚Ä£ Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">B.2</span></a>, using a weight of <span class="ltx_text ltx_font_typewriter" id="A6.SS1.p1.5.2">weight_replay_finetune</span> for the <math alttext="64" class="ltx_Math" display="inline" id="A6.SS1.p1.3.m3.1"><semantics id="A6.SS1.p1.3.m3.1a"><mn id="A6.SS1.p1.3.m3.1.1" xref="A6.SS1.p1.3.m3.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.3.m3.1b"><cn id="A6.SS1.p1.3.m3.1.1.cmml" type="integer" xref="A6.SS1.p1.3.m3.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.3.m3.1c">64</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.3.m3.1d">64</annotation></semantics></math>k pre-training individuals, and a weight of <math alttext="1" class="ltx_Math" display="inline" id="A6.SS1.p1.4.m4.1"><semantics id="A6.SS1.p1.4.m4.1a"><mn id="A6.SS1.p1.4.m4.1.1" xref="A6.SS1.p1.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.4.m4.1b"><cn id="A6.SS1.p1.4.m4.1.1.cmml" type="integer" xref="A6.SS1.p1.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.4.m4.1c">1</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.4.m4.1d">1</annotation></semantics></math> for the fine-tuning individuals. We use a constant learning rate of <math alttext="3\cdot 10^{-5}" class="ltx_Math" display="inline" id="A6.SS1.p1.5.m5.1"><semantics id="A6.SS1.p1.5.m5.1a"><mrow id="A6.SS1.p1.5.m5.1.1" xref="A6.SS1.p1.5.m5.1.1.cmml"><mn id="A6.SS1.p1.5.m5.1.1.2" xref="A6.SS1.p1.5.m5.1.1.2.cmml">3</mn><mo id="A6.SS1.p1.5.m5.1.1.1" lspace="0.222em" rspace="0.222em" xref="A6.SS1.p1.5.m5.1.1.1.cmml">‚ãÖ</mo><msup id="A6.SS1.p1.5.m5.1.1.3" xref="A6.SS1.p1.5.m5.1.1.3.cmml"><mn id="A6.SS1.p1.5.m5.1.1.3.2" xref="A6.SS1.p1.5.m5.1.1.3.2.cmml">10</mn><mrow id="A6.SS1.p1.5.m5.1.1.3.3" xref="A6.SS1.p1.5.m5.1.1.3.3.cmml"><mo id="A6.SS1.p1.5.m5.1.1.3.3a" xref="A6.SS1.p1.5.m5.1.1.3.3.cmml">‚àí</mo><mn id="A6.SS1.p1.5.m5.1.1.3.3.2" xref="A6.SS1.p1.5.m5.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.5.m5.1b"><apply id="A6.SS1.p1.5.m5.1.1.cmml" xref="A6.SS1.p1.5.m5.1.1"><ci id="A6.SS1.p1.5.m5.1.1.1.cmml" xref="A6.SS1.p1.5.m5.1.1.1">‚ãÖ</ci><cn id="A6.SS1.p1.5.m5.1.1.2.cmml" type="integer" xref="A6.SS1.p1.5.m5.1.1.2">3</cn><apply id="A6.SS1.p1.5.m5.1.1.3.cmml" xref="A6.SS1.p1.5.m5.1.1.3"><csymbol cd="ambiguous" id="A6.SS1.p1.5.m5.1.1.3.1.cmml" xref="A6.SS1.p1.5.m5.1.1.3">superscript</csymbol><cn id="A6.SS1.p1.5.m5.1.1.3.2.cmml" type="integer" xref="A6.SS1.p1.5.m5.1.1.3.2">10</cn><apply id="A6.SS1.p1.5.m5.1.1.3.3.cmml" xref="A6.SS1.p1.5.m5.1.1.3.3"><minus id="A6.SS1.p1.5.m5.1.1.3.3.1.cmml" xref="A6.SS1.p1.5.m5.1.1.3.3"></minus><cn id="A6.SS1.p1.5.m5.1.1.3.3.2.cmml" type="integer" xref="A6.SS1.p1.5.m5.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.5.m5.1c">3\cdot 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.5.m5.1d">3 ‚ãÖ 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math> for fine-tuning, the rest of the optimizer staying at it is during pre-training.</p>
</div>
</section>
<section class="ltx_subsection" id="A6.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.2 </span>Hallucinations</h4>
<div class="ltx_para ltx_noindent" id="A6.SS2.p1">
<p class="ltx_p" id="A6.SS2.p1.1">As briefly mentioned in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>, our framework offers a simple way to monitor fact-conflicting hallucinations (as defined in <cite class="ltx_cite ltx_citemacro_cite">Zhang et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib51" title="">2023</a>)</cite>) during training. These hallucinations are characterized by overconfidence in predicting facts absent (or rare) from the training data. To assess this, we evaluate the model on held-out individuals not present in the training distribution. A hallucinating model would predict incorrect attribute values with high confidence. For these held-out individuals, the attribute loss must exceed the no knowledge baseline, with higher values indicating overconfidence (i.e., hallucinations). Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F13" title="Figure M ‚Ä£ F.2 Hallucinations ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">M</span></a> shows that hallucinations appear shortly after the plateau phase. However, the model remains less confident in these hallucinations than in its grounded predictions for seen individuals (see middle right and right panels). The higher probability mass on the most likely prediction and lower entropy of the predictive distribution for seen individuals suggest that hallucinations can be detected to some extent. We found these observations to be robust to change in the input distribution. For example, progressively increasing the population size did not significantly affect these metrics.</p>
</div>
<figure class="ltx_figure" id="A6.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="160" id="A6.F13.g1" src="x18.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure M: </span>The model starts hallucinating during training. The blue line corresponds to the model performance on seen individuals (as elsewhere in the paper) and the purple one to its performance on <math alttext="16" class="ltx_Math" display="inline" id="A6.F13.2.m1.1"><semantics id="A6.F13.2.m1.1b"><mn id="A6.F13.2.m1.1.1" xref="A6.F13.2.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.F13.2.m1.1c"><cn id="A6.F13.2.m1.1.1.cmml" type="integer" xref="A6.F13.2.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F13.2.m1.1d">16</annotation><annotation encoding="application/x-llamapun" id="A6.F13.2.m1.1e">16</annotation></semantics></math>k held-out individuals. (left) attribute loss, (middle left) knowledge accuracy, (middle right) average probability of the most likely predicted token (for attribute values), and (right) average entropy of the predictive distribution (for attribute values). Overall, the model is less confident in its hallucinations than in grounded predictions.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS2.p2">
<p class="ltx_p" id="A6.SS2.p2.1">This experiment is only a preliminary exploration of hallucinations within our setup. Future work could, for example, investigate how the confidence gap evolves when increasing the number of individuals. For instance, if we consider the network‚Äôs associative memory to be a linear key-value database, increasing the number of individuals while holding the number of hidden neurons constant would bring key representations (individual names) closer, making it harder to distinguish unseen keys, thereby reducing the confidence gap and increasing hallucinations. Understanding which training individuals indirectly inform predictions for unseen individuals and what is the underlying similarity metric is another intriguing direction. Finally, on the more practical side, this framework could serve as a test-bed for methods aiming at detecting or mitigating hallucinations, as successful general-purpose methods should also be performing well in this simplified setting. We leave these investigations to future work.</p>
</div>
</section>
<section class="ltx_subsection" id="A6.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.3 </span>Additional analysis for fine-tuning</h4>
<div class="ltx_para ltx_noindent" id="A6.SS3.p1">
<p class="ltx_p" id="A6.SS3.p1.1">In the main text, we have presented results for two sets of fine-tuning experiments, one with replay and one without replay. In Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a>, we have reported fine-tuning dynamics in a fine-tuning loss vs. pre-training loss reference frame. We here visualize the evolution of the model performance as a function of time. Importantly, these plots make it easier to remark that the drop in model performance on pre-training data occurs very early during fine-tuning (on the order of a hundred steps), and that the increase in performance on fine-tuning data is happening on a longer time-scale (see Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F14" title="Figure N ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">N</span></a>). Additionally, the accuracy plots show that the increase in loss to values close to no-knowledge baseline does not necessarily mean that all pre-training knowledge is erased as some knowledge (i.e. non-zero accuracy) about the pre-training data remains.</p>
</div>
<figure class="ltx_figure" id="A6.F14">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="200" id="A6.F14.g1" src="x19.png" width="650"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="200" id="A6.F14.g2" src="x20.png" width="650"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure N: </span>Evolution of the performance of the model on the pre-training distribution (left and middle left panels) and on the fine-tuning distribution (middle right and right panels), as fine-tuning progresses. In the first row, there is no replay of the pre-training data during fine-tuning and we vary the number of fine-tuning individuals. In the second row, obtained for <math alttext="4" class="ltx_Math" display="inline" id="A6.F14.2.m1.1"><semantics id="A6.F14.2.m1.1b"><mn id="A6.F14.2.m1.1.1" xref="A6.F14.2.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A6.F14.2.m1.1c"><cn id="A6.F14.2.m1.1.1.cmml" type="integer" xref="A6.F14.2.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F14.2.m1.1d">4</annotation><annotation encoding="application/x-llamapun" id="A6.F14.2.m1.1e">4</annotation></semantics></math>k fine-tuning individuals, we introduce some replay whose weight we vary (the weight corresponds to how much bigger the probability of sampling a pre-training individual is compared to one in the fine-tuning set). The data presented here is the same as the one in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a> (middle and right panels), but here plotted as a function of time and including accuracy.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS3.p2">
<p class="ltx_p" id="A6.SS3.p2.1">In Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F15" title="Figure O ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">O</span></a>, we provide the evolution of (some of) the attention scores for one of the fine-tuning experiment with no replay (<math alttext="4" class="ltx_Math" display="inline" id="A6.SS3.p2.1.m1.1"><semantics id="A6.SS3.p2.1.m1.1a"><mn id="A6.SS3.p2.1.m1.1.1" xref="A6.SS3.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p2.1.m1.1b"><cn id="A6.SS3.p2.1.m1.1.1.cmml" type="integer" xref="A6.SS3.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p2.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p2.1.m1.1d">4</annotation></semantics></math>k individuals), focusing on the metrics that we have introduced in Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS2" title="D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D.2</span></a> as they are most relevant to our analysis. We find attention scores to be particularly stable, which enables us to conclude that the performance drop during fine-tuning is not strongly linked to changes in attention patterns.</p>
</div>
<figure class="ltx_figure" id="A6.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="A6.F15.g1" src="x21.png" width="625"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure O: </span>The attention patterns remain remarkably relatively during fine-tuning. We here report the following metrics: (left) attention to name tokens when seeing the last name token, (middle left) attention to general text tokens when predicting the first attribute value token, (middle right) attention to the last name token when predicting the first attribute value token, (right) (normalized) entropy of the probability distribution defined by attention scores. The attention patterns analyzed here were obtained on the pre-training distribution; performing the same analysis on the fine-tuning distribution (not reported here) barely changes observed behaviors. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS2" title="D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D.2</span></a> for the rationale behind the choice of metrics.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS3.p3">
<p class="ltx_p" id="A6.SS3.p3.7">We complement our analysis with an experiment in which we fine-tune the model on rare, but seen during pre-training, individuals. We do so using our celebrities distribution, setting the total number of individuals to <math alttext="128" class="ltx_Math" display="inline" id="A6.SS3.p3.1.m1.1"><semantics id="A6.SS3.p3.1.m1.1a"><mn id="A6.SS3.p3.1.m1.1.1" xref="A6.SS3.p3.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.1.m1.1b"><cn id="A6.SS3.p3.1.m1.1.1.cmml" type="integer" xref="A6.SS3.p3.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.1.m1.1c">128</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.1.m1.1d">128</annotation></semantics></math>k, <span class="ltx_text ltx_font_typewriter" id="A6.SS3.p3.7.1">n_celebrities</span> to <math alttext="8" class="ltx_Math" display="inline" id="A6.SS3.p3.2.m2.1"><semantics id="A6.SS3.p3.2.m2.1a"><mn id="A6.SS3.p3.2.m2.1.1" xref="A6.SS3.p3.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.2.m2.1b"><cn id="A6.SS3.p3.2.m2.1.1.cmml" type="integer" xref="A6.SS3.p3.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.2.m2.1c">8</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.2.m2.1d">8</annotation></semantics></math>k and <span class="ltx_text ltx_font_typewriter" id="A6.SS3.p3.7.2">weight_celebrities</span> to 8. After training on <math alttext="16" class="ltx_Math" display="inline" id="A6.SS3.p3.3.m3.1"><semantics id="A6.SS3.p3.3.m3.1a"><mn id="A6.SS3.p3.3.m3.1.1" xref="A6.SS3.p3.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.3.m3.1b"><cn id="A6.SS3.p3.3.m3.1.1.cmml" type="integer" xref="A6.SS3.p3.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.3.m3.1c">16</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.3.m3.1d">16</annotation></semantics></math>k training steps, the model confidently and correctly predicts the attribute value of the celebrities but gets around <math alttext="50" class="ltx_Math" display="inline" id="A6.SS3.p3.4.m4.1"><semantics id="A6.SS3.p3.4.m4.1a"><mn id="A6.SS3.p3.4.m4.1.1" xref="A6.SS3.p3.4.m4.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.4.m4.1b"><cn id="A6.SS3.p3.4.m4.1.1.cmml" type="integer" xref="A6.SS3.p3.4.m4.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.4.m4.1c">50</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.4.m4.1d">50</annotation></semantics></math>% accuracy on non-celebrities, which are the majority of the population. Overall, we find that fine-tuning on existing individuals does not lead to fast performance drop fine-tuning on new individuals has (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F16" title="Figure P ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">P</span></a>). We are able to add a significant amount of knowledge in the model‚Äôs weights, as the accuracy on the <math alttext="120" class="ltx_Math" display="inline" id="A6.SS3.p3.5.m5.1"><semantics id="A6.SS3.p3.5.m5.1a"><mn id="A6.SS3.p3.5.m5.1.1" xref="A6.SS3.p3.5.m5.1.1.cmml">120</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.5.m5.1b"><cn id="A6.SS3.p3.5.m5.1.1.cmml" type="integer" xref="A6.SS3.p3.5.m5.1.1">120</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.5.m5.1c">120</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.5.m5.1d">120</annotation></semantics></math>k non-celebrities goes from <math alttext="50" class="ltx_Math" display="inline" id="A6.SS3.p3.6.m6.1"><semantics id="A6.SS3.p3.6.m6.1a"><mn id="A6.SS3.p3.6.m6.1.1" xref="A6.SS3.p3.6.m6.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.6.m6.1b"><cn id="A6.SS3.p3.6.m6.1.1.cmml" type="integer" xref="A6.SS3.p3.6.m6.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.6.m6.1c">50</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.6.m6.1d">50</annotation></semantics></math>% to close to <math alttext="70" class="ltx_Math" display="inline" id="A6.SS3.p3.7.m7.1"><semantics id="A6.SS3.p3.7.m7.1a"><mn id="A6.SS3.p3.7.m7.1.1" xref="A6.SS3.p3.7.m7.1.1.cmml">70</mn><annotation-xml encoding="MathML-Content" id="A6.SS3.p3.7.m7.1b"><cn id="A6.SS3.p3.7.m7.1.1.cmml" type="integer" xref="A6.SS3.p3.7.m7.1.1">70</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS3.p3.7.m7.1c">70</annotation><annotation encoding="application/x-llamapun" id="A6.SS3.p3.7.m7.1d">70</annotation></semantics></math>%. These results supporting that fine-tuning on existing individuals is net-positive are confirmed by our alternating training distribution experiment of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F22" title="Figure V ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
<figure class="ltx_figure" id="A6.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="160" id="A6.F16.g1" src="x22.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure P: </span>Evolution of the model‚Äôs performance when fine-tuned on rare (FT on non-celebrities line) or frequent (FT on celebrities line) individuals from the pre-training distribution. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS3" title="F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.3</span></a> for more detail.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A6.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.4 </span>Reproducing fine-tuning behavior on a toy associative memory problem</h4>
<div class="ltx_para ltx_noindent" id="A6.SS4.p1">
<p class="ltx_p" id="A6.SS4.p1.1">In this section, we investigate whether the fine-tuning behavior observed in our language model experiments can be attributed to changes in their feed-forward associative memories. To this end, we train a single-hidden-layer multi-layer perceptron on a synthetic heterogeneous associative recall task, analogous to retrieving attribute values (e.g., university, major) given an individual‚Äôs name.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS4.p2">
<p class="ltx_p" id="A6.SS4.p2.8">Our network has <math alttext="256" class="ltx_Math" display="inline" id="A6.SS4.p2.1.m1.1"><semantics id="A6.SS4.p2.1.m1.1a"><mn id="A6.SS4.p2.1.m1.1.1" xref="A6.SS4.p2.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.1.m1.1b"><cn id="A6.SS4.p2.1.m1.1.1.cmml" type="integer" xref="A6.SS4.p2.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.1.m1.1c">256</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.1.m1.1d">256</annotation></semantics></math> hidden neurons with ReLU activation. Both keys (names) and values (attributes) are represented by <math alttext="64" class="ltx_Math" display="inline" id="A6.SS4.p2.2.m2.1"><semantics id="A6.SS4.p2.2.m2.1a"><mn id="A6.SS4.p2.2.m2.1.1" xref="A6.SS4.p2.2.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.2.m2.1b"><cn id="A6.SS4.p2.2.m2.1.1.cmml" type="integer" xref="A6.SS4.p2.2.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.2.m2.1c">64</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.2.m2.1d">64</annotation></semantics></math>-dimensional random embeddings drawn from a normal distribution and then projected to the L2 unit sphere. The model learns to map keys to one of <math alttext="30" class="ltx_Math" display="inline" id="A6.SS4.p2.3.m3.1"><semantics id="A6.SS4.p2.3.m3.1a"><mn id="A6.SS4.p2.3.m3.1.1" xref="A6.SS4.p2.3.m3.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.3.m3.1b"><cn id="A6.SS4.p2.3.m3.1.1.cmml" type="integer" xref="A6.SS4.p2.3.m3.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.3.m3.1c">30</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.3.m3.1d">30</annotation></semantics></math> possible values, effectively performing <math alttext="30" class="ltx_Math" display="inline" id="A6.SS4.p2.4.m4.1"><semantics id="A6.SS4.p2.4.m4.1a"><mn id="A6.SS4.p2.4.m4.1.1" xref="A6.SS4.p2.4.m4.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.4.m4.1b"><cn id="A6.SS4.p2.4.m4.1.1.cmml" type="integer" xref="A6.SS4.p2.4.m4.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.4.m4.1c">30</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.4.m4.1d">30</annotation></semantics></math>-way classification. It is learned with
the cross-entropy loss and the AdamW optimizer with a cosine learning rate schedule (initial learning rate <math alttext="0.03" class="ltx_Math" display="inline" id="A6.SS4.p2.5.m5.1"><semantics id="A6.SS4.p2.5.m5.1a"><mn id="A6.SS4.p2.5.m5.1.1" xref="A6.SS4.p2.5.m5.1.1.cmml">0.03</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.5.m5.1b"><cn id="A6.SS4.p2.5.m5.1.1.cmml" type="float" xref="A6.SS4.p2.5.m5.1.1">0.03</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.5.m5.1c">0.03</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.5.m5.1d">0.03</annotation></semantics></math>, <math alttext="16k" class="ltx_Math" display="inline" id="A6.SS4.p2.6.m6.1"><semantics id="A6.SS4.p2.6.m6.1a"><mrow id="A6.SS4.p2.6.m6.1.1" xref="A6.SS4.p2.6.m6.1.1.cmml"><mn id="A6.SS4.p2.6.m6.1.1.2" xref="A6.SS4.p2.6.m6.1.1.2.cmml">16</mn><mo id="A6.SS4.p2.6.m6.1.1.1" xref="A6.SS4.p2.6.m6.1.1.1.cmml">‚Å¢</mo><mi id="A6.SS4.p2.6.m6.1.1.3" xref="A6.SS4.p2.6.m6.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.6.m6.1b"><apply id="A6.SS4.p2.6.m6.1.1.cmml" xref="A6.SS4.p2.6.m6.1.1"><times id="A6.SS4.p2.6.m6.1.1.1.cmml" xref="A6.SS4.p2.6.m6.1.1.1"></times><cn id="A6.SS4.p2.6.m6.1.1.2.cmml" type="integer" xref="A6.SS4.p2.6.m6.1.1.2">16</cn><ci id="A6.SS4.p2.6.m6.1.1.3.cmml" xref="A6.SS4.p2.6.m6.1.1.3">ùëò</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.6.m6.1c">16k</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.6.m6.1d">16 italic_k</annotation></semantics></math> steps, batch size <math alttext="128" class="ltx_Math" display="inline" id="A6.SS4.p2.7.m7.1"><semantics id="A6.SS4.p2.7.m7.1a"><mn id="A6.SS4.p2.7.m7.1.1" xref="A6.SS4.p2.7.m7.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.7.m7.1b"><cn id="A6.SS4.p2.7.m7.1.1.cmml" type="integer" xref="A6.SS4.p2.7.m7.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.7.m7.1c">128</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.7.m7.1d">128</annotation></semantics></math>, weight decay <math alttext="0.01" class="ltx_Math" display="inline" id="A6.SS4.p2.8.m8.1"><semantics id="A6.SS4.p2.8.m8.1a"><mn id="A6.SS4.p2.8.m8.1.1" xref="A6.SS4.p2.8.m8.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p2.8.m8.1b"><cn id="A6.SS4.p2.8.m8.1.1.cmml" type="float" xref="A6.SS4.p2.8.m8.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p2.8.m8.1c">0.01</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p2.8.m8.1d">0.01</annotation></semantics></math>).</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS4.p3">
<p class="ltx_p" id="A6.SS4.p3.9">We pre-train the model on <math alttext="8192" class="ltx_Math" display="inline" id="A6.SS4.p3.1.m1.1"><semantics id="A6.SS4.p3.1.m1.1a"><mn id="A6.SS4.p3.1.m1.1.1" xref="A6.SS4.p3.1.m1.1.1.cmml">8192</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.1.m1.1b"><cn id="A6.SS4.p3.1.m1.1.1.cmml" type="integer" xref="A6.SS4.p3.1.m1.1.1">8192</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.1.m1.1c">8192</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.1.m1.1d">8192</annotation></semantics></math> key-value pairs and then fine-tune it with a constant learning rate of <math alttext="0.001" class="ltx_Math" display="inline" id="A6.SS4.p3.2.m2.1"><semantics id="A6.SS4.p3.2.m2.1a"><mn id="A6.SS4.p3.2.m2.1.1" xref="A6.SS4.p3.2.m2.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.2.m2.1b"><cn id="A6.SS4.p3.2.m2.1.1.cmml" type="float" xref="A6.SS4.p3.2.m2.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.2.m2.1c">0.001</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.2.m2.1d">0.001</annotation></semantics></math> for <math alttext="4000" class="ltx_Math" display="inline" id="A6.SS4.p3.3.m3.1"><semantics id="A6.SS4.p3.3.m3.1a"><mn id="A6.SS4.p3.3.m3.1.1" xref="A6.SS4.p3.3.m3.1.1.cmml">4000</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.3.m3.1b"><cn id="A6.SS4.p3.3.m3.1.1.cmml" type="integer" xref="A6.SS4.p3.3.m3.1.1">4000</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.3.m3.1c">4000</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.3.m3.1d">4000</annotation></semantics></math> steps. Fine-tuning incorporates a variable number of new key-value pairs and optionally includes replay of pre-training data. The replay weight controls the relative sampling probability of pre-training versus fine-tuning examples (e.g., a weight of <math alttext="2" class="ltx_Math" display="inline" id="A6.SS4.p3.4.m4.1"><semantics id="A6.SS4.p3.4.m4.1a"><mn id="A6.SS4.p3.4.m4.1.1" xref="A6.SS4.p3.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.4.m4.1b"><cn id="A6.SS4.p3.4.m4.1.1.cmml" type="integer" xref="A6.SS4.p3.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.4.m4.1c">2</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.4.m4.1d">2</annotation></semantics></math> with <math alttext="2" class="ltx_Math" display="inline" id="A6.SS4.p3.5.m5.1"><semantics id="A6.SS4.p3.5.m5.1a"><mn id="A6.SS4.p3.5.m5.1.1" xref="A6.SS4.p3.5.m5.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.5.m5.1b"><cn id="A6.SS4.p3.5.m5.1.1.cmml" type="integer" xref="A6.SS4.p3.5.m5.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.5.m5.1c">2</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.5.m5.1d">2</annotation></semantics></math> pre-training and <math alttext="1" class="ltx_Math" display="inline" id="A6.SS4.p3.6.m6.1"><semantics id="A6.SS4.p3.6.m6.1a"><mn id="A6.SS4.p3.6.m6.1.1" xref="A6.SS4.p3.6.m6.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.6.m6.1b"><cn id="A6.SS4.p3.6.m6.1.1.cmml" type="integer" xref="A6.SS4.p3.6.m6.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.6.m6.1c">1</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.6.m6.1d">1</annotation></semantics></math> fine-tuning examples results in sampling probabilities of <math alttext="2/5" class="ltx_Math" display="inline" id="A6.SS4.p3.7.m7.1"><semantics id="A6.SS4.p3.7.m7.1a"><mrow id="A6.SS4.p3.7.m7.1.1" xref="A6.SS4.p3.7.m7.1.1.cmml"><mn id="A6.SS4.p3.7.m7.1.1.2" xref="A6.SS4.p3.7.m7.1.1.2.cmml">2</mn><mo id="A6.SS4.p3.7.m7.1.1.1" xref="A6.SS4.p3.7.m7.1.1.1.cmml">/</mo><mn id="A6.SS4.p3.7.m7.1.1.3" xref="A6.SS4.p3.7.m7.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.7.m7.1b"><apply id="A6.SS4.p3.7.m7.1.1.cmml" xref="A6.SS4.p3.7.m7.1.1"><divide id="A6.SS4.p3.7.m7.1.1.1.cmml" xref="A6.SS4.p3.7.m7.1.1.1"></divide><cn id="A6.SS4.p3.7.m7.1.1.2.cmml" type="integer" xref="A6.SS4.p3.7.m7.1.1.2">2</cn><cn id="A6.SS4.p3.7.m7.1.1.3.cmml" type="integer" xref="A6.SS4.p3.7.m7.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.7.m7.1c">2/5</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.7.m7.1d">2 / 5</annotation></semantics></math>, <math alttext="2/5" class="ltx_Math" display="inline" id="A6.SS4.p3.8.m8.1"><semantics id="A6.SS4.p3.8.m8.1a"><mrow id="A6.SS4.p3.8.m8.1.1" xref="A6.SS4.p3.8.m8.1.1.cmml"><mn id="A6.SS4.p3.8.m8.1.1.2" xref="A6.SS4.p3.8.m8.1.1.2.cmml">2</mn><mo id="A6.SS4.p3.8.m8.1.1.1" xref="A6.SS4.p3.8.m8.1.1.1.cmml">/</mo><mn id="A6.SS4.p3.8.m8.1.1.3" xref="A6.SS4.p3.8.m8.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.8.m8.1b"><apply id="A6.SS4.p3.8.m8.1.1.cmml" xref="A6.SS4.p3.8.m8.1.1"><divide id="A6.SS4.p3.8.m8.1.1.1.cmml" xref="A6.SS4.p3.8.m8.1.1.1"></divide><cn id="A6.SS4.p3.8.m8.1.1.2.cmml" type="integer" xref="A6.SS4.p3.8.m8.1.1.2">2</cn><cn id="A6.SS4.p3.8.m8.1.1.3.cmml" type="integer" xref="A6.SS4.p3.8.m8.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.8.m8.1c">2/5</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.8.m8.1d">2 / 5</annotation></semantics></math>, and <math alttext="1/5" class="ltx_Math" display="inline" id="A6.SS4.p3.9.m9.1"><semantics id="A6.SS4.p3.9.m9.1a"><mrow id="A6.SS4.p3.9.m9.1.1" xref="A6.SS4.p3.9.m9.1.1.cmml"><mn id="A6.SS4.p3.9.m9.1.1.2" xref="A6.SS4.p3.9.m9.1.1.2.cmml">1</mn><mo id="A6.SS4.p3.9.m9.1.1.1" xref="A6.SS4.p3.9.m9.1.1.1.cmml">/</mo><mn id="A6.SS4.p3.9.m9.1.1.3" xref="A6.SS4.p3.9.m9.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS4.p3.9.m9.1b"><apply id="A6.SS4.p3.9.m9.1.1.cmml" xref="A6.SS4.p3.9.m9.1.1"><divide id="A6.SS4.p3.9.m9.1.1.1.cmml" xref="A6.SS4.p3.9.m9.1.1.1"></divide><cn id="A6.SS4.p3.9.m9.1.1.2.cmml" type="integer" xref="A6.SS4.p3.9.m9.1.1.2">1</cn><cn id="A6.SS4.p3.9.m9.1.1.3.cmml" type="integer" xref="A6.SS4.p3.9.m9.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS4.p3.9.m9.1c">1/5</annotation><annotation encoding="application/x-llamapun" id="A6.SS4.p3.9.m9.1d">1 / 5</annotation></semantics></math>).</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.SS4.p4">
<p class="ltx_p" id="A6.SS4.p4.1">Mirroring Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>, we conduct two experiments:</p>
<ol class="ltx_enumerate" id="A6.I1">
<li class="ltx_item" id="A6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A6.I1.i1.p1">
<p class="ltx_p" id="A6.I1.i1.p1.1">Fine-tuning without replay, while varying the number of new samples (left panel of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F17" title="Figure Q ‚Ä£ F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">Q</span></a>, top row of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F18" title="Figure R ‚Ä£ F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">R</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="A6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="A6.I1.i2.p1">
<p class="ltx_p" id="A6.I1.i2.p1.1">Fine-tuning on <math alttext="128" class="ltx_Math" display="inline" id="A6.I1.i2.p1.1.m1.1"><semantics id="A6.I1.i2.p1.1.m1.1a"><mn id="A6.I1.i2.p1.1.m1.1.1" xref="A6.I1.i2.p1.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A6.I1.i2.p1.1.m1.1b"><cn id="A6.I1.i2.p1.1.m1.1.1.cmml" type="integer" xref="A6.I1.i2.p1.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.I1.i2.p1.1.m1.1c">128</annotation><annotation encoding="application/x-llamapun" id="A6.I1.i2.p1.1.m1.1d">128</annotation></semantics></math> new samples and varying replay weight (right panel of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F17" title="Figure Q ‚Ä£ F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">Q</span></a>, bottom row of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F18" title="Figure R ‚Ä£ F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">R</span></a>).</p>
</div>
</li>
</ol>
<p class="ltx_p" id="A6.SS4.p4.2">We also experimented with fine-tuning on old key-value pairs, as in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F16" title="Figure P ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">P</span></a>, and once again observed qualitatively similar behaviors. Overall, these results provide evidence for the hypothesis that mostly feed-forward associative memories are altered during the incorporation of new knowledge through fine-tuning.</p>
</div>
<figure class="ltx_figure" id="A6.F17"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="160" id="A6.F17.g1" src="x23.png" width="425"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure Q: </span>Equivalent of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a> for the toy associative memory model. In the right plot, we set the number of fine-tuning examples to <math alttext="128" class="ltx_Math" display="inline" id="A6.F17.2.m1.1"><semantics id="A6.F17.2.m1.1b"><mn id="A6.F17.2.m1.1.1" xref="A6.F17.2.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A6.F17.2.m1.1c"><cn id="A6.F17.2.m1.1.1.cmml" type="integer" xref="A6.F17.2.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F17.2.m1.1d">128</annotation><annotation encoding="application/x-llamapun" id="A6.F17.2.m1.1e">128</annotation></semantics></math>. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS4" title="F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.4</span></a> for experimental details.</figcaption>
</figure>
<figure class="ltx_figure" id="A6.F18">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="200" id="A6.F18.g1" src="x24.png" width="650"/></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" height="200" id="A6.F18.g2" src="x25.png" width="650"/></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure R: </span>Equivalent of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F14" title="Figure N ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">N</span></a> for the toy associative memory model. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS4" title="F.4 Reproducing fine-tuning behavior on a toy associative memory problem ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.4</span></a> for experimental details.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A6.SS5">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.5 </span>Experiments with regular changes in training distribution</h4>
<div class="ltx_para ltx_noindent" id="A6.SS5.p1">
<p class="ltx_p" id="A6.SS5.p1.2">To complement our fine-tuning analysis, we consider the setup in which the training distribution is regularly changed, either to a new group of individual every change (this corresponds to varying <span class="ltx_text ltx_font_typewriter" id="A6.SS5.p1.2.1">number_groups</span> and fixing <span class="ltx_text ltx_font_typewriter" id="A6.SS5.p1.2.2">number_repeats</span> to <math alttext="1" class="ltx_Math" display="inline" id="A6.SS5.p1.1.m1.1"><semantics id="A6.SS5.p1.1.m1.1a"><mn id="A6.SS5.p1.1.m1.1.1" xref="A6.SS5.p1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A6.SS5.p1.1.m1.1b"><cn id="A6.SS5.p1.1.m1.1.1.cmml" type="integer" xref="A6.SS5.p1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS5.p1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A6.SS5.p1.1.m1.1d">1</annotation></semantics></math>) or alternating between two groups of individuals (this corresponds to varying <span class="ltx_text ltx_font_typewriter" id="A6.SS5.p1.2.3">number_repeats</span> and fixing <span class="ltx_text ltx_font_typewriter" id="A6.SS5.p1.2.4">number_groups</span> to <math alttext="2" class="ltx_Math" display="inline" id="A6.SS5.p1.2.m2.1"><semantics id="A6.SS5.p1.2.m2.1a"><mn id="A6.SS5.p1.2.m2.1.1" xref="A6.SS5.p1.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A6.SS5.p1.2.m2.1b"><cn id="A6.SS5.p1.2.m2.1.1.cmml" type="integer" xref="A6.SS5.p1.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS5.p1.2.m2.1c">2</annotation><annotation encoding="application/x-llamapun" id="A6.SS5.p1.2.m2.1d">2</annotation></semantics></math>). While this kind of experiment is further away from the current training paradigms of large language models and is more akin to a continual learning setup (e.g., <cite class="ltx_cite ltx_citemacro_cite">Kirkpatrick et¬†al. (<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib25" title="">2017</a>)</cite>), it enables us to monitor the plasticity of the network, that is how fast it learns new knowledge and forget about existing one, in a dynamic way. Overall, we find that our fine-tuning findings are robust across different stages of learning and these new results enable us to sometimes refine our conclusions.</p>
</div>
<figure class="ltx_figure" id="A6.F19"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="350" id="A6.F19.g1" src="x26.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure S: </span>Evolution of the model performance on different groups of individuals when it is trained sequentially on these groups. The color indicates the group of people the model is evaluated on: the darker the color, the later the network was trained on this group. For all plots the total number of individuals considered is equal to <math alttext="64" class="ltx_Math" display="inline" id="A6.F19.2.m1.1"><semantics id="A6.F19.2.m1.1b"><mn id="A6.F19.2.m1.1.1" xref="A6.F19.2.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A6.F19.2.m1.1c"><cn id="A6.F19.2.m1.1.1.cmml" type="integer" xref="A6.F19.2.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F19.2.m1.1d">64</annotation><annotation encoding="application/x-llamapun" id="A6.F19.2.m1.1e">64</annotation></semantics></math>k. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS5" title="F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.5</span></a> for more detail.</figcaption>
</figure>
<figure class="ltx_figure" id="A6.F20"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="350" id="A6.F20.g1" src="x27.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure T: </span>Same as Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a>, but with a constant learning rate scheduler.</figcaption>
</figure>
<figure class="ltx_figure" id="A6.F21"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="350" id="A6.F21.g1" src="x28.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure U: </span>Similar to the middle panel of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a> (8 groups), this time when training for longer. The total number of individuals is adapted so that the size of each group remains the same as before. All other hyperparameters remain the same.</figcaption>
</figure>
<figure class="ltx_figure" id="A6.F22"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="350" id="A6.F22.g1" src="x29.png" width="650"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure V: </span>Evolution of the model performance on different groups of individuals when it is trained alternating between two groups. The color indicates the group of people the model is evaluated on: green is for the first group, blue for the second one. For all plots the total number of individuals considered is equal to <math alttext="64" class="ltx_Math" display="inline" id="A6.F22.2.m1.1"><semantics id="A6.F22.2.m1.1b"><mn id="A6.F22.2.m1.1.1" xref="A6.F22.2.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A6.F22.2.m1.1c"><cn id="A6.F22.2.m1.1.1.cmml" type="integer" xref="A6.F22.2.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F22.2.m1.1d">64</annotation><annotation encoding="application/x-llamapun" id="A6.F22.2.m1.1e">64</annotation></semantics></math>k. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.SS5" title="F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F.5</span></a> for more detail.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A6.SS5.p2">
<p class="ltx_p" id="A6.SS5.p2.1">We observe a few interesting patterns. First, it becomes increasingly easier to learn a new distribution over time (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a>), which is likely induced by the improvement of the attention pattern quality over the course of learning (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F23" title="Figure W ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">W</span></a>), until the cosine learning rate scheduler eventually damps down weight changes. At the same time, forgetting, measured in log loss differences, becomes more important and occurs much faster than learning, confirming the results of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a>. However, changing distributions multiple times during early learning dynamics when the learning rate is relatively high reduce this plasticity increase, at it partially impairs future ability of the network to learn new groups (c.f. performance drop from Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a> middle to Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F21" title="Figure U ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">U</span></a>, or Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F20" title="Figure T ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">T</span></a>). For small learning rates (i.e. at the end of training), performance on old data sometimes get improved after some initial performance drop, without it being replayed (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F23" title="Figure W ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">W</span></a>), an intriguing phenomenon what we have partially observed during fine-tuning (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F14" title="Figure N ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">N</span></a>, top row). Additionally, for very small learning rates, learning eventually becomes harder and forgetting is not catastrophic, leading to the model remembering more about the second to last group than the last one (see e.g., the 8 groups plot in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a>). Still, too many distribution changes to unknown distributions when learning rates are small ultimately removes any knowledge from the network (e.g. Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F21" title="Figure U ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">U</span></a>).</p>
</div>
<figure class="ltx_figure" id="A6.F23"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="160" id="A6.F23.g1" src="x30.png" width="200"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure W: </span>Final attribute loss at the end of an attention patching experiment in which the model of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a> (8 groups) serves as reference (green line), as a function of the number of steps the reference model was trained. For comparison, we include the one we obtained when training on all individuals at once (grey line), as in Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F4" title="Figure D ‚Ä£ D.1 Implementation of the attention patching experiment ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D</span></a>. We use this metric as a measure of how good the attention patterns of a given model (the reference model) at a given time are for learning and solving the task at hand. We do not observe an initial bump in performance when changing individual distribution. There are two main reasons for that: First, attention patterns get formed early on due to training occurring on less individuals. Second, the granularity that we use (<math alttext="2" class="ltx_Math" display="inline" id="A6.F23.2.m1.1"><semantics id="A6.F23.2.m1.1b"><mn id="A6.F23.2.m1.1.1" xref="A6.F23.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A6.F23.2.m1.1c"><cn id="A6.F23.2.m1.1.1.cmml" type="integer" xref="A6.F23.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F23.2.m1.1d">2</annotation><annotation encoding="application/x-llamapun" id="A6.F23.2.m1.1e">2</annotation></semantics></math>k steps) would not allow us to see such a bump here.</figcaption>
</figure>
<figure class="ltx_figure" id="A6.F24"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="A6.F24.g1" src="x31.png" width="625"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure X: </span>Evolution of the attention patterns for the experiment reported in the middle panel of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a> (one loop over <math alttext="8" class="ltx_Math" display="inline" id="A6.F24.2.m1.1"><semantics id="A6.F24.2.m1.1b"><mn id="A6.F24.2.m1.1.1" xref="A6.F24.2.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A6.F24.2.m1.1c"><cn id="A6.F24.2.m1.1.1.cmml" type="integer" xref="A6.F24.2.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.F24.2.m1.1d">8</annotation><annotation encoding="application/x-llamapun" id="A6.F24.2.m1.1e">8</annotation></semantics></math> different groups of individuals). In the first three panels, we report (left) the average attention to name tokens when seeing the last name token, (middle left) attention to general text tokens when predicting the first attribute value token, (middle right) attention to the last name token when predicting the first attribute value token. In the right panel, we select the last layer line from the attribute to name and attribute to text plots, and the first layer line from the name to name line. See Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.SS2" title="D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D.2</span></a> for the rationale behind the choice of metrics. The attention patterns are more unstable than in the constant distribution scenario (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F6" title="Figure F ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F</span></a>). Yet they remain relatively stable, particularly for the one highlighted in the right panel towards the end of learning, in light of the frequent distribution changes and the relatively high learning rate used for most of the training.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="A6.SS5.p3">
<p class="ltx_p" id="A6.SS5.p3.1"><span class="ltx_text ltx_phantom" id="A6.SS5.p3.1.1"><span style="visibility:hidden">X</span></span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A7">
<h3 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Hyperparameter configurations</h3>
<section class="ltx_subsection" id="A7.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Default configuration</h4>
<figure class="ltx_table" id="A7.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T1.24" style="width:444.9pt;height:605.7pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_align_middle" id="A7.T1.24.24">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T1.24.24.25.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A7.T1.24.24.25.1.1"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.25.1.1.1">Name</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A7.T1.24.24.25.1.2"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.25.1.2.1">Value</span></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.T1.24.24.25.1.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.25.1.3.1">
<span class="ltx_p" id="A7.T1.24.24.25.1.3.1.1" style="width:256.1pt;"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.25.1.3.1.1.1">Description</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.26.2">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A7.T1.24.24.26.2.1"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.26.2.1.1">Model</span></td>
</tr>
<tr class="ltx_tr" id="A7.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.1.1.1.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.1.1.1.2.1">parameters</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.1.1.1.1">
<math alttext="44" class="ltx_Math" display="inline" id="A7.T1.1.1.1.1.m1.1"><semantics id="A7.T1.1.1.1.1.m1.1a"><mn id="A7.T1.1.1.1.1.m1.1.1" xref="A7.T1.1.1.1.1.m1.1.1.cmml">44</mn><annotation-xml encoding="MathML-Content" id="A7.T1.1.1.1.1.m1.1b"><cn id="A7.T1.1.1.1.1.m1.1.1.cmml" type="integer" xref="A7.T1.1.1.1.1.m1.1.1">44</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.1.1.1.1.m1.1c">44</annotation><annotation encoding="application/x-llamapun" id="A7.T1.1.1.1.1.m1.1d">44</annotation></semantics></math>M</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T1.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.1.1.1.3.1">
<span class="ltx_p" id="A7.T1.1.1.1.3.1.1" style="width:256.1pt;">Number of parameters.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.2.2.2">
<td class="ltx_td ltx_align_left" id="A7.T1.2.2.2.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.2.2.2.2.1">n_layers</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.2.2.2.1"><math alttext="8" class="ltx_Math" display="inline" id="A7.T1.2.2.2.1.m1.1"><semantics id="A7.T1.2.2.2.1.m1.1a"><mn id="A7.T1.2.2.2.1.m1.1.1" xref="A7.T1.2.2.2.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A7.T1.2.2.2.1.m1.1b"><cn id="A7.T1.2.2.2.1.m1.1.1.cmml" type="integer" xref="A7.T1.2.2.2.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.2.2.2.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="A7.T1.2.2.2.1.m1.1d">8</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.2.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.2.2.2.3.1">
<span class="ltx_p" id="A7.T1.2.2.2.3.1.1" style="width:256.1pt;">Number of layers.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.3.3.3">
<td class="ltx_td ltx_align_left" id="A7.T1.3.3.3.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.3.3.3.2.1">n_heads</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.3.3.3.1"><math alttext="8" class="ltx_Math" display="inline" id="A7.T1.3.3.3.1.m1.1"><semantics id="A7.T1.3.3.3.1.m1.1a"><mn id="A7.T1.3.3.3.1.m1.1.1" xref="A7.T1.3.3.3.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A7.T1.3.3.3.1.m1.1b"><cn id="A7.T1.3.3.3.1.m1.1.1.cmml" type="integer" xref="A7.T1.3.3.3.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.3.3.3.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="A7.T1.3.3.3.1.m1.1d">8</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.3.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.3.3.3.3.1">
<span class="ltx_p" id="A7.T1.3.3.3.3.1.1" style="width:256.1pt;">Number of attention heads per attention layer.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.4.4.4">
<td class="ltx_td ltx_align_left" id="A7.T1.4.4.4.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.4.4.4.2.1">d_model</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.4.4.4.1"><math alttext="512" class="ltx_Math" display="inline" id="A7.T1.4.4.4.1.m1.1"><semantics id="A7.T1.4.4.4.1.m1.1a"><mn id="A7.T1.4.4.4.1.m1.1.1" xref="A7.T1.4.4.4.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A7.T1.4.4.4.1.m1.1b"><cn id="A7.T1.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.T1.4.4.4.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.4.4.4.1.m1.1c">512</annotation><annotation encoding="application/x-llamapun" id="A7.T1.4.4.4.1.m1.1d">512</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.4.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.4.4.4.3.1">
<span class="ltx_p" id="A7.T1.4.4.4.3.1.1" style="width:256.1pt;">Model dimension (residual stream).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.5.5.5">
<td class="ltx_td ltx_align_left" id="A7.T1.5.5.5.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.5.5.5.2.1">d_hidden</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.5.5.5.1"><math alttext="2048" class="ltx_Math" display="inline" id="A7.T1.5.5.5.1.m1.1"><semantics id="A7.T1.5.5.5.1.m1.1a"><mn id="A7.T1.5.5.5.1.m1.1.1" xref="A7.T1.5.5.5.1.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A7.T1.5.5.5.1.m1.1b"><cn id="A7.T1.5.5.5.1.m1.1.1.cmml" type="integer" xref="A7.T1.5.5.5.1.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.5.5.5.1.m1.1c">2048</annotation><annotation encoding="application/x-llamapun" id="A7.T1.5.5.5.1.m1.1d">2048</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.5.5.5.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.5.5.5.3.1">
<span class="ltx_p" id="A7.T1.5.5.5.3.1.1" style="width:256.1pt;">Hidden dimension of the multi-layer perception.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.6.6.6">
<td class="ltx_td ltx_align_left" id="A7.T1.6.6.6.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.6.6.6.2.1">key_size</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.6.6.6.1"><math alttext="64" class="ltx_Math" display="inline" id="A7.T1.6.6.6.1.m1.1"><semantics id="A7.T1.6.6.6.1.m1.1a"><mn id="A7.T1.6.6.6.1.m1.1.1" xref="A7.T1.6.6.6.1.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A7.T1.6.6.6.1.m1.1b"><cn id="A7.T1.6.6.6.1.m1.1.1.cmml" type="integer" xref="A7.T1.6.6.6.1.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.6.6.6.1.m1.1c">64</annotation><annotation encoding="application/x-llamapun" id="A7.T1.6.6.6.1.m1.1d">64</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.6.6.6.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.6.6.6.3.1">
<span class="ltx_p" id="A7.T1.6.6.6.3.1.1" style="width:256.1pt;">Dimension of the key and values.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.27.3">
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.27.3.1"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.27.3.1.1">sequence_mixer</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.27.3.2">Attention</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.24.24.27.3.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.27.3.3.1">
<span class="ltx_p" id="A7.T1.24.24.27.3.3.1.1" style="width:256.1pt;">Which sequence mixing block we are using.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.28.4">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A7.T1.24.24.28.4.1"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.28.4.1.1">Training</span></td>
</tr>
<tr class="ltx_tr" id="A7.T1.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.7.7.7.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.7.7.7.2.1">training_steps</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.7.7.7.1">
<math alttext="16" class="ltx_Math" display="inline" id="A7.T1.7.7.7.1.m1.1"><semantics id="A7.T1.7.7.7.1.m1.1a"><mn id="A7.T1.7.7.7.1.m1.1.1" xref="A7.T1.7.7.7.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A7.T1.7.7.7.1.m1.1b"><cn id="A7.T1.7.7.7.1.m1.1.1.cmml" type="integer" xref="A7.T1.7.7.7.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.7.7.7.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="A7.T1.7.7.7.1.m1.1d">16</annotation></semantics></math>k</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T1.7.7.7.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.7.7.7.3.1">
<span class="ltx_p" id="A7.T1.7.7.7.3.1.1" style="width:256.1pt;">Number of training steps.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.8.8.8">
<td class="ltx_td ltx_align_left" id="A7.T1.8.8.8.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.8.8.8.2.1">batch_size</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.8.8.8.1"><math alttext="128" class="ltx_Math" display="inline" id="A7.T1.8.8.8.1.m1.1"><semantics id="A7.T1.8.8.8.1.m1.1a"><mn id="A7.T1.8.8.8.1.m1.1.1" xref="A7.T1.8.8.8.1.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A7.T1.8.8.8.1.m1.1b"><cn id="A7.T1.8.8.8.1.m1.1.1.cmml" type="integer" xref="A7.T1.8.8.8.1.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.8.8.8.1.m1.1c">128</annotation><annotation encoding="application/x-llamapun" id="A7.T1.8.8.8.1.m1.1d">128</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.8.8.8.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.8.8.8.3.1">
<span class="ltx_p" id="A7.T1.8.8.8.3.1.1" style="width:256.1pt;">Batch size.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.9.9.9">
<td class="ltx_td ltx_align_left" id="A7.T1.9.9.9.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.9.9.9.2.1">lr_scheduler</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.9.9.9.3">cosine</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.9.9.9.1">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.9.9.9.1.1">
<span class="ltx_p" id="A7.T1.9.9.9.1.1.1" style="width:256.1pt;">Learning rate scheduler, default is cosine scheduler (no warm-up, final learning rate: <math alttext="10^{-7}" class="ltx_Math" display="inline" id="A7.T1.9.9.9.1.1.1.m1.1"><semantics id="A7.T1.9.9.9.1.1.1.m1.1a"><msup id="A7.T1.9.9.9.1.1.1.m1.1.1" xref="A7.T1.9.9.9.1.1.1.m1.1.1.cmml"><mn id="A7.T1.9.9.9.1.1.1.m1.1.1.2" xref="A7.T1.9.9.9.1.1.1.m1.1.1.2.cmml">10</mn><mrow id="A7.T1.9.9.9.1.1.1.m1.1.1.3" xref="A7.T1.9.9.9.1.1.1.m1.1.1.3.cmml"><mo id="A7.T1.9.9.9.1.1.1.m1.1.1.3a" xref="A7.T1.9.9.9.1.1.1.m1.1.1.3.cmml">‚àí</mo><mn id="A7.T1.9.9.9.1.1.1.m1.1.1.3.2" xref="A7.T1.9.9.9.1.1.1.m1.1.1.3.2.cmml">7</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="A7.T1.9.9.9.1.1.1.m1.1b"><apply id="A7.T1.9.9.9.1.1.1.m1.1.1.cmml" xref="A7.T1.9.9.9.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A7.T1.9.9.9.1.1.1.m1.1.1.1.cmml" xref="A7.T1.9.9.9.1.1.1.m1.1.1">superscript</csymbol><cn id="A7.T1.9.9.9.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.T1.9.9.9.1.1.1.m1.1.1.2">10</cn><apply id="A7.T1.9.9.9.1.1.1.m1.1.1.3.cmml" xref="A7.T1.9.9.9.1.1.1.m1.1.1.3"><minus id="A7.T1.9.9.9.1.1.1.m1.1.1.3.1.cmml" xref="A7.T1.9.9.9.1.1.1.m1.1.1.3"></minus><cn id="A7.T1.9.9.9.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A7.T1.9.9.9.1.1.1.m1.1.1.3.2">7</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.9.9.9.1.1.1.m1.1c">10^{-7}</annotation><annotation encoding="application/x-llamapun" id="A7.T1.9.9.9.1.1.1.m1.1d">10 start_POSTSUPERSCRIPT - 7 end_POSTSUPERSCRIPT</annotation></semantics></math>).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.10.10.10">
<td class="ltx_td ltx_align_left" id="A7.T1.10.10.10.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.10.10.10.2.1">lr</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.10.10.10.1"><math alttext="4\cdot 10^{-4}" class="ltx_Math" display="inline" id="A7.T1.10.10.10.1.m1.1"><semantics id="A7.T1.10.10.10.1.m1.1a"><mrow id="A7.T1.10.10.10.1.m1.1.1" xref="A7.T1.10.10.10.1.m1.1.1.cmml"><mn id="A7.T1.10.10.10.1.m1.1.1.2" xref="A7.T1.10.10.10.1.m1.1.1.2.cmml">4</mn><mo id="A7.T1.10.10.10.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.T1.10.10.10.1.m1.1.1.1.cmml">‚ãÖ</mo><msup id="A7.T1.10.10.10.1.m1.1.1.3" xref="A7.T1.10.10.10.1.m1.1.1.3.cmml"><mn id="A7.T1.10.10.10.1.m1.1.1.3.2" xref="A7.T1.10.10.10.1.m1.1.1.3.2.cmml">10</mn><mrow id="A7.T1.10.10.10.1.m1.1.1.3.3" xref="A7.T1.10.10.10.1.m1.1.1.3.3.cmml"><mo id="A7.T1.10.10.10.1.m1.1.1.3.3a" xref="A7.T1.10.10.10.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A7.T1.10.10.10.1.m1.1.1.3.3.2" xref="A7.T1.10.10.10.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A7.T1.10.10.10.1.m1.1b"><apply id="A7.T1.10.10.10.1.m1.1.1.cmml" xref="A7.T1.10.10.10.1.m1.1.1"><ci id="A7.T1.10.10.10.1.m1.1.1.1.cmml" xref="A7.T1.10.10.10.1.m1.1.1.1">‚ãÖ</ci><cn id="A7.T1.10.10.10.1.m1.1.1.2.cmml" type="integer" xref="A7.T1.10.10.10.1.m1.1.1.2">4</cn><apply id="A7.T1.10.10.10.1.m1.1.1.3.cmml" xref="A7.T1.10.10.10.1.m1.1.1.3"><csymbol cd="ambiguous" id="A7.T1.10.10.10.1.m1.1.1.3.1.cmml" xref="A7.T1.10.10.10.1.m1.1.1.3">superscript</csymbol><cn id="A7.T1.10.10.10.1.m1.1.1.3.2.cmml" type="integer" xref="A7.T1.10.10.10.1.m1.1.1.3.2">10</cn><apply id="A7.T1.10.10.10.1.m1.1.1.3.3.cmml" xref="A7.T1.10.10.10.1.m1.1.1.3.3"><minus id="A7.T1.10.10.10.1.m1.1.1.3.3.1.cmml" xref="A7.T1.10.10.10.1.m1.1.1.3.3"></minus><cn id="A7.T1.10.10.10.1.m1.1.1.3.3.2.cmml" type="integer" xref="A7.T1.10.10.10.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.10.10.10.1.m1.1c">4\cdot 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A7.T1.10.10.10.1.m1.1d">4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.10.10.10.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.10.10.10.3.1">
<span class="ltx_p" id="A7.T1.10.10.10.3.1.1" style="width:256.1pt;">Maximum learning rate.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.11.11.11">
<td class="ltx_td ltx_align_left" id="A7.T1.11.11.11.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.11.11.11.2.1">weight_decay</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.11.11.11.1"><math alttext="0.1" class="ltx_Math" display="inline" id="A7.T1.11.11.11.1.m1.1"><semantics id="A7.T1.11.11.11.1.m1.1a"><mn id="A7.T1.11.11.11.1.m1.1.1" xref="A7.T1.11.11.11.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A7.T1.11.11.11.1.m1.1b"><cn id="A7.T1.11.11.11.1.m1.1.1.cmml" type="float" xref="A7.T1.11.11.11.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.11.11.11.1.m1.1c">0.1</annotation><annotation encoding="application/x-llamapun" id="A7.T1.11.11.11.1.m1.1d">0.1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.11.11.11.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.11.11.11.3.1">
<span class="ltx_p" id="A7.T1.11.11.11.3.1.1" style="width:256.1pt;">Weight decay.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.13.13.13">
<td class="ltx_td ltx_align_left" id="A7.T1.13.13.13.3"><span class="ltx_text ltx_font_typewriter" id="A7.T1.13.13.13.3.1">optimizer</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.13.13.13.4">AdamW</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.13.13.13.2">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.13.13.13.2.2">
<span class="ltx_p" id="A7.T1.13.13.13.2.2.2" style="width:256.1pt;">Optimizer (momentum parameters for the AdamW optimizer are <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="A7.T1.12.12.12.1.1.1.m1.1"><semantics id="A7.T1.12.12.12.1.1.1.m1.1a"><mrow id="A7.T1.12.12.12.1.1.1.m1.1.1" xref="A7.T1.12.12.12.1.1.1.m1.1.1.cmml"><msub id="A7.T1.12.12.12.1.1.1.m1.1.1.2" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2.cmml"><mi id="A7.T1.12.12.12.1.1.1.m1.1.1.2.2" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2.2.cmml">Œ≤</mi><mn id="A7.T1.12.12.12.1.1.1.m1.1.1.2.3" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="A7.T1.12.12.12.1.1.1.m1.1.1.1" xref="A7.T1.12.12.12.1.1.1.m1.1.1.1.cmml">=</mo><mn id="A7.T1.12.12.12.1.1.1.m1.1.1.3" xref="A7.T1.12.12.12.1.1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.T1.12.12.12.1.1.1.m1.1b"><apply id="A7.T1.12.12.12.1.1.1.m1.1.1.cmml" xref="A7.T1.12.12.12.1.1.1.m1.1.1"><eq id="A7.T1.12.12.12.1.1.1.m1.1.1.1.cmml" xref="A7.T1.12.12.12.1.1.1.m1.1.1.1"></eq><apply id="A7.T1.12.12.12.1.1.1.m1.1.1.2.cmml" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2"><csymbol cd="ambiguous" id="A7.T1.12.12.12.1.1.1.m1.1.1.2.1.cmml" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2">subscript</csymbol><ci id="A7.T1.12.12.12.1.1.1.m1.1.1.2.2.cmml" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2.2">ùõΩ</ci><cn id="A7.T1.12.12.12.1.1.1.m1.1.1.2.3.cmml" type="integer" xref="A7.T1.12.12.12.1.1.1.m1.1.1.2.3">1</cn></apply><cn id="A7.T1.12.12.12.1.1.1.m1.1.1.3.cmml" type="float" xref="A7.T1.12.12.12.1.1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.12.12.12.1.1.1.m1.1c">\beta_{1}=0.9</annotation><annotation encoding="application/x-llamapun" id="A7.T1.12.12.12.1.1.1.m1.1d">italic_Œ≤ start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9</annotation></semantics></math>, <math alttext="\beta_{2}=0.95" class="ltx_Math" display="inline" id="A7.T1.13.13.13.2.2.2.m2.1"><semantics id="A7.T1.13.13.13.2.2.2.m2.1a"><mrow id="A7.T1.13.13.13.2.2.2.m2.1.1" xref="A7.T1.13.13.13.2.2.2.m2.1.1.cmml"><msub id="A7.T1.13.13.13.2.2.2.m2.1.1.2" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2.cmml"><mi id="A7.T1.13.13.13.2.2.2.m2.1.1.2.2" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2.2.cmml">Œ≤</mi><mn id="A7.T1.13.13.13.2.2.2.m2.1.1.2.3" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="A7.T1.13.13.13.2.2.2.m2.1.1.1" xref="A7.T1.13.13.13.2.2.2.m2.1.1.1.cmml">=</mo><mn id="A7.T1.13.13.13.2.2.2.m2.1.1.3" xref="A7.T1.13.13.13.2.2.2.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.T1.13.13.13.2.2.2.m2.1b"><apply id="A7.T1.13.13.13.2.2.2.m2.1.1.cmml" xref="A7.T1.13.13.13.2.2.2.m2.1.1"><eq id="A7.T1.13.13.13.2.2.2.m2.1.1.1.cmml" xref="A7.T1.13.13.13.2.2.2.m2.1.1.1"></eq><apply id="A7.T1.13.13.13.2.2.2.m2.1.1.2.cmml" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2"><csymbol cd="ambiguous" id="A7.T1.13.13.13.2.2.2.m2.1.1.2.1.cmml" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2">subscript</csymbol><ci id="A7.T1.13.13.13.2.2.2.m2.1.1.2.2.cmml" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2.2">ùõΩ</ci><cn id="A7.T1.13.13.13.2.2.2.m2.1.1.2.3.cmml" type="integer" xref="A7.T1.13.13.13.2.2.2.m2.1.1.2.3">2</cn></apply><cn id="A7.T1.13.13.13.2.2.2.m2.1.1.3.cmml" type="float" xref="A7.T1.13.13.13.2.2.2.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.13.13.13.2.2.2.m2.1c">\beta_{2}=0.95</annotation><annotation encoding="application/x-llamapun" id="A7.T1.13.13.13.2.2.2.m2.1d">italic_Œ≤ start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.95</annotation></semantics></math>).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.29.5">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A7.T1.24.24.29.5.1"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.29.5.1.1">Data</span></td>
</tr>
<tr class="ltx_tr" id="A7.T1.14.14.14">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.14.14.14.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.14.14.14.2.1">sequence_length</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.14.14.14.1"><math alttext="512" class="ltx_Math" display="inline" id="A7.T1.14.14.14.1.m1.1"><semantics id="A7.T1.14.14.14.1.m1.1a"><mn id="A7.T1.14.14.14.1.m1.1.1" xref="A7.T1.14.14.14.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A7.T1.14.14.14.1.m1.1b"><cn id="A7.T1.14.14.14.1.m1.1.1.cmml" type="integer" xref="A7.T1.14.14.14.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.14.14.14.1.m1.1c">512</annotation><annotation encoding="application/x-llamapun" id="A7.T1.14.14.14.1.m1.1d">512</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T1.14.14.14.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.14.14.14.3.1">
<span class="ltx_p" id="A7.T1.14.14.14.3.1.1" style="width:256.1pt;">Sequence length.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.15.15.15">
<td class="ltx_td ltx_align_left" id="A7.T1.15.15.15.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.15.15.15.2.1">n_individuals</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.15.15.15.1">
<math alttext="64" class="ltx_Math" display="inline" id="A7.T1.15.15.15.1.m1.1"><semantics id="A7.T1.15.15.15.1.m1.1a"><mn id="A7.T1.15.15.15.1.m1.1.1" xref="A7.T1.15.15.15.1.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A7.T1.15.15.15.1.m1.1b"><cn id="A7.T1.15.15.15.1.m1.1.1.cmml" type="integer" xref="A7.T1.15.15.15.1.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.15.15.15.1.m1.1c">64</annotation><annotation encoding="application/x-llamapun" id="A7.T1.15.15.15.1.m1.1d">64</annotation></semantics></math>k</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.15.15.15.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.15.15.15.3.1">
<span class="ltx_p" id="A7.T1.15.15.15.3.1.1" style="width:256.1pt;">Number of different individuals in the population.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.30.6">
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.30.6.1"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.30.6.1.1">indiv_dist_train</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.30.6.2">uniform</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.24.24.30.6.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.30.6.3.1">
<span class="ltx_p" id="A7.T1.24.24.30.6.3.1.1" style="width:256.1pt;">Distribution from which we sample individuals whenever we generate a new biography (at train time).</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.31.7">
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.31.7.1"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.31.7.1.1">indiv_dist_eval</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.31.7.2">uniform</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.24.24.31.7.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.31.7.3.1">
<span class="ltx_p" id="A7.T1.24.24.31.7.3.1.1" style="width:256.1pt;">Same as previous line, but for evaluation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.32.8">
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.32.8.1"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.32.8.1.1">shuffle_templates</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.32.8.2">True</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.24.24.32.8.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.32.8.3.1">
<span class="ltx_p" id="A7.T1.24.24.32.8.3.1.1" style="width:256.1pt;">Whether to shuffle templates.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.16.16.16">
<td class="ltx_td ltx_align_left" id="A7.T1.16.16.16.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.16.16.16.2.1">n_templates</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.16.16.16.1"><math alttext="25" class="ltx_Math" display="inline" id="A7.T1.16.16.16.1.m1.1"><semantics id="A7.T1.16.16.16.1.m1.1a"><mn id="A7.T1.16.16.16.1.m1.1.1" xref="A7.T1.16.16.16.1.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A7.T1.16.16.16.1.m1.1b"><cn id="A7.T1.16.16.16.1.m1.1.1.cmml" type="integer" xref="A7.T1.16.16.16.1.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.16.16.16.1.m1.1c">25</annotation><annotation encoding="application/x-llamapun" id="A7.T1.16.16.16.1.m1.1d">25</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.16.16.16.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.16.16.16.3.1">
<span class="ltx_p" id="A7.T1.16.16.16.3.1.1" style="width:256.1pt;">Number of templates per attribute type.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.17.17.17">
<td class="ltx_td ltx_align_left" id="A7.T1.17.17.17.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.17.17.17.2.1">n_templates_train</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.17.17.17.1"><math alttext="20" class="ltx_Math" display="inline" id="A7.T1.17.17.17.1.m1.1"><semantics id="A7.T1.17.17.17.1.m1.1a"><mn id="A7.T1.17.17.17.1.m1.1.1" xref="A7.T1.17.17.17.1.m1.1.1.cmml">20</mn><annotation-xml encoding="MathML-Content" id="A7.T1.17.17.17.1.m1.1b"><cn id="A7.T1.17.17.17.1.m1.1.1.cmml" type="integer" xref="A7.T1.17.17.17.1.m1.1.1">20</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.17.17.17.1.m1.1c">20</annotation><annotation encoding="application/x-llamapun" id="A7.T1.17.17.17.1.m1.1d">20</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.17.17.17.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.17.17.17.3.1">
<span class="ltx_p" id="A7.T1.17.17.17.3.1.1" style="width:256.1pt;">Number of templates used in training.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.18.18.18">
<td class="ltx_td ltx_align_left" id="A7.T1.18.18.18.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.18.18.18.2.1">n_sequences_eval</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.18.18.18.1">
<math alttext="16" class="ltx_Math" display="inline" id="A7.T1.18.18.18.1.m1.1"><semantics id="A7.T1.18.18.18.1.m1.1a"><mn id="A7.T1.18.18.18.1.m1.1.1" xref="A7.T1.18.18.18.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A7.T1.18.18.18.1.m1.1b"><cn id="A7.T1.18.18.18.1.m1.1.1.cmml" type="integer" xref="A7.T1.18.18.18.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.18.18.18.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="A7.T1.18.18.18.1.m1.1d">16</annotation></semantics></math>k</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.18.18.18.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.18.18.18.3.1">
<span class="ltx_p" id="A7.T1.18.18.18.3.1.1" style="width:256.1pt;">Number of sequences for evaluation.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.33.9">
<td class="ltx_td ltx_align_left ltx_border_t" colspan="3" id="A7.T1.24.24.33.9.1"><span class="ltx_text ltx_font_bold" id="A7.T1.24.24.33.9.1.1">Miscellaneous</span></td>
</tr>
<tr class="ltx_tr" id="A7.T1.19.19.19">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.19.19.19.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.19.19.19.2.1">n_seeds</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T1.19.19.19.1"><math alttext="1" class="ltx_Math" display="inline" id="A7.T1.19.19.19.1.m1.1"><semantics id="A7.T1.19.19.19.1.m1.1a"><mn id="A7.T1.19.19.19.1.m1.1.1" xref="A7.T1.19.19.19.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A7.T1.19.19.19.1.m1.1b"><cn id="A7.T1.19.19.19.1.m1.1.1.cmml" type="integer" xref="A7.T1.19.19.19.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.19.19.19.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A7.T1.19.19.19.1.m1.1d">1</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A7.T1.19.19.19.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.19.19.19.3.1">
<span class="ltx_p" id="A7.T1.19.19.19.3.1.1" style="width:256.1pt;">Number of seeds per hyperparameter configuration.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.34.10">
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.34.10.1"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.34.10.1.1">tokenizer</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.34.10.2">SentencePiece</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.24.24.34.10.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.34.10.3.1">
<span class="ltx_p" id="A7.T1.24.24.34.10.3.1.1" style="width:256.1pt;">Tokenizer, as in <cite class="ltx_cite ltx_citemacro_citep">(Hoffmann et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib22" title="">2022</a>)</cite>.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.20.20.20">
<td class="ltx_td ltx_align_left" id="A7.T1.20.20.20.2"><span class="ltx_text ltx_font_typewriter" id="A7.T1.20.20.20.2.1">vocab_size</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.20.20.20.1">
<math alttext="32" class="ltx_Math" display="inline" id="A7.T1.20.20.20.1.m1.1"><semantics id="A7.T1.20.20.20.1.m1.1a"><mn id="A7.T1.20.20.20.1.m1.1.1" xref="A7.T1.20.20.20.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A7.T1.20.20.20.1.m1.1b"><cn id="A7.T1.20.20.20.1.m1.1.1.cmml" type="integer" xref="A7.T1.20.20.20.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.20.20.20.1.m1.1c">32</annotation><annotation encoding="application/x-llamapun" id="A7.T1.20.20.20.1.m1.1d">32</annotation></semantics></math>k</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.20.20.20.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.20.20.20.3.1">
<span class="ltx_p" id="A7.T1.20.20.20.3.1.1" style="width:256.1pt;">Vocabulary size of the tokenizer.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.24">
<td class="ltx_td ltx_align_left" id="A7.T1.24.24.24.5"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.24.5.1">checkpoints</span></td>
<td class="ltx_td ltx_align_left" id="A7.T1.21.21.21.1"><math alttext="50" class="ltx_Math" display="inline" id="A7.T1.21.21.21.1.m1.1"><semantics id="A7.T1.21.21.21.1.m1.1a"><mn id="A7.T1.21.21.21.1.m1.1.1" xref="A7.T1.21.21.21.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A7.T1.21.21.21.1.m1.1b"><cn id="A7.T1.21.21.21.1.m1.1.1.cmml" type="integer" xref="A7.T1.21.21.21.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.21.21.21.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="A7.T1.21.21.21.1.m1.1d">50</annotation></semantics></math></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.T1.24.24.24.4">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.24.4.3">
<span class="ltx_p" id="A7.T1.24.24.24.4.3.3" style="width:256.1pt;">One checkpoint every <math alttext="125" class="ltx_Math" display="inline" id="A7.T1.22.22.22.2.1.1.m1.1"><semantics id="A7.T1.22.22.22.2.1.1.m1.1a"><mn id="A7.T1.22.22.22.2.1.1.m1.1.1" xref="A7.T1.22.22.22.2.1.1.m1.1.1.cmml">125</mn><annotation-xml encoding="MathML-Content" id="A7.T1.22.22.22.2.1.1.m1.1b"><cn id="A7.T1.22.22.22.2.1.1.m1.1.1.cmml" type="integer" xref="A7.T1.22.22.22.2.1.1.m1.1.1">125</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.22.22.22.2.1.1.m1.1c">125</annotation><annotation encoding="application/x-llamapun" id="A7.T1.22.22.22.2.1.1.m1.1d">125</annotation></semantics></math> steps until <math alttext="2" class="ltx_Math" display="inline" id="A7.T1.23.23.23.3.2.2.m2.1"><semantics id="A7.T1.23.23.23.3.2.2.m2.1a"><mn id="A7.T1.23.23.23.3.2.2.m2.1.1" xref="A7.T1.23.23.23.3.2.2.m2.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A7.T1.23.23.23.3.2.2.m2.1b"><cn id="A7.T1.23.23.23.3.2.2.m2.1.1.cmml" type="integer" xref="A7.T1.23.23.23.3.2.2.m2.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.23.23.23.3.2.2.m2.1c">2</annotation><annotation encoding="application/x-llamapun" id="A7.T1.23.23.23.3.2.2.m2.1d">2</annotation></semantics></math>k steps, and <math alttext="32" class="ltx_Math" display="inline" id="A7.T1.24.24.24.4.3.3.m3.1"><semantics id="A7.T1.24.24.24.4.3.3.m3.1a"><mn id="A7.T1.24.24.24.4.3.3.m3.1.1" xref="A7.T1.24.24.24.4.3.3.m3.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A7.T1.24.24.24.4.3.3.m3.1b"><cn id="A7.T1.24.24.24.4.3.3.m3.1.1.cmml" type="integer" xref="A7.T1.24.24.24.4.3.3.m3.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.T1.24.24.24.4.3.3.m3.1c">32</annotation><annotation encoding="application/x-llamapun" id="A7.T1.24.24.24.4.3.3.m3.1d">32</annotation></semantics></math> checkpoints uniformly spaced over the entire learning trajectory.</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.T1.24.24.35.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A7.T1.24.24.35.11.1"><span class="ltx_text ltx_font_typewriter" id="A7.T1.24.24.35.11.1.1">accelerator</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A7.T1.24.24.35.11.2">Google TPUv3</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A7.T1.24.24.35.11.3">
<span class="ltx_inline-block ltx_align_top" id="A7.T1.24.24.35.11.3.1">
<span class="ltx_p" id="A7.T1.24.24.35.11.3.1.1" style="width:256.1pt;">Hardware accelerator.</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Default hyperparameters used in our experiments.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A7.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>Hyperparameters for Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS1" title="2.1 The three phases underlying knowledge acquisition ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.1</span></a>
</h4>
<figure class="ltx_table" id="A7.SS2.36">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" id="A7.SS2.4.4" style="width:400.6pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.4.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.4.4.4.5.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.4.4.4.5.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.4.4.4.5.1.1.1">Main experiment</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.1.1.1.1.2.1">
<span class="ltx_p" id="A7.SS2.1.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.1.1.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.1.1.1.1.1.1">
<span class="ltx_p" id="A7.SS2.1.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.1.1.1.1.1.1.1.m1.5"><semantics id="A7.SS2.1.1.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.1.1.1.1.1.1.1.m1.5b"><list id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.1.1.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.1.1.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.1.1.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.2.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.2.2.2.2.2.1">
<span class="ltx_p" id="A7.SS2.2.2.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.2.2.2.2.2.1.1.1">n_seeds</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.2.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.2.2.2.2.1.1">
<span class="ltx_p" id="A7.SS2.2.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="5" class="ltx_Math" display="inline" id="A7.SS2.2.2.2.2.1.1.1.m1.1"><semantics id="A7.SS2.2.2.2.2.1.1.1.m1.1a"><mn id="A7.SS2.2.2.2.2.1.1.1.m1.1.1" xref="A7.SS2.2.2.2.2.1.1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.2.2.2.2.1.1.1.m1.1b"><cn id="A7.SS2.2.2.2.2.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS2.2.2.2.2.1.1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.2.2.2.2.1.1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.2.2.2.2.1.1.1.m1.1d">5</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.4.4.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.4.4.4.4.2">Compute time: <math alttext="78" class="ltx_Math" display="inline" id="A7.SS2.3.3.3.3.1.m1.1"><semantics id="A7.SS2.3.3.3.3.1.m1.1a"><mn id="A7.SS2.3.3.3.3.1.m1.1.1" xref="A7.SS2.3.3.3.3.1.m1.1.1.cmml">78</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.3.3.3.3.1.m1.1b"><cn id="A7.SS2.3.3.3.3.1.m1.1.1.cmml" type="integer" xref="A7.SS2.3.3.3.3.1.m1.1.1">78</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.3.3.3.3.1.m1.1c">78</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.3.3.3.3.1.m1.1d">78</annotation></semantics></math> hours (train) and <math alttext="154" class="ltx_Math" display="inline" id="A7.SS2.4.4.4.4.2.m2.1"><semantics id="A7.SS2.4.4.4.4.2.m2.1a"><mn id="A7.SS2.4.4.4.4.2.m2.1.1" xref="A7.SS2.4.4.4.4.2.m2.1.1.cmml">154</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.4.4.4.4.2.m2.1b"><cn id="A7.SS2.4.4.4.4.2.m2.1.1.cmml" type="integer" xref="A7.SS2.4.4.4.4.2.m2.1.1">154</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.4.4.4.4.2.m2.1c">154</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.4.4.4.4.2.m2.1d">154</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS2.9.9" style="width:400.6pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.9.9.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.9.9.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.9.9.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.9.9.5.6.1.1.1">Ablation number of individuals</span> (Figures¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.5.5.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.5.5.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.5.5.1.1.2.1">
<span class="ltx_p" id="A7.SS2.5.5.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.5.5.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.5.5.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.5.5.1.1.1.1">
<span class="ltx_p" id="A7.SS2.5.5.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.5.5.1.1.1.1.1.m1.5"><semantics id="A7.SS2.5.5.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.5.5.1.1.1.1.1.m1.5b"><list id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.5.5.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.5.5.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.5.5.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.6.6.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.6.6.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.6.6.2.2.2.1">
<span class="ltx_p" id="A7.SS2.6.6.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.6.6.2.2.2.1.1.1">n_individuals</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.6.6.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.6.6.2.2.1.1">
<span class="ltx_p" id="A7.SS2.6.6.2.2.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS2.6.6.2.2.1.1.1.m1.7"><semantics id="A7.SS2.6.6.2.2.1.1.1.m1.7a"><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.9" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.10" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.11" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.12" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.13" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.2.cmml">128</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.14" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.2" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.2.cmml">256</mn><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.1" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.6.6.2.2.1.1.1.m1.7b"><list id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.8.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7"><apply id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4"><times id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5"><times id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6"><times id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.2">128</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7"><times id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.2">256</cn><ci id="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS2.6.6.2.2.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.6.6.2.2.1.1.1.m1.7c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.6.6.2.2.1.1.1.m1.7d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k , 128 roman_k , 256 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.7.7.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.7.7.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.7.7.3.3.2.1">
<span class="ltx_p" id="A7.SS2.7.7.3.3.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.7.7.3.3.2.1.1.1">n_seeds</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.7.7.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.7.7.3.3.1.1">
<span class="ltx_p" id="A7.SS2.7.7.3.3.1.1.1" style="width:227.6pt;"><math alttext="5" class="ltx_Math" display="inline" id="A7.SS2.7.7.3.3.1.1.1.m1.1"><semantics id="A7.SS2.7.7.3.3.1.1.1.m1.1a"><mn id="A7.SS2.7.7.3.3.1.1.1.m1.1.1" xref="A7.SS2.7.7.3.3.1.1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.7.7.3.3.1.1.1.m1.1b"><cn id="A7.SS2.7.7.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS2.7.7.3.3.1.1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.7.7.3.3.1.1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.7.7.3.3.1.1.1.m1.1d">5</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.9.9.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.9.9.5.5.2">Compute time: <math alttext="600" class="ltx_Math" display="inline" id="A7.SS2.8.8.4.4.1.m1.1"><semantics id="A7.SS2.8.8.4.4.1.m1.1a"><mn id="A7.SS2.8.8.4.4.1.m1.1.1" xref="A7.SS2.8.8.4.4.1.m1.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.8.8.4.4.1.m1.1b"><cn id="A7.SS2.8.8.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS2.8.8.4.4.1.m1.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.8.8.4.4.1.m1.1c">600</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.8.8.4.4.1.m1.1d">600</annotation></semantics></math> hours (train) and <math alttext="214" class="ltx_Math" display="inline" id="A7.SS2.9.9.5.5.2.m2.1"><semantics id="A7.SS2.9.9.5.5.2.m2.1a"><mn id="A7.SS2.9.9.5.5.2.m2.1.1" xref="A7.SS2.9.9.5.5.2.m2.1.1.cmml">214</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.9.9.5.5.2.m2.1b"><cn id="A7.SS2.9.9.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS2.9.9.5.5.2.m2.1.1">214</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.9.9.5.5.2.m2.1c">214</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.9.9.5.5.2.m2.1d">214</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS2.13.13" style="width:400.6pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.13.13.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.13.13.4.5.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.13.13.4.5.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.13.13.4.5.1.1.1">Ablation weight decay</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.10.10.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.10.10.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.10.10.1.1.2.1">
<span class="ltx_p" id="A7.SS2.10.10.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.10.10.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.10.10.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.10.10.1.1.1.1">
<span class="ltx_p" id="A7.SS2.10.10.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.10.10.1.1.1.1.1.m1.5"><semantics id="A7.SS2.10.10.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.10.10.1.1.1.1.1.m1.5b"><list id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.10.10.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.10.10.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.10.10.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.11.11.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.11.11.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.11.11.2.2.2.1">
<span class="ltx_p" id="A7.SS2.11.11.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.11.11.2.2.2.1.1.1">weight_decay</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.11.11.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.11.11.2.2.1.1">
<span class="ltx_p" id="A7.SS2.11.11.2.2.1.1.1" style="width:227.6pt;"><math alttext="[0.01,0.03,0.1,0.3,1]" class="ltx_Math" display="inline" id="A7.SS2.11.11.2.2.1.1.1.m1.5"><semantics id="A7.SS2.11.11.2.2.1.1.1.m1.5a"><mrow id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml"><mo id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2.1" stretchy="false" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml">[</mo><mn id="A7.SS2.11.11.2.2.1.1.1.m1.1.1" xref="A7.SS2.11.11.2.2.1.1.1.m1.1.1.cmml">0.01</mn><mo id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2.2" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.11.11.2.2.1.1.1.m1.2.2" xref="A7.SS2.11.11.2.2.1.1.1.m1.2.2.cmml">0.03</mn><mo id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2.3" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.11.11.2.2.1.1.1.m1.3.3" xref="A7.SS2.11.11.2.2.1.1.1.m1.3.3.cmml">0.1</mn><mo id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2.4" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.11.11.2.2.1.1.1.m1.4.4" xref="A7.SS2.11.11.2.2.1.1.1.m1.4.4.cmml">0.3</mn><mo id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2.5" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.11.11.2.2.1.1.1.m1.5.5" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.5.cmml">1</mn><mo id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2.6" stretchy="false" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.11.11.2.2.1.1.1.m1.5b"><list id="A7.SS2.11.11.2.2.1.1.1.m1.5.6.1.cmml" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.6.2"><cn id="A7.SS2.11.11.2.2.1.1.1.m1.1.1.cmml" type="float" xref="A7.SS2.11.11.2.2.1.1.1.m1.1.1">0.01</cn><cn id="A7.SS2.11.11.2.2.1.1.1.m1.2.2.cmml" type="float" xref="A7.SS2.11.11.2.2.1.1.1.m1.2.2">0.03</cn><cn id="A7.SS2.11.11.2.2.1.1.1.m1.3.3.cmml" type="float" xref="A7.SS2.11.11.2.2.1.1.1.m1.3.3">0.1</cn><cn id="A7.SS2.11.11.2.2.1.1.1.m1.4.4.cmml" type="float" xref="A7.SS2.11.11.2.2.1.1.1.m1.4.4">0.3</cn><cn id="A7.SS2.11.11.2.2.1.1.1.m1.5.5.cmml" type="integer" xref="A7.SS2.11.11.2.2.1.1.1.m1.5.5">1</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.11.11.2.2.1.1.1.m1.5c">[0.01,0.03,0.1,0.3,1]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.11.11.2.2.1.1.1.m1.5d">[ 0.01 , 0.03 , 0.1 , 0.3 , 1 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.13.13.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.13.13.4.4.2">Compute time: <math alttext="86" class="ltx_Math" display="inline" id="A7.SS2.12.12.3.3.1.m1.1"><semantics id="A7.SS2.12.12.3.3.1.m1.1a"><mn id="A7.SS2.12.12.3.3.1.m1.1.1" xref="A7.SS2.12.12.3.3.1.m1.1.1.cmml">86</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.12.12.3.3.1.m1.1b"><cn id="A7.SS2.12.12.3.3.1.m1.1.1.cmml" type="integer" xref="A7.SS2.12.12.3.3.1.m1.1.1">86</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.12.12.3.3.1.m1.1c">86</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.12.12.3.3.1.m1.1d">86</annotation></semantics></math> hours (train) and <math alttext="29" class="ltx_Math" display="inline" id="A7.SS2.13.13.4.4.2.m2.1"><semantics id="A7.SS2.13.13.4.4.2.m2.1a"><mn id="A7.SS2.13.13.4.4.2.m2.1.1" xref="A7.SS2.13.13.4.4.2.m2.1.1.cmml">29</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.13.13.4.4.2.m2.1b"><cn id="A7.SS2.13.13.4.4.2.m2.1.1.cmml" type="integer" xref="A7.SS2.13.13.4.4.2.m2.1.1">29</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.13.13.4.4.2.m2.1c">29</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.13.13.4.4.2.m2.1d">29</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS2.18.18" style="width:400.6pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.18.18.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.18.18.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.18.18.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.18.18.5.6.1.1.1">Ablation batch size</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.14.14.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.14.14.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.14.14.1.1.2.1">
<span class="ltx_p" id="A7.SS2.14.14.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.14.14.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.14.14.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.14.14.1.1.1.1">
<span class="ltx_p" id="A7.SS2.14.14.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.14.14.1.1.1.1.1.m1.5"><semantics id="A7.SS2.14.14.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.14.14.1.1.1.1.1.m1.5b"><list id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.14.14.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.14.14.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.14.14.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.15.15.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.15.15.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.15.15.2.2.2.1">
<span class="ltx_p" id="A7.SS2.15.15.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.15.15.2.2.2.1.1.1">training_steps</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.15.15.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.15.15.2.2.1.1">
<span class="ltx_p" id="A7.SS2.15.15.2.2.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS2.15.15.2.2.1.1.1.m1.5"><semantics id="A7.SS2.15.15.2.2.1.1.1.m1.5a"><mrow id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml">[</mo><mrow id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.7" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.8" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.9" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.1" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.10" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.1" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.15.15.2.2.1.1.1.m1.5b"><list id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5"><apply id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4"><times id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5"><times id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.15.15.2.2.1.1.1.m1.5.5.5.5.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.15.15.2.2.1.1.1.m1.5c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.15.15.2.2.1.1.1.m1.5d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.16.16.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.16.16.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.16.16.3.3.2.1">
<span class="ltx_p" id="A7.SS2.16.16.3.3.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.16.16.3.3.2.1.1.1">batch_size</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.16.16.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.16.16.3.3.1.1">
<span class="ltx_p" id="A7.SS2.16.16.3.3.1.1.1" style="width:227.6pt;"><math alttext="[32,64,128,256,512]" class="ltx_Math" display="inline" id="A7.SS2.16.16.3.3.1.1.1.m1.5"><semantics id="A7.SS2.16.16.3.3.1.1.1.m1.5a"><mrow id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml"><mo id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2.1" stretchy="false" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml">[</mo><mn id="A7.SS2.16.16.3.3.1.1.1.m1.1.1" xref="A7.SS2.16.16.3.3.1.1.1.m1.1.1.cmml">32</mn><mo id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2.2" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.16.16.3.3.1.1.1.m1.2.2" xref="A7.SS2.16.16.3.3.1.1.1.m1.2.2.cmml">64</mn><mo id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2.3" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.16.16.3.3.1.1.1.m1.3.3" xref="A7.SS2.16.16.3.3.1.1.1.m1.3.3.cmml">128</mn><mo id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2.4" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.16.16.3.3.1.1.1.m1.4.4" xref="A7.SS2.16.16.3.3.1.1.1.m1.4.4.cmml">256</mn><mo id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2.5" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.16.16.3.3.1.1.1.m1.5.5" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.5.cmml">512</mn><mo id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2.6" stretchy="false" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.16.16.3.3.1.1.1.m1.5b"><list id="A7.SS2.16.16.3.3.1.1.1.m1.5.6.1.cmml" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.6.2"><cn id="A7.SS2.16.16.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS2.16.16.3.3.1.1.1.m1.1.1">32</cn><cn id="A7.SS2.16.16.3.3.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS2.16.16.3.3.1.1.1.m1.2.2">64</cn><cn id="A7.SS2.16.16.3.3.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS2.16.16.3.3.1.1.1.m1.3.3">128</cn><cn id="A7.SS2.16.16.3.3.1.1.1.m1.4.4.cmml" type="integer" xref="A7.SS2.16.16.3.3.1.1.1.m1.4.4">256</cn><cn id="A7.SS2.16.16.3.3.1.1.1.m1.5.5.cmml" type="integer" xref="A7.SS2.16.16.3.3.1.1.1.m1.5.5">512</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.16.16.3.3.1.1.1.m1.5c">[32,64,128,256,512]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.16.16.3.3.1.1.1.m1.5d">[ 32 , 64 , 128 , 256 , 512 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.18.18.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.18.18.5.5.2">Compute time: <math alttext="685" class="ltx_Math" display="inline" id="A7.SS2.17.17.4.4.1.m1.1"><semantics id="A7.SS2.17.17.4.4.1.m1.1a"><mn id="A7.SS2.17.17.4.4.1.m1.1.1" xref="A7.SS2.17.17.4.4.1.m1.1.1.cmml">685</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.17.17.4.4.1.m1.1b"><cn id="A7.SS2.17.17.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS2.17.17.4.4.1.m1.1.1">685</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.17.17.4.4.1.m1.1c">685</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.17.17.4.4.1.m1.1d">685</annotation></semantics></math> hours (train) and <math alttext="148" class="ltx_Math" display="inline" id="A7.SS2.18.18.5.5.2.m2.1"><semantics id="A7.SS2.18.18.5.5.2.m2.1a"><mn id="A7.SS2.18.18.5.5.2.m2.1.1" xref="A7.SS2.18.18.5.5.2.m2.1.1.cmml">148</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.18.18.5.5.2.m2.1b"><cn id="A7.SS2.18.18.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS2.18.18.5.5.2.m2.1.1">148</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.18.18.5.5.2.m2.1c">148</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.18.18.5.5.2.m2.1d">148</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS2.25.25" style="width:400.6pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.25.25.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.25.25.7.8.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.25.25.7.8.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.25.25.7.8.1.1.1">Ablation model size</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.19.19.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.19.19.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.19.19.1.1.2.1">
<span class="ltx_p" id="A7.SS2.19.19.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.19.19.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.19.19.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.19.19.1.1.1.1">
<span class="ltx_p" id="A7.SS2.19.19.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.19.19.1.1.1.1.1.m1.5"><semantics id="A7.SS2.19.19.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.19.19.1.1.1.1.1.m1.5b"><list id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.19.19.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.19.19.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.19.19.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.23.23.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.23.23.5.5.5">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.23.23.5.5.5.1">
<span class="ltx_p" id="A7.SS2.23.23.5.5.5.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.23.23.5.5.5.1.1.1">parameters</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.23.23.5.5.4">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.23.23.5.5.4.4">
<span class="ltx_p" id="A7.SS2.23.23.5.5.4.4.4" style="width:227.6pt;"><math alttext="[50" class="ltx_math_unparsed" display="inline" id="A7.SS2.20.20.2.2.1.1.1.m1.1"><semantics id="A7.SS2.20.20.2.2.1.1.1.m1.1a"><mrow id="A7.SS2.20.20.2.2.1.1.1.m1.1b"><mo id="A7.SS2.20.20.2.2.1.1.1.m1.1.1" stretchy="false">[</mo><mn id="A7.SS2.20.20.2.2.1.1.1.m1.1.2">50</mn></mrow><annotation encoding="application/x-tex" id="A7.SS2.20.20.2.2.1.1.1.m1.1c">[50</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.20.20.2.2.1.1.1.m1.1d">[ 50</annotation></semantics></math>m, <math alttext="150" class="ltx_Math" display="inline" id="A7.SS2.21.21.3.3.2.2.2.m2.1"><semantics id="A7.SS2.21.21.3.3.2.2.2.m2.1a"><mn id="A7.SS2.21.21.3.3.2.2.2.m2.1.1" xref="A7.SS2.21.21.3.3.2.2.2.m2.1.1.cmml">150</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.21.21.3.3.2.2.2.m2.1b"><cn id="A7.SS2.21.21.3.3.2.2.2.m2.1.1.cmml" type="integer" xref="A7.SS2.21.21.3.3.2.2.2.m2.1.1">150</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.21.21.3.3.2.2.2.m2.1c">150</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.21.21.3.3.2.2.2.m2.1d">150</annotation></semantics></math>m, <math alttext="400" class="ltx_Math" display="inline" id="A7.SS2.22.22.4.4.3.3.3.m3.1"><semantics id="A7.SS2.22.22.4.4.3.3.3.m3.1a"><mn id="A7.SS2.22.22.4.4.3.3.3.m3.1.1" xref="A7.SS2.22.22.4.4.3.3.3.m3.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.22.22.4.4.3.3.3.m3.1b"><cn id="A7.SS2.22.22.4.4.3.3.3.m3.1.1.cmml" type="integer" xref="A7.SS2.22.22.4.4.3.3.3.m3.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.22.22.4.4.3.3.3.m3.1c">400</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.22.22.4.4.3.3.3.m3.1d">400</annotation></semantics></math>m<math alttext="]" class="ltx_Math" display="inline" id="A7.SS2.23.23.5.5.4.4.4.m4.1"><semantics id="A7.SS2.23.23.5.5.4.4.4.m4.1a"><mo id="A7.SS2.23.23.5.5.4.4.4.m4.1.1" stretchy="false" xref="A7.SS2.23.23.5.5.4.4.4.m4.1.1.cmml">]</mo><annotation-xml encoding="MathML-Content" id="A7.SS2.23.23.5.5.4.4.4.m4.1b"><ci id="A7.SS2.23.23.5.5.4.4.4.m4.1.1.cmml" xref="A7.SS2.23.23.5.5.4.4.4.m4.1.1">]</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.23.23.5.5.4.4.4.m4.1c">]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.23.23.5.5.4.4.4.m4.1d">]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.25.25.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.25.25.7.7.2">Compute time: <math alttext="30" class="ltx_Math" display="inline" id="A7.SS2.24.24.6.6.1.m1.1"><semantics id="A7.SS2.24.24.6.6.1.m1.1a"><mn id="A7.SS2.24.24.6.6.1.m1.1.1" xref="A7.SS2.24.24.6.6.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.24.24.6.6.1.m1.1b"><cn id="A7.SS2.24.24.6.6.1.m1.1.1.cmml" type="integer" xref="A7.SS2.24.24.6.6.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.24.24.6.6.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.24.24.6.6.1.m1.1d">30</annotation></semantics></math> hours (train) and <math alttext="89" class="ltx_Math" display="inline" id="A7.SS2.25.25.7.7.2.m2.1"><semantics id="A7.SS2.25.25.7.7.2.m2.1a"><mn id="A7.SS2.25.25.7.7.2.m2.1.1" xref="A7.SS2.25.25.7.7.2.m2.1.1.cmml">89</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.25.25.7.7.2.m2.1b"><cn id="A7.SS2.25.25.7.7.2.m2.1.1.cmml" type="integer" xref="A7.SS2.25.25.7.7.2.m2.1.1">89</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.25.25.7.7.2.m2.1c">89</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.25.25.7.7.2.m2.1d">89</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS2.30.30" style="width:400.6pt;height:81.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.30.30.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.30.30.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.30.30.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.30.30.5.6.1.1.1">Ablation sequence mixer</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A3.F3" title="Figure C ‚Ä£ C.1 The three phases are robust to sensible hyperparameter choices ‚Ä£ Appendix C Additional analysis of the learning dynamics (Section 2.1) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">C</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.26.26.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.26.26.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.26.26.1.1.2.1">
<span class="ltx_p" id="A7.SS2.26.26.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.26.26.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.26.26.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.26.26.1.1.1.1">
<span class="ltx_p" id="A7.SS2.26.26.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.26.26.1.1.1.1.1.m1.5"><semantics id="A7.SS2.26.26.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.26.26.1.1.1.1.1.m1.5b"><list id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.26.26.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.26.26.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.26.26.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.28.28.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.28.28.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.28.28.3.3.3.1">
<span class="ltx_p" id="A7.SS2.28.28.3.3.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.28.28.3.3.3.1.1.1">sequence_mixer</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.28.28.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.28.28.3.3.2.2">
<span class="ltx_p" id="A7.SS2.28.28.3.3.2.2.2" style="width:227.6pt;"><math alttext="[" class="ltx_Math" display="inline" id="A7.SS2.27.27.2.2.1.1.1.m1.1"><semantics id="A7.SS2.27.27.2.2.1.1.1.m1.1a"><mo id="A7.SS2.27.27.2.2.1.1.1.m1.1.1" stretchy="false" xref="A7.SS2.27.27.2.2.1.1.1.m1.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="A7.SS2.27.27.2.2.1.1.1.m1.1b"><ci id="A7.SS2.27.27.2.2.1.1.1.m1.1.1.cmml" xref="A7.SS2.27.27.2.2.1.1.1.m1.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.27.27.2.2.1.1.1.m1.1c">[</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.27.27.2.2.1.1.1.m1.1d">[</annotation></semantics></math>Attention, RG-LRU <cite class="ltx_cite ltx_citemacro_citep">(De et¬†al., <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#bib.bib12" title="">2024</a>)</cite><math alttext="]" class="ltx_Math" display="inline" id="A7.SS2.28.28.3.3.2.2.2.m2.1"><semantics id="A7.SS2.28.28.3.3.2.2.2.m2.1a"><mo id="A7.SS2.28.28.3.3.2.2.2.m2.1.1" stretchy="false" xref="A7.SS2.28.28.3.3.2.2.2.m2.1.1.cmml">]</mo><annotation-xml encoding="MathML-Content" id="A7.SS2.28.28.3.3.2.2.2.m2.1b"><ci id="A7.SS2.28.28.3.3.2.2.2.m2.1.1.cmml" xref="A7.SS2.28.28.3.3.2.2.2.m2.1.1">]</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.28.28.3.3.2.2.2.m2.1c">]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.28.28.3.3.2.2.2.m2.1d">]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.30.30.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.30.30.5.5.2">Compute time: <math alttext="32" class="ltx_Math" display="inline" id="A7.SS2.29.29.4.4.1.m1.1"><semantics id="A7.SS2.29.29.4.4.1.m1.1a"><mn id="A7.SS2.29.29.4.4.1.m1.1.1" xref="A7.SS2.29.29.4.4.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.29.29.4.4.1.m1.1b"><cn id="A7.SS2.29.29.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS2.29.29.4.4.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.29.29.4.4.1.m1.1c">32</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.29.29.4.4.1.m1.1d">32</annotation></semantics></math> hours (train) and <math alttext="15" class="ltx_Math" display="inline" id="A7.SS2.30.30.5.5.2.m2.1"><semantics id="A7.SS2.30.30.5.5.2.m2.1a"><mn id="A7.SS2.30.30.5.5.2.m2.1.1" xref="A7.SS2.30.30.5.5.2.m2.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.30.30.5.5.2.m2.1b"><cn id="A7.SS2.30.30.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS2.30.30.5.5.2.m2.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.30.30.5.5.2.m2.1c">15</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.30.30.5.5.2.m2.1d">15</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS2.36.36" style="width:400.6pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS2.36.36.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS2.36.36.6.7.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS2.36.36.6.7.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS2.36.36.6.7.1.1.1">Ablation template variety</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A2.F1" title="Figure A ‚Ä£ B.1 Rationale behind our design choices ‚Ä£ Appendix B Experimental setup ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">A</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS2.31.31.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.31.31.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.31.31.1.1.2.1">
<span class="ltx_p" id="A7.SS2.31.31.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.31.31.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS2.31.31.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.31.31.1.1.1.1">
<span class="ltx_p" id="A7.SS2.31.31.1.1.1.1.1" style="width:227.6pt;"><math alttext="[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]" class="ltx_Math" display="inline" id="A7.SS2.31.31.1.1.1.1.1.m1.5"><semantics id="A7.SS2.31.31.1.1.1.1.1.m1.5a"><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml">[</mo><msup id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.cmml"><mo id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3a" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.cmml">‚àí</mo><mn id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.2.cmml">4</mn></mrow></msup><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚ãÖ</mo><msup id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.cmml"><mo id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3a" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.cmml">‚àí</mo><mn id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚ãÖ</mo><msup id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.cmml"><mo id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3a" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.cmml">‚àí</mo><mn id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚ãÖ</mo><msup id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.cmml"><mo id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3a" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.cmml">‚àí</mo><mn id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml">4</mn></mrow></msup></mrow><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.2.cmml">1.6</mn><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.1" lspace="0.222em" rspace="0.222em" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚ãÖ</mo><msup id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.cmml"><mn id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.2.cmml">10</mn><mrow id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.cmml"><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3a" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.cmml">‚àí</mo><mn id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.2" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.31.31.1.1.1.1.1.m1.5b"><list id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1">superscript</csymbol><cn id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.2">10</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3"><minus id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3"></minus><cn id="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.1.1.1.1.3.2">4</cn></apply></apply><apply id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2"><ci id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.1">‚ãÖ</ci><cn id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.2">2</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3">superscript</csymbol><cn id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.2">10</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3"><minus id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3"></minus><cn id="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.2.2.2.2.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3"><ci id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.1">‚ãÖ</ci><cn id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.2">4</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3">superscript</csymbol><cn id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.2">10</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3"><minus id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3"></minus><cn id="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.3.3.3.3.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4"><ci id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.1">‚ãÖ</ci><cn id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.2">8</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3">superscript</csymbol><cn id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.2">10</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3"><minus id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3"></minus><cn id="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.4.4.4.4.3.3.2">4</cn></apply></apply></apply><apply id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5"><ci id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.1">‚ãÖ</ci><cn id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="float" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.2">1.6</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3"><csymbol cd="ambiguous" id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3">superscript</csymbol><cn id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.2">10</cn><apply id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3"><minus id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.1.cmml" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3"></minus><cn id="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.2.cmml" type="integer" xref="A7.SS2.31.31.1.1.1.1.1.m1.5.5.5.5.3.3.2">3</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.31.31.1.1.1.1.1.m1.5c">[10^{-4},2\cdot 10^{-4},4\cdot 10^{-4},8\cdot 10^{-4},1.6\cdot 10^{-3}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.31.31.1.1.1.1.1.m1.5d">[ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 2 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 8 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT , 1.6 ‚ãÖ 10 start_POSTSUPERSCRIPT - 3 end_POSTSUPERSCRIPT ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.33.33.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.33.33.3.3.3">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.33.33.3.3.3.1">
<span class="ltx_p" id="A7.SS2.33.33.3.3.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.33.33.3.3.3.1.1.1">shuffle_templates</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.33.33.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.33.33.3.3.2.2">
<span class="ltx_p" id="A7.SS2.33.33.3.3.2.2.2" style="width:227.6pt;"><math alttext="[" class="ltx_Math" display="inline" id="A7.SS2.32.32.2.2.1.1.1.m1.1"><semantics id="A7.SS2.32.32.2.2.1.1.1.m1.1a"><mo id="A7.SS2.32.32.2.2.1.1.1.m1.1.1" stretchy="false" xref="A7.SS2.32.32.2.2.1.1.1.m1.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="A7.SS2.32.32.2.2.1.1.1.m1.1b"><ci id="A7.SS2.32.32.2.2.1.1.1.m1.1.1.cmml" xref="A7.SS2.32.32.2.2.1.1.1.m1.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.32.32.2.2.1.1.1.m1.1c">[</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.32.32.2.2.1.1.1.m1.1d">[</annotation></semantics></math>True, False<math alttext="]" class="ltx_Math" display="inline" id="A7.SS2.33.33.3.3.2.2.2.m2.1"><semantics id="A7.SS2.33.33.3.3.2.2.2.m2.1a"><mo id="A7.SS2.33.33.3.3.2.2.2.m2.1.1" stretchy="false" xref="A7.SS2.33.33.3.3.2.2.2.m2.1.1.cmml">]</mo><annotation-xml encoding="MathML-Content" id="A7.SS2.33.33.3.3.2.2.2.m2.1b"><ci id="A7.SS2.33.33.3.3.2.2.2.m2.1.1.cmml" xref="A7.SS2.33.33.3.3.2.2.2.m2.1.1">]</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.33.33.3.3.2.2.2.m2.1c">]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.33.33.3.3.2.2.2.m2.1d">]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.34.34.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.34.34.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.34.34.4.4.2.1">
<span class="ltx_p" id="A7.SS2.34.34.4.4.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS2.34.34.4.4.2.1.1.1">templates_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS2.34.34.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS2.34.34.4.4.1.1">
<span class="ltx_p" id="A7.SS2.34.34.4.4.1.1.1" style="width:227.6pt;"><math alttext="[1,2,4,8,16]" class="ltx_Math" display="inline" id="A7.SS2.34.34.4.4.1.1.1.m1.5"><semantics id="A7.SS2.34.34.4.4.1.1.1.m1.5a"><mrow id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml"><mo id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2.1" stretchy="false" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml">[</mo><mn id="A7.SS2.34.34.4.4.1.1.1.m1.1.1" xref="A7.SS2.34.34.4.4.1.1.1.m1.1.1.cmml">1</mn><mo id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2.2" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.34.34.4.4.1.1.1.m1.2.2" xref="A7.SS2.34.34.4.4.1.1.1.m1.2.2.cmml">2</mn><mo id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2.3" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.34.34.4.4.1.1.1.m1.3.3" xref="A7.SS2.34.34.4.4.1.1.1.m1.3.3.cmml">4</mn><mo id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2.4" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.34.34.4.4.1.1.1.m1.4.4" xref="A7.SS2.34.34.4.4.1.1.1.m1.4.4.cmml">8</mn><mo id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2.5" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml">,</mo><mn id="A7.SS2.34.34.4.4.1.1.1.m1.5.5" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.5.cmml">16</mn><mo id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2.6" stretchy="false" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS2.34.34.4.4.1.1.1.m1.5b"><list id="A7.SS2.34.34.4.4.1.1.1.m1.5.6.1.cmml" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.6.2"><cn id="A7.SS2.34.34.4.4.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS2.34.34.4.4.1.1.1.m1.1.1">1</cn><cn id="A7.SS2.34.34.4.4.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS2.34.34.4.4.1.1.1.m1.2.2">2</cn><cn id="A7.SS2.34.34.4.4.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS2.34.34.4.4.1.1.1.m1.3.3">4</cn><cn id="A7.SS2.34.34.4.4.1.1.1.m1.4.4.cmml" type="integer" xref="A7.SS2.34.34.4.4.1.1.1.m1.4.4">8</cn><cn id="A7.SS2.34.34.4.4.1.1.1.m1.5.5.cmml" type="integer" xref="A7.SS2.34.34.4.4.1.1.1.m1.5.5">16</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.34.34.4.4.1.1.1.m1.5c">[1,2,4,8,16]</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.34.34.4.4.1.1.1.m1.5d">[ 1 , 2 , 4 , 8 , 16 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS2.36.36.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS2.36.36.6.6.2">Compute time: <math alttext="163" class="ltx_Math" display="inline" id="A7.SS2.35.35.5.5.1.m1.1"><semantics id="A7.SS2.35.35.5.5.1.m1.1a"><mn id="A7.SS2.35.35.5.5.1.m1.1.1" xref="A7.SS2.35.35.5.5.1.m1.1.1.cmml">163</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.35.35.5.5.1.m1.1b"><cn id="A7.SS2.35.35.5.5.1.m1.1.1.cmml" type="integer" xref="A7.SS2.35.35.5.5.1.m1.1.1">163</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.35.35.5.5.1.m1.1c">163</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.35.35.5.5.1.m1.1d">163</annotation></semantics></math> hours (train) and <math alttext="53" class="ltx_Math" display="inline" id="A7.SS2.36.36.6.6.2.m2.1"><semantics id="A7.SS2.36.36.6.6.2.m2.1a"><mn id="A7.SS2.36.36.6.6.2.m2.1.1" xref="A7.SS2.36.36.6.6.2.m2.1.1.cmml">53</mn><annotation-xml encoding="MathML-Content" id="A7.SS2.36.36.6.6.2.m2.1b"><cn id="A7.SS2.36.36.6.6.2.m2.1.1.cmml" type="integer" xref="A7.SS2.36.36.6.6.2.m2.1.1">53</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS2.36.36.6.6.2.m2.1c">53</annotation><annotation encoding="application/x-llamapun" id="A7.SS2.36.36.6.6.2.m2.1d">53</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A7.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.3 </span>Hyperparameters for Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.SS2" title="2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2.2</span></a>
</h4>
<figure class="ltx_table" id="A7.SS3.5">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" id="A7.SS3.4.4" style="width:400.6pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS3.4.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS3.4.4.4.5.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS3.4.4.4.5.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS3.4.4.4.5.1.1.1">Attention patching experiment</span> (Figures¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F4" title="Figure D ‚Ä£ D.1 Implementation of the attention patching experiment ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">D</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS3.1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS3.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS3.1.1.1.1.2.1">
<span class="ltx_p" id="A7.SS3.1.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS3.1.1.1.1.2.1.1.1">start_patching</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS3.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS3.1.1.1.1.1.1">
<span class="ltx_p" id="A7.SS3.1.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[0\mathrm{k},0.5\mathrm{k},1\mathrm{k},2\mathrm{k},4\mathrm{k},8\mathrm{k},16%
\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS3.1.1.1.1.1.1.1.m1.7"><semantics id="A7.SS3.1.1.1.1.1.1.1.m1.7a"><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">0</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.9" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">0.5</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.10" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">1</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.11" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">2</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.12" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">4</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.13" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.2.cmml">8</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.14" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.2" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.2.cmml">16</mn><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.1" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.1.1.1.1.1.1.1.m1.7b"><list id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.8.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7"><apply id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.2">0</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="float" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.2">0.5</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.2">1</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.2">2</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.2">4</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6"><times id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.2">8</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7"><times id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.2">16</cn><ci id="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS3.1.1.1.1.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.1.1.1.1.1.1.1.m1.7c">[0\mathrm{k},0.5\mathrm{k},1\mathrm{k},2\mathrm{k},4\mathrm{k},8\mathrm{k},16%
\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.1.1.1.1.1.1.1.m1.7d">[ 0 roman_k , 0.5 roman_k , 1 roman_k , 2 roman_k , 4 roman_k , 8 roman_k , 16 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS3.2.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS3.2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS3.2.2.2.2.2.1">
<span class="ltx_p" id="A7.SS3.2.2.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS3.2.2.2.2.2.1.1.1">reference_patching</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS3.2.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS3.2.2.2.2.1.1">
<span class="ltx_p" id="A7.SS3.2.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[0\mathrm{k},0.5\mathrm{k},1\mathrm{k},2\mathrm{k},4\mathrm{k},8\mathrm{k},16%
\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS3.2.2.2.2.1.1.1.m1.7"><semantics id="A7.SS3.2.2.2.2.1.1.1.m1.7a"><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.2.cmml">0</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.9" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.2.cmml">0.5</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.10" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.2.cmml">1</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.11" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.2.cmml">2</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.12" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.2.cmml">4</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.13" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.2.cmml">8</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.14" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.2" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.2.cmml">16</mn><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.1" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.2.2.2.2.1.1.1.m1.7b"><list id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.8.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7"><apply id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.2">0</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="float" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.2">0.5</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.2">1</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4"><times id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.2">2</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5"><times id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.2">4</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6"><times id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.2">8</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7"><times id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.2">16</cn><ci id="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS3.2.2.2.2.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.2.2.2.2.1.1.1.m1.7c">[0\mathrm{k},0.5\mathrm{k},1\mathrm{k},2\mathrm{k},4\mathrm{k},8\mathrm{k},16%
\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.2.2.2.2.1.1.1.m1.7d">[ 0 roman_k , 0.5 roman_k , 1 roman_k , 2 roman_k , 4 roman_k , 8 roman_k , 16 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS3.4.4.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS3.4.4.4.4.2">Compute time: <math alttext="73" class="ltx_Math" display="inline" id="A7.SS3.3.3.3.3.1.m1.1"><semantics id="A7.SS3.3.3.3.3.1.m1.1a"><mn id="A7.SS3.3.3.3.3.1.m1.1.1" xref="A7.SS3.3.3.3.3.1.m1.1.1.cmml">73</mn><annotation-xml encoding="MathML-Content" id="A7.SS3.3.3.3.3.1.m1.1b"><cn id="A7.SS3.3.3.3.3.1.m1.1.1.cmml" type="integer" xref="A7.SS3.3.3.3.3.1.m1.1.1">73</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.3.3.3.3.1.m1.1c">73</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.3.3.3.3.1.m1.1d">73</annotation></semantics></math> hours (train) and <math alttext="160" class="ltx_Math" display="inline" id="A7.SS3.4.4.4.4.2.m2.1"><semantics id="A7.SS3.4.4.4.4.2.m2.1a"><mn id="A7.SS3.4.4.4.4.2.m2.1.1" xref="A7.SS3.4.4.4.4.2.m2.1.1.cmml">160</mn><annotation-xml encoding="MathML-Content" id="A7.SS3.4.4.4.4.2.m2.1b"><cn id="A7.SS3.4.4.4.4.2.m2.1.1.cmml" type="integer" xref="A7.SS3.4.4.4.4.2.m2.1.1">160</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.4.4.4.4.2.m2.1c">160</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.4.4.4.4.2.m2.1d">160</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="A7.SS3.5.5" style="width:400.6pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS3.5.5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS3.5.5.1.2.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS3.5.5.1.2.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS3.5.5.1.2.1.1.1">Attention pattern analysis</span> (Figures¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F3" title="Figure 3 ‚Ä£ 2.2 The attention-based circuits supporting recall are created during the loss plateau ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A4.F6" title="Figure F ‚Ä£ D.2 Details of the attention pattern analysis ‚Ä£ Appendix D Details of the mechanistic study and additional analyses (Section 2.2) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">F</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS3.5.5.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS3.5.5.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS3.5.5.1.1.2.1">
<span class="ltx_p" id="A7.SS3.5.5.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS3.5.5.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS3.5.5.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS3.5.5.1.1.1.1">
<span class="ltx_p" id="A7.SS3.5.5.1.1.1.1.1" style="width:227.6pt;"><math alttext="4\cdot 10^{-4}" class="ltx_Math" display="inline" id="A7.SS3.5.5.1.1.1.1.1.m1.1"><semantics id="A7.SS3.5.5.1.1.1.1.1.m1.1a"><mrow id="A7.SS3.5.5.1.1.1.1.1.m1.1.1" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.cmml"><mn id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.2" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.2.cmml">4</mn><mo id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.1.cmml">‚ãÖ</mo><msup id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.cmml"><mn id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.2" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.cmml"><mo id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3a" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.2" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A7.SS3.5.5.1.1.1.1.1.m1.1b"><apply id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.cmml" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1"><ci id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.1.cmml" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.1">‚ãÖ</ci><cn id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.2">4</cn><apply id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.cmml" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.1.cmml" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3">superscript</csymbol><cn id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.2">10</cn><apply id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.cmml" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3"><minus id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.1.cmml" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3"></minus><cn id="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A7.SS3.5.5.1.1.1.1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS3.5.5.1.1.1.1.1.m1.1c">4\cdot 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A7.SS3.5.5.1.1.1.1.1.m1.1d">4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS3.5.5.1.3.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS3.5.5.1.3.1.1">Run taken from results of Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S2.F2" title="Figure 2 ‚Ä£ 2 How language models acquire knowledge during learning ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">2</span></a>.</td>
</tr>
</tbody>
</table>
</span></div>
</div>
</div>
</figure>
</section>
<section class="ltx_subsection" id="A7.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.4 </span>Hyperparameters for Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3" title="3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">3</span></a>
</h4>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS4.p1">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS4.p1.5" style="width:400.6pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS4.p1.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS4.p1.5.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS4.p1.5.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS4.p1.5.5.6.1.1.1">Inverse power law distribution</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F7" title="Figure G ‚Ä£ E.1 Learning curves for different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">G</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS4.p1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.1.1.1.2.1">
<span class="ltx_p" id="A7.SS4.p1.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p1.1.1.1.2.1.1.1">n_individuals</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.1.1.1.1.1">
<span class="ltx_p" id="A7.SS4.p1.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p1.1.1.1.1.1.1.m1.7"><semantics id="A7.SS4.p1.1.1.1.1.1.1.m1.7a"><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.9" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.10" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.11" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.12" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.13" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.2.cmml">128</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.14" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.2" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.2.cmml">256</mn><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.1" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p1.1.1.1.1.1.1.m1.7b"><list id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.8.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7"><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.2">128</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7"><times id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.2">256</cn><ci id="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS4.p1.1.1.1.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p1.1.1.1.1.1.1.m1.7c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p1.1.1.1.1.1.1.m1.7d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k , 128 roman_k , 256 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p1.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p1.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.2.2.2.2.1">
<span class="ltx_p" id="A7.SS4.p1.2.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p1.2.2.2.2.1.1.1">training_steps</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p1.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.2.2.2.1.1">
<span class="ltx_p" id="A7.SS4.p1.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[8\mathrm{k},16\mathrm{k},32\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p1.2.2.2.1.1.1.m1.3"><semantics id="A7.SS4.p1.2.2.2.1.1.1.m1.3a"><mrow id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.4.cmml"><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.4" stretchy="false" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.4.cmml">[</mo><mrow id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.2.cmml">8</mn><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.5" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.4.cmml">,</mo><mrow id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.2.cmml">16</mn><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.6" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.4.cmml">,</mo><mrow id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.2.cmml">32</mn><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.7" stretchy="false" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p1.2.2.2.1.1.1.m1.3b"><list id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.4.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3"><apply id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.2">8</cn><ci id="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.2">16</cn><ci id="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.2">32</cn><ci id="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p1.2.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p1.2.2.2.1.1.1.m1.3c">[8\mathrm{k},16\mathrm{k},32\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p1.2.2.2.1.1.1.m1.3d">[ 8 roman_k , 16 roman_k , 32 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p1.5.5.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p1.5.5.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.5.5.7.1.1.1">
<span class="ltx_p" id="A7.SS4.p1.5.5.7.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p1.5.5.7.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p1.5.5.7.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.5.5.7.1.2.1">
<span class="ltx_p" id="A7.SS4.p1.5.5.7.1.2.1.1" style="width:227.6pt;">Inverse power law</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p1.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p1.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.3.3.3.2.1">
<span class="ltx_p" id="A7.SS4.p1.3.3.3.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p1.3.3.3.2.1.1.1">alpha</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p1.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p1.3.3.3.1.1">
<span class="ltx_p" id="A7.SS4.p1.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="[0,0.2,0.4,0.6,0.8,1]" class="ltx_Math" display="inline" id="A7.SS4.p1.3.3.3.1.1.1.m1.6"><semantics id="A7.SS4.p1.3.3.3.1.1.1.m1.6a"><mrow id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml"><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.1" stretchy="false" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">[</mo><mn id="A7.SS4.p1.3.3.3.1.1.1.m1.1.1" xref="A7.SS4.p1.3.3.3.1.1.1.m1.1.1.cmml">0</mn><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.2" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">,</mo><mn id="A7.SS4.p1.3.3.3.1.1.1.m1.2.2" xref="A7.SS4.p1.3.3.3.1.1.1.m1.2.2.cmml">0.2</mn><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.3" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">,</mo><mn id="A7.SS4.p1.3.3.3.1.1.1.m1.3.3" xref="A7.SS4.p1.3.3.3.1.1.1.m1.3.3.cmml">0.4</mn><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.4" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">,</mo><mn id="A7.SS4.p1.3.3.3.1.1.1.m1.4.4" xref="A7.SS4.p1.3.3.3.1.1.1.m1.4.4.cmml">0.6</mn><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.5" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">,</mo><mn id="A7.SS4.p1.3.3.3.1.1.1.m1.5.5" xref="A7.SS4.p1.3.3.3.1.1.1.m1.5.5.cmml">0.8</mn><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.6" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">,</mo><mn id="A7.SS4.p1.3.3.3.1.1.1.m1.6.6" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.6.cmml">1</mn><mo id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2.7" stretchy="false" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p1.3.3.3.1.1.1.m1.6b"><list id="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.1.cmml" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.7.2"><cn id="A7.SS4.p1.3.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p1.3.3.3.1.1.1.m1.1.1">0</cn><cn id="A7.SS4.p1.3.3.3.1.1.1.m1.2.2.cmml" type="float" xref="A7.SS4.p1.3.3.3.1.1.1.m1.2.2">0.2</cn><cn id="A7.SS4.p1.3.3.3.1.1.1.m1.3.3.cmml" type="float" xref="A7.SS4.p1.3.3.3.1.1.1.m1.3.3">0.4</cn><cn id="A7.SS4.p1.3.3.3.1.1.1.m1.4.4.cmml" type="float" xref="A7.SS4.p1.3.3.3.1.1.1.m1.4.4">0.6</cn><cn id="A7.SS4.p1.3.3.3.1.1.1.m1.5.5.cmml" type="float" xref="A7.SS4.p1.3.3.3.1.1.1.m1.5.5">0.8</cn><cn id="A7.SS4.p1.3.3.3.1.1.1.m1.6.6.cmml" type="integer" xref="A7.SS4.p1.3.3.3.1.1.1.m1.6.6">1</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p1.3.3.3.1.1.1.m1.6c">[0,0.2,0.4,0.6,0.8,1]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p1.3.3.3.1.1.1.m1.6d">[ 0 , 0.2 , 0.4 , 0.6 , 0.8 , 1 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p1.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS4.p1.5.5.5.2">Compute time: <math alttext="1584" class="ltx_Math" display="inline" id="A7.SS4.p1.4.4.4.1.m1.1"><semantics id="A7.SS4.p1.4.4.4.1.m1.1a"><mn id="A7.SS4.p1.4.4.4.1.m1.1.1" xref="A7.SS4.p1.4.4.4.1.m1.1.1.cmml">1584</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p1.4.4.4.1.m1.1b"><cn id="A7.SS4.p1.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p1.4.4.4.1.m1.1.1">1584</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p1.4.4.4.1.m1.1c">1584</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p1.4.4.4.1.m1.1d">1584</annotation></semantics></math> hours (train) and <math alttext="521" class="ltx_Math" display="inline" id="A7.SS4.p1.5.5.5.2.m2.1"><semantics id="A7.SS4.p1.5.5.5.2.m2.1a"><mn id="A7.SS4.p1.5.5.5.2.m2.1.1" xref="A7.SS4.p1.5.5.5.2.m2.1.1.cmml">521</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p1.5.5.5.2.m2.1b"><cn id="A7.SS4.p1.5.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS4.p1.5.5.5.2.m2.1.1">521</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p1.5.5.5.2.m2.1c">521</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p1.5.5.5.2.m2.1d">521</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS4.p2">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS4.p2.5" style="width:400.6pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS4.p2.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS4.p2.5.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS4.p2.5.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS4.p2.5.5.6.1.1.1">Celebrities distribution (vary number of individuals)</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F8" title="Figure H ‚Ä£ E.1 Learning curves for different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">H</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS4.p2.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.1.1.1.2.1">
<span class="ltx_p" id="A7.SS4.p2.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p2.1.1.1.2.1.1.1">n_individuals</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p2.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.1.1.1.1.1">
<span class="ltx_p" id="A7.SS4.p2.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p2.1.1.1.1.1.1.m1.7"><semantics id="A7.SS4.p2.1.1.1.1.1.1.m1.7a"><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.9" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.10" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.11" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.12" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.13" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.2.cmml">128</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.14" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.2" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.2.cmml">256</mn><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.1" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p2.1.1.1.1.1.1.m1.7b"><list id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.8.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7"><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.2">128</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7"><times id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.2">256</cn><ci id="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS4.p2.1.1.1.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p2.1.1.1.1.1.1.m1.7c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p2.1.1.1.1.1.1.m1.7d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k , 128 roman_k , 256 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p2.5.5.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p2.5.5.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.5.5.7.1.1.1">
<span class="ltx_p" id="A7.SS4.p2.5.5.7.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p2.5.5.7.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p2.5.5.7.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.5.5.7.1.2.1">
<span class="ltx_p" id="A7.SS4.p2.5.5.7.1.2.1.1" style="width:227.6pt;">Celebrities</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p2.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.2.2.2.2.1">
<span class="ltx_p" id="A7.SS4.p2.2.2.2.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p2.2.2.2.2.1.1.1">n_celebrities</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p2.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.2.2.2.1.1">
<span class="ltx_p" id="A7.SS4.p2.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},16\mathrm{k},64\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p2.2.2.2.1.1.1.m1.3"><semantics id="A7.SS4.p2.2.2.2.1.1.1.m1.3a"><mrow id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.4.cmml"><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.4" stretchy="false" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.4.cmml">[</mo><mrow id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.5" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.4.cmml">,</mo><mrow id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.2.cmml">16</mn><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.6" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.4.cmml">,</mo><mrow id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.2.cmml">64</mn><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.7" stretchy="false" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p2.2.2.2.1.1.1.m1.3b"><list id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.4.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3"><apply id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.2">16</cn><ci id="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.2">64</cn><ci id="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p2.2.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p2.2.2.2.1.1.1.m1.3c">[4\mathrm{k},16\mathrm{k},64\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p2.2.2.2.1.1.1.m1.3d">[ 4 roman_k , 16 roman_k , 64 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p2.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p2.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.3.3.3.2.1">
<span class="ltx_p" id="A7.SS4.p2.3.3.3.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p2.3.3.3.2.1.1.1">weight_celebrities</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p2.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p2.3.3.3.1.1">
<span class="ltx_p" id="A7.SS4.p2.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="[2,4,8,16]" class="ltx_Math" display="inline" id="A7.SS4.p2.3.3.3.1.1.1.m1.4"><semantics id="A7.SS4.p2.3.3.3.1.1.1.m1.4a"><mrow id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml"><mo id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2.1" stretchy="false" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml">[</mo><mn id="A7.SS4.p2.3.3.3.1.1.1.m1.1.1" xref="A7.SS4.p2.3.3.3.1.1.1.m1.1.1.cmml">2</mn><mo id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2.2" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p2.3.3.3.1.1.1.m1.2.2" xref="A7.SS4.p2.3.3.3.1.1.1.m1.2.2.cmml">4</mn><mo id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2.3" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p2.3.3.3.1.1.1.m1.3.3" xref="A7.SS4.p2.3.3.3.1.1.1.m1.3.3.cmml">8</mn><mo id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2.4" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p2.3.3.3.1.1.1.m1.4.4" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.4.cmml">16</mn><mo id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2.5" stretchy="false" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p2.3.3.3.1.1.1.m1.4b"><list id="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.1.cmml" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.5.2"><cn id="A7.SS4.p2.3.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p2.3.3.3.1.1.1.m1.1.1">2</cn><cn id="A7.SS4.p2.3.3.3.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS4.p2.3.3.3.1.1.1.m1.2.2">4</cn><cn id="A7.SS4.p2.3.3.3.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS4.p2.3.3.3.1.1.1.m1.3.3">8</cn><cn id="A7.SS4.p2.3.3.3.1.1.1.m1.4.4.cmml" type="integer" xref="A7.SS4.p2.3.3.3.1.1.1.m1.4.4">16</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p2.3.3.3.1.1.1.m1.4c">[2,4,8,16]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p2.3.3.3.1.1.1.m1.4d">[ 2 , 4 , 8 , 16 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p2.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS4.p2.5.5.5.2">Compute time: <math alttext="1128" class="ltx_Math" display="inline" id="A7.SS4.p2.4.4.4.1.m1.1"><semantics id="A7.SS4.p2.4.4.4.1.m1.1a"><mn id="A7.SS4.p2.4.4.4.1.m1.1.1" xref="A7.SS4.p2.4.4.4.1.m1.1.1.cmml">1128</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p2.4.4.4.1.m1.1b"><cn id="A7.SS4.p2.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p2.4.4.4.1.m1.1.1">1128</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p2.4.4.4.1.m1.1c">1128</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p2.4.4.4.1.m1.1d">1128</annotation></semantics></math> hours (train) and <math alttext="768" class="ltx_Math" display="inline" id="A7.SS4.p2.5.5.5.2.m2.1"><semantics id="A7.SS4.p2.5.5.5.2.m2.1a"><mn id="A7.SS4.p2.5.5.5.2.m2.1.1" xref="A7.SS4.p2.5.5.5.2.m2.1.1.cmml">768</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p2.5.5.5.2.m2.1b"><cn id="A7.SS4.p2.5.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS4.p2.5.5.5.2.m2.1.1">768</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p2.5.5.5.2.m2.1c">768</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p2.5.5.5.2.m2.1d">768</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS4.p3">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS4.p3.5" style="width:400.6pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS4.p3.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS4.p3.5.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS4.p3.5.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS4.p3.5.5.6.1.1.1">Celebrities distribution (vary number of steps)</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F8" title="Figure H ‚Ä£ E.1 Learning curves for different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">H</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS4.p3.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.1.1.1.2.1">
<span class="ltx_p" id="A7.SS4.p3.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p3.1.1.1.2.1.1.1">training_steps</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p3.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.1.1.1.1.1">
<span class="ltx_p" id="A7.SS4.p3.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p3.1.1.1.1.1.1.m1.7"><semantics id="A7.SS4.p3.1.1.1.1.1.1.m1.7a"><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.9" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.10" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.11" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.12" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.13" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.2.cmml">128</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.14" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.2" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.2.cmml">256</mn><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.1" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.1.1.1.1.1.1.m1.7b"><list id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.8.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7"><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.2">128</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7"><times id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.2">256</cn><ci id="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS4.p3.1.1.1.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.1.1.1.1.1.1.m1.7c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.1.1.1.1.1.1.m1.7d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k , 128 roman_k , 256 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p3.5.5.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p3.5.5.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.5.5.7.1.1.1">
<span class="ltx_p" id="A7.SS4.p3.5.5.7.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p3.5.5.7.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p3.5.5.7.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.5.5.7.1.2.1">
<span class="ltx_p" id="A7.SS4.p3.5.5.7.1.2.1.1" style="width:227.6pt;">Celebrities</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p3.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p3.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.2.2.2.2.1">
<span class="ltx_p" id="A7.SS4.p3.2.2.2.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p3.2.2.2.2.1.1.1">n_celebrities</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p3.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.2.2.2.1.1">
<span class="ltx_p" id="A7.SS4.p3.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},16\mathrm{k},64\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p3.2.2.2.1.1.1.m1.3"><semantics id="A7.SS4.p3.2.2.2.1.1.1.m1.3a"><mrow id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.4.cmml"><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.4" stretchy="false" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.4.cmml">[</mo><mrow id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.5" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.4.cmml">,</mo><mrow id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.2.cmml">16</mn><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.6" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.4.cmml">,</mo><mrow id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.2.cmml">64</mn><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.7" stretchy="false" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.2.2.2.1.1.1.m1.3b"><list id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.4.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3"><apply id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.2">16</cn><ci id="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.2">64</cn><ci id="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p3.2.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.2.2.2.1.1.1.m1.3c">[4\mathrm{k},16\mathrm{k},64\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.2.2.2.1.1.1.m1.3d">[ 4 roman_k , 16 roman_k , 64 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p3.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p3.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.3.3.3.2.1">
<span class="ltx_p" id="A7.SS4.p3.3.3.3.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p3.3.3.3.2.1.1.1">weight_celebrities</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p3.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p3.3.3.3.1.1">
<span class="ltx_p" id="A7.SS4.p3.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="[2,4,8,16]" class="ltx_Math" display="inline" id="A7.SS4.p3.3.3.3.1.1.1.m1.4"><semantics id="A7.SS4.p3.3.3.3.1.1.1.m1.4a"><mrow id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml"><mo id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2.1" stretchy="false" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml">[</mo><mn id="A7.SS4.p3.3.3.3.1.1.1.m1.1.1" xref="A7.SS4.p3.3.3.3.1.1.1.m1.1.1.cmml">2</mn><mo id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2.2" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p3.3.3.3.1.1.1.m1.2.2" xref="A7.SS4.p3.3.3.3.1.1.1.m1.2.2.cmml">4</mn><mo id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2.3" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p3.3.3.3.1.1.1.m1.3.3" xref="A7.SS4.p3.3.3.3.1.1.1.m1.3.3.cmml">8</mn><mo id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2.4" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p3.3.3.3.1.1.1.m1.4.4" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.4.cmml">16</mn><mo id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2.5" stretchy="false" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.3.3.3.1.1.1.m1.4b"><list id="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.1.cmml" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.5.2"><cn id="A7.SS4.p3.3.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p3.3.3.3.1.1.1.m1.1.1">2</cn><cn id="A7.SS4.p3.3.3.3.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS4.p3.3.3.3.1.1.1.m1.2.2">4</cn><cn id="A7.SS4.p3.3.3.3.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS4.p3.3.3.3.1.1.1.m1.3.3">8</cn><cn id="A7.SS4.p3.3.3.3.1.1.1.m1.4.4.cmml" type="integer" xref="A7.SS4.p3.3.3.3.1.1.1.m1.4.4">16</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.3.3.3.1.1.1.m1.4c">[2,4,8,16]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.3.3.3.1.1.1.m1.4d">[ 2 , 4 , 8 , 16 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p3.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS4.p3.5.5.5.2">Compute time: <math alttext="1512" class="ltx_Math" display="inline" id="A7.SS4.p3.4.4.4.1.m1.1"><semantics id="A7.SS4.p3.4.4.4.1.m1.1a"><mn id="A7.SS4.p3.4.4.4.1.m1.1.1" xref="A7.SS4.p3.4.4.4.1.m1.1.1.cmml">1512</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.4.4.4.1.m1.1b"><cn id="A7.SS4.p3.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p3.4.4.4.1.m1.1.1">1512</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.4.4.4.1.m1.1c">1512</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.4.4.4.1.m1.1d">1512</annotation></semantics></math> hours (train) and <math alttext="541" class="ltx_Math" display="inline" id="A7.SS4.p3.5.5.5.2.m2.1"><semantics id="A7.SS4.p3.5.5.5.2.m2.1a"><mn id="A7.SS4.p3.5.5.5.2.m2.1.1" xref="A7.SS4.p3.5.5.5.2.m2.1.1.cmml">541</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p3.5.5.5.2.m2.1b"><cn id="A7.SS4.p3.5.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS4.p3.5.5.5.2.m2.1.1">541</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p3.5.5.5.2.m2.1c">541</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p3.5.5.5.2.m2.1d">541</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS4.p4">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS4.p4.5" style="width:400.6pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS4.p4.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS4.p4.5.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS4.p4.5.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS4.p4.5.5.6.1.1.1">Warm-up distribution (vary number of individuals)</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F9" title="Figure I ‚Ä£ E.1 Learning curves for different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">I</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F12" title="Figure L ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">L</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS4.p4.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p4.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.1.1.1.2.1">
<span class="ltx_p" id="A7.SS4.p4.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p4.1.1.1.2.1.1.1">n_individuals</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.p4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.1.1.1.1.1">
<span class="ltx_p" id="A7.SS4.p4.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p4.1.1.1.1.1.1.m1.7"><semantics id="A7.SS4.p4.1.1.1.1.1.1.m1.7a"><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.9" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.10" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.11" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.12" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.13" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.2.cmml">128</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.14" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.2" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.2.cmml">256</mn><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.1" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p4.1.1.1.1.1.1.m1.7b"><list id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.8.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7"><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.2">128</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7"><times id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.2">256</cn><ci id="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS4.p4.1.1.1.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p4.1.1.1.1.1.1.m1.7c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p4.1.1.1.1.1.1.m1.7d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k , 128 roman_k , 256 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p4.5.5.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p4.5.5.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.5.5.7.1.1.1">
<span class="ltx_p" id="A7.SS4.p4.5.5.7.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.p4.5.5.7.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p4.5.5.7.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.5.5.7.1.2.1">
<span class="ltx_p" id="A7.SS4.p4.5.5.7.1.2.1.1" style="width:227.6pt;">Warm-up</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p4.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p4.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.2.2.2.2.1">
<span class="ltx_p" id="A7.SS4.p4.2.2.2.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p4.2.2.2.2.1.1.1">indiv_warmup</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p4.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.2.2.2.1.1">
<span class="ltx_p" id="A7.SS4.p4.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[2\mathrm{k},4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.p4.2.2.2.1.1.1.m1.5"><semantics id="A7.SS4.p4.2.2.2.1.1.1.m1.5a"><mrow id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml">[</mo><mrow id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.2.cmml">2</mn><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.7" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.2.cmml">4</mn><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.8" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.2.cmml">8</mn><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.9" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.2.cmml">16</mn><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.10" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.2.cmml">32</mn><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p4.2.2.2.1.1.1.m1.5b"><list id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.6.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5"><apply id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.2">2</cn><ci id="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.2">4</cn><ci id="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.2">8</cn><ci id="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4"><times id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.2">16</cn><ci id="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5"><times id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.2">32</cn><ci id="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.p4.2.2.2.1.1.1.m1.5.5.5.5.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p4.2.2.2.1.1.1.m1.5c">[2\mathrm{k},4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p4.2.2.2.1.1.1.m1.5d">[ 2 roman_k , 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p4.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p4.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.3.3.3.2.1">
<span class="ltx_p" id="A7.SS4.p4.3.3.3.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.p4.3.3.3.2.1.1.1">epochs_warmup</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.p4.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.p4.3.3.3.1.1">
<span class="ltx_p" id="A7.SS4.p4.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="[1,2,4,8]" class="ltx_Math" display="inline" id="A7.SS4.p4.3.3.3.1.1.1.m1.4"><semantics id="A7.SS4.p4.3.3.3.1.1.1.m1.4a"><mrow id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml"><mo id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2.1" stretchy="false" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml">[</mo><mn id="A7.SS4.p4.3.3.3.1.1.1.m1.1.1" xref="A7.SS4.p4.3.3.3.1.1.1.m1.1.1.cmml">1</mn><mo id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2.2" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p4.3.3.3.1.1.1.m1.2.2" xref="A7.SS4.p4.3.3.3.1.1.1.m1.2.2.cmml">2</mn><mo id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2.3" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p4.3.3.3.1.1.1.m1.3.3" xref="A7.SS4.p4.3.3.3.1.1.1.m1.3.3.cmml">4</mn><mo id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2.4" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.p4.3.3.3.1.1.1.m1.4.4" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.4.cmml">8</mn><mo id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2.5" stretchy="false" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.p4.3.3.3.1.1.1.m1.4b"><list id="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.1.cmml" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.5.2"><cn id="A7.SS4.p4.3.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p4.3.3.3.1.1.1.m1.1.1">1</cn><cn id="A7.SS4.p4.3.3.3.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS4.p4.3.3.3.1.1.1.m1.2.2">2</cn><cn id="A7.SS4.p4.3.3.3.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS4.p4.3.3.3.1.1.1.m1.3.3">4</cn><cn id="A7.SS4.p4.3.3.3.1.1.1.m1.4.4.cmml" type="integer" xref="A7.SS4.p4.3.3.3.1.1.1.m1.4.4">8</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p4.3.3.3.1.1.1.m1.4c">[1,2,4,8]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p4.3.3.3.1.1.1.m1.4d">[ 1 , 2 , 4 , 8 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.p4.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS4.p4.5.5.5.2">Compute time: <math alttext="1944" class="ltx_Math" display="inline" id="A7.SS4.p4.4.4.4.1.m1.1"><semantics id="A7.SS4.p4.4.4.4.1.m1.1a"><mn id="A7.SS4.p4.4.4.4.1.m1.1.1" xref="A7.SS4.p4.4.4.4.1.m1.1.1.cmml">1944</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p4.4.4.4.1.m1.1b"><cn id="A7.SS4.p4.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS4.p4.4.4.4.1.m1.1.1">1944</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p4.4.4.4.1.m1.1c">1944</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p4.4.4.4.1.m1.1d">1944</annotation></semantics></math> hours (train) and <math alttext="1152" class="ltx_Math" display="inline" id="A7.SS4.p4.5.5.5.2.m2.1"><semantics id="A7.SS4.p4.5.5.5.2.m2.1a"><mn id="A7.SS4.p4.5.5.5.2.m2.1.1" xref="A7.SS4.p4.5.5.5.2.m2.1.1.cmml">1152</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.p4.5.5.5.2.m2.1b"><cn id="A7.SS4.p4.5.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS4.p4.5.5.5.2.m2.1.1">1152</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.p4.5.5.5.2.m2.1c">1152</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.p4.5.5.5.2.m2.1d">1152</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<figure class="ltx_table" id="A7.SS4.5">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS4.5.5" style="width:400.6pt;height:108pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS4.5.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS4.5.5.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS4.5.5.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS4.5.5.5.6.1.1.1">Warm-up distribution (vary number of steps)</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S3.F4" title="Figure 4 ‚Ä£ 3 Data distributional properties drive knowledge acquisition ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F9" title="Figure I ‚Ä£ E.1 Learning curves for different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">I</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F10" title="Figure J ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">J</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A5.F11" title="Figure K ‚Ä£ E.2 Extensive comparison of the performance of different data distributions ‚Ä£ Appendix E Additional analysis for the impact of data distribution properties (Section 3) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">K</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS4.1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.1.1.1.1.2.1">
<span class="ltx_p" id="A7.SS4.1.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.1.1.1.1.2.1.1.1">training_steps</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS4.1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.1.1.1.1.1.1">
<span class="ltx_p" id="A7.SS4.1.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.1.1.1.1.1.1.1.m1.7"><semantics id="A7.SS4.1.1.1.1.1.1.1.m1.7a"><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml"><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.8" stretchy="false" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">[</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">4</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.9" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">8</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.10" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">16</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.11" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">32</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.12" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">64</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.13" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.2.cmml">128</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.14" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">,</mo><mrow id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.cmml"><mn id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.2" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.2.cmml">256</mn><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.1" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.1.cmml">‚Å¢</mo><mi id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.3" mathvariant="normal" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.3.cmml">k</mi></mrow><mo id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.15" stretchy="false" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.1.1.1.1.1.1.1.m1.7b"><list id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.8.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7"><apply id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.2">4</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.2">8</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.2">16</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.2">32</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.2">64</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply><apply id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6"><times id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.2">128</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.6.6.6.6.3">k</ci></apply><apply id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7"><times id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.1.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.1"></times><cn id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.2.cmml" type="integer" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.2">256</cn><ci id="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.3.cmml" xref="A7.SS4.1.1.1.1.1.1.1.m1.7.7.7.7.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.1.1.1.1.1.1.1.m1.7c">[4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k},64\mathrm{k},128\mathrm{k},%
256\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.1.1.1.1.1.1.1.m1.7d">[ 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k , 64 roman_k , 128 roman_k , 256 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.5.5.5.7.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.5.5.5.7.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.5.5.5.7.1.1.1">
<span class="ltx_p" id="A7.SS4.5.5.5.7.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS4.5.5.5.7.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.5.5.5.7.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.5.5.5.7.1.2.1">
<span class="ltx_p" id="A7.SS4.5.5.5.7.1.2.1.1" style="width:227.6pt;">Warm-up</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.2.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.2.2.2.2.2.1">
<span class="ltx_p" id="A7.SS4.2.2.2.2.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.2.2.2.2.2.1.1.1">indiv_warmup</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.2.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.2.2.2.2.1.1">
<span class="ltx_p" id="A7.SS4.2.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[2\mathrm{k},4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS4.2.2.2.2.1.1.1.m1.5"><semantics id="A7.SS4.2.2.2.2.1.1.1.m1.5a"><mrow id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml">[</mo><mrow id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.2" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.2.cmml">2</mn><mo id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.1" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.7" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.2" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.2.cmml">4</mn><mo id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.1" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.8" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.2" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.2.cmml">8</mn><mo id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.1" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.9" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.2" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.2.cmml">16</mn><mo id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.1" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.10" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.2" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.2.cmml">32</mn><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.1" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.2.2.2.2.1.1.1.m1.5b"><list id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.6.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5"><apply id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1"><times id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.2">2</cn><ci id="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2"><times id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.2">4</cn><ci id="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3"><times id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.2">8</cn><ci id="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4"><times id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.2">16</cn><ci id="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5"><times id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.2">32</cn><ci id="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS4.2.2.2.2.1.1.1.m1.5.5.5.5.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.2.2.2.2.1.1.1.m1.5c">[2\mathrm{k},4\mathrm{k},8\mathrm{k},16\mathrm{k},32\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.2.2.2.2.1.1.1.m1.5d">[ 2 roman_k , 4 roman_k , 8 roman_k , 16 roman_k , 32 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.3.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.3.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.3.3.3.3.2.1">
<span class="ltx_p" id="A7.SS4.3.3.3.3.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS4.3.3.3.3.2.1.1.1">epochs_warmup</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS4.3.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS4.3.3.3.3.1.1">
<span class="ltx_p" id="A7.SS4.3.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="[1,2,4,8]" class="ltx_Math" display="inline" id="A7.SS4.3.3.3.3.1.1.1.m1.4"><semantics id="A7.SS4.3.3.3.3.1.1.1.m1.4a"><mrow id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml"><mo id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2.1" stretchy="false" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml">[</mo><mn id="A7.SS4.3.3.3.3.1.1.1.m1.1.1" xref="A7.SS4.3.3.3.3.1.1.1.m1.1.1.cmml">1</mn><mo id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2.2" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.3.3.3.3.1.1.1.m1.2.2" xref="A7.SS4.3.3.3.3.1.1.1.m1.2.2.cmml">2</mn><mo id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2.3" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.3.3.3.3.1.1.1.m1.3.3" xref="A7.SS4.3.3.3.3.1.1.1.m1.3.3.cmml">4</mn><mo id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2.4" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml">,</mo><mn id="A7.SS4.3.3.3.3.1.1.1.m1.4.4" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.4.cmml">8</mn><mo id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2.5" stretchy="false" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS4.3.3.3.3.1.1.1.m1.4b"><list id="A7.SS4.3.3.3.3.1.1.1.m1.4.5.1.cmml" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.5.2"><cn id="A7.SS4.3.3.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS4.3.3.3.3.1.1.1.m1.1.1">1</cn><cn id="A7.SS4.3.3.3.3.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS4.3.3.3.3.1.1.1.m1.2.2">2</cn><cn id="A7.SS4.3.3.3.3.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS4.3.3.3.3.1.1.1.m1.3.3">4</cn><cn id="A7.SS4.3.3.3.3.1.1.1.m1.4.4.cmml" type="integer" xref="A7.SS4.3.3.3.3.1.1.1.m1.4.4">8</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.3.3.3.3.1.1.1.m1.4c">[1,2,4,8]</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.3.3.3.3.1.1.1.m1.4d">[ 1 , 2 , 4 , 8 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS4.5.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS4.5.5.5.5.2">Compute time: <math alttext="2808" class="ltx_Math" display="inline" id="A7.SS4.4.4.4.4.1.m1.1"><semantics id="A7.SS4.4.4.4.4.1.m1.1a"><mn id="A7.SS4.4.4.4.4.1.m1.1.1" xref="A7.SS4.4.4.4.4.1.m1.1.1.cmml">2808</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.4.4.4.4.1.m1.1b"><cn id="A7.SS4.4.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS4.4.4.4.4.1.m1.1.1">2808</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.4.4.4.4.1.m1.1c">2808</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.4.4.4.4.1.m1.1d">2808</annotation></semantics></math> hours (train) and <math alttext="1008" class="ltx_Math" display="inline" id="A7.SS4.5.5.5.5.2.m2.1"><semantics id="A7.SS4.5.5.5.5.2.m2.1a"><mn id="A7.SS4.5.5.5.5.2.m2.1.1" xref="A7.SS4.5.5.5.5.2.m2.1.1.cmml">1008</mn><annotation-xml encoding="MathML-Content" id="A7.SS4.5.5.5.5.2.m2.1b"><cn id="A7.SS4.5.5.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS4.5.5.5.5.2.m2.1.1">1008</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS4.5.5.5.5.2.m2.1c">1008</annotation><annotation encoding="application/x-llamapun" id="A7.SS4.5.5.5.5.2.m2.1d">1008</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A7.SS5">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.5 </span>Hyperparameters for Section¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4" title="4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">4</span></a>
</h4>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p1">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS5.p1.3" style="width:400.6pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS5.p1.3.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS5.p1.3.3.4.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS5.p1.3.3.4.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS5.p1.3.3.4.1.1.1">Hallucinations</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F13" title="Figure M ‚Ä£ F.2 Hallucinations ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">M</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS5.p1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p1.1.1.1.2.1">
<span class="ltx_p" id="A7.SS5.p1.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p1.1.1.1.2.1.1.1">lr</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p1.1.1.1.1.1">
<span class="ltx_p" id="A7.SS5.p1.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="4\cdot 10^{-4}" class="ltx_Math" display="inline" id="A7.SS5.p1.1.1.1.1.1.1.m1.1"><semantics id="A7.SS5.p1.1.1.1.1.1.1.m1.1a"><mrow id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.2" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.2.cmml">4</mn><mo id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.1.cmml">‚ãÖ</mo><msup id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.cmml"><mn id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.cmml"><mo id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3a" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.2" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p1.1.1.1.1.1.1.m1.1b"><apply id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.cmml" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1"><ci id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.1">‚ãÖ</ci><cn id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.2">4</cn><apply id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3">superscript</csymbol><cn id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.2">10</cn><apply id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3"><minus id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.1.cmml" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3"></minus><cn id="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A7.SS5.p1.1.1.1.1.1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p1.1.1.1.1.1.1.m1.1c">4\cdot 10^{-4}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p1.1.1.1.1.1.1.m1.1d">4 ‚ãÖ 10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p1.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS5.p1.3.3.3.2">Compute time: <math alttext="3" class="ltx_Math" display="inline" id="A7.SS5.p1.2.2.2.1.m1.1"><semantics id="A7.SS5.p1.2.2.2.1.m1.1a"><mn id="A7.SS5.p1.2.2.2.1.m1.1.1" xref="A7.SS5.p1.2.2.2.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p1.2.2.2.1.m1.1b"><cn id="A7.SS5.p1.2.2.2.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p1.2.2.2.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p1.2.2.2.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p1.2.2.2.1.m1.1d">3</annotation></semantics></math> hours (train) and <math alttext="5" class="ltx_Math" display="inline" id="A7.SS5.p1.3.3.3.2.m2.1"><semantics id="A7.SS5.p1.3.3.3.2.m2.1a"><mn id="A7.SS5.p1.3.3.3.2.m2.1.1" xref="A7.SS5.p1.3.3.3.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p1.3.3.3.2.m2.1b"><cn id="A7.SS5.p1.3.3.3.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p1.3.3.3.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p1.3.3.3.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p1.3.3.3.2.m2.1d">5</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p2">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS5.p2.4" style="width:400.6pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS5.p2.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS5.p2.4.4.5.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS5.p2.4.4.5.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS5.p2.4.4.5.1.1.1">Fine-tuning without replay</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F14" title="Figure N ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">N</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F15" title="Figure O ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">O</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS5.p2.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p2.1.1.1.2.1">
<span class="ltx_p" id="A7.SS5.p2.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p2.1.1.1.2.1.1.1">n_individuals_finetune</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p2.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p2.1.1.1.1.1">
<span class="ltx_p" id="A7.SS5.p2.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="[1\mathrm{k},2\mathrm{k},4\mathrm{k},8\mathrm{k},16\mathrm{k}]" class="ltx_Math" display="inline" id="A7.SS5.p2.1.1.1.1.1.1.m1.5"><semantics id="A7.SS5.p2.1.1.1.1.1.1.m1.5a"><mrow id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml"><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.6" stretchy="false" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml">[</mo><mrow id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.cmml"><mn id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.2" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.2.cmml">1</mn><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.1" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.3" mathvariant="normal" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.3.cmml">k</mi></mrow><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.7" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.cmml"><mn id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.2" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.2.cmml">2</mn><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.1" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.1.cmml">‚Å¢</mo><mi id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.3" mathvariant="normal" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.3.cmml">k</mi></mrow><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.8" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.cmml"><mn id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.2" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.2.cmml">4</mn><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.1" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.1.cmml">‚Å¢</mo><mi id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.3" mathvariant="normal" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.3.cmml">k</mi></mrow><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.9" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.cmml"><mn id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.2" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.2.cmml">8</mn><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.1" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.1.cmml">‚Å¢</mo><mi id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.3" mathvariant="normal" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.3.cmml">k</mi></mrow><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.10" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml">,</mo><mrow id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.cmml"><mn id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.2" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.2.cmml">16</mn><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.1" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.1.cmml">‚Å¢</mo><mi id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.3" mathvariant="normal" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.3.cmml">k</mi></mrow><mo id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.11" stretchy="false" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p2.1.1.1.1.1.1.m1.5b"><list id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.6.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5"><apply id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1"><times id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.1.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.1"></times><cn id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.2.cmml" type="integer" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.2">1</cn><ci id="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.3.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.1.1.1.1.3">k</ci></apply><apply id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2"><times id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.1.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.1"></times><cn id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.2.cmml" type="integer" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.2">2</cn><ci id="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.3.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.2.2.2.2.3">k</ci></apply><apply id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3"><times id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.1.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.1"></times><cn id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.2.cmml" type="integer" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.2">4</cn><ci id="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.3.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.3.3.3.3.3">k</ci></apply><apply id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4"><times id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.1.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.1"></times><cn id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.2.cmml" type="integer" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.2">8</cn><ci id="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.3.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.4.4.4.4.3">k</ci></apply><apply id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5"><times id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.1.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.1"></times><cn id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.2.cmml" type="integer" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.2">16</cn><ci id="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.3.cmml" xref="A7.SS5.p2.1.1.1.1.1.1.m1.5.5.5.5.3">k</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p2.1.1.1.1.1.1.m1.5c">[1\mathrm{k},2\mathrm{k},4\mathrm{k},8\mathrm{k},16\mathrm{k}]</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p2.1.1.1.1.1.1.m1.5d">[ 1 roman_k , 2 roman_k , 4 roman_k , 8 roman_k , 16 roman_k ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p2.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p2.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p2.2.2.2.2.1">
<span class="ltx_p" id="A7.SS5.p2.2.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p2.2.2.2.2.1.1.1">lr_finetune</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p2.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p2.2.2.2.1.1">
<span class="ltx_p" id="A7.SS5.p2.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="3\cdot 10^{-5}" class="ltx_Math" display="inline" id="A7.SS5.p2.2.2.2.1.1.1.m1.1"><semantics id="A7.SS5.p2.2.2.2.1.1.1.m1.1a"><mrow id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.2" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.2.cmml">3</mn><mo id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.1.cmml">‚ãÖ</mo><msup id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.cmml"><mn id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.2" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.cmml"><mo id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3a" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.2" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p2.2.2.2.1.1.1.m1.1b"><apply id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.cmml" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1"><ci id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.1">‚ãÖ</ci><cn id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.2">3</cn><apply id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.1.cmml" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3">superscript</csymbol><cn id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.2">10</cn><apply id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.cmml" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3"><minus id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.1.cmml" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3"></minus><cn id="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A7.SS5.p2.2.2.2.1.1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p2.2.2.2.1.1.1.m1.1c">3\cdot 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p2.2.2.2.1.1.1.m1.1d">3 ‚ãÖ 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p2.4.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS5.p2.4.4.4.2">Compute time: <math alttext="17" class="ltx_Math" display="inline" id="A7.SS5.p2.3.3.3.1.m1.1"><semantics id="A7.SS5.p2.3.3.3.1.m1.1a"><mn id="A7.SS5.p2.3.3.3.1.m1.1.1" xref="A7.SS5.p2.3.3.3.1.m1.1.1.cmml">17</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p2.3.3.3.1.m1.1b"><cn id="A7.SS5.p2.3.3.3.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p2.3.3.3.1.m1.1.1">17</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p2.3.3.3.1.m1.1c">17</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p2.3.3.3.1.m1.1d">17</annotation></semantics></math> hours (train) and <math alttext="95" class="ltx_Math" display="inline" id="A7.SS5.p2.4.4.4.2.m2.1"><semantics id="A7.SS5.p2.4.4.4.2.m2.1a"><mn id="A7.SS5.p2.4.4.4.2.m2.1.1" xref="A7.SS5.p2.4.4.4.2.m2.1.1.cmml">95</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p2.4.4.4.2.m2.1b"><cn id="A7.SS5.p2.4.4.4.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p2.4.4.4.2.m2.1.1">95</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p2.4.4.4.2.m2.1c">95</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p2.4.4.4.2.m2.1d">95</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p3">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS5.p3.5" style="width:400.6pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS5.p3.5.5">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS5.p3.5.5.6.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS5.p3.5.5.6.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS5.p3.5.5.6.1.1.1">Fine-tuning with replay</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#S4.F5" title="Figure 5 ‚Ä£ 4 Hallucinations hinder the integration of new knowledge post-training ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">5</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F14" title="Figure N ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">N</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS5.p3.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p3.1.1.1.2.1">
<span class="ltx_p" id="A7.SS5.p3.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p3.1.1.1.2.1.1.1">n_individuals_finetune</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p3.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p3.1.1.1.1.1">
<span class="ltx_p" id="A7.SS5.p3.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="4\mathrm{k}" class="ltx_Math" display="inline" id="A7.SS5.p3.1.1.1.1.1.1.m1.1"><semantics id="A7.SS5.p3.1.1.1.1.1.1.m1.1a"><mrow id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.2" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.2.cmml">4</mn><mo id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.1" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.3" mathvariant="normal" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p3.1.1.1.1.1.1.m1.1b"><apply id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.cmml" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1"><times id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.1"></times><cn id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.2">4</cn><ci id="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p3.1.1.1.1.1.1.m1.1.1.3">k</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p3.1.1.1.1.1.1.m1.1c">4\mathrm{k}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p3.1.1.1.1.1.1.m1.1d">4 roman_k</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p3.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p3.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p3.2.2.2.2.1">
<span class="ltx_p" id="A7.SS5.p3.2.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p3.2.2.2.2.1.1.1">weight_replay_finetune</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p3.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p3.2.2.2.1.1">
<span class="ltx_p" id="A7.SS5.p3.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[2,1,1/2,1/4,1/8,1/16,1/32]" class="ltx_Math" display="inline" id="A7.SS5.p3.2.2.2.1.1.1.m1.7"><semantics id="A7.SS5.p3.2.2.2.1.1.1.m1.7a"><mrow id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml"><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.6" stretchy="false" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">[</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.1.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.1.1.cmml">2</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.7" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">,</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.2.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.2.2.cmml">1</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.8" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">,</mo><mrow id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.cmml"><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.2.cmml">1</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.1.cmml">/</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.3" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.3.cmml">2</mn></mrow><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.9" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">,</mo><mrow id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.cmml"><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.2.cmml">1</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.1.cmml">/</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.3" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.3.cmml">4</mn></mrow><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.10" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">,</mo><mrow id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.cmml"><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.2.cmml">1</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.1.cmml">/</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.3" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.3.cmml">8</mn></mrow><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.11" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">,</mo><mrow id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.cmml"><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.2.cmml">1</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.1.cmml">/</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.3" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.3.cmml">16</mn></mrow><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.12" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">,</mo><mrow id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.cmml"><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.2" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.2.cmml">1</mn><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.1" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.1.cmml">/</mo><mn id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.3" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.3.cmml">32</mn></mrow><mo id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.13" stretchy="false" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p3.2.2.2.1.1.1.m1.7b"><list id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.6.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5"><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.1.1">2</cn><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.2.2">1</cn><apply id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1"><divide id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.1.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.1"></divide><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.2.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.2">1</cn><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.3.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.3.3.1.1.3">2</cn></apply><apply id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2"><divide id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.1.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.1"></divide><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.2.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.2">1</cn><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.3.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.4.4.2.2.3">4</cn></apply><apply id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3"><divide id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.1.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.1"></divide><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.2.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.2">1</cn><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.3.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.5.5.3.3.3">8</cn></apply><apply id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4"><divide id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.1.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.1"></divide><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.2.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.2">1</cn><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.3.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.6.6.4.4.3">16</cn></apply><apply id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5"><divide id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.1.cmml" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.1"></divide><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.2.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.2">1</cn><cn id="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.3.cmml" type="integer" xref="A7.SS5.p3.2.2.2.1.1.1.m1.7.7.5.5.3">32</cn></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p3.2.2.2.1.1.1.m1.7c">[2,1,1/2,1/4,1/8,1/16,1/32]</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p3.2.2.2.1.1.1.m1.7d">[ 2 , 1 , 1 / 2 , 1 / 4 , 1 / 8 , 1 / 16 , 1 / 32 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p3.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p3.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p3.3.3.3.2.1">
<span class="ltx_p" id="A7.SS5.p3.3.3.3.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p3.3.3.3.2.1.1.1">lr_finetune</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p3.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p3.3.3.3.1.1">
<span class="ltx_p" id="A7.SS5.p3.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="3\cdot 10^{-5}" class="ltx_Math" display="inline" id="A7.SS5.p3.3.3.3.1.1.1.m1.1"><semantics id="A7.SS5.p3.3.3.3.1.1.1.m1.1a"><mrow id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.2" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.2.cmml">3</mn><mo id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.1.cmml">‚ãÖ</mo><msup id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.cmml"><mn id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.2" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.cmml"><mo id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3a" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.2" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p3.3.3.3.1.1.1.m1.1b"><apply id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.cmml" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1"><ci id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.1">‚ãÖ</ci><cn id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.2">3</cn><apply id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.1.cmml" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3">superscript</csymbol><cn id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.2">10</cn><apply id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.cmml" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3"><minus id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.1.cmml" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3"></minus><cn id="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A7.SS5.p3.3.3.3.1.1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p3.3.3.3.1.1.1.m1.1c">3\cdot 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p3.3.3.3.1.1.1.m1.1d">3 ‚ãÖ 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p3.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS5.p3.5.5.5.2">Compute time: <math alttext="26" class="ltx_Math" display="inline" id="A7.SS5.p3.4.4.4.1.m1.1"><semantics id="A7.SS5.p3.4.4.4.1.m1.1a"><mn id="A7.SS5.p3.4.4.4.1.m1.1.1" xref="A7.SS5.p3.4.4.4.1.m1.1.1.cmml">26</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p3.4.4.4.1.m1.1b"><cn id="A7.SS5.p3.4.4.4.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p3.4.4.4.1.m1.1.1">26</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p3.4.4.4.1.m1.1c">26</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p3.4.4.4.1.m1.1d">26</annotation></semantics></math> hours (train) and <math alttext="174" class="ltx_Math" display="inline" id="A7.SS5.p3.5.5.5.2.m2.1"><semantics id="A7.SS5.p3.5.5.5.2.m2.1a"><mn id="A7.SS5.p3.5.5.5.2.m2.1.1" xref="A7.SS5.p3.5.5.5.2.m2.1.1.cmml">174</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p3.5.5.5.2.m2.1b"><cn id="A7.SS5.p3.5.5.5.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p3.5.5.5.2.m2.1.1">174</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p3.5.5.5.2.m2.1c">174</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p3.5.5.5.2.m2.1d">174</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p4">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS5.p4.7" style="width:400.6pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS5.p4.7.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS5.p4.7.7.8.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS5.p4.7.7.8.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS5.p4.7.7.8.1.1.1">Fine-tuning on celebrities</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F16" title="Figure P ‚Ä£ F.3 Additional analysis for fine-tuning ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">P</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS5.p4.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p4.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.1.1.1.2.1">
<span class="ltx_p" id="A7.SS5.p4.1.1.1.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p4.1.1.1.2.1.1.1">n_individuals</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p4.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.1.1.1.1.1">
<span class="ltx_p" id="A7.SS5.p4.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="128\mathrm{k}" class="ltx_Math" display="inline" id="A7.SS5.p4.1.1.1.1.1.1.m1.1"><semantics id="A7.SS5.p4.1.1.1.1.1.1.m1.1a"><mrow id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.2" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.2.cmml">128</mn><mo id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.1" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.3" mathvariant="normal" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.1.1.1.1.1.1.m1.1b"><apply id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.cmml" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1"><times id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.1"></times><cn id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.2">128</cn><ci id="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p4.1.1.1.1.1.1.m1.1.1.3">k</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.1.1.1.1.1.1.m1.1c">128\mathrm{k}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.1.1.1.1.1.1.m1.1d">128 roman_k</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p4.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.2.2.2.2.1">
<span class="ltx_p" id="A7.SS5.p4.2.2.2.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p4.2.2.2.2.1.1.1">training_steps</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.2.2.2.1.1">
<span class="ltx_p" id="A7.SS5.p4.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="16\mathrm{k}" class="ltx_Math" display="inline" id="A7.SS5.p4.2.2.2.1.1.1.m1.1"><semantics id="A7.SS5.p4.2.2.2.1.1.1.m1.1a"><mrow id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.2" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.2.cmml">16</mn><mo id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.1" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.3" mathvariant="normal" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.2.2.2.1.1.1.m1.1b"><apply id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.cmml" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1"><times id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.1"></times><cn id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.2">16</cn><ci id="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p4.2.2.2.1.1.1.m1.1.1.3">k</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.2.2.2.1.1.1.m1.1c">16\mathrm{k}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.2.2.2.1.1.1.m1.1d">16 roman_k</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p4.7.7.9.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.7.7.9.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.7.7.9.1.1.1">
<span class="ltx_p" id="A7.SS5.p4.7.7.9.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p4.7.7.9.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.7.7.9.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.7.7.9.1.2.1">
<span class="ltx_p" id="A7.SS5.p4.7.7.9.1.2.1.1" style="width:227.6pt;">Celebrities</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p4.3.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.3.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.3.3.3.2.1">
<span class="ltx_p" id="A7.SS5.p4.3.3.3.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS5.p4.3.3.3.2.1.1.1">n_celebrities</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.3.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.3.3.3.1.1">
<span class="ltx_p" id="A7.SS5.p4.3.3.3.1.1.1" style="width:227.6pt;"><math alttext="8\mathrm{k}" class="ltx_Math" display="inline" id="A7.SS5.p4.3.3.3.1.1.1.m1.1"><semantics id="A7.SS5.p4.3.3.3.1.1.1.m1.1a"><mrow id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.2" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.2.cmml">8</mn><mo id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.1" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.1.cmml">‚Å¢</mo><mi id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.3" mathvariant="normal" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.3.3.3.1.1.1.m1.1b"><apply id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.cmml" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1"><times id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.1"></times><cn id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.2">8</cn><ci id="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p4.3.3.3.1.1.1.m1.1.1.3">k</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.3.3.3.1.1.1.m1.1c">8\mathrm{k}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.3.3.3.1.1.1.m1.1d">8 roman_k</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p4.4.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.4.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.4.4.4.2.1">
<span class="ltx_p" id="A7.SS5.p4.4.4.4.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS5.p4.4.4.4.2.1.1.1">weight_celebrities</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.4.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.4.4.4.1.1">
<span class="ltx_p" id="A7.SS5.p4.4.4.4.1.1.1" style="width:227.6pt;"><math alttext="8" class="ltx_Math" display="inline" id="A7.SS5.p4.4.4.4.1.1.1.m1.1"><semantics id="A7.SS5.p4.4.4.4.1.1.1.m1.1a"><mn id="A7.SS5.p4.4.4.4.1.1.1.m1.1.1" xref="A7.SS5.p4.4.4.4.1.1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.4.4.4.1.1.1.m1.1b"><cn id="A7.SS5.p4.4.4.4.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p4.4.4.4.1.1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.4.4.4.1.1.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.4.4.4.1.1.1.m1.1d">8</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p4.5.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.5.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.5.5.5.2.1">
<span class="ltx_p" id="A7.SS5.p4.5.5.5.2.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p4.5.5.5.2.1.1.1">lr_finetune</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p4.5.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p4.5.5.5.1.1">
<span class="ltx_p" id="A7.SS5.p4.5.5.5.1.1.1" style="width:227.6pt;"><math alttext="3\cdot 10^{-5}" class="ltx_Math" display="inline" id="A7.SS5.p4.5.5.5.1.1.1.m1.1"><semantics id="A7.SS5.p4.5.5.5.1.1.1.m1.1a"><mrow id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.cmml"><mn id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.2" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.2.cmml">3</mn><mo id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.1.cmml">‚ãÖ</mo><msup id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.cmml"><mn id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.2" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.2.cmml">10</mn><mrow id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.cmml"><mo id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3a" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.cmml">‚àí</mo><mn id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.2" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.5.5.5.1.1.1.m1.1b"><apply id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.cmml" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1"><ci id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.1.cmml" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.1">‚ãÖ</ci><cn id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.2.cmml" type="integer" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.2">3</cn><apply id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.cmml" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3"><csymbol cd="ambiguous" id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.1.cmml" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3">superscript</csymbol><cn id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.2">10</cn><apply id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.cmml" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3"><minus id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.1.cmml" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3"></minus><cn id="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A7.SS5.p4.5.5.5.1.1.1.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.5.5.5.1.1.1.m1.1c">3\cdot 10^{-5}</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.5.5.5.1.1.1.m1.1d">3 ‚ãÖ 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p4.7.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS5.p4.7.7.7.2">Compute time: <math alttext="6" class="ltx_Math" display="inline" id="A7.SS5.p4.6.6.6.1.m1.1"><semantics id="A7.SS5.p4.6.6.6.1.m1.1a"><mn id="A7.SS5.p4.6.6.6.1.m1.1.1" xref="A7.SS5.p4.6.6.6.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.6.6.6.1.m1.1b"><cn id="A7.SS5.p4.6.6.6.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p4.6.6.6.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.6.6.6.1.m1.1c">6</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.6.6.6.1.m1.1d">6</annotation></semantics></math> hours (train) and <math alttext="48" class="ltx_Math" display="inline" id="A7.SS5.p4.7.7.7.2.m2.1"><semantics id="A7.SS5.p4.7.7.7.2.m2.1a"><mn id="A7.SS5.p4.7.7.7.2.m2.1.1" xref="A7.SS5.p4.7.7.7.2.m2.1.1.cmml">48</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p4.7.7.7.2.m2.1b"><cn id="A7.SS5.p4.7.7.7.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p4.7.7.7.2.m2.1.1">48</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p4.7.7.7.2.m2.1c">48</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p4.7.7.7.2.m2.1d">48</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p5">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS5.p5.13" style="width:400.6pt;height:144pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS5.p5.13.13">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS5.p5.13.13.14.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS5.p5.13.13.14.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS5.p5.13.13.14.1.1.1">Sequential learning with new groups</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F19" title="Figure S ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">S</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F20" title="Figure T ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">T</span></a> (and <a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F21" title="Figure U ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">U</span></a>))</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS5.p5.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p5.2.2.2.3">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.2.2.2.3.1">
<span class="ltx_p" id="A7.SS5.p5.2.2.2.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p5.2.2.2.3.1.1.1">n_individuals</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p5.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.2.2.2.2.2">
<span class="ltx_p" id="A7.SS5.p5.2.2.2.2.2.2" style="width:227.6pt;"><math alttext="64" class="ltx_Math" display="inline" id="A7.SS5.p5.1.1.1.1.1.1.m1.1"><semantics id="A7.SS5.p5.1.1.1.1.1.1.m1.1a"><mn id="A7.SS5.p5.1.1.1.1.1.1.m1.1.1" xref="A7.SS5.p5.1.1.1.1.1.1.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.1.1.1.1.1.1.m1.1b"><cn id="A7.SS5.p5.1.1.1.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p5.1.1.1.1.1.1.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.1.1.1.1.1.1.m1.1c">64</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.1.1.1.1.1.1.m1.1d">64</annotation></semantics></math>k (<math alttext="256" class="ltx_Math" display="inline" id="A7.SS5.p5.2.2.2.2.2.2.m2.1"><semantics id="A7.SS5.p5.2.2.2.2.2.2.m2.1a"><mn id="A7.SS5.p5.2.2.2.2.2.2.m2.1.1" xref="A7.SS5.p5.2.2.2.2.2.2.m2.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.2.2.2.2.2.2.m2.1b"><cn id="A7.SS5.p5.2.2.2.2.2.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p5.2.2.2.2.2.2.m2.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.2.2.2.2.2.2.m2.1c">256</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.2.2.2.2.2.2.m2.1d">256</annotation></semantics></math>k)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p5.4.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.4.4.4.3">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.4.4.4.3.1">
<span class="ltx_p" id="A7.SS5.p5.4.4.4.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p5.4.4.4.3.1.1.1">training_steps</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.4.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.4.4.4.2.2">
<span class="ltx_p" id="A7.SS5.p5.4.4.4.2.2.2" style="width:227.6pt;"><math alttext="16" class="ltx_Math" display="inline" id="A7.SS5.p5.3.3.3.1.1.1.m1.1"><semantics id="A7.SS5.p5.3.3.3.1.1.1.m1.1a"><mn id="A7.SS5.p5.3.3.3.1.1.1.m1.1.1" xref="A7.SS5.p5.3.3.3.1.1.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.3.3.3.1.1.1.m1.1b"><cn id="A7.SS5.p5.3.3.3.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p5.3.3.3.1.1.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.3.3.3.1.1.1.m1.1c">16</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.3.3.3.1.1.1.m1.1d">16</annotation></semantics></math>k (<math alttext="64" class="ltx_Math" display="inline" id="A7.SS5.p5.4.4.4.2.2.2.m2.1"><semantics id="A7.SS5.p5.4.4.4.2.2.2.m2.1a"><mn id="A7.SS5.p5.4.4.4.2.2.2.m2.1.1" xref="A7.SS5.p5.4.4.4.2.2.2.m2.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.4.4.4.2.2.2.m2.1b"><cn id="A7.SS5.p5.4.4.4.2.2.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p5.4.4.4.2.2.2.m2.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.4.4.4.2.2.2.m2.1c">64</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.4.4.4.2.2.2.m2.1d">64</annotation></semantics></math>k)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p5.6.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.6.6.6.3">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.6.6.6.3.1">
<span class="ltx_p" id="A7.SS5.p5.6.6.6.3.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p5.6.6.6.3.1.1.1">lr_scheduler</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.6.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.6.6.6.2.2">
<span class="ltx_p" id="A7.SS5.p5.6.6.6.2.2.2" style="width:227.6pt;"><math alttext="[" class="ltx_Math" display="inline" id="A7.SS5.p5.5.5.5.1.1.1.m1.1"><semantics id="A7.SS5.p5.5.5.5.1.1.1.m1.1a"><mo id="A7.SS5.p5.5.5.5.1.1.1.m1.1.1" stretchy="false" xref="A7.SS5.p5.5.5.5.1.1.1.m1.1.1.cmml">[</mo><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.5.5.5.1.1.1.m1.1b"><ci id="A7.SS5.p5.5.5.5.1.1.1.m1.1.1.cmml" xref="A7.SS5.p5.5.5.5.1.1.1.m1.1.1">[</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.5.5.5.1.1.1.m1.1c">[</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.5.5.5.1.1.1.m1.1d">[</annotation></semantics></math>cosine, constant<math alttext="]" class="ltx_Math" display="inline" id="A7.SS5.p5.6.6.6.2.2.2.m2.1"><semantics id="A7.SS5.p5.6.6.6.2.2.2.m2.1a"><mo id="A7.SS5.p5.6.6.6.2.2.2.m2.1.1" stretchy="false" xref="A7.SS5.p5.6.6.6.2.2.2.m2.1.1.cmml">]</mo><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.6.6.6.2.2.2.m2.1b"><ci id="A7.SS5.p5.6.6.6.2.2.2.m2.1.1.cmml" xref="A7.SS5.p5.6.6.6.2.2.2.m2.1.1">]</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.6.6.6.2.2.2.m2.1c">]</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.6.6.6.2.2.2.m2.1d">]</annotation></semantics></math> (cosine)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p5.13.13.15.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.13.13.15.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.13.13.15.1.1.1">
<span class="ltx_p" id="A7.SS5.p5.13.13.15.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p5.13.13.15.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.13.13.15.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.13.13.15.1.2.1">
<span class="ltx_p" id="A7.SS5.p5.13.13.15.1.2.1.1" style="width:227.6pt;">Sequential</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p5.8.8.8">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.8.8.8.3">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.8.8.8.3.1">
<span class="ltx_p" id="A7.SS5.p5.8.8.8.3.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS5.p5.8.8.8.3.1.1.1">n_groups</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.8.8.8.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.8.8.8.2.2">
<span class="ltx_p" id="A7.SS5.p5.8.8.8.2.2.2" style="width:227.6pt;"><math alttext="[4,8,16]" class="ltx_Math" display="inline" id="A7.SS5.p5.7.7.7.1.1.1.m1.3"><semantics id="A7.SS5.p5.7.7.7.1.1.1.m1.3a"><mrow id="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.2" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.1.cmml"><mo id="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.2.1" stretchy="false" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.1.cmml">[</mo><mn id="A7.SS5.p5.7.7.7.1.1.1.m1.1.1" xref="A7.SS5.p5.7.7.7.1.1.1.m1.1.1.cmml">4</mn><mo id="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.2.2" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.1.cmml">,</mo><mn id="A7.SS5.p5.7.7.7.1.1.1.m1.2.2" xref="A7.SS5.p5.7.7.7.1.1.1.m1.2.2.cmml">8</mn><mo id="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.2.3" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.1.cmml">,</mo><mn id="A7.SS5.p5.7.7.7.1.1.1.m1.3.3" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.3.cmml">16</mn><mo id="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.2.4" stretchy="false" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.7.7.7.1.1.1.m1.3b"><list id="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.1.cmml" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.4.2"><cn id="A7.SS5.p5.7.7.7.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p5.7.7.7.1.1.1.m1.1.1">4</cn><cn id="A7.SS5.p5.7.7.7.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS5.p5.7.7.7.1.1.1.m1.2.2">8</cn><cn id="A7.SS5.p5.7.7.7.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS5.p5.7.7.7.1.1.1.m1.3.3">16</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.7.7.7.1.1.1.m1.3c">[4,8,16]</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.7.7.7.1.1.1.m1.3d">[ 4 , 8 , 16 ]</annotation></semantics></math> (<math alttext="32" class="ltx_Math" display="inline" id="A7.SS5.p5.8.8.8.2.2.2.m2.1"><semantics id="A7.SS5.p5.8.8.8.2.2.2.m2.1a"><mn id="A7.SS5.p5.8.8.8.2.2.2.m2.1.1" xref="A7.SS5.p5.8.8.8.2.2.2.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.8.8.8.2.2.2.m2.1b"><cn id="A7.SS5.p5.8.8.8.2.2.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p5.8.8.8.2.2.2.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.8.8.8.2.2.2.m2.1c">32</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.8.8.8.2.2.2.m2.1d">32</annotation></semantics></math>)</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p5.9.9.9">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.9.9.9.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.9.9.9.2.1">
<span class="ltx_p" id="A7.SS5.p5.9.9.9.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS5.p5.9.9.9.2.1.1.1">n_repeats</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p5.9.9.9.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p5.9.9.9.1.1">
<span class="ltx_p" id="A7.SS5.p5.9.9.9.1.1.1" style="width:227.6pt;"><math alttext="1" class="ltx_Math" display="inline" id="A7.SS5.p5.9.9.9.1.1.1.m1.1"><semantics id="A7.SS5.p5.9.9.9.1.1.1.m1.1a"><mn id="A7.SS5.p5.9.9.9.1.1.1.m1.1.1" xref="A7.SS5.p5.9.9.9.1.1.1.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.9.9.9.1.1.1.m1.1b"><cn id="A7.SS5.p5.9.9.9.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p5.9.9.9.1.1.1.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.9.9.9.1.1.1.m1.1c">1</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.9.9.9.1.1.1.m1.1d">1</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p5.13.13.13">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS5.p5.13.13.13.4">Compute time: <math alttext="26" class="ltx_Math" display="inline" id="A7.SS5.p5.10.10.10.1.m1.1"><semantics id="A7.SS5.p5.10.10.10.1.m1.1a"><mn id="A7.SS5.p5.10.10.10.1.m1.1.1" xref="A7.SS5.p5.10.10.10.1.m1.1.1.cmml">26</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.10.10.10.1.m1.1b"><cn id="A7.SS5.p5.10.10.10.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p5.10.10.10.1.m1.1.1">26</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.10.10.10.1.m1.1c">26</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.10.10.10.1.m1.1d">26</annotation></semantics></math> (<math alttext="+13" class="ltx_Math" display="inline" id="A7.SS5.p5.11.11.11.2.m2.1"><semantics id="A7.SS5.p5.11.11.11.2.m2.1a"><mrow id="A7.SS5.p5.11.11.11.2.m2.1.1" xref="A7.SS5.p5.11.11.11.2.m2.1.1.cmml"><mo id="A7.SS5.p5.11.11.11.2.m2.1.1a" xref="A7.SS5.p5.11.11.11.2.m2.1.1.cmml">+</mo><mn id="A7.SS5.p5.11.11.11.2.m2.1.1.2" xref="A7.SS5.p5.11.11.11.2.m2.1.1.2.cmml">13</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.11.11.11.2.m2.1b"><apply id="A7.SS5.p5.11.11.11.2.m2.1.1.cmml" xref="A7.SS5.p5.11.11.11.2.m2.1.1"><plus id="A7.SS5.p5.11.11.11.2.m2.1.1.1.cmml" xref="A7.SS5.p5.11.11.11.2.m2.1.1"></plus><cn id="A7.SS5.p5.11.11.11.2.m2.1.1.2.cmml" type="integer" xref="A7.SS5.p5.11.11.11.2.m2.1.1.2">13</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.11.11.11.2.m2.1c">+13</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.11.11.11.2.m2.1d">+ 13</annotation></semantics></math>) hours (train) and <math alttext="78" class="ltx_Math" display="inline" id="A7.SS5.p5.12.12.12.3.m3.1"><semantics id="A7.SS5.p5.12.12.12.3.m3.1a"><mn id="A7.SS5.p5.12.12.12.3.m3.1.1" xref="A7.SS5.p5.12.12.12.3.m3.1.1.cmml">78</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.12.12.12.3.m3.1b"><cn id="A7.SS5.p5.12.12.12.3.m3.1.1.cmml" type="integer" xref="A7.SS5.p5.12.12.12.3.m3.1.1">78</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.12.12.12.3.m3.1c">78</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.12.12.12.3.m3.1d">78</annotation></semantics></math> (<math alttext="+432" class="ltx_Math" display="inline" id="A7.SS5.p5.13.13.13.4.m4.1"><semantics id="A7.SS5.p5.13.13.13.4.m4.1a"><mrow id="A7.SS5.p5.13.13.13.4.m4.1.1" xref="A7.SS5.p5.13.13.13.4.m4.1.1.cmml"><mo id="A7.SS5.p5.13.13.13.4.m4.1.1a" xref="A7.SS5.p5.13.13.13.4.m4.1.1.cmml">+</mo><mn id="A7.SS5.p5.13.13.13.4.m4.1.1.2" xref="A7.SS5.p5.13.13.13.4.m4.1.1.2.cmml">432</mn></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p5.13.13.13.4.m4.1b"><apply id="A7.SS5.p5.13.13.13.4.m4.1.1.cmml" xref="A7.SS5.p5.13.13.13.4.m4.1.1"><plus id="A7.SS5.p5.13.13.13.4.m4.1.1.1.cmml" xref="A7.SS5.p5.13.13.13.4.m4.1.1"></plus><cn id="A7.SS5.p5.13.13.13.4.m4.1.1.2.cmml" type="integer" xref="A7.SS5.p5.13.13.13.4.m4.1.1.2">432</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p5.13.13.13.4.m4.1c">+432</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p5.13.13.13.4.m4.1d">+ 432</annotation></semantics></math>) hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p6">
<div class="ltx_inline-block ltx_transformed_outer" id="A7.SS5.p6.4" style="width:400.6pt;height:90pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1.0,1.0) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A7.SS5.p6.4.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.SS5.p6.4.4.5.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" colspan="2" id="A7.SS5.p6.4.4.5.1.1">
<span class="ltx_text ltx_font_bold" id="A7.SS5.p6.4.4.5.1.1.1">Sequential learning with alternating groups</span> (Figure¬†<a class="ltx_ref" href="https://arxiv.org/html/2503.21676v2#A6.F22" title="Figure V ‚Ä£ F.5 Experiments with regular changes in training distribution ‚Ä£ Appendix F Details of the fine-tuning analysis and additional experiments (Section 4) ‚Ä£ Appendix ‚Ä£ How do language models learn facts? Dynamics, curricula and hallucinations"><span class="ltx_text ltx_ref_tag">V</span></a>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.SS5.p6.4.4.6.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p6.4.4.6.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p6.4.4.6.1.1.1">
<span class="ltx_p" id="A7.SS5.p6.4.4.6.1.1.1.1" style="width:142.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SS5.p6.4.4.6.1.1.1.1.1">indiv_dist_train</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A7.SS5.p6.4.4.6.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p6.4.4.6.1.2.1">
<span class="ltx_p" id="A7.SS5.p6.4.4.6.1.2.1.1" style="width:227.6pt;">Sequential</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p6.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p6.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p6.1.1.1.2.1">
<span class="ltx_p" id="A7.SS5.p6.1.1.1.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS5.p6.1.1.1.2.1.1.1">n_groups</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p6.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p6.1.1.1.1.1">
<span class="ltx_p" id="A7.SS5.p6.1.1.1.1.1.1" style="width:227.6pt;"><math alttext="2" class="ltx_Math" display="inline" id="A7.SS5.p6.1.1.1.1.1.1.m1.1"><semantics id="A7.SS5.p6.1.1.1.1.1.1.m1.1a"><mn id="A7.SS5.p6.1.1.1.1.1.1.m1.1.1" xref="A7.SS5.p6.1.1.1.1.1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p6.1.1.1.1.1.1.m1.1b"><cn id="A7.SS5.p6.1.1.1.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p6.1.1.1.1.1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p6.1.1.1.1.1.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p6.1.1.1.1.1.1.m1.1d">2</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p6.2.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p6.2.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p6.2.2.2.2.1">
<span class="ltx_p" id="A7.SS5.p6.2.2.2.2.1.1" style="width:142.3pt;">¬†¬†¬†- <span class="ltx_text ltx_font_typewriter" id="A7.SS5.p6.2.2.2.2.1.1.1">n_repeats</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A7.SS5.p6.2.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A7.SS5.p6.2.2.2.1.1">
<span class="ltx_p" id="A7.SS5.p6.2.2.2.1.1.1" style="width:227.6pt;"><math alttext="[2,4,8]" class="ltx_Math" display="inline" id="A7.SS5.p6.2.2.2.1.1.1.m1.3"><semantics id="A7.SS5.p6.2.2.2.1.1.1.m1.3a"><mrow id="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.2" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.1.cmml"><mo id="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.2.1" stretchy="false" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.1.cmml">[</mo><mn id="A7.SS5.p6.2.2.2.1.1.1.m1.1.1" xref="A7.SS5.p6.2.2.2.1.1.1.m1.1.1.cmml">2</mn><mo id="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.2.2" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.1.cmml">,</mo><mn id="A7.SS5.p6.2.2.2.1.1.1.m1.2.2" xref="A7.SS5.p6.2.2.2.1.1.1.m1.2.2.cmml">4</mn><mo id="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.2.3" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.1.cmml">,</mo><mn id="A7.SS5.p6.2.2.2.1.1.1.m1.3.3" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.3.cmml">8</mn><mo id="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.2.4" stretchy="false" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A7.SS5.p6.2.2.2.1.1.1.m1.3b"><list id="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.1.cmml" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.4.2"><cn id="A7.SS5.p6.2.2.2.1.1.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p6.2.2.2.1.1.1.m1.1.1">2</cn><cn id="A7.SS5.p6.2.2.2.1.1.1.m1.2.2.cmml" type="integer" xref="A7.SS5.p6.2.2.2.1.1.1.m1.2.2">4</cn><cn id="A7.SS5.p6.2.2.2.1.1.1.m1.3.3.cmml" type="integer" xref="A7.SS5.p6.2.2.2.1.1.1.m1.3.3">8</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p6.2.2.2.1.1.1.m1.3c">[2,4,8]</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p6.2.2.2.1.1.1.m1.3d">[ 2 , 4 , 8 ]</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A7.SS5.p6.4.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" colspan="2" id="A7.SS5.p6.4.4.4.2">Compute time: <math alttext="10" class="ltx_Math" display="inline" id="A7.SS5.p6.3.3.3.1.m1.1"><semantics id="A7.SS5.p6.3.3.3.1.m1.1a"><mn id="A7.SS5.p6.3.3.3.1.m1.1.1" xref="A7.SS5.p6.3.3.3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p6.3.3.3.1.m1.1b"><cn id="A7.SS5.p6.3.3.3.1.m1.1.1.cmml" type="integer" xref="A7.SS5.p6.3.3.3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p6.3.3.3.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p6.3.3.3.1.m1.1d">10</annotation></semantics></math> hours (train) and <math alttext="39" class="ltx_Math" display="inline" id="A7.SS5.p6.4.4.4.2.m2.1"><semantics id="A7.SS5.p6.4.4.4.2.m2.1a"><mn id="A7.SS5.p6.4.4.4.2.m2.1.1" xref="A7.SS5.p6.4.4.4.2.m2.1.1.cmml">39</mn><annotation-xml encoding="MathML-Content" id="A7.SS5.p6.4.4.4.2.m2.1b"><cn id="A7.SS5.p6.4.4.4.2.m2.1.1.cmml" type="integer" xref="A7.SS5.p6.4.4.4.2.m2.1.1">39</cn></annotation-xml><annotation encoding="application/x-tex" id="A7.SS5.p6.4.4.4.2.m2.1c">39</annotation><annotation encoding="application/x-llamapun" id="A7.SS5.p6.4.4.4.2.m2.1d">39</annotation></semantics></math> hours (eval).</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<div class="ltx_para ltx_noindent ltx_align_center" id="A7.SS5.p7">
<p class="ltx_p" id="A7.SS5.p7.1"><span class="ltx_text ltx_phantom" id="A7.SS5.p7.1.1"><span style="visibility:hidden">XX</span></span></p>
</div>
</section>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Jul 24 12:00:16 2025 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
